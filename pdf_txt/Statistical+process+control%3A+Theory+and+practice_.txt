K12137A major tool for quality control and management, statistical process 
control (SPC) monitors sequential processes, such as production lines and 
Internet traffic, to ensure that they work stably and satisfactorily. Along 
with covering traditional methods, Introduction to Statistical Process 
Control  describes many recent SPC methods that improve upon the more 
established techniques. The author—a leading researcher on SPC—shows 
how these methods can handle new applications.
After exploring the role of SPC and other statistical methods in quality 
control and management, the book covers basic statistical concepts and 
methods useful in SPC. It then systematically describes traditional SPC 
charts, including the Shewhart, CUSUM, and EWMA charts, as well as 
recent control charts based on change-point detection and fundamental 
multivariate SPC charts under the normality assumption. The text also 
introduces novel univariate and multivariate control charts for cases when 
the normality assumption is invalid and discusses control charts for profile 
monitoring. All computations in the examples are solved using R, with R 
functions and datasets available for download on the author’s website. 
Features
• Explores the major advantages and limitations of both traditional and 
state-of-the-art SPC methods
• Offers practical guidelines on implementing the techniques
• Examines the most recent research results in various areas, including 
univariate and multivariate nonparametric SPC, SPC based on 
change-point detection, and profile monitoring
• Keeps the mathematical and statistical prerequisites to a minimum, 
only requiring basic linear algebra, some calculus, and introductory 
statistics
• Provides more advanced or technical material in discussions at the 
end of each chapter, along with exercises that encourage hands-on 
practice with the methods
• Presents pseudo codes for important methodsPeihua Qiu
QiuIntroduction to
Statistical 
Process Control
Introduction to  
Statistical Process ControlStatisticsTexts in Statistical Science
K12137_Cover.indd   1 9/9/13   10:26 AMIntroduction to
Statistical 
Process ControlCHAPMAN & HALL/CRC  
Texts in Statistical Science Series
Series Editors
Francesca Dominici, Harvard School of Public Health, USA
Julian J. Faraway, University of Bath, UK
Martin Tanner, Northwestern University, USA
Jim Zidek, University of British Columbia, Canada
Analysis of Failure and Survival Data
P . J. Smith
The Analysis of Time Series: An Introduction, 
Sixth Edition
C. Chatfield
Applied Bayesian Forecasting and Time Series 
Analysis
A. Pole, M. West, and J. Harrison
Applied Categorical and Count Data Analysis  
W. Tang, H. He, and X.M. Tu 
Applied Nonparametric Statistical Methods,  
Fourth Edition 
P . Sprent and N.C. Smeeton
Applied Statistics: Handbook of GENST AT 
Analyses 
E.J. Snell and H. Simpson 
Applied Statistics: Principles and Examples 
D.R. Cox and E.J. Snell
Applied Stochastic Modelling, Second Edition 
B.J.T. Morgan
Bayesian Data Analysis,  Third Edition 
A. Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson,  
A. Vehtari, and D.B. Rubin
Bayesian Ideas and Data Analysis: An 
Introduction for Scientists and Statisticians 
R. Christensen, W. Johnson, A. Branscum,  
and T.E. Hanson
Bayesian Methods for Data Analysis,  
Third Edition 
B.P . Carlin and T.A. Louis
Beyond ANOVA: Basics of Applied Statistics 
R.G. Miller, Jr.
The BUGS Book: A Practical Introduction to 
Bayesian Analysis  
D. Lunn, C. Jackson, N. Best, A. Thomas, and  
D. Spiegelhalter
A Course in Categorical Data Analysis
T. Leonard
A Course in Large Sample Theory
T.S. FergusonData Driven Statistical Methods 
P . Sprent 
Decision Analysis: A Bayesian Approach
J.Q. Smith
Design and Analysis of Experiments with SAS
J. Lawson
Elementary Applications of Probability Theory, 
Second Edition 
H.C. Tuckwell
Elements of Simulation 
B.J.T. Morgan
Epidemiology: Study Design and  
Data Analysis, Third Edition
M. Woodward
Essential Statistics, Fourth Edition 
D.A.G. Rees
Exercises and Solutions in Statistical Theory
L.L. Kupper, B.H. Neelon, and S.M. O’Brien
Exercises and Solutions in Biostatistical Theory
L.L. Kupper, B.H. Neelon, and S.M. O’Brien
Extending the Linear Model with R: 
Generalized Linear, Mixed Effects and 
Nonparametric Regression Models
J.J. Faraway
A First Course in Linear Model Theory
N. Ravishanker and D.K. Dey
Generalized Additive Models:  
An Introduction with R
S. Wood
Generalized Linear Mixed Models:  
Modern Concepts, Methods and Applications
W. W. Stroup
Graphics for Statistics and Data Analysis with R
K.J. Keen
Interpreting Data: A First Course  
in Statistics
A.J.B. Anderson
Introduction to General and Generalized  
Linear Models
H. Madsen and P . ThyregodAn Introduction to Generalized  
Linear Models, Third Edition
A.J. Dobson and A.G. Barnett
Introduction to Multivariate Analysis 
C. Chatfield and A.J. Collins
Introduction to Optimization Methods and 
Their Applications in Statistics 
B.S. Everitt
Introduction to Probability with R 
K. Baclawski
Introduction to Randomized Controlled 
Clinical Trials, Second Edition 
J.N.S. Matthews
Introduction to Statistical Inference and Its 
Applications with R 
M.W. Trosset 
Introduction to Statistical Limit Theory
A.M. Polansky
Introduction to Statistical Methods for  
Clinical Trials 
T.D. Cook and D.L. DeMets 
Introduction to Statistical Process Control 
P . Qiu 
Introduction to the Theory of Statistical 
Inference 
H. Liero and S. Zwanzig
Large Sample Methods in Statistics
P .K. Sen and J. da Motta Singer
Linear Algebra and Matrix Analysis for 
Statistics
S. Banerjee and A. Roy
Logistic Regression Models 
J.M. Hilbe 
Markov Chain Monte Carlo:  
Stochastic Simulation for Bayesian Inference, 
Second Edition
D. Gamerman and H.F. Lopes
Mathematical Statistics 
K. Knight 
Modeling and Analysis of Stochastic Systems, 
Second Edition
V.G. Kulkarni
Modelling Binary Data, Second Edition
D. Collett
Modelling Survival Data in Medical Research, 
Second Edition
D. CollettMultivariate Analysis of  Variance and 
Repeated Measures: A Practical Approach for 
Behavioural Scientists
D.J. Hand and C.C. Taylor
Multivariate Statistics: A Practical Approach
B. Flury and H. Riedwyl
Multivariate Survival Analysis and Competing 
Risks
M. Crowder
Nonparametric Methods in Statistics with SAS 
Applications
O. Korosteleva
Pólya Urn Models
H. Mahmoud
Practical Data Analysis for Designed 
Experiments
B.S. Yandell
Practical Longitudinal Data Analysis
D.J. Hand and M. Crowder
Practical Multivariate Analysis, Fifth Edition
A. Afifi, S. May, and V.A. Clark
Practical Statistics for Medical Research
D.G. Altman
A Primer on Linear Models
J.F. Monahan
Principles of Uncertainty
J.B. Kadane
Probability: Methods and Measurement
A. O’Hagan
Problem Solving: A Statistician’s Guide,  
Second Edition 
C. Chatfield
Randomization, Bootstrap and Monte Carlo 
Methods in Biology, Third Edition 
B.F.J. Manly
Readings in Decision Analysis 
S. French
Sampling Methodologies with Applications 
P .S.R.S. Rao
Stationary Stochastic Processes: Theory and 
Applications 
G. Lindgren
Statistical Analysis of Reliability Data
M.J. Crowder, A.C. Kimber,  
T.J. Sweeting, and R.L. Smith
Statistical Methods for Spatial Data Analysis
O. Schabenberger and C.A. GotwayStatistical Methods for SPC and TQM
D. Bissell
Statistical Methods in Agriculture and 
Experimental Biology,  Second Edition
R. Mead, R.N. Curnow, and A.M. Hasted
Statistical Process Control: Theory and 
Practice, Third Edition 
G.B. Wetherill and D.W. Brown
Statistical Theory: A Concise Introduction 
F. Abramovich and Y. Ritov 
Statistical Theory, Fourth Edition
B.W. Lindgren 
Statistics for Accountants
S. Letchford
Statistics for Epidemiology 
N.P . Jewell
Statistics for Technology: A Course in Applied 
Statistics, Third Edition
C. Chatfield
Statistics in Engineering: A Practical Approach
A.V. MetcalfeStatistics in Research and Development,  
Second Edition
R. Caulcutt
Stochastic Processes: An Introduction,  
Second Edition
P .W. Jones and P . Smith 
Survival Analysis Using S: Analysis of  
Time-to-Event Data
M. Tableman and J.S. Kim
The Theory of Linear Models
B. Jørgensen
Time Series Analysis
H. Madsen
Time Series: Modeling, Computation, and 
Inference
R. Prado and M. West
Understanding Advanced Statistical Methods
P .H. Westfall and K.S.S. HenningTexts in Statistical Science
Peihua Qiu
Department of Biostatistics
University of Florida, USAIntroduction to
Statistical 
Process ControlCRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2014 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Version Date: 20130703
International Standard Book Number-13: 978-1-4822-2041-4 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts 
have been made to publish reliable data and information, but the author and publisher cannot assume 
responsibility for the validity of all materials or the consequences of their use. The authors and publishers 
have attempted to trace the copyright holders of all material reproduced in this publication and apologize to 
copyright holders if permission to publish in this form has not been obtained. If any copyright material has 
not been acknowledged please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmit -
ted, or utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, 
including photocopying, microfilming, and recording, or in any information storage or retrieval system, 
without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.
com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood 
Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that provides licenses and 
registration for a variety of users. For organizations that have been granted a photocopy license by the CCC, 
a separate system of payment has been arranged.
Trademark Notice:  Product or corporate names may be trademarks or registered trademarks, and are used 
only for identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.comvii
To the memory of my motherContents
List of Figures xv
List of T ables xxix
Preface xxxv
1 Introduction 1
1.1 Quality and the Early History of Quality Improvement 1
1.2 Quality Management 3
1.3 Statistical Process Control 6
1.4 Organization of the Book 8
1.5 Exercises 9
2 Basic Statistical Concepts and Methods 11
2.1 Introduction 11
2.2 Population and Population Distribution 11
2.3 Important Continuous Distributions 14
2.3.1 Normal distribution 15
2.3.2 Chi-square distribution 15
2.3.3 tdistribution 16
2.3.4 Fdistribution 18
2.3.5 Weibull distribution and exponential distribution 18
2.4 Important Discrete Distributions 19
2.4.1 Binary variable and Bernoulli distribution 19
2.4.2 Binomial and multinomial distributions 19
2.4.3 Geometric distribution 20
2.4.4 Hypergeometric distribution 20
2.4.5 Poisson distribution 21
2.5 Data and Data Description 21
2.6 Tabular and Graphical Methods for Describing Data 25
2.6.1 Frequency table, pie chart, and bar chart 25
2.6.2 Dot plot, stem-and-leaf plot, and box plot 26
2.6.3 Frequency histogram and density histogram 28
2.7 Parametric Statistical Inferences 33
2.7.1 Point estimation and sampling distribution 33
2.7.2 Maximum likelihood estimation and least squares estimation 38
ixx CONTENTS
2.7.3 Conﬁdence intervals and hypothesis testing 41
2.7.4 The delta method and the bootstrap method 49
2.8 Nonparametric Statistical Inferences 50
2.8.1 Order statistics and their properties 51
2.8.2 Goodness-of-ﬁt tests 54
2.8.3 Rank tests 56
2.8.4 Nonparametric density estimation 61
2.8.5 Nonparametric regression 62
2.9 Exercises 67
3 Univariate Shewhart Charts and Process Capability 73
3.1 Introduction 73
3.2 Shewhart Charts for Numerical Variables 74
3.2.1 The Xand R charts 74
3.2.2 The Xand s charts 84
3.2.3 The Xand R charts for monitoring individual observations 88
3.3 She whart Charts for Categorical Variables 91
3.3.1 The pchart and mpchart 91
3.3.2 The cchart, uchart, and Dchart 97
3.4 Process Capability Analysis 102
3.4.1 Process capability and its measurement 102
3.4.2 Process capability ratios 103
3.5 Some Discussions 110
3.6 Exercises 112
4 Univariate CUSUM Charts 119
4.1 Introduction 119
4.2 Monitoring the Mean of a Normal Process 121
4.2.1 The V-mask and decision interval forms of the CUSUM
chart 121
4.2.2 Design and implementation of the CUSUM chart 126
4.2.3 Cases with correlated observations 135
4.2.4 Optimality of the CUSUM chart 141
4.3 Monitoring the Variance of a Normal Process 144
4.3.1 Process variability and quality of products 144
4.3.2 CUSUM charts for monitoring process variance 146
4.3.3 Joint monitoring of process mean and variance 151
4.4 CUSUM Charts for Distributions in Exponential Family 154
4.4.1 Cases with some continuous distributions in the exponential
family 155
4.4.2 Cases with discrete distributions in the exponential family 158
4.5 Self-Starting and Adaptive CUSUM Charts 162
4.5.1 Self-Starting CUSUM charts 162
4.5.2 Adaptive CUSUM charts 168
4.6 Some Theory for Computing ARL Values 169CONTENTS xi
4.6.1 The Markov chain approach 170
4.6.2 The integral equations approach 172
4.7 Some Discussions 173
4.8 Exercises 174
5 Univariate EWMA Charts 181
5.1 Introduction 181
5.2 Monitoring the Mean of a Normal Process 182
5.2.1 Design and implementation of the EWMA chart 182
5.2.2 Cases with correlated observations 191
5.2.3 Comparison with CUSUM charts 193
5.3 Monitoring the Variance of a Normal Process 198
5.3.1 Monitoring the process variance 199
5.3.2 Joint monitoring of the process mean and variance 205
5.4 Self-Starting and Adaptive EWMA Charts 211
5.4.1 Self-starting EWMA charts 211
5.4.2 Adaptive EWMA charts 214
5.5 Some Discussions 219
5.6 Exercises 221
6 Univariate Control Charts by Change-Point Detection 225
6.1 Introduction 225
6.2 Univariate Change-Point Detection 226
6.2.1 Detection of a single change-point 226
6.2.2 Detection of multiple change-points 230
6.3 Control Charts by Change-Point Detection 233
6.3.1 Monitoring of the process mean 234
6.3.2 Monitoring of the process variance 241
6.3.3 Monitoring of both the process mean and variance 247
6.4 Some Discussions 252
6.5 Exercises 254
7 Multivariate Statistical Process Control 257
7.1 Introduction 257
7.2 Multivariate Shewhart Charts 258
7.2.1 Multivariate normal distributions and some basic properties 258
7.2.2 Some multivariate Shewhart charts 264
7.3 Multivariate CUSUM Charts 271
7.3.1 MCUSUM charts for monitoring the process mean 271
7.3.2 MCUSUM charts for monitoring the process covariance
matrix 281
7.4 Multivariate EWMA Charts 284
7.4.1 MEWMA charts for monitoring the process mean 284
7.4.2 MEWMA charts for monitoring the process covariance
matrix 289xii CONTENTS
7.5 Multi variate Control Charts by Change-Point Detection 294
7.6 Multivariate Control Charts by LASSO 299
7.6.1 LASSO for regression variable selection 300
7.6.2 A LASSO-based MEWMA chart 300
7.7 Some Discussions 306
7.8 Exercises 308
8 Univariate Nonparametric Process Control 315
8.1 Introduction 315
8.2 Rank-Based Nonparametric Control Charts 317
8.2.1 Nonparametric Shewhart charts 317
8.2.2 Nonparametric CUSUM charts 324
8.2.3 Nonparametric EWMA charts 330
8.2.4 Nonparametric CPD charts 338
8.3 Nonparametric SPC by Categorical Data Analysis 341
8.3.1 Process monitoring by categorizing process observations 342
8.3.2 Alternative control charts and some comparisons 348
8.4 Some Discussions 356
8.5 Exercises 358
9 Multivariate Nonparametric Process Control 363
9.1 Introduction 363
9.2 Rank-Based Multivariate Nonparametric Control Charts 366
9.2.1 Control charts based on longitudinal ranking 366
9.2.2 Control charts based on cross-component ranking 376
9.3 Multivariate Nonparametric SPC by Log-Linear Modeling 387
9.3.1 Analyzing categorical data by log-linear modeling 389
9.3.2 Nonparametric SPC by log-linear modeling 392
9.4 Some Discussions 401
9.5 Exercises 402
10 Proﬁle Monitoring 407
10.1 Introduction 407
10.2 Parametric Proﬁle Monitoring 408
10.2.1 Linear proﬁle monitoring 408
10.2.2 Nonlinear proﬁle monitoring 418
10.3 Nonparametric Proﬁle Monitoring 423
10.3.1 Nonparametric mixed-effects modeling 424
10.3.2 Phase II nonparametric proﬁle monitoring 428
10.4 Some Discussions 433
10.5 Exercises 434
ARFunctions for SPC 437
A.1 Basic RFunctions 437
A.2RPackages for SPC 440
A.3 List of RFunctions Used in the Book 440CONTENTS xiii
B Datasets Used in the Book 447
Bibliography 451
Index 477List of Figures
1.1 Demonstration of a production process. 4
2.1 (a) Cumulative distribution function Φ(x)of the standard normal
distribution. (b) Probability density function φ(x)of the standard
normal distribution. 16
2.2 (a) Density curves of χ2
kin cases when k=1,2,3, and 4. (b) Density
curves of tkin cases when k=1,2,and 5. The solid curve in the
plot is the density curve of the standard normal distribution. (c)
Density curves of Fk1,k2in cases when (k1,k2)=(2, 6),(6,6),(3,5),
and(20,20). (d) Density curves of Weibull(1,b)in cases when
b=0.5,1,1.5,and 5. 17
2.3 (a) Pie chart of the data shown in Table 2.2. (b) The corresponding
bar chart. 26
2.4 A dot plot of the data in Example 2.4. 27
2.5 A stem-and-leaf plot of the data in Example 2.4. 27
2.6 The box plot of the data in Example 2.4. 28
2.7 A frequency histogram of the data in Example 2.4. 29
2.8 (a) Frequency histogram corresponding to Table 2.4. (b) Frequency
histogram corresponding to Table 2.5 using class intervals with
different lengths. 30
2.9 A density histogram corresponding to Table 2.5 with unequal class
intervals. 31
2.10 Smoothed histograms with different shapes. (a) Symmetric and
unimodal. (b) Symmetric and bimodal. (c) Skewed to the right and
unimodal. (d) Skewed to the left and unimodal. 32
2.11 The ecdf constructed from the data in Example 2.8. The dark point
at the beginning of each horizontal line segment denotes that the
value of the ecdf at each jump position equals the height of the dark
point. 53
2.12 Kernel density estimates of the aluminum smelter data discussed in
Example 2.5 of Subsection 2.6.3. The kernel function Kis chosen
to be the pdf φof the standard normal distribution. The solid curve
denotes the kernel density estimate when hn=0.05, and the dashed
curve denotes the kernel density estimate when hn=0.25. 62
xvxvi LIST OF FIGURES
2.13 (a) The Nadaraya-Watson kernel estimator of f(x)(dashed hori-
zontal line) has the property that, among all constants, its weighted
distance to observations in the neighborhood [x−hn/2,x+hn/2]
is the smallest. (b) The local linear kernel estimator equals the
value of the dashed line at x. The dashed line has the property
that its weighted distance to observations in the neighborhood
[x−hn/2,x+hn/2]is the smallest among all possible lines. The
little circles in each plot denote the observations. The solid curve
going through the data denotes the true regression function. The
solid curve at the bottom denotes the weights that are controlled by
the kernel function. 65
3.1 The Xchart (plot (a)) and the Rchart (plot (b)) constructed from
the data of the ﬁrst 20 samples summarized in Table 3.2 about the
injection molding process. The sample means and sample ranges of
the ﬁrst 20 samples are shown by solid dots in the plots connected
by solid lines. Since the process seems IC at the ﬁrst 20 time points,
the charts are then used for phase II process monitoring. The phase
II sample means and sample ranges are shown by little circles
connected by dotted lines. We get a signal of mean shift at the
24th time point, and the process is stopped at that time point for
investigation of possible special causes of the signal. 79
3.2 The value of βin cases when m=5,10, and 20, and k∈[0,3]. 81
3.3 The values of ARL 1(plot (a)) and σ(1)
RL(plot (b)) in cases when
m=5,10, and 20, and k∈[0,3]. 82
3.4 The Xchart contains some non-random patterns. 84
3.5 The Xchart (plot (a)) and the schart (plot (b)) constructed from
the data of the ﬁrst 20 samples summarized in Table 3.2 about the
injection molding process. The sample means and sample standard
deviations of the ﬁrst 20 samples are connected by solid lines. Since
the process is IC at the ﬁrst 20 time points, the charts are used
for phase II process monitoring. The phase II sample means and
sample standard deviations are shown by little circles connected by
dotted lines. We get a signal of process variability shift at the 22nd
time point, and the process should be stopped at that time point for
investigation of possible special causes of the signal. 87
3.6 The Xchart (plot (a)) and the Rchart (plot (b)) for monitoring
20 individual observations on concentration (in g/l) of the active
ingredient in a liquid cleaner produced by a chemical process. 92
3.7 The pchart for monitoring the data in Table 3.5. 94
3.8 The actual Type I error probability /tildewideαin different cases. Plot (a):
m=25 and α=0.01. Plot (b): m=50 and α=0.01. Plot (c):
m=25 and α=0.001. Plot (d): m=50 and α=0.001. The dashed
horizontal line in each plot denotes the value of α. 95LIST OF FIGURES xvii
3.9 The cchart for monitoring the numbers of defects found on 15
selected steel plates. 99
3.10 Density histogram of the compressive strengths of 50 randomly
selected manufactured parts of an injection molding process. The
solid curve is the estimated density curve of the data. 104
3.11 (a) The distributions shown by the solid and dashed curves have
the same center, but the one shown by the dashed curve has a
smaller spread than the one shown by the solid curve. (b) The two
distributions shown by the solid and dashed curves have different
centers, but they have the same spread. In each plot, LSL and USL
on the top denote the lower and upper speciﬁcation limits, and Tis
their center. 105
4.1 (a) The Xchart constructed from all 20 samples with the control
limits computed by the formulas in (3.6). (b) An alternative Xchart
for a phase II SPC, in which the IC process distribution is assumed to
be known N(0,1)and the lower and upper control limits of the chart
are set to be −3/√
5 and 3/√
5, respectively. In each plot, the ﬁrst
10 sample means are denoted by solid dots and they are connected
by solid lines, and the second 10 sample means are denoted by little
circles and they are connected by dotted lines. The dashed horizontal
lines labeled U, C, and L denote the upper control limit, the center
line, and the lower control limit, respectively. 120
4.2 Values of the statistic Cncomputed from the data considered in
Example 4.1. In the plot, the ﬁrst 10 values of Cnare denoted by
solid dots and they are connected by solid lines, and the second 10
values of Cnare denoted by little circles and they are connected
by dotted lines. A process mean shift of size 0.2 occurs at the time
τ=11. 123
4.3 (a) Values of the charting statistic Cncomputed from the data
considered in Example 4.1 are denoted by solid dots that are
connected by solid lines, where an upward process mean shift of
sizeδ=0.2 occurs at τ=11. When n≥τ,Cnare all above the solid
half-line that starts at (τ,Cτ−h)with a slope of k=δ/2. (b) Values
of the charting statistic Cnare the same as those in plot (a). The
shaded region denotes a truncated V-mask that can be used for mean
shift detection at n=20. A mean shift occurred before nis detected
if some values of {Ci,i<n}are located outside the V-mask. 124
4.4 Values of the charting statistic C+
n, computed by (4.7) from the data
considered in Example 4.1, are shown by the black dots. In the chart,
kandhare chosen to be 0.25 and 5.597, respectively, so that the
ARL 0value of the chart is 200. 126xviii LIST OF FIGURES
4.5 ARL 0values of the CUSUM chart (4.7)–(4.8) in cases when
k=0,0.25, 0.5,0.75, and h=1,1.5,2,2.5,3,3.5,4. To better demon-
strate the difference among different cases, the y-axis is in natural
logscale. 128
4.6 ARL 1values of the CUSUM chart (4.7)–(4.8) in cases when
k=0.25, 0.5,0.75, the assumed ARL 0value is 200, and the shift
sizeδchanges its value from 0 to 2 with a step of 0.1. To better
demonstrate the difference among different cases, the y-axis is in
natural logscale. 133
4.7 (a) Original data. (b) Residuals of the ﬁtted AR(1) model. (c) Control
chart (4.7)–(4.8) with (k,h) = (0.25, 5.597) when it is applied to
the standardized original data. (d) Control chart (4.7)–(4.8) with
(k,h)=(0.25, 5.597) when it is applied to the standardized residuals. 142
4.8 (a) A dataset with 100 observations among which the ﬁrst 50 obser-
vations are from the distribution N(0,1), the second 50 observations
are from the distribution N(0,22), and all observations are inde-
pendent. (b) Control chart (4.7)–(4.8) with (k,h) = (0.25, 5.597)
when it is applied to the data in plot (a). (c) A dataset with 100
observations among which the ﬁrst 50 observations are from the
distribution N(0,1), the second 50 observations are from the distri-
bution N(0,0.52), and all observations are independent. (d) Control
chart (4.7)–(4.8) with (k,h)=(0.25, 5.597) when it is applied to the
data in plot (c). 147
4.9 (a) CUSUM chart (4.21)–(4.22) when it is applied to the data shown
in Figure 4.8(a) and when k+=1.848 and hU=7.416 (shown by
the dashed horizontal line). (b) CUSUM chart (4.23)–(4.24) when it
is applied to the data shown in Figure 4.8(c) and when k−=0.462
andhL=−2.446 (shown by the dashed horizontal line). 149
4.10 (a) Sample means of 20 samples of size 5 each with the ﬁrst 10
samples from the N(0,1)distribution, the second 10 samples from
theN(1,1)distribution, and all samples independent of each other.
(b) CUSUM-M chart with (k,h)=(0.5, 0.881) for the data shown
in plot (a). (c) CUSUM-V chart with (k+,hU) = (1.848, 2.533)
for the data shown in plot (a). (d) Sample means of 20 samples of
size 5 each with the ﬁrst 10 samples from the N(0,1)distribution,
the second 10 samples from the N(0,22)distribution, and all
samples independent of each other. (e) CUSUM-M chart with
(k,h)=(0.5, 0.881) for the data shown in plot (d). (f) CUSUM-V
chart with (k+,hU)=(1.848, 2.533) for the data shown in plot (d).
The dashed horizontal lines in plots (b), (c), (e), and (f) are control
limits of the related control charts. 153
4.11 The CUSUM chart (4.41)–(4.42) with k+=14.524 and h+=4.0
when it is applied to the data in Example 4.10 161LIST OF FIGURES xix
4.12 The self-starting CUSUM chart (4.49) with (k,h)=(0.25, 5.597) is
shown by the solid curve. The conventional CUSUM chart (4.7)–
(4.8) with the same values of (k,h)is shown by the dotted curve. The
dashed horizontal line denotes the control limit hfor both charts. 167
5.1 Values of σ2
Enin cases when σ2=1,λ=0.05, 0.1, or 0.2, and n
changes from 1 to 30. 184
5.2 The EWMA chart with λ=0.1 and ρ=2.703 (black dots connected
by a solid line) when it is applied to the data in Example 5.1. The
two dashed lines denote the upper control limit Uand the lower
control limit L, and the dotted line denotes the center line C. 185
5.3 ARL 0values of the EWMA chart deﬁned by (5.1) and (5.7) in cases
when the IC process distribution is N(0,1),λ=0.05, 0.1,0.2,or
0.3, and ρchanges from 1.0 to 3.0 with a step of 0.5. 187
5.4 ARL 1values of the EWMA chart deﬁned by (5.1) and (5.7) in
cases when the IC process distribution is N(0,1),ARL 0=200,
λ=0.05, 0.1,or 0.2, and the shift size δchanges from 0 to 2.0 with
a step of 0.1. 189
5.5 Actual ARL 0values of the EWMA chart deﬁned by (5.1) and (5.7)
in cases when the actual IC process distribution is the standardized
version with mean 0 and variance 1 of the χ2
dfdistribution, where
d fchanges from 1 to 10. In the EWMA chart, the parameters (λ,ρ)
are chosen to be (0.05, 2.216),(0.1, 2.454), or (0.2, 2.635) (so that
the nominal ARL 0values of the chart are 200 in all three cases when
the IC process distribution is N(0,1)), and the corresponding results
are shown by the solid, dashed, and dotted curves, respectively. The
dot-dashed horizontal line denotes the nominal ARL 0value. 190
5.6 (a) Control chart (4.7)–(4.8) with (k,h)=(0.25, 5.597) when it is
applied to 100 individual observations collected from a production
process that has an upward mean shift of size 0.5 at the 51st time
point. (b) The same chart when it is applied to the standardized
sample means of 20 samples of size 5 each collected from a
production process that has an upward mean shift of size 0.5 at
the 11th time point. Plots (c) and (d) are the same as plots (a) and
(b), except that the CUSUM chart is replaced by the EWMA chart
deﬁned by (5.1) and (5.7) with (λ,ρ)=(0.1, 2.454). 195
5.7 The weights wi=λ(1−λ)n−i, for i=1,2,..., n, received by the
i-th observation XiinEnwhen n=100, λ=0.05 (plot (a)), λ=0.1
(plot (b)), λ=0.2 (plot (c)), or λ=0.5 (plot (d)). 198xx LIST OF FIGURES
5.8 (a) A dataset of 100 observations with the ﬁrst 50 observations
from the distribution N(0,1), the second 50 observations from the
distribution N(0,22), and all observations being independent. (b) The
EWMA chart deﬁned by (5.1) and (5.7) with (λ,ρ)=(0.2, 2.635)
for the data in plot (a). (c) A dataset of 100 observations with the
ﬁrst 50 observations from the distribution N(0,1), the second 50
observations from the distribution N(0,0.52), and all observations
being independent. (d) The EWMA chart deﬁned by (5.1) and (5.7)
with(λ,ρ)=(0.2, 2.635) when it is applied to the data in plot (c). 200
5.9 (a) Upward EWMA chart deﬁned by (5.12) and (5.18) when it is
applied to the data shown in Figure 5.8(a) and when λ=0.1 and
ρU=2.595 (the dashed horizontal line denotes the upper control
limit U=1.842). (b) Downward EWMA chart deﬁned by (5.12)
and (5.18) when it is applied to the data shown in Figure 5.8(c) and
when λ=0.1 and ρL=1.580 (the dashed horizontal line denotes
the lower control limit L=0.487). 203
5.10 Four different situations are considered, in each of which the ﬁrst
50 observations are generated from the N(0,1)distribution and the
remaining 50 observations are generated from one of the following
four distributions: N(1,1),N(0,22),N(1,22), and N(0,0.52). Plots
(a), (c), (e), and (g) show four sets of data in the four situations,
respectively. Plots (b), (d), (f), and (h) show the corresponding
upward EWMA chart deﬁned by (5.12) and the upper control limit
Uin (5.18) with λ=0.1 and ρU=2.595. 208
5.11 The two-sided EWMA chart deﬁned by (5.12) and (5.18) with
λ=0.1,ρU=3.199, and ρL=1.750 when it is applied to the four
datasets shown in Figure 5.10(a), (c), (e), (g). 209
5.12 Four different situations are considered, in each of which the ﬁrst 50
samples of size 5 each are generated from the N(0,1)distribution
and the remaining 50 samples of size 5 each are generated from
one of the following four distributions: N(1,1)(plot (a)), N(0,22)
(plot (d)), N(1,22)(plot (g)), and N(0,0.52)(plot (j)). Plots in the
ﬁrst column show the sample means, plots in the second column
show the two-sided EWMA charts with the charting statistic En,M
that is based on the sample means, and plots in the third column
show the upward EWMA charts with the charting statistic En,Vthat
is based on the sample variances. Each EWMA chart is designed
using λ=0.1 and ARL 0=400, so that the joint monitoring scheme
consisting of the mean chart and the variance chart has an ARL 0
value of 200. 210LIST OF FIGURES xxi
5.13 (a) The ﬁrst 10 observations are generated from the N(0,1)distri-
bution and the remaining 30 observations are generated from the
N(0.5, 1)distribution. All observations are independent. (b) The
self-starting two-sided EWMA chart deﬁned by (5.25) and (5.27)
(solid curve) and the conventional two-sided EWMA chart deﬁned
by (5.1) and (5.7) (dotted curve). In both charts, λis chosen to be
0.05 and ARL 0is chosen to be 200. 214
5.14 In cases when λ=0.1,u=2,4,6,anden∈[−10,10], the four
quantities η1(en),w1(en) =η1(en)/en,η2(en), and w2(en) =
η2(en)/enare presented in plots (a)–(d), respectively. In each plot,
the dash-dotted and the long-dashed lines denote the corresponding
quantities of the Shewhart chart and the conventional EWMA chart,
respectively. 217
5.15 Plot (a) shows a dataset with 100 independent observations, the ﬁrst
50 of which are generated from the N(0,1)distribution, and the
remaining 50 of which are generated from the N(0.5, 1)distribution.
Plots (b), (c), and (d) show the conventional two-sided EWMA
chart deﬁned by (5.1) and (5.7) with λ=0.01 and ρ=1.973, the
conventional two-sided EWMA chart with λ=0.5 and ρ=3.071,
and the AEWMA chart using η1(en)with λ=0.0398, u=2.8990,
andh=0.4306, respectively. All three charts have the same ARL 0
value of 500. Plots (e)–(h) show the corresponding results for
another dataset with 100 independent observations, the ﬁrst 50 of
which are generated from the N(0,1)distribution, and the remaining
50 of which are generated from the N(2,1)distribution. Dashed
horizontal lines in various plots denote the control limits. 220
6.1 (a) The ﬁrst 10 observations are generated from the N(0,0.52)
distribution, the second 10 observations are generated from
theN(1,0.52)distribution, and the remaining 10 observa-
tions are generated from the N(0,0.52)distribution. All ob-
servations are independent of each other. (b) The sequence
{X2(2,h)+ Q(h, 30), h=2,3,..., 29}is shown by the solid curve,
and the sequence {X2(1,h)+ Q(h, 20), h=1,2,..., 19}is shown by
the dashed curve. 233
6.2 (a) A dataset consisting of 100 observations generated independently
from the distribution N(0,1). (b) The computed values of {|Tjn|,1≤
j≤99}from the data shown in plot (a). (c) The same dataset as that
in plot (a), except that the value of each of the last 50 observations
was increased by 1. (d) The computed values of {|Tjn|,1≤j≤99}
from the data shown in plot (c). 236xxii LIST OF FIGURES
6.3 (a) The ﬁrst 20 observations are generated from the N(0,1)distri-
bution, and the remaining 10 observations are generated from the
N(2,1)distribution. All observations are independent of each other.
(b) The CPD control chart (6.14)–(6.15) (solid line) with n0−1=9
and the control limit hncomputed by the numerical approximation
formula (6.18) when α=0.005 (dashed line). 241
6.4 ARL 1values (in natural log scale) of the CPD control chart (6.14)–
(6.15) (solid curves) and the self-starting CUSUM chart (dotted,
short-dashed, and long-dashed curves) when the process mean shift
size δchanges from 0 to 3. (a) α=0.01 (or ARL 0=100) and
τ=10. (b) α=0.01 (or ARL 0=100) and τ=100. (c) α=0.002
(orARL 0=500) and τ=10. (d) α=0.002 (or ARL 0=500) and
τ=100. 243
6.5 (a) The ﬁrst 20 observations are generated from the N(0,1)distri-
bution, and the remaining 10 observations are generated from the
N(0,22)distribution. All observations are independent of each other.
(b) The CPD control chart (6.25)–(6.26) (solid line) with n0−1=9
and the control limit hncomputed by the numerical approximation
formula (dashed line). 248
6.6 (a) The ﬁrst 20 observations are generated from the N(0,1)distri-
bution, and the remaining 10 observations are generated from the
N(2,1)distribution. All observations are independent of each other.
(b)–(d) The CPD control charts (6.14)–(6.15), (6.25)–(6.26), and
(6.29)–(6.30) in cases with n0−1=9,α=0.005, and hncomputed
by the related approximation formulas. Plots (e)–(h) and (i)–(l)
show the corresponding results when the process distribution shifts
at the 21st time point from N(0,1)toN(0,32)and from N(0,1)to
N(1,22), respectively. 253
7.1 (a) Surface of f(x1,x2)when(X1,X2)has a bivariate normal
distribution, σX1=1,σX2=0.5, and Cor (X1,X2) =0. (b) Three
contour curves {(x1,x2)):f(x1,x2) =c}off(x1,x2)shown in
plot (a) when c=0.05, 0.1, and 0.2. (c) Surface of f(x1,x2)when
(X1,X2)′has a bivariate normal distribution, σX1=1,σX2=0.5, and
Cor(X 1,X2)=0.8. (b) Three contour curves {(x1,x2)):f(x1,x2)=
c}off(x1,x2)shown in plot (c) when c=0.05, 0.1, and 0.2. 261
7.2 In the case when p=2,µX1=3,µX2=3,σX1=1,σX2=0.5, and
Cor(X 1,X2) =0.8, the elliptical region is constructed from the
distribution of d2
S(X,µ)directly such that Xhas a 95% chance
to be in the region, and the square has the same property but it
is constructed from individual components of Xby assuming the
components are independent. 263
7.3 The Shewhart chart (7.7)–(7.8) when it is applied to the data in Table
7.1 and when α=0.005. The dashed horizontal line denotes the
control limit. 268LIST OF FIGURES xxiii
7.4 The Shewhart chart (7.9)–(7.10) when it is applied to the last 10
observations presented in Table 7.1. The dashed horizontal line
denotes the control limit when α=0.005. 269
7.5 Observed data (plots (a), (c), (e)) and the corresponding individual
two-sided CUSUM charts (plots (b), (d), (f)). In each individual
CUSUM chart, the upward CUSUM is shown by the dark dots
connected by the solid lines, the downward CUSUM is shown by
the small circles connected by the dotted lines, and the control limits
are shown by the horizontal dashed lines. 273
7.6 Plots (a)–(c) show the three components of the original observed
data Xn, plots (d)–(f) show the three components of the standardized
residuals Zn, plots (g)–(i) show the three individual CUSUM charts
deﬁned by (7.23)–(7.24), and plots (j) and (k) show the multivariate
CUSUM charts (7.25) and (7.26)–(7.27). In plots (g)–(k), the
horizontal dashed lines denote the control limits. In control charts
(7.25) and (7.26)–(7.27), kandARL 0are chosen to be 0.5 and 200. 279
7.7 Plots (a)–(c) show the Shewhart chart, the multivariate CUSUM
chart (7.32)–(7.33) with k=4, and the COT chart (7.30)–(7.31) with
k=1, respectively, when they are applied to a dataset of the ﬁrst
30 observations of a 3-dimensional production process in scenario
(i). In each chart, the ARL 0value is chosen to be 200, and the
corresponding control limit is denoted by the horizontal dashed line
in the related plot. Results in scenarios (ii) and (iii) are shown in the
corresponding plots in the 2nd and 3rd rows, respectively. 283
7.8 The MEWMA chart (7.39)–(7.40) when it is applied to the data
considered in Example 7.3 and when λ=0.2 and ARL 0=200. The
dashed horizontal line denotes the control limit. 287
7.9 The self-starting MEWMA chart (7.45)–(7.46) when it is applied to
the data presented in Table 7.5 and when λ=0.2 and ARL 0=200.
The dashed horizontal line denotes the control limit hSS=14.167. 291
7.10 The MEWMA chart (7.51)–(7.52) when it is applied to the data
presented in Table 7.7 and when λ=0.2 and ARL 0=200. The
dashed horizontal line denotes the control limit. 295
7.11 The three components of the ﬁrst 50 observations obtained from
a 3-dimensional production process (plots (a)–(c)) and the CPD
control chart (7.54)–(7.55) (plot (d)). In plot (d), the dashed curve
denotes the control limit hn, approximated by the third formula of
(7.56) when αis chosen to be 0.005. 298
8.1 Actual IC ARL values of the conventional CUSUM chart (4.7)–(4.8)
in cases when the assumed IC ARL value is 500, and the true process
distribution is the standardized version (with mean 0 and variance 1)
of the chi-square (plot (a)) or t(plot (b)) distribution with degrees of
freedom changing from 1 to 60 in plot (a) and from 3 to 60 in plot
(b). 316xxiv LIST OF FIGURES
8.2 (a) Observed data from a production process with the IC process
distribution of t3, and the process has a median shift at the 21st time
point. The data consist of 30 batches of observations with the batch
size of m=10. (b) The upward NSR chart (8.1)–(8.2) with the upper
control limit of U=49 (dashed horizontal line). 321
8.3 (a) Phase II batch data with the batch size of m=5 obtained from a
production process. (b) The DFP chart (8.4)–(8.6) with the assumed
ARL 0value of 370. In the chart, the dashed horizontal lines denote
the lower and upper control limits obtained from a reference sample
of size M=1000. 325
8.4 (a) Phase II batch data with the batch size m=6 obtained from a
production process. (b) The upward NSR CUSUM chart (8.8)–(8.9)
with k=8 and h=10 (denoted by the dashed horizontal line). 327
8.5 (a) An IC dataset of size M=100 (dark diamonds before the
vertical dotted line) and a phase II batch dataset with the batch size
m=5 obtained from a production process. (b) The two-sided NRS
CUSUM chart (8.10)–(8.13) with k=0.5/radicalbig
mM(m+M+1)/12 and
h=353. In plot (b), the dark dots and dark diamonds denote the
values of C+
nandC−
n, respectively, and the upper and lower control
limits are shown by the dashed horizontal lines. 329
8.6 (a) Phase II batch data with the batch size of m=10 obtained from
a production process. (b) The NSR EWMA chart deﬁned by (8.17)
and (8.19) with λ=0.1 and ARL 0=370. The dashed horizontal
lines in plot (b) denote the upper and lower control limits of the
control chart. 332
8.7 The NRS EWMA chart (8.20)–(8.21) with λ=0.1 and ARL 0=500
when it is applied to the phase II SPC problem considered in
Example 8.4. 334
8.8 (a) An IC dataset of size M=100 (dark diamond points before the
vertical dotted line) and a phase II dataset (dark dot points after the
vertical dotted line). (b) The NLR EWMA chart (8.23)–(8.25) with
λ=0.05 and ARL 0=370. In plot (b), the dashed line denotes the
control limits hn. 336
8.9 (a) The ﬁrst 100 observations obtained from a production process,
among which the ﬁrst 14 of them are IC. (b) The NCPD control
chart (8.28)–(8.29) starting at n=15 with ARL 0=200. The dashed
line in plot (b) denotes the control limits hn. 341
8.10 (a) The ﬁrst 100 phase II observations obtained from a production
process for online monitoring. (b) The nonparametric P-CUSUM
chart (8.34)–(8.35) with p=10,kP=0.01, and ARL 0=200. In the
chart, the boundary points qlare estimated by the l/p-th sample
quantiles, for l=1,2,..., p−1, of an IC data of size M=500. The
dashed horizontal line in plot (b) denotes the control limit hP. 348LIST OF FIGURES xxv
8.11 Optimal OC ARL values of four control charts when the IC ARL is
500, M=500, m=5, and the actual IC process distribution is the
standardized version of N(0,1)(plot (a)), t4(plot (b)), χ2
1(plot (c)),
andχ2
4(plot (d)). Scale on the y-axis is in natural logarithm. 354
8.12 Optimal OC ARL values of four control charts when the IC ARL is
500, M=500, m=5, and the actual IC process distribution is the
standardized version of N(0,1)(plot (a)), t4(plot (b)), χ2
1(plot (c)),
andχ2
4(plot (d)). Scale on the y-axis is in natural logarithm. 355
9.1 (a) The small diamonds denote the actual IC ARL values of the
multivariate CUSUM chart (7.28)–(7.29) in cases when there are
four quality characteristic variables involved in an SPC application,
the variables are independent of each other, and each has the
standardized version with mean 0 and variance 1 of the Poisson(/tildewideλ)
distribution where/tildewideλ=0.01, 0.1,0.5,1.0,1.5,2.0, and 5.0. (b) The
small diamonds denote the actual IC ARL values of the chart after the
original observations are square-root transformed and standardized
to have mean 0 and variance 1. In the chart (7.28)–(7.29), the control
limit hand the allowance constant kare chosen to be 4.503 and
1.0, respectively, such that its nominal IC ARL equals 200 under
the normality assumption. The dashed line in each plot denotes the
nominal IC ARL value of 200. 364
9.2 Actual IC ARL values of the multivariate CUSUM chart (7.28)–
(7.29), denoted as MCUSUM, and the multivariate EWMA chart
(7.39)–(7.40), denoted as MEWMA, in cases when there are three
quality characteristic variables involved in an SPC application, the
variables are independent of each other, and each has the standard-
ized version with mean 0 and variance 1 of the χ2
rdistribution
where r=1,5,10,20, and 50. In the multivariate CUSUM chart,
(k,h)are chosen to be (1.0, 3.786) (solid curve). In the multivariate
EWMA chart, (λ,h)are chosen to be (0.05, 9.603) (dotted curve)
or(0.2, 11.956) (dot-dashed curve). All charts have nominal IC
ARL values of 200 (dashed horizontal line) under the normality
assumption. 365
9.3 (a) First component of the observed 2-dimensional batch data with
batch size m=50 obtained at the ﬁrst 20 time points. (b) Second
component of the observed data. (c) MNS chart (9.2)–(9.3) when it
is applied to the observed data. (d) MNSR chart (9.6)–(9.7) when
it is applied to the observed data. In both charts, αis chosen to be
0.005, and the control limit is chosen to be χ2
0.995,2=10.597 (dashed
horizontal lines in plots (c) and (d)). 369xxvi LIST OF FIGURES
9.4 (a) First component of a reference sample of size M=100 (dark
diamond points before the vertical dotted line) and a phase II dataset
(dark dot points after the vertical dotted line). (b) Second component
of the reference sample and the phase II dataset. (c) rchart (9.18).
(d)Schart (9.19)–(9.20). In both charts, αis chosen to be 0.05, and
the empirical Mahalanobis depth deﬁned in (9.13) is used. 374
9.5 (a) First component of a reference sample of size M=100 (dark
diamond points before the vertical dotted line) and a phase II dataset
(dark dot points after the vertical dotted line). (b) Second component
of the reference sample and the phase II dataset. (c) Qchart (9.23),
in which αis chosen to be 0.05, and the empirical Mahalanobis
depth deﬁned in (9.13) is used. 375
9.6 Aluminum smelter data after autocorrelation in each component is
excluded. 381
9.7 Density plots of the ﬁve components of the aluminum smelter data
after autocorrelation in each component is excluded. 382
9.8 (a) MA-CUSUM chart (denoted as Cn1) based on the ﬁrst antirank.
(b) MA-CUSUM chart (denoted as Cn15) based on both the ﬁrst and
the last antiranks. The horizontal dashed lines in both plots indicate
the control limits of the charts such that their ARL 0values are both
200. 383
9.9 The OC ARL values of the MMA-CUSUM (solid lines) and MA-
CUSUM charts (dashed lines). The ARL 0values of the two charts
are ﬁxed at 200. The allowance constant k1and the control limit h1
are 0.5 and 12.488 in the MMA-CUSUM chart, and 0.5 and 8.029 in
the MA-CUSUM chart. (a) µ1=(a, a,a,a)′andavaries among 0,
0.2, 0.4, 0.6, 0.8, and 1; (b) µ1=(a, 1,1,1)′andavaries among 0,
0.2, 0.4, 0.6, 0.8, and 1; (c) µ1=(a, 0,0,0)′andavaries among 0,
0.5, 1.0, 1.5, 2.0, 2.5, and 3; (d) µ1=(a, 0,0,0)′andavaries among
−3.0,−2.5,−2.0,−1.5,−1.0,−0.5, and 0. 388
9.10 MLL-CUSUM chart (9.38)–(9.39) with k=0.1 and ARL 0=200
when it is applied to the residuals of the quality characteristic
variables SiO 2,MgO, andAl2O3in the aluminum smelter example.
The horizontal dashed line denotes the control limit. 398LIST OF FIGURES xxvii
9.11 (a) OC ARL values of charts MLL-CUSUM (solid curve),
MCUSUM1 (dashed curve), and MCUSUM2 (dotted curve). The
shift is assumed to be (a,0,0)in the median vector of the process
distribution starting at the 100th time point. (b) Corresponding
results of plot (a) when the shift is (a,0.4,0.4). (c) OC ARL values
of charts MLL-CUSUM (solid curve), MEWMA1 (dashed curve),
and MEWMA2 (dotted curve), when there is a shift (a,0,0)in the
median vector starting at the 100th time point. (d) Corresponding re-
sults of plot (c) when the shift is (a,0.4,0.4). (e) OC ARL values of
charts MLL-CUSUM (solid curve), MA-CUSUM1 (dashed curve),
and MA-CUSUM2 (dotted curve), when there is a shift (a,0,0)in
the median vector starting at the 100th time point. (f) Corresponding
results of plot (e) when the shift is (a,0.4,0.4). 400
10.1 (a) Estimated intercepts {/hatwideaj,j=1,2,..., 20}. (b) Estimated
slopes{/hatwidebj,j=1,2,..., 20}. (c) Estimated error variances
{/hatwideσ2
j,j=1,2,..., 20}. (d) Shewhart chart (10.6)–(10.7) with
α=0.005. The dashed horizontal line in (d) denotes the control
limit χ2
1−α,2. 411
10.2 (a) EWMA chart (10.9)–(10.10) for monitoring the estimated
intercepts {/hatwideaj,j=1,2,..., 20}shown in Figure 10.1(a). (b) EWMA
chart (10.11)–(10.12) for monitoring the estimated slopes {/hatwidebj,j=
1,2,..., 20}shown in Figure 10.1(b). (c) EWMA chart (10.13)–
(10.14) for monitoring the estimated error variances {/hatwideσ2
j,j=
1,2,..., 20}shown in Figure 10.1(c). In these charts, λI,λS, and λV
are all chosen to be 0.2, ρI,ρS, and ρVare chosen to be 3.0156,
3.0109, and 1.3723, respectively, so that the ARL 0values of the three
charts are all around 584.5 and the joint monitoring scheme has the
ARL 0value of about 200. The dashed horizontal lines in the three
plots denote the upper or lower control limits. 414
10.3 (a) Shewhart chart (10.17) for monitoring the estimated intercepts
{/hatwidea∗
j,j=1,2,..., m}in the calibration problem discussed in Example
10.2. (b) Shewhart chart (10.18) for monitoring the estimated
slopes{/hatwidebj,j=1,2,..., m}. (c) Estimated error variances {/hatwideσ2
j,j=
1,2,..., m}. (d) Shewhart chart (10.19)–(10.20) for monitoring
the estimated error variances {/hatwideσ2
j,j=1,2,..., 20}. The dashed
horizontal lines in plots (a), (b), and (d) denote the upper and lower
control limits. 417
10.4 (a){/hatwidebj,j=1,2,..., 20}. (b){/hatwidedj,j=1,2,..., 20}. (c) Shewhart
chart (10.26) with control limit χ2
0.995,2=10.597. (d) EWMA chart
(10.27)–(10.28) with control limit χ2
0.995,2=10.597. In plots (c) and
(d), the dashed horizontal lines denote the control limits. 422
10.5 Shewhart chart (10.31)–(10.32) with α=0.005 when it is applied to
the data presented in Table 10.3. The horizontal dashed line denotes
the control limit. 423xxviii LIST OF FIGURES
10.6 Three AEC proﬁles (lines connecting points with three different
symbols) and the NME estimator (solid curve) of the IC proﬁle
function. 427
10.7 (a) Solid, dashed, dotted, and dash-dotted curves represent estimated
within-proﬁle correlations /hatwideρ(x∗
i,x∗
i+1),/hatwideρ(x∗
i,x∗
i+3),/hatwideρ(x∗
1,x∗
i), and
/hatwideρ(x∗
i,x∗
53), for i=1,2,..., 53, where {x∗
i,i=1,2,..., 53}are 53
equally spaced points in the design interval [−26,78]. (b) Estimated
standard deviation /hatwideν(x∗
i)of the response variable yatx∗
i, for
i=1,2,..., 53. 428
10.8 NMEPM and NFEPM control charts for monitoring the AEC
process. The solid and dashed horizontal lines indicate their control
limits, respectively. 433List of Tables
2.1 Probability distribution function of the grades of an introductory
statistics class. 12
2.2 Frequency table of the party status of 1,000 randomly chosen voters. 25
2.3 A frequency table of the data in Example 2.4. 28
2.4 Frequency table of the aluminum smelter data discussed in Example
2.5, using class intervals with the same length. 30
2.5 Frequency table of the aluminum smelter data discussed in Example
2.5 using class intervals with different lengths. 31
2.6 Critical values Lαfor several commonly used values of α. 56
2.7 Some upper-tail probabilities PH0(S+≥s+)of the null distribution
of the Wilcoxon signed-rank test statistic S+. 58
2.8 Ranks of {|Xi−/tildewideµ0|,i=1,2,..., n}for the observed data in Example
2.9. 59
2.9 Some upper-tail probabilities PH0(W≥w)of the null distribution of
the Wilcoxon rank-sum test statistic W. 60
3.1 Constants d1(m)andd2(m)used in constructing the XandRcharts
when the sample size 2 ≤m≤25. 76
3.2 Summary statistics of the 24 samples collected from an injection
molding process. The ﬁrst 20 samples are for setting up the control
charts, and the last 4 samples are for online process monitoring. The
quality characteristic in this example is the compressive strength of
the manufactured parts. 79
3.3 The overall probability of Type I error, /tildewideα, of the Xchart with FAR
αwhen it is applied to an IC dataset with nsamples, in cases when
nandαtake various values. 83
3.4 Twenty observations (labeled by Xi) on concentration (in g/l) of the
active ingredient in a liquid cleaner produced by a chemical process,
and the sample ranges (labeled by MR i) of the moving windows with
window size/tildewidem=2. 91
3.5 Numbers of non-conforming products in 20 samples along with the
sample proportions of non-conforming products. 94
4.1 Computed hvalues of the CUSUM chart (4.7)–(4.8) for some
commonly used ARL 0andkvalues. 130
xxixxxx LIST OF TABLES
4.2 The left part presents the zero-state (ZS) ARL 0values, the steady-
state (SS) ARL 0values, and their relative differences (ZS−SS)/ZS
of the chart (4.7)–(4.8) when k=0.5 and h=2,2.5,3,3.5,4,4.5,5.
The right part presents the ZS ARL 1values, the SS ARL 1values, and
their relative differences of the same chart for detecting a mean shift
of size δ=1. 133
4.3 The left part presents the actual ARL 0values of the chart (4.7)–(4.8)
when(k,h) = (0.25, 5.597),(0.5, 3.502), or (0.75, 2.481) (so that
its nominal ARL 0values are 200 in all three cases) and when the
process observations are correlated and follow the AR(1) model
(4.15) with the coefﬁcient φ. The right part presents the actual ARL 1
values of the chart when a mean shift of size δ=0.5 occurs at the
initial observation time in various cases considered. 137
4.4 Actual ARL 0values of the chart (4.7)–(4.8) when (k,h) =
(0.25, 5.597),(0.5, 3.502), or (0.75, 2.481) (so that its nominal
ARL 0values are 200 in all three cases) and when the process obser-
vations are grouped into batches of size m=5 each. The original
process observations are correlated and follow the AR(1) model
(4.15) with the coefﬁcient φ. 139
4.5 The actual ARL 0values of the chart (4.41)–(4.42) for detecting an
upward shift from π0=0.1 to π1=0.2 based on samples of size
m=100 each collected at consecutive time points. The value of k+
is computed to be 14.524 by the formula given immediately below
(4.41). 160
4.6 The actual ARL 0values of the chart (4.46)–(4.47) in cases with
several estimated values of the IC mean µ0and IC standard deviation
σ0, along with its actual ARL 1values for detecting a mean shift of
size 0.2. In the chart (4.46)–(4.47), the parameters (k+,h+)are
chosen to be (0.5, 3.502), so that its nominal ARL 0is 200. 164
4.7 The ﬁrst 10 values of Xn,Xn,sn,Zn, and C+
n,SS,respectively. 166
5.1 Computed ρvalues of the EWMA chart deﬁned by (5.1) and (5.7)
for some commonly used ARL 0andλvalues. 188
5.2 The left part presents the actual ARL 0values of the EWMA
chart deﬁned by (5.1) and (5.7) when (λ,ρ)are chosen to be
(0.05, 2.216),(0.1, 2.454), or(0.2, 2.635) (so that its nominal ARL 0
value is 200 in all three cases) and when the process observations are
correlated and follow the AR(1) model with the coefﬁcient φ. The
right part presents the actual ARL 1values of the chart when a mean
shift of size δ=0.5 occurs at the initial observation time in various
cases considered. 192LIST OF TABLES xxxi
5.3 Optimal ARL 1values and the related parameter values of the upward
CUSUM chart (4.7)–(4.8) and the upward EWMA chart deﬁned
by (5.1) with the upper control limit in (5.7) in cases when the IC
process distribution is N(0,1), and the process has an upward mean
shift of size δat the initial time point, where δchanges its value
from 0.1 to 2.0 with a step of 0.1. 197
5.4 Computed ρUandρLvalues of the upward and downward EWMA
charts deﬁned by (5.12) and (5.18) for some commonly used ARL 0
andλvalues. In the entry with a “∗”, the actual ARL 0value is
moderately different from the assumed ARL 0. For the two entries
with a “-” symbol, the assumed ARL 0value cannot be reached. 202
5.5 The actual ARL 0values of the upward EWMA chart deﬁned by
(5.8) and (5.9) and the two-sided EWMA chart deﬁned by (5.1) and
(5.7) in cases with several estimated values of the IC mean µ0and
IC standard deviation σ0, along with their actual ARL 1values for
detecting a mean shift of size 0.2. In the upward chart, (λ,ρU)are
chosen to be (0.1, 2.365) so that its nominal ARL 0value is 200. In
the two-sided EWMA chart, (λ,ρ)are chosen to be (0.1, 2.454),
and its ARL 0value is also 200. 212
5.6 “Optimal” parameter values of the AEWMA chart determined by
the algorithm suggested by Capizzi and Masarotto (2003) in cases
when ARL 0=100 or 500, ν=0.05, η(en)=η1(en)orη2(en), and
σ=1. This table is reproduced from Tables 3 and 4 in Capizzi and
Masarotto (2003). In cases when σ/ne}ationslash=1, the values of handushould
be multiplied by σ. 218
6.1 The second column presents a sequence of 20 observations, and
the third and fourth columns present the corresponding values of
{/tildewideS2
i,i=1,2,..., 19}and{/hatwide/tildewideS2
i,i=1,2,..., 19}, respectively. 229
6.2 Control limits hnwhen n0=10, the sample size ntakes various
values between 10 and 200, and the conditional false signal rate α
equals 0.05, 0.02, 0.01, 0.005, 0.002, and 0.001. This table is copied
from Table 3 in Hawkins et al. (2003). 238
6.3 The second column presents a sequence of 30 observations, and
the third, fourth, ﬁfth, and sixth columns present the corresponding
values of {Wn,n=9,10,..., 30},{S2
n,n=9,10,..., 30},{Tmax,n,n=
10,11,..., 30}, and{hn,n=10,11,..., 30}. 240
6.4 ARL 1values of the CPD control chart (6.14)–(6.15) when α∈{0.02,
0.01, 0.005, 0.002}, and a shift of size δ∈ {0, 0.25, 0.5,1.0,2.0}
occurs at τ∈{10, 25,50,100, 250}. 242
6.5 Control limits hnwhen n0=10, the sample size ntakes various
values between 10 and 30, and the conditional false signal rate α
equals 0.05, 0.02, 0.01, 0.005, 0.002, and 0.001. 246xxxii LIST OF TABLES
6.6 The second column presents a sequence of 30 observations, and
the third, fourth, ﬁfth, and sixth columns present the corresponding
values of {Wn,n=9,10,..., 30},{S2
n,n=9,10,..., 30},{Bmax,n,n=
11,12,..., 30}, and{hn,n=10,11,..., 30}. 247
6.7 Control limits hnwhen n0=10, the sample size ntakes values
between 10 and 14, and the conditional false signal rate αequals
0.05, 0.02, 0.01, 0.005, 0.002, and 0.001. 249
7.1 This table contains 30 observations from a 3-dimensional production
process. 267
7.2 This table presents 20 phase II observations from a 3-dimensional
production process and the calculated values of the multivariate
Shewhart charting statistic T2
0,n. 274
7.3 This table presents the ﬁrst 30 phase II observations of a 3-
dimensional production process and the calculated values of the
charting statistics Cnand/tildewideCndeﬁned in (7.25) and (7.26), respec-
tively. 280
7.4 ARL 1values of the chart (7.39)–(7.40) for detecting several
mean shifts of various sizes when p=3,ARL 0=200, and
λ=0.1,0.2,0.3,0.4, and 0.5. 286
7.5 This table presents the ﬁrst 30 phase II observations of a 3-
dimensional production process, the three components of uncom-
puted by (7.44), and the values of the charting statistic V2
n,SSof the
self-starting MEWMA chart (7.45)–(7.46). 290
7.6 This table presents the values of the control limit hof the MEWMA
chart (7.51)–(7.52) for some commonly used λandARL 0values in
cases when p=2,3,4,5. This table is part of Table 1 in Hawkins
and Maboudou-Tchao (2008). 293
7.7 This table presents the ﬁrst 30 phase II observations of a 3-
dimensional production process (columns 2–4), the three com-
ponents of Yn=(Yn1,Yn2,Yn3)′computed by (7.50) (columns 5–7),
and the values of the charting statistic Cnof the MEWMA chart
(7.51)–(7.52) (last column) in which λandARL 0are chosen to be
0.2 and 200, respectively. 294
7.8 OC ARL values of the control charts LEWMA, MEWMA, and
REWMA in the case when p=5,λ=0.2, and ARL 0=500.
Numbers in parentheses are standard errors. They are shown as
“.00” when they are smaller than 0.005. 305
7.9 This table presents the ﬁrst 50 observation vectors obtained from a
sheet metal assembly process. 310
7.10 This table presents the ﬁrst 30 phase II observations of a 3-
dimensional production process. 313
8.1 This table presents the values of α+andARL+
0of the upward NSR
chart (8.1)–(8.2) in various cases when m=5,6,8, and 10. 320LIST OF TABLES xxxiii
8.2 This table presents the computed values of the largest asuch that
(8.6) holds (1st line in each entry), the actual p0values (2nd line in
each entry), and the actual ARL 0values (3rd line in each entry) of
the DFP chart (8.4)–(8.6) for several commonly used p0,M, and m
values. 323
8.3 This table presents the computed values of a(1st line in each entry),
the actual p0values (2nd line in each entry), and the actual ARL 0
values (3rd line in each entry) of the DFP chart (8.4)–(8.6) for
several commonly used ARL 0,M, and mvalues. 324
8.4 Approximate optimal values of the allowance constant kof the
upward NSR CUSUM chart (8.8)–(8.9) in cases when the process
distribution is symmetric, m=4,6,and 10, and the size of the
process mean shift equals δ=0.2σ,0.6σ,σ,2σ,and 3 σ, where σ
is the IC process standard deviation. 326
8.5 Computed ARL 0values of the upward NSR CUSUM chart (8.8)–
(8.9) in cases when the process distribution is symmetric, m=6, and
(k,h)take various different values. 327
8.6 Computed values of ρused by the NSR EWMA chart deﬁned by
(8.17) and (8.19), for some commonly used values of m,λ, and
ARL 0. 332
8.7 Computed hnvalues of the NLR EWMA chart (8.23)–(8.25) in cases
when M=100, λ=0.05 or 0.1, and ARL 0=370 or 500. 337
8.8 Computed hnvalues of the NCPD control chart (8.28)–(8.29) in
cases when n0=14, and ARL 0=50, 100, 200, 500, 1000, and 2000. 340
8.9 Computed hPvalues of the nonparametric P-CUSUM chart (8.34)–
(8.35) based on 10,000 replications when ARL 0=200, 300, 500, or
1000, p=2, 3, 5, 10, 15, or 20, kP=0.001, 0.005, 0.01, or 0.05,
m=1, or 5, and M=500. 346
8.10 Computed optimal OC ARL values of the nonparametric P-CUSUM
chart (8.34)–(8.35) when M=500, m=5,ARL 0=500, p=5, the
IC observation distribution is the standardized version with mean 0
and standard deviation 1 of χ2
1orχ2
4, and the OC distribution has a
(mean, variance) shift from (0,1)to(µ1,σ2
1). 347
8.11 The actual IC ARL values and their standard errors (in parentheses)
of the seven control charts when the nominal IC ARL values are
ﬁxed at 500 and the actual IC process distribution is the standardized
version of N(0,1),t4,χ2
1, and χ2
4. 353
8.12 The ﬁrst 30 batches of phase II observations with the batch size
m=10 obtained from a production process for process monitoring. 359
9.1 Results from the autoregression modeling of the ﬁve variables in the
aluminum smelter example. 380xxxiv LIST OF TABLES
9.2 Comparison of the MA-CUSUM charts based on different antiranks
of the pcomponents of X, where p=4 and Xhas the IC joint
distribution N4(0,I4). The ARL 0value of each chart is ﬁxed at 200
andk1=1. “AR1” denotes the MA-CUSUM chart based on the ﬁrst
antirank, “AR12” denotes the MA-CUSUM chart based on the ﬁrst
and the second antiranks, and the other notations initiated with “AR”
are similarly deﬁned. The numbers in this table are the OC ARL
values and their standard errors (in parentheses) based on 10,000
replicated simulations. 385
9.3 The numbers in the column labeled by CUSUM 12denote the
minimum OC ARL values and their standard errors (in parentheses)
of the joint monitoring scheme (9.29)–(9.30) and (9.31)–(9.32),
computed based on 10,000 replicated simulations. h1,minandh2,min
are the corresponding control limits in the case when k1andk2are
ﬁxed at 1, and the ARL 0values are ﬁxed at 200. The corresponding
OC ARL values and their standard errors (in parentheses) of the two
individual charts with (k1=1,h1=h1,min)and(k2=1,h2=h2,min)
are presented in the columns labeled by CUSUM 1andCUSUM 2,
respectively. 386
9.4 The OC distribution of A1(i),Q=∑4
j=1(g∗
1,j−g1,j)2/g1,j, and
∑4
j=1µ1jfor several shifts considered in Table 9.3. 386
9.5 An s×t2-way contingency table. 389
9.6 This table presents the ﬁrst 20 observation vectors obtained from a
2-dimensional production process. 403
9.7 This table presents the ﬁrst 40 observation vectors obtained from a
2-dimensional production process. 405
10.1 The ﬁrst 20 observed proﬁles of a production process obtained
during phase II SPC. The design points of all proﬁles are 0.2, 0.4,
0.6, 0.8, and 1.0. 410
10.2 This table presents 22 observed proﬁles in the calibration problem
discussed by Mestek et al. (1994) and Mahmoud and Woodall
(2004). In each proﬁle, ﬁve levels of xare considered, and two
replicated observations of yare collected at each level of x. 416
10.3 The ﬁrst 20 observed proﬁles of a production process obtained
during phase II SPC. The design points of all proﬁles are the same,
with values 0.1, 0.25, 0.4, 0.55, 0.7, 0.85, and 1.0. 421
10.4 The ﬁrst 20 observed proﬁles of a production process obtained
during phase II SPC. The design points of all proﬁles are the same,
with values 0.1, 0.25, 0.4, 0.55, 0.7, 0.85, and 1.0. 436Preface
Statistical process control (SPC) is for monitoring sequential processes (e.g., pro-
duction lines, Internet trafﬁc, medical systems, social or economic status) to make
sure that they work stably and satisfactorily. It is a major tool for quality control
and management. In the past 10–20 years, SPC has made great progress. Many new
SPC methods have been developed for improving traditional SPC methods and for
handling new SPC applications. This book aims to make a systematic description of
both the traditional and recent SPC methods.
I started doing my research on SPC around 1998 after I joined the faculty of the
School of Statistics at the University of Minnesota. At that time, I was doing research
on jump regression analysis, which is about regression modeling when the underly-
ing regression function has jumps. My senior colleague, Professor Doug Hawkins,
published a book on CUSUM charts that year, and he kindly gave me a free copy
of his book. Before I read the book, I had heard of CUSUM charts, but never had a
chance to learn that subject systematically. The book makes a thorough description
about the existing CUSUM charts. It has 10 chapters. Nine of them are on cases when
a univariate quality characteristic variable is of interest for process monitoring, and
only one of them is on multivariate SPC, which is about cases with multiple qual-
ity characteristic variables being monitored. All multivariate SPC methods described
in that chapter are based on the assumption that the multiple quality characteristic
variables follow a joint normal distribution. In my opinion, there are two major lim-
itations in the SPC research of that time. First, in most applications, the quality of
a product is affected by multiple characteristics of the product (cf., Section 7.1 for
a more detailed explanation). Therefore, the SPC research should focus on multi-
variate cases, instead of univariate cases. Second, my extensive consulting experi-
ence tells me that multivariate data would hardly follow a joint normal distribution.
Therefore, we should address the multivariate SPC problem without the normality
assumption. With encouragement from Doug, I started my own research on mul-
tivariate SPC. After ﬁnding the fact that traditional multivariate SPC charts would
be unreliable in cases when the normality assumption was invalid (cf., Figures 9.1
and 9.2), I started to study existing statistical methods for describing multivariate
non-normal data and for transforming multivariate non-normal data to multivariate
normal data. After more than one year’s study, I realized that existing statistical tools
for describing and handling multivariate non-normal data were limited, and the mul-
tivariate SPC problem should be handled using certain statistical methods that were
not based on the normality assumption. Since then, my co-authors and I have pro-
posed antirank-based multivariate SPC charts that are appropriate to use in most
xxxvxxxvi PREFA CE
applications and a general framework to handle the multivariate SPC problem using
the log-linear model (cf., Sections 9.2 and 9.3). Besides our research on multivariate
SPC, my co-authors and I have also made some contributions to univariate SPC, SPC
based on change-point detection, and proﬁle monitoring.
This book has 10 chapters. Chapter 1 describes brieﬂy the concept of quality,
the early history of research on quality improvement, some basic concepts on qual-
ity management, the role of SPC and other statistical methods in quality control and
management, and the overall scope of the book. Chapter 2 describes some basic sta-
tistical concepts and methods that are useful in SPC. Chapters 3–5 make a system-
atic description of some traditional SPC charts, including the Shewhart, CUSUM,
and EWMA charts. Some more recent control charts based on change-point detec-
tion are described in Chapter 6. Some fundamental multivariate SPC charts under the
normality assumption are described in Chapter 7. Then, Chapters 8 and 9 introduce
some recent univariate and multivariate control charts designed for cases when the
normality assumption is invalid. Control charts for proﬁle monitoring are discussed
in Chapter 10. At the end of each chapter, some exercises are provided for readers to
practice the methods described in the chapter. Computations involved in all examples
in the book are accomplished using the statistical software package R. Some basic
Rfunctions are introduced in Appendix A, along with some Rpackages developed
speciﬁcally for SPC analysis and all Rfunctions written by the author for the book.
A list of all datasets used in the book is given in Appendix B.
The mathematical and statistical levels required are intentionally low. Readers
with some background in basic linear algebra, calculus through integration and dif-
ferentiation, and an introductory level of statistics can understand most parts of the
book without much difﬁculty. For a given topic, some major methods and proce-
dures are introduced in detail, and some more advanced or more technical material is
brieﬂy discussed in the section titled “Some Discussions” of each chapter. For some
important methods, pseudo computer codes are given in the book. All Rfunctions
and datasets used in the book are posted on the author’s web page for free download.
This book can be used as a primary textbook for a one-semester course on sta-
tistical process control. This course should be appropriate for both undergraduate
and graduate students from statistics, industrial engineering, systems engineering,
management sciences, and other related disciplines that are concerned about process
quality control. It can also be used as a supplemental textbook for courses on quality
improvement and system management. SPC researchers from both universities and
industries should ﬁnd this book useful because it includes many of the most recent
research results in various SPC research areas, including univariate and multivariate
nonparametric SPC, SPC based on change-point detection, and proﬁle monitoring.
Quality control practitioners in almost all industries should ﬁnd this book useful as
well, because many state-of-the-art SPC techniques are described in the book, their
major advantages and limitations are discussed, and some practical guidelines about
their implementations are provided.
I am grateful to Doug Hawkins for introducing the SPC topic to me, for his
guidance on my early SPC research, for his constant encouragement and help, and
for his numerous comments and suggestions during the course of my SPC research.PREFACE xxxvii
I thank all my co-authors of SPC research, including Singdhansu Chatterjee, Doug
Hawkins, Chang Wook Kang, Zhonghua Li, Zhaojun Wang, Jingnan Zhang, Jiujun
Zhang, and Changliang Zou, for their patience, stimulating discussions, and helpful
comments and suggestions. I am fortunate to have had Josh Wiltsie read the entire
manuscript. He provided a great amount of constructive comments and suggestions.
Both Giovanna Capizzi and Arthur Yeh provided detailed review reports about the
book manuscript that greatly improved the quality of the book. Part of the book
manuscript was used as lecture notes in my recent advanced topic course offered at
the School of Statistics of University of Minnesota in Fall 2012. Students from that
class, especially Mr. Yicheng Kang, corrected a number of typos and mistakes in
the manuscript. Dr. Changliang Zou kindly helped me with the computation of the
nonparametric EWMA chart described in Subsection 8.2.3.
This book project took more than 3 years to ﬁnish. During that period of time,
my wife, Yan, gave me a great amount of support and help, by taking care of our two
sons and much household work as well. My two sons, Andrew and Alan, helped me
in their own way by not interrupting me during my writing of the book manuscript
at home and by keeping my home ofﬁce quiet. I thank all of them for their love and
constant support.
PEIHUA QIU
Gainesville, Florida
August 2013Chapter 1
Introduction
In our daily life, we often talk about the quality of a product. The product can be
small items, such as the clothes, shoes, watches, food, and so forth, that we could
not live without. It can also be larger items, such as bikes, cars, televisions, and so
forth, that our families routinely use. It can even be the network systems that manage
our communities or even the entire society, such as the banking system, health care
system, internet system, and so forth. In cases when the quality of any of these prod-
ucts has a problem, our life could become miserable. Besides the products mentioned
above that affect everyone’s life, we are actually concerned about the quality of any
products that we produce, although some of them may not affect everyone’s life, or
they may not affect some people’s lives directly (e.g., certain satellites, luxury prod-
ucts). This raises an important question. How can we control or assure the quality
of products? To answer the question, many management philosophies and statistical
methodologies have been developed in the literature. A central part of these method-
ologies is the so-called statistical process control (SPC). This book describes some
fundamental SPC methodologies.
Although SPC provides major statistical methodologies for quality control, there
are some other scientiﬁc methods that are helpful for improving the quality of prod-
ucts. In this chapter, we give a brief overview of these methods, and introduce some
basic concepts and terminologies that are related to quality, quality improvement, and
SPC. From the introduction, we hope to provide a big picture about quality control
and the major role of SPC in quality control.
1.1 Quality and the Early History of Quality Improvement
Most people have their own conceptual understanding of quality. Intuitively, a prod-
uct with good quality should meet the requirements of its users. This is the so-called
“ﬁtness-for-use” criterion that is commonly used in the literature for deﬁning quality.
Garvin (1987) gives eight dimensions to the deﬁnition of quality, which are brieﬂy
summarized in the box below.
12 INTRODUCTION
Eight Dimensions of Quality
Performance concerns how well a product performs certain speciﬁc functions.
Features refer to the functions that the product performs, especially to those func-
tions that its competitors do not have.
Reliability concerns how often the product fails.
Conformance concerns whether the product meets its designed standard.
Durability refers to the effective service life of the product.
Serviceability concerns the maintenance of the product, and the product is good
in this dimension if its maintenance is easy and convenient.
Aesthetics is related to the visual appeal of the product.
Perceived quality refers to the reputation of the product.
Therefore, quality is a multifaceted concept. It is also a dynamic concept in the
sense that it keeps changing over time. For instance, a good quality personal com-
puter bought ten years ago would not be good any more in today’s standards.
In the history of human beings, improving the quality of life might be one major
motivation for the entire society to keep making progress. For instance, in order to
improve communication, our ancestors created numbers and languages. To further
improve communication and computation, computers and the internet were devel-
oped not so long ago. Nowadays, more and more modern communication techniques
are developed on a daily basis, making our communication even more convenient.
On the other hand, the quality of our life is reﬂected in the quality of many different
products and systems that we use. It is difﬁcult to imagine a good life with bad ser-
vices of our banks and medical systems and with our cars, computers, and other daily
used products frequently broken. So, quality and its improvement is not new to us.
It actually exists in our daily life and in the entire history of mankind. For instance,
the ancient Chinese people invented the movable type system of printing about one
thousand years ago (Needham, 1986), and we have been trying to improve the quality
of printing since then.
Although quality and quality improvement are an indispensable component of
our society, we did not have systematic theory and methods about them until about
a century ago. At that time, several western companies, including the AT&T Com-
pany, realized the importance of quality assurance of their products and services. The
Western Electric Company was reorganized by AT&T in 1907 for inspection and
testing of manufactured or installed products and purchased materials of the AT&T
Company (Wadsworth et al., 2002). The Inspection Department within the Western
Electric Company had more than 5000 members by 1924. One prominent ﬁgure in
that department was Joseph M. Juran who later became a well-known international
consultant in quality control and management. In 1925, a new Inspection Department
was created in the newly formed Bell Telephone Laboratories. This department had
several pioneers of modern quality control and management, including Donald A.
Quarles, Walter A. Shewhart, Harold F. Dodge, and George D. Edwards. Many im-
portant statistical concepts and terminologies, including the Shewhart control chart,QUALITY MANAGEMENT 3
risks of type I and type II errors in statistical hypothesis testing, were created by them
around that time.
During World War II, because of the US involvement in the war, a large amount
of war materials were needed, which resulted in the rapid expansion of the US man-
ufacturing industry. To assure the quality of the manufactured goods, many skilled
people in quality inspection and testing were needed. Consequently, some training
programs in quality inspection and testing were established by individual companies
and by government organizations as well, such as the War Department. One impor-
tant ﬁgure working with the War Department was Dr. W. Edwards Deming, who later
became a leading quality control consultant. In the 1940s, several research groups
were established across the country to perform research in quality control. The fa-
mous Hotelling’s T2statistic was proposed by Harold Hotelling in 1947. (Hotelling
was a member of the Statistical Research Group at Columbia University.) In 1946,
the American Society of Quality Control was established, with George Edwards of
the Bell Telephone Laboratories as the ﬁrst president of the new society. For many
other early developments in quality control and management, readers are encouraged
to read an overview given in Chapter 1 of Wadsworth et al. (2002).
1.2 Quality Management
Aproduction process turns materials, workers’ labor and skills, manufacturing fa-
cilities (e.g., machines), and other necessary inputs into desired outputs, in the form
of products. Then, the products are properly evaluated and monitored. Any problems
found in the evaluation and monitoring will be investigated, and the process is fur-
ther improved. See Figure 1.1 for a demonstration. The products of the production
process can be soft-drink cans, shoes, and other physically visible items. They can
also be software packages, services, information, and other things that may not be
physically visible but still meet the needs of certain people. In this book, if there is
no further speciﬁcation, products refer to both types, although the ﬁrst type is men-
tioned more often in our description for simplicity of perception.
The quality of a production process is determined by the quality of its products.
The production process is of high quality only if its products are overall of high
quality. The quality characteristics of a product can usually be measured numeri-
cally, and thus be denoted by numerical variables. For instance, if the weight of a
soft-drink can is an important quality characteristic, then that characteristic can be
denoted by a numerical variable “weight.” However, certain quality characteristics
cannot be conveniently measured numerically. For instance, a soft-drink can should
be classiﬁed as a defective product if it is dented. In this case, the shape of the soft-
drink can is categorical, and it has two categories “dented” and “not-dented.” In the
literature, such binary categorical quality characteristics are often called attributes.
As a distinction, the numerical quality characteristics are often called variables. To
make the related terminologies consistent with those in other areas of statistics, in
this book, we call all quality characteristics variables, and they are classiﬁed as con-
tinuous numerical variables, discrete numerical variables, andcategorical variables
(cf., Peck and Devore, 2012). The traditional attributes are just binary categorical4 INTRODUCTION
Inputs
Materials❆
❆
❆
❆ ❯
Labor ❍❍ ❥
Facilities✟✟ ✯Production
...✲Outputs
Products✲ Process
Control✛
Process Adjustment
Figure 1.1: Demonstration of a production process.
variables with two categories “defective” and “non-defective,” or “conforming” and
“non-conforming.” One beneﬁt with the proposed classiﬁcation system of the qual-
ity characteristics is that all possible quality characteristics can be properly classiﬁed
in this system. In the traditional classiﬁcation system using variables and attributes,
categorical quality characteristics with more than two categories would be difﬁcult to
classify, and such categorical quality characteristics are popular in applications (e.g.,
color, taste, customers’ feedback on certain services in categories of “satisfactory,”
“neutral,” “dissatisfactory,” and so forth).
As described in Section 1.1, quality is a multifaceted concept. So, to have a com-
plete evaluation of the quality of a production process, we should consider different
quality characteristics that can be used for evaluating different dimensions of the
quality. For instance, for the soft-drink can mentioned above, besides the amounts
of major ingredients in the drink (for evaluating its performance, conformance, and
features), we may also want to consider the decoration on the can surface (for evalu-
ating its aesthetics), its lifetime from production to the time that the drink inside the
can turns bad (for evaluating its durability), and so forth.
The values of the quality characteristics of a product are obviously related to the
input variables of the related production process (cf., Figure 1.1). Because of the
fact that it is impossible to exhaustively list all possible input variables that have
an impact on the quality characteristics of the product and that some listed input
variables are uncontrollable, the relationship between the quality characteristics and
the controllable input variables has a certain randomness involved (cf., Qiu, 2005,
Section 2.1). When we design a product or a production process, we usually set
some speciﬁc requirements on the randomness. For instance, for a speciﬁc type of
soft drink, we may require the average value of sugar content in a can to be at a given
level, with a given upper bound on a spread measure (e.g., the standard deviation)QUALITY MANAGEMENT 5
of the sugar content readings of different cans. The quality of the products that meet
such designed requirements is referred to as the quality of design. Intuitively, the
soft drink would have a good quality of design if the designed spreads of the quality
characteristics are small, the designed average values of the healthy ingredients are
high, and the designed average values of the unhealthy ingredients are low. It is
natural to require a good quality of design on all products. But, in practice, a better
quality of design usually implies a higher cost and a lower productivity. Therefore,
we need to make compromises among these related considerations.
After the designed requirements on a product have been speciﬁed, the manufac-
tured products of the related production process may not be able to meet all these
designed requirements, due to various reasons, including defects in materials, inad-
equate skills of the workforce, poorly planned manufacturing, inappropriate inspec-
tion and tests, and so forth. Quality of a product related to its conformance to the
designed requirements is called the quality of conformance.
To assure the quality of a production process, it is clear that the quality of all
components and/or stages of the process should be assured, including the quality of
the raw materials, education and skills of the workforce, manufacturing planning and
operation, tests and monitoring of the products, and so forth. To this end, some qual-
ity management systems have been developed and implemented in industries, among
which the total quality management (TQM) andsix-sigma systems are especially
popular. TQM places emphasis on identifying customers’ needs and requirements,
and on satisfying all these needs and requirements by continuously improving all as-
pects of the production process. Six-sigma takes a project-by-project approach. Each
project focuses on improving certain substantial components of the production pro-
cess, using a speciﬁc ﬁve-step problem-solving approach: deﬁne, measure, analyze,
improve, and control (DMAIC). The DMAIC approach uses many statistical tools,
including control charts, experimental design, regression analysis, and so forth.
In quality management, statistics turn out to play an important role. As demon-
strated by Figure 1.1, quality of a production process depends on various input vari-
ables, some of which are uncontrollable or even difﬁcult for us to recognize as ex-
isting. As a consequence, the relationship between the quality characteristics of a
product and the controllable input variables is random. To ﬁnd and quantitatively de-
scribe such a random relationship, design of experiments (DOE), analysis of variance
(ANOVA), and regression analysis provide major statistical tools. More speciﬁcally,
DOE provides a structured and organized method for determining the relationship
between the controllable input variables and the output variables (i.e., the quality
characteristics in the current setting). It usually involves designing a set of experi-
ments, in which all relevant input variables are varied systematically. When the re-
sults of these experiments are obtained (i.e., the output variables are observed in all
experiments) and analyzed by ANOV A or regression, those input variables that most
inﬂuence the output variables can be identiﬁed, along with the input variables that do
not inﬂuence the output variables signiﬁcantly. To investigate whether manufactured
products meet all their designed requirements, control charts are especially useful.
By a control chart, manufactured products of a production process are sampled se-
quentially, and their quality characteristics are monitored over time. Any deviations6 INTRODUCTION
ofthe quality characteristics from their designed requirements would be signaled
as soon as possible, and the root causes of such deviations would be identiﬁed and
properly deleted, which is usually achieved by adjusting the controllable input vari-
ables. Besides the statistical methods mentioned above, there are some other methods
that are commonly used in quality management. For instance, when inspecting raw
materials or manufactured products, acceptance sampling plans provide appropriate
sampling methodologies for inspection and make decisions on whether the raw ma-
terials or manufactured products should be accepted or rejected after the sampled
items are inspected.
1.3 Statistical Process Control
From the brief discussion about quality control and management in the above two
sections, it can be seen that it is important to check whether the manufactured prod-
ucts conform to their designed requirements. If the answer is negative, then the pro-
duction process should be stopped as soon as possible. Otherwise, much time and
money is wasted because the products would not be able to meet consumers’ needs
in such cases. SPC is a major statistical tool for checking the conformance of the
products to their designed requirements, and it is the focus of this book. For those
who are interested in reading a broader description about quality control and manage-
ment, or about other statistical tools that are useful in quality control, we recommend
books by Montgomery (2009), Ryan (2000), Wadsworth et al. (2002), among many
others.
As mentioned in Section 1.2, even in cases when the production process works
stably, the quality characteristics of interest would still have randomness or variabil-
ity involved. This type of variability is mainly caused by certain uncontrollable (or
difﬁcult/expensive to control) input variables, and is referred to as common cause
variation. Common cause variation is considered to be an inherent part of the pro-
duction process and cannot be changed without changing the process itself. How-
ever, with the progress in science and technology, certain uncontrollable (or difﬁ-
cult/expensive to control) input variables in the past might now be partially or com-
pletely controllable. Consequently, certain common cause variation can be removed,
and the quality of design of the production process can be improved. In cases when
only common cause variation is present in the production process, the process is con-
sidered to be stable, in statistical control, or simply in-control (IC). When some com-
ponent(s) of the production process become(s) out of order, certain corresponding
quality characteristics would have a relatively large variability or a systematic varia-
tion from the designed requirements, and consequently many manufactured products
would not be able to meet the designed requirements. This type of variation is re-
ferred to as special (or assignable) cause variation, and the component(s) of the
process that cause(s) the variation is the special cause. Examples of special causes
of variation include defective raw materials, improper operation of the workers, im-
properly adjusted machines, and so forth. When a production process has special
cause variation present, it is considered to be unstable, out of statistical control, or
simply out-of-control (OC). The major goal of SPC is to distinguish special causeSTATISTICAL PROCESS CONTROL 7
variation from common cause variation, and give a signal as soon as special cause
variation occurs.
SPC is often divided into two different phases. In phase I, we try to properly set
up a production process and make it run stably. Because of the fact that we do not
know much about the process at the beginning of this phase, statistical analysis in-
volved in this phase has an exploratory nature. Usually, the numerical relationship
between the quality characteristics of the manufactured products and certain con-
trollable input variables is ﬁrst studied, using DOE, ANOV A, regression, and other
related statistical methods. Then, the controllable input variables are set at some spe-
ciﬁc levels such that the quality characteristics would roughly meet their designed
requirements by the established relationship between the controllable input variables
and the quality characteristics. Under this condition, a set of process data (i.e., obser-
vations of the quality characteristics) is gathered and analyzed by a SPC chart. Any
unusual “patterns” in the data lead to adjustments and ﬁne tuning of the controllable
input variables of the process. Then, a new set of process data is collected under the
adjusted condition, and analyzed by a SPC chart again. This control-and-adjustment
step is repeated several times, until all special causes are believed to be removed and
the process works stably. Then, we are left with a clean set of data, gathered under
stable operating conditions and illustrative of the actual process performance. This
set is then used for estimating the IC distribution of the quality characteristics. In
phase II, the process is believed to be IC at the beginning, and our major goal is to
monitor the process online to make sure that it keeps running stably. To this end,
manufactured products are sampled sequentially over time, and observations of the
quality characteristics of the sampled products are monitored using a SPC chart, and
the chart gives a signal once it detects a signiﬁcant special cause deviation of the
quality characteristics. After a signal of a special cause deviation is delivered, the
process should be stopped immediately, and the special causes should be ﬁgured out
and removed. From the above description, we can see some substantial differences
between phase I and phase II SPC problems. First, the size of the observed process
data is usually ﬁxed in the phase I problem, while the observed data in the phase II
problem increase sequentially. Second, the distribution of the quality characteristics
is often unknown in the phase I problem, while this distribution is routinely assumed
to be known or it can be estimated from an IC data in the phase II problem. Be-
cause of these substantial differences between phase I and phase II problems, SPC
methodologies designed for solving the two problems are also quite different.
After creation of the Shewhart control chart by Walter A. Shewhart more than
80 years ago (Shewhart, 1931), SPC has made tremendous progress. Noticeable
progress in SPC includes the creation of the cumulative sum (CUSUM) control chart
by Page (1954) and the exponentially weighted moving average (EWMA) control
chart by Roberts (1959). One fundamental difference between a Shewhart chart and
a CUSUM or EWMA chart is that the former uses only the data observed at the cur-
rent time point for detecting variation caused by special causes and it ignores all data
that are observed at earlier time points, while the latter uses all available data that are
observed at both the current and earlier time points. In recent years, many new SPC
methodologies have been developed for improving traditional SPC methods and for8 INTRODUCTION
handling new SPC applications, which include control charts based on change-point
detection, nonparametric control charts designed for cases when the traditional nor-
mality assumption is invalid, and control charts for monitoring proﬁles. This book
will systematically describe both the traditional and some recent SPC methods.
1.4 Organization of the Book
This book has 10 chapters. Chapter 2 introduces some basic statistical concepts and
methods that are useful in constructing and understanding SPC charts. The remain-
ing eight chapters describe both the traditional and some recent SPC charts that are
designed for handling different scenarios. Chapters 3–5 describe three traditional
families of control charts that are commonly used in practice. They are the Shewhart
charts, the CUSUM charts, and the EWMA charts, respectively. Chapter 6 intro-
duces an alternative family of control charts that were proposed recently based on
change-point detection. Compared to the Shewhart, CUSUM, or EWMA charts, con-
trol charts based on change-point detection have the advantage that the occurrence
time of a special cause deviation can be estimated simultaneously when a signal of
the special cause deviation is delivered. Control charts described in Chapters 3–6 are
mainly for situations when a single quality characteristic is involved and its IC and
OC distributions are normal. Such control charts are routinely called univariate SPC
charts in the literature. When multiple quality characteristics are involved, the corre-
sponding SPC problem is often referred to as the multivariate SPC problem. Some
fundamental multivariate SPC charts under the normality assumption are described in
Chapter 7. Then, Chapters 8 and 9 introduce some recent control charts designed for
various cases when the normality assumption is invalid: Those for univariate SPC are
introduced in Chapter 8 and those for multivariate SPC are introduced in Chapter 9.
In certain applications, instead of monitoring one or more quality characteristics, we
are interested in monitoring the functional relationship between a response variable
and some predictors. This is the so-called proﬁle monitoring problem in the literature.
Some fundamental control charts for proﬁle monitoring are discussed in Chapter 10.
The book also has two appendices at the end. The ﬁrst appendix introduces some
basic functions of the statistical software package R, and some Rpackages and func-
tions developed speciﬁcally for SPC analysis. The second appendix gives a list of all
datasets used in the book.
This book is written in such a way that readers with some background in basic
linear algebra, calculus through integration and differentiation, and an introductory
level of statistics can easily understand most parts of the book. For a given topic,
some major methods and procedures will be introduced in detail, and some more
advanced or more technical material will be brieﬂy discussed in the section titled
“Some Discussions” of each chapter. For some important methods, pseudo computer
codes will be given in the book, and all the datasets and source codes in Rthat are
used in the examples, ﬁgures, tables, and exercises of the book will be posted on the
book web page for free download. At the end of each chapter, some exercises are
provided for readers to practice the methods described in the chapter.EXERCISES 9
1.5 Exer cises
1.1 Choose a product that you are familiar with, and discuss the eight dimensions of
its quality.
1.2 For the production process of soft-drink cans of a given brand in a factory, list
all possible input variables, and answer the following questions:
(i) Among the variables listed, which ones are controllable?
(ii) Among the variables listed, which ones are uncontrollable or controllable but
difﬁcult/expensive to control?
(iii) Are there any other factors or variables that might affect the quality of the
products but are ignored in your list?
The variables considered in parts (ii) and (iii) are the major source of common
cause variation in the quality characteristics of products. Discovery of them can
potentially improve the quality of design of products.
1.3 Assume that you are interested in buying a car of a speciﬁc brand and model, and
would like to know the designed requirements of certain quality characteristics.
Can you list at least 10 such quality characteristics? Which ones are continuous
numerical, discrete numerical, or categorical variables?
1.4 Using the soft-drink example in exercise 1.2, discuss the difference between
quality of design and quality of conformance. To improve the quality of design
of the products, what can we potentially do? What kind of actions or adjustments
can potentially improve the quality of conformance?
1.5 Both quality of design and quality of conformance are related to costs and pro-
ductivity. Using the soft-drink example in exercise 1.2, discuss this relationship
in detail.
1.6 SPC charts try to distinguish special cause variation from common cause vari-
ation. Using a quality characteristic found in the car example in exercise 1.3,
describe the two types of variation and their major causes, and then answer the
following questions:
(i) In which situations is the related production process considered IC?
(ii) In which situations is the related production process considered OC?
(iii) If an OC signal is given by a control chart, what appropriate actions should
we take?
1.7 Using the soft-drink example discussed in exercise 1.2, describe the phase I and
phase II SPC problems.Chapter 2
Basic Statistical Concepts and Methods
2.1 Introduction
As described in Chapter 1, statistical process control (SPC) is a major statistical tool
for monitoring a production process to make sure that it works stably. The stability of
the production process is reﬂected by the conformance of the quality characteristics
of its products to their designed requirements. Because the quality characteristics
are affected by both controllable and uncontrollable input variables of the produc-
tion process (cf., Figure 1.1), observations of the quality characteristics would have
random noise involved, which represents the common cause variation in the quality
characteristics (cf., the related discussion in Section 1.3). To describe and analyze
such data with random noise, the use of various statistical concepts and methods is
necessary, and is brieﬂy introduced in this chapter.
This chapter is written for the convenience of those readers who do not know
or do not remember some of the basic statistical concepts and methods well. It can
be skipped by readers with a background in introductory-level statistics. The intro-
duction here is kept to a minimum. For a more complete discussion about statistical
theory and inference, see, for example, Lehmann and Casella (1998), Lehmann and
Romano (2005), and Casella and Berger (2002). For a more complete introduction
about commonly used statistical methods, see. for example, Devore (2011).
2.2 Population and Population Distribution
In statistics, any statement and/or conclusion is only applicable to a speciﬁc popu-
lation, which is the entire collection of members or subjects about which informa-
tion is desired. For instance, if we are interested in knowing the working status of
a production process of soft-drink cans of a given brand, then the collection of all
manufactured soft-drink cans of that production process is our population.
In a particular application, usually we are only interested in one or several speciﬁc
characteristics of the members in a population, e.g., indices of certain ingredients in
a soft-drink can in the above example. These characteristics are often called vari-
ables because their values can change among different members in the population.
As another example, suppose that we are interested in knowing the numerical rela-
tionship between the height and weight of all current college students in this country.
Then, the collection of all current college students in the country is our population,
and height and weight are two variables of interest. By the nature of their values, all
1112 BASIC STATISTICAL CONCEPTS AND METHODS
Table 2.1: Probability distribution function of the grades of an introductory statistics class.
Grade A B C D F
Probability 0.09 0.35 0.38 0.15 0.03
variables are classiﬁed into three categories: categorical variables, discrete numeri-
cal variables, and continuous numerical variables. A variable is called a categorical
variable if all its values are categories. Examples of categorical variables include gen-
der, race, color, conformance status of a product, and so forth. A variable is discrete
numerical if all its values are isolated numbers on the number line. It is continu-
ous numerical if the set of all its values is an interval on the number line. Height
and weight mentioned above are examples of continuous numerical variables, while
the number of accidents on a given road segment during a given time period is an
example of a discrete numerical variable.
Let us ﬁrst focus on single-variable cases. Suppose that a member is randomly
selected from a population. After the selection, the variable value of the selected
member becomes known. But before the selection, the variable value of the member
to be selected could be any possible value. In that sense, the variable is random and is
therefore called a random variable. In the case when several variables are involved,
the random variable is multivariate, or it is a random vector.
For a given population, it is often of interest to know how all the values in the
population are distributed, or equivalently, how all the possible values of the related
random variable are distributed. This distribution is called the population distribu-
tion. By the connection between a population and a random variable, the population
distribution is the same as the distribution of the related random variable.
We now consider how to describe the population distribution. If the related ran-
dom variable is categorical in the sense that all its possible values belong to several
categories, then a table listing all the categories and the corresponding proportions
of the population members in the categories is sufﬁcient for describing the popula-
tion distribution. This table is often called the probability distribution function or the
probability mass function (see Table 2.1).
Example 2.1 An introductory statistics class has 100 students. Assume that the
course grading system has 5 levels: A, B, C, D, and F . At the end of the semester,
9 students in the class get the grade of A, 35 students get the grade of B, 38 students
get the grade of C, 15 students get the grade of D, and 3 students get the grade of
F . If we are interested in the distribution of students’ grades in this class, then all
students in the class constitute a population. Let X denote the grade of a randomly
selected student in the class. Then, X is the random variable of our interest, and its
probability distribution function, which is also the probability distribution function
of the population, is given in Table 2.1.
If a random variable Xis univariate numerical, then its distribution can be de-
scribed by the following cumulative distribution function (cdf):
F(x)=P(X≤x), forx∈R, (2.1)POPULATION AND POPULATION DISTRIBUTION 13
where P(X≤x)denotes the probability of the event that Xis less than or equal to a
given value xon the number line R. From (2.1), F(x)is obviously a non-decreasing
and right-continuous function on Rwith its values in [0,1]. When xgets larger, F(x)
is closer to 1; it is closer to 0 when xgets smaller.
In the case when the cdf F(x)is absolutely continuous, in the sense that there is
a nonnegative, real-valued, measurable function fonRsuch that
F(x)=/integraldisplayx
−∞f(u)du, forx∈R, (2.2)
the random variable Xis said to be absolutely continuous, and fis called its proba-
bility density function (pdf). The corresponding curve of a pdf is called a (probability)
density curve. Thus, for an absolutely continuous random variable X, its pdf fcan
be computed easily from its cdf Fby the relationship
f(x)=F′(x), forx∈R. (2.3)
From the deﬁnition (2.2), a pdf must be a nonnegative integrable function, and the
area under its entire curve is one. These are also the sufﬁcient conditions for a mea-
surable function on Rto be a pdf. If Xhas a pdf f, then the area under the density
curve and above an interval [a,b]equals P(a≤X≤b), for any −∞≤ a≤b≤∞.
That is, areas underneath the density curve give probabilities for the random variable
X.
If a random variable Xis discrete, in the sense that all its possible values are
isolated on the number line R, then the center of its possible values can be measured
by
µX=N
∑
j=1xjpj, (2.4)
where{xj,j=1,2,..., N}are all the values of X, and{pj,j=1,2,..., N}are
the corresponding probabilities. Obviously, µXis a weighted average of {xj,j=
1,2,..., N}with the probabilities {pj,j=1,2,..., N}being the weights. In the case
when the probabilities are all the same, µXis just the simple average of {xj,j=
1,2,..., N}. In the literature, µXis often called the mean ofXor the expected value
ofX. Another commonly used notation for µXis E(X), where E is the ﬁrst letter of
“expected value.” The spread of all possible values of Xcan be measured by
σ2
X=N
∑
j=1(xj−µX)2pj, (2.5)
where σ2
Xis called the variance ofX. Sometimes we also write σ2
Xas Var(X), where
Var denotes “variance.” Its square root σXis called the standard deviation ofX.
Because σXhas the same unit as X, it is often more convenient for measuring the
spread; but, mathematically, σ2
Xis easier to handle. From (2.4) and (2.5), it is obvious
that
σ2
X=E(X−µX)2=E/parenleftbig
X2/parenrightbig
−µ2
X.14 BASIC STATISTICAL CONCEPTS AND METHODS
Namely, σ2
Xis the mean squared distance from Xto its center µX, and it can also be
computed from E/parenleftbig
X2/parenrightbig
andµX.
In cases when Xis an absolutely continuous random variable with a pdf f, its
mean is deﬁned by
µX=/integraldisplay∞
−∞u f(u)du, (2.6)
and its variance is deﬁned by
σ2
X=/integraldisplay∞
−∞(u−µX)2f(u)du=E(X−µX)2. (2.7)
In cases when p>1 characteristics of the members in a population are of in-
terest (e.g., pquality characteristics of the products of a production process), a p-
dimensional random vector X= (X 1,X2,..., Xp)′can be used for denoting the p
characteristics of a randomly selected member from the population. The (joint) cdf
ofXcan be deﬁned similarly to (2.1) by
F(x)= P(X1≤x1,X2≤x2,..., Xp≤xp), forx=(x 1,x2,..., xp)′∈Rp,(2.8)
where Rpdenotes the p-dimensional Euclidean space. If there is a nonnegative, real-
valued, p-dimensional, measurable function fonRpsuch that
F(x)=/integraldisplayx1
−∞···/integraldisplayxp
−∞f(u)du, forx∈Rp, (2.9)
then Xis said to be absolutely continuous, and fis its (joint) pdf.
In cases when the cdf of Xhas the property that
F(x)= P(X1≤x1)P(X2≤x2)···P(Xp≤xp), for any x∈Rp, (2.10)
theprandom variables X1,X2,..., Xpare said to be independent. Intuitively speaking,
a sequence of random variables are independent of each other if the values of any
subset of the sequence provide no information about the values of the remaining
random variables in the sequence. Based on (2.1)–(2.3) and (2.8)–(2.10), if Xhas a
pdff, then each of X1,X2,..., Xpmust have a pdf, and X1,X2,..., Xpare independent
if and only if
f(x)= fX1(x1)fX2(x2)···fXp(xp), for any x∈Rp, (2.11)
where fXj(xj)denotes the pdf of Xj, for j=1,2,..., p.
2.3 Important Continuous Distributions
In statistics, a number of parametric distribution families are frequently used in devel-
oping various statistical methods and theories. Some important distribution families
of absolutely continuous numerical random variables are introduced in this section.
Some important distribution families of discrete numerical random variables are in-
troduced in the next section. For a more complete discussion on parametric distri-
bution families, see Johnson et al. (1992), Johnson et al. (1994), and Johnson et al.
(1995).IMPORTANT CONTINUOUS DISTRIBUTIONS 15
2.3.1 Normal distribution
A very important family of parametric distributions is the normal (orGaussian) dis-
tribution family. When an absolutely continuous random variable Xhas the following
pdf:
f(x)=1√
2πσexp/bracketleftbigg
−(x−µ)2
2σ2/bracketrightbigg
, forx∈R, (2.12)
where µandσare two parameters, then its distribution is called a normal distribu-
tion. It can be easily checked, using (2.6) and (2.7), that if Xhas a normal distribution
with parameters µandσas deﬁned in equation (2.12), then µX=µandσ2
X=σ2.
Therefore, a normal distribution is uniquely determined by its mean and variance. We
use the conventional notation X∼N(µ,σ2)to denote “X has a normal distribution
with mean µand variance σ2.” The normal distribution is important in statistics for
two major reasons. One is that distributions of many continuous variables in practice,
such as the height or weight of all people in this country, can be described reasonably
well by normal distributions. The second major reason is that much statistical theory
is developed under the assumption of normality.
Some properties of a normal distribution are as follows. Its density curve is bell-
shaped, symmetric about the mean µ, and its spread is controlled by the standard
deviation σ. Therefore, µis alocation parameter andσis ascale parameter. If
X∼N(µ,σ2), then the random variable deﬁned by
Z=X−µ
σ
has a normal distribution with mean zero and variance one. This speciﬁc normal dis-
tribution with mean zero and variance one is called the standard normal distribution.
Its cdf Φ(x)and pdf φ(x)are displayed in Figure 2.1. From Figure 2.1(b), the density
curve of Zindeed looks bell-shaped. By the way, in statistics, it is a convention to
useZto denote a random variable that has the standard normal distribution.
2.3.2 Chi-square distribution
IfX1,X2,..., Xkare independent normal random variables with means µ1,µ2,..., µk,
respectively, and with a common variance one, then the distribution of
Q=X2
1+X2
2+···+X2
k
is called the non-central chi-square distribution with kdegrees of freedom (df) and
with a non-central parameter δ=µ2
1+µ2
2+...+µ2
k. By notation, it is denoted as
Q∼χ2
k(δ). Ifδ=0 (i.e., all µ1,µ2,..., µkare 0), then the corresponding distribution
is called the (central) chi-square distribution with df equal to k, which is simply
denoted as χ2
k. The pdf of the χ2
kdistribution has the expression
f(x)=1
2k/2Γ(k/2)xk/2−1e−x/2, forx≥0,16 BASIC STATISTICAL CONCEPTS AND METHODS
xΦ□x□
0 0.25 0.5 0.75 1
−2 −1 0 1 2
(a)
0.0 0.1 0.2 0.3 0.4
xφ□x□
−2 −1 0 1 2
(b)
Figure 2.1 (a) Cumulative distribution function Φ(x)of the standard normal distribution.
(b) Probability density function φ(x)of the standard normal distribution.
where Γ(x) =/integraltext∞
0ux−1e−uduis the gamma function. If Q∼χ2
k, then it can be
checked using (2.6) and (2.7) that
µQ=k, σ2
Q=2k.
When k=1,2,3, and 4, the density curves of χ2
kare shown in Figure 2.2(a),
from which it can be seen that the curves tend to be more and more symmetric when
kincreases. One important property of the chi-square distribution is that, if Q1and
Q2are two independent random variables, Q1∼χ2
k1, and Q2∼χ2
k2, then Q1+Q2∼
χ2
k1+k2.
2.3.3 t distribution
Another important continuous distribution is the tdistribution deﬁned as follows.
Assume that ZandVare two independent random variables, Zhas the standard
normal distribution, and Vhas a chi-square distribution with df equal to k. Then, the
distribution of
T=Z/radicalbig
V/k
is called thet distribution with kdegrees of freedom. From its deﬁnition, the tdistri-
bution is uniquely determined by its only parameter k. For that reason, the distribu-
tion is conventionally denoted as tk. Its pdf is
f(x)=Γ((k+1)/2)√
kπΓ(k/2)/parenleftbigg
1+x2
k/parenrightbigg−(k+1)/2
, forx∈R.IMPORTANT CONTINUOUS DISTRIBUTIONS 17
xf(x)
0 2 4 6 80 0.25 0.5 0.75 1k=1
k=2
k=3
k=4
(a)xf(x)
−2 −1 0 1 20 0.1 0.2 0.3 0.4N(0,1)
t_1
t_2
t_5
(b)
xf(x)
0 1 2 3 40 0.25 0.5 0.75 1F_2,6
F_6,6
F_3,5
F_20,20
(c)xf(x)
0 0.5 1 1.5 2 2.50 0.5 1 1.5 2 2.5b=0.5
b=1
b=1.5
b=5
(d)
Figure 2.2 (a) Density curves of χ2
kin cases when k =1,2,3, and 4. (b) Density curves of t k
in cases when k =1,2,and 5. The solid curve in the plot is the density curve of the standard
normal distribution. (c) Density curves of F k1,k2in cases when (k1,k2) = (2, 6),(6,6),(3,5),
and(20,20). (d) Density curves of Weibull (1,b)in cases when b =0.5,1,1.5,and 5.
By (2.6) and (2.7), it can be checked that, when T∼tk,µTexists only when k>1
andσ2
Texists and is ﬁnite only when k>2. In such cases,
µT=0,when k>1, σ2
T=k
k−2,when k>2.
When k=1,2,and 5, the density curves of tkare shown in Figure 2.2(b) where
the solid curve is the density curve of the standard normal distribution. From the plot,
we can have the following conclusions:
(i)For a given value of k, the density curve of tkis bell-shaped and symmetric about
0;
(ii)When kincreases, the density curve of tkgets closer to the density curve of the
standard normal distribution; and18 BASIC STATISTICAL CONCEPTS AND METHODS
(iii) Forany constant a>0 and any ﬁnite positive integer k, it is always true that
P(T≥a)>P(Z≥a),
where T∼tkandZ∼N(0,1). Note that the probabilities P(T≥a)andP(Z≥a)
equal the areas of the tkandN(0,1)density curves, respectively, in the right-
tail region of [a,∞). Therefore, this conclusion implies that the density curve of
atdistribution has heavier tails, compared to the density curve of the standard
normal distribution.
2.3.4 F distribution
IfX1andX2are two independent random variables, X1∼χ2
k1, and X2∼χ2
k2, then the
distribution of
F=X1/k1
X2/k2
is called theF distribution with numerator degrees of freedom k1and denominator
degrees of freedom k2. It is denoted as F∼Fk1,k2. The pdf of the Fk1,k2distribution is
f(x)=1
xB(k 1/2,k2/2)/radicaligg
(k1x)k1kk2
2
(k1x+k2)k1+k2, forx≥0,
where B(x,y)=/integraltext1
0ux−1(1−u)y−1duis the beta function. Its mean exists and is ﬁnite
only when k2>2, and its variance exists and is ﬁnite only when k2>4. In such cases,
µF=k2
k2−2,when k2>2, σ2
F=2k2
2(k1+k2−2)
k1(k2−2)2(k2−4),when k2>4.
Incases when (k1,k2) = (2, 6),(6,6),(3,5), and(20,20), the density curves of
Fk1,k2are shown in Figure 2.2(c), from which it can be seen that the density curve
of the Fdistribution is quite ﬂexible and can have many different shapes. From the
deﬁnitions of the tandFdistributions, it is obvious that, if T∼tk, then T2∼F1,k.
2.3.5 Weibull distribution and exponential distribution
In life science and reliability analysis, the Weibull distribution family is widely used
for describing the distribution of the life times of products. Its pdf is
f(x)=b
a/parenleftigx
a/parenrightigb−1
e−(x/a)b, forx≥0,
where a>0is a scale parameter, and b>0 is a shape parameter. If a random variable
Whas a Weibull distribution with scale parameter aand shape parameter b, denoted
asW∼Weibull(a,b), then its mean and variance are
µW=aΓ(1+1/b), σ2
W=a2/bracketleftbig
Γ(1+2/b)−Γ2(1+1/b)/bracketrightbig
.
When a=1 and b=0.5,1,1.5, and 5, the density curves of Weibull(a,b)are
shown in Figure 2.2(d). In the special case when b=1, the Weibull distribution
becomes the exponential distribution, which is another continuous distribution that
is widely used in applications.IMPORTANT DISCRETE DISTRIBUTIONS 19
2.4 Important Discrete Distributions
2.4.1 Binary variable and Bernoulli distribution
In practice, many variables are binary in the sense that they only take two possible
values. Examples of binary variables include gender (either male or female), result
of an inspection of a product (pass or fail the inspection), status of a cancer patient
after a ﬁve-year period (alive or dead), and so forth. For convenience, in statistics,
we usually label the value of a binary variable that we are interested in studying as
success (S), and the other value as failure (F). If a random variable Xis binary, then
its probability distribution function is determined by
π=P(X=S), 1−π=P(X=F),
which is called the Bernoulli distribution. Without losing any information, we can
assign the number 1 to S, and the number 0 to F. After this assignment, Xbecomes a
binary numerical random variable, and it is obvious that
µX=π, σ2
X=π(1−π).
2.4.2 Binomial and multinomial distributions
Now, let us consider the experiment of ﬂipping a coin ntimes. This experiment sat-
isﬁes the following four requirements:
(i)The experiment consists of ntrials with nﬁxed.
(ii)Thentrials are independent of each other, in the sense that the result of one trial
does not affect the result of any other trials.
(iii) Each trial has only two possible outcomes: S and F. Such a trial is often called
a Bernoulli trial.
(iv) The probability of S is the same from trial to trial.
An experiment meeting the above four requirements is called a binomial experi-
ment. So, ﬂipping a coin ntimes is an example of a binomial experiment. Now, let
Xdenote the number of S’s in a binomial experiment with ntrials, and πdenote the
probability of S. Then, Xis a discrete numerical random variable taking the values of
0,1,2,..., n. Its probability distribution can be described by the following formula:
P(X=x)=/parenleftbigg
n
x/parenrightbigg
πx(1−π)n−x, forx=0,1,2,..., n, (2.13)
where /parenleftbigg
n
x/parenrightbigg
=n!
x!(n−x)!
is called the binomial coefﬁcient, which denotes the number of combinations when
choosing xsubjects from a total of nsubjects. The distribution described by (2.13) is
called the binomial distribution, denoted as Binomial(n,π). If X∼Binomial(n,π),
then Xis often called a binomial random variable, and its mean and variance are
µX=nπ, σ2
X=nπ(1−π). (2.14)20 BASIC STATISTICAL CONCEPTS AND METHODS
The binomial distribution can be generalized as follows. Assume that, in an ex-
periment of ntrials, each trial has kpossible outcomes with k≥2, the probabilities
of the koutcomes are {π1,π2,..., πk}in each trial, and the trials are independent of
each other. Let Xjbe the number of trials having the j-th outcome, for j=1,2,..., k.
Then, the distribution of (X1,X2,..., Xk)is
P(X 1=x1,X2=x2,..., Xk=xk)=n!
x1!x2!···xk!πx1
1πx2
2···πxk
k,
for any non-negative integers (x1,x2,..., xk)that satisfy ∑k
j=1xj=n. This distribu-
tion is called the multinomial distribution, denoted as Multinomial (n,π1,π2,..., πk).
Obviously, when k=2, the multinomial distribution is equivalent to a binomial dis-
tribution. Further, in cases when k>2, the distribution of a single Xj, for any j, is
Binomial(n,πj). Therefore, by (2.14), for j=1,2,..., k,
µXj=nπj, σ2
Xj=nπj(1−πj).
2.4.3 Geometric distribution
LetXbe the number of Bernoulli trials needed to get the ﬁrst S. Then, Xis a discrete
numerical random variable taking the values of {1,2,...}. Its probability distribution
can be described by
P(X=x)=(1−π)x−1π, forx=1,2,...
This distribution is called the geometric distribution, denoted as Geom( π). If X∼
Geom( π), then it is easy to check that
µX=1
π, σ2
X=1−π
π2.
The geometric distribution plays an important role in statistical process control
(SPC), because in SPC we are mainly concerned about the ﬁrst time when a con-
trol chart gives a signal that a production process is out-of-control. See Section 3.2
in Chapter 3 for a related discussion.
2.4.4 Hypergeometric distribution
In statistics, ball models are often used for introducing certain important discrete dis-
tributions. To introduce the hypergeometric distribution, a related ball model can be
described as follows. Assume that an urn contains a total of Nballs, among which
there are Mred balls and N−Mblack balls, where N>0 and 0≤M≤Nare two
integers. We select nballs from the urn without replacement. Let Xbe the num-
ber of selected red balls. Then, Xis a discrete random variable taking the values of
{0,1,..., min(n, M)}. Its distribution can be described by
P(X=x)=/parenleftbigg
M
x/parenrightbigg/parenleftbigg
N−M
n−x/parenrightbigg
/parenleftbigg
N
n/parenrightbigg, forx=0,1,..., min(n, M).DATA AND DATA DESCRIPTION 21
This distrib ution is called the hypergeometric distribution, and its mean and variance
are
µX=nM
N; σ2
X=nM(N−n)(N−M)
N2(N−1), when N>1.
2.4.5 Poisson distribution
When describing the distribution of a discrete random variable Xwhose value is a
count (e.g., the number of trafﬁc accidents on a speciﬁc segment of a road in a given
time period), the Poisson distribution is often useful. By deﬁnition, Xhas a Poisson
distribution if it takes count values in {0,1,2,...} and
P(X=x)=λxe−λ
x!, forx=0,1,..., (2.15)
where λ>0 is a parameter. If Xhas a Poisson distribution with parameter λ, denoted
asX∼Poisson( λ), then it can be checked using (2.4), (2.5), and (2.15) that
µX=λ, σ2
X=λ. (2.16)
From (2.16), we can notice an important property of the Poisson distribution; its
mean and variance are the same. In practice, people often use this property to ver-
ify whether a dataset follows a Poisson distribution. Another important property of
the Poisson distribution is that, if X1andX2are two independent random variables,
X1∼Poisson( λ1), and X2∼Poisson( λ2), then X1+X2∼Poisson( λ1+λ2). In quality
control, the Poisson distribution is often used for describing the distribution of the
number of defects in an inspection unit. See related discussion in Subsection 3.3.2.
2.5 Data and Data Description
In applications, it is often of interest to know the population distribution. For in-
stance, before a presidential election, people are interested in knowing the propor-
tion of approvals of a speciﬁc candidate in the entire population of legitimate voters.
Because individuals of the population in this example take only two possible values,
either approval or disapproval, the population distribution is uniquely determined by
the approval rate in the population, or the population proportion of approvals. More
generally, when a population distribution has a parametric form, such as those dis-
cussed in Sections 2.3 and 2.4, the population parameters appearing in the parametric
form uniquely determine the entire population distribution. Therefore, it sufﬁces to
know the values of these parameters in order to know the population distribution. In
some instances, our major interest is in one or more population parameters instead
of the entire population distribution. As an example, it is often sufﬁcient to know the
average exam score of the students in a class in order to have a rough idea about the
overall performance of these students in the exam. However, to know the population
distribution or its parameters, we need to know variable values for all members in
the population. In many applications, the related population is large. It is therefore
time-consuming or even impossible to observe the variable value for each member22 BASIC STATISTICAL CONCEPTS AND METHODS
in the population. To overcome this difﬁculty, in statistics, we often use the idea of
sampling the population, described below.
Asample of the population is a subset of the population, selected in some pre-
scribed manner for study. After a sample is obtained, the population distribution or
its parameters can be estimated based on the sample. In practice, most people call
the observed sample selected properly from a population data, although the word
“data” is also used for some other purposes in our daily life (e.g., to represent certain
generic information that may not necessarily be a sample from a population).
To have an accurate estimation of the population distribution or its parameters,
the sample should represent the population well. In the literature, many different
sampling techniques have been proposed to handle different cases. Interested readers
can read Cochran (1977) or other textbooks on statistical sampling for a systematic
discussion about this topic. In this book, if there is no further speciﬁcation, we as-
sume that all samples are simple random samples. A simple random sample of size
nis a sample that consists of nselected members, which is generated in a way that
the result of one selection has nothing to do with the result of any other selection,
and every member in the population has the same chance to be selected to the sam-
ple. By this deﬁnition, each observation in the sample can be thought of as a random
variable whose distribution is just the population distribution, because the value of
the observation can be any member in the population (i.e., the observation value is
random) and each member in the population has the same chance to be selected to
the sample. Of course, after the sample is physically obtained, observations in the
sample are uniquely determined and non-random. To make the distinction, we con-
ventionally use capital letters to denote observations in a sample that are treated as
random variables, and little letters to denote observations in a physically obtained
sample.
Simple random samples have some nice statistical properties. One property can
be described as follows. Assume that the characteristic of interest in each member
of a population is univariate numerical, the cdf of the population distribution is F,
and{X1,X2,..., Xn}is a simple random sample from the population. Then, by the
deﬁnition of the simple random sample, {X1,X2,..., Xn}is a sequence of independent
and identically distributed (i.i.d.) random variables with a common cdf F. The joint
cdf of{X1,X2,..., Xn}is
P(X 1≤x1,X2≤x2,..., Xn≤xn)=Πn
i=1P(X i≤xi)=Πn
i=1F(xi),
for any(x1,x2,..., xn)′∈Rn. If the population distribution has a pdf f, then the joint
distribution of {X1,X2,..., Xn}also has a pdf, and the pdf is
Πn
i=1f(xi), for(x1,x2,..., xn)′∈Rn.
See (2.11) and the related discussion in Section 2.2.
For a sample {X1,X2,..., Xn}, there are several ways to describe its center. One
natural way is to use the sample mean
X=1
nn
∑
i=1Xi,DATA AND DATA DESCRIPTION 23
which is a simple average of all nobservations. By using the sample mean, if there
are some extremely large or extremely small values in the data, which are often
called outliers, then they would affect the sample mean quite dramatically, which
is demonstrated by the example below.
Example 2.2 A state government wants to know the salary information of faculty
members in high education institutes in that state. For that purpose, 10 faculty mem-
bers are randomly chosen and their most recent salaries (in thousands) are listed
below.
67,84,56,210, 79,85,73,64,88,93
The value of sample mean is x=89.9. But, obviously this is not a good measure of the
data center , because there are only two observations larger than x and the remaining
8 observations ar e all below x. This phenomenon is due to the outlier “210” which
pulls the mean salary up quite dramatically.
From Example 2.2, in cases when outliers are present, the sample mean may not
be a good measure of the data center. In such cases, to remove the impact of outliers,
people often use the sample median for measuring the data center. To compute the
sample median, the observations in the sample {X1,X2,..., Xn}are ﬁrst ordered from
the smallest to the largest as follows:
X(1)≤X(2)≤···≤ X(n). (2.17)
Then, X(1)is the ﬁrst order statistic, X(2)is the second order statistic, and so on.
Roughly speaking, the sample median is deﬁned by the observation at the middle
position of the ordered data. So, about half of the observations in the data are smaller
than the sample median, and the other half are larger than the sample median. More
speciﬁcally, the sample median, denoted as /tildewideX, is deﬁned by
/tildewideX=/braceleftigg
X((n+1)/2), ifnis odd
X(n/2)+X(n/2+ 1)
2,ifnis even.
By this deﬁnition, obviously, the sample median is not affected by a small amount of
outliers in the data.
An alternative method to remove the impact of outliers is to use the so-called
trimmed sample mean, computed as follows. First, we need to choose a trimming
percentage q%, where q∈[0,50). Then, the data are ordered, as in (2.17), and the
q% smallest observations and the q% largest observations are removed. Finally, the
q% trimmed sample mean is computed as the simple average of the remaining obser-
vations.
Example 2.2 (continued) For the data discussed in Example 2.2, the ordered data
are
56,64,67,73,79,84,85,88,93,210.
So, the sample median is /tildewidex= (79+84)/2=81.5, which is smaller than the sam-
ple mean x=89.9 because the former is not affected by the outlier 210. The 10%24 BASIC STATISTICAL CONCEPTS AND METHODS
trimmed sample mean is(64+67+73+79+84+85+88+93)/8=79.125, af-
ter the 10% (i.e., one in this example) smallest observations and the 10% largest
observations are removed.
Besides the center of a dataset. another important feature of the dataset is its
spread. Consider the following three datasets, each of which has ﬁve observations:
Dataset 1: 1, 3, 5, 7, 9
Dataset 2: 1, 4.5, 5, 5.5, 9
Dataset 3: 4, 4.5, 5, 5.5, 6
Obviously, the sample means of the three datasets are all the same with a value of 5.
But, their distributions have quite different spreads. The ﬁrst dataset seems to have
the largest spread, while the spread of the third dataset seems to be the smallest. To
describe the spread of a dataset of size n, denoted by {X1,X2,..., Xn}, a conventional
measure is the sample variance, deﬁned by
s2=1
n−1n
∑
i=1(Xi−X)2.
The sample variance s2is basically the average of the squares of the ndeviations
{Xi−X,i=1,2,..., n}. Therefore, if its value is large, then overall the individual
observations are far away from the sample mean, implying that the data spread is
large. The square root of the sample variance, s, is another spread measure, which
is called the sample standard deviation. Regarding the two measures, the sample
standard deviation is easier to interpret as a measure of the data spread because it has
the same unit as the original observations, but the sample variance is easier to handle
mathematically.
Similar to the sample mean, the sample variance or the sample standard deviation
would be affected in a substantial way by possible outliers in the data. To eliminate
such effect, we can once again consider the ordered observations in (2.17). Then, the
sample ﬁrst quartile, denoted as Q1, is deﬁned by the median of the ﬁrst half of the
ordered data. More speciﬁcally,
Q1=/braceleftbiggmedian of {X(1),..., X((n−1)/2)}, ifnis odd
median of {X(1),..., X(n/2)}, ifnis even.
The sample third quartile, denoted as Q3, is deﬁned similarly, by the median of the
second half of the ordered data. Then, in cases when outliers are present, we can use
the sample inter-quartile range (IQR), deﬁned by Q3−Q1, as a measure of the data
spread. Obviously, IQR would not be affected by a small number of outliers in the
data.
It should be pointed out that all the measures of the data center and data spread
discussed in this section can also be applied to a population of numerical members
to measure the center and spread of all members in the population, although some of
these measures of the population distribution are not explicitly deﬁned in the book.
For instance, we can deﬁne population median in the same way as the sample median,TABULAR AND GRAPHICAL METHODS FOR DESCRIBING DATA 25
Table 2.2: Frequency table of the party status of 1,000 randomly chosen voters.
Party Democrat Republican Green Party Other
Frequency 437 486 53 24
except that all population members should be used in deﬁning the population median.
If a sample represents a population well, then the sample version of a given measure
should provide a good estimate of the corresponding population version. See Section
2.7 for a related discussion.
2.6 Tabular and Graphical Methods for Describing Data
2.6.1 Frequency table, pie chart, and bar chart
To discuss tabular and graphical methods for describing categorical data, let us con-
sider the following example.
Example 2.3 Before a presidential election, a TV network made a survey in the na-
tion, and they randomly selected 1,000 legitimate voters to ask for their favorite
candidates. Each voter was also asked to tell the TV network his or her party status.
The data about the party status are summarized in Table 2.2.
In Example 2.3, the data about party status is categorical with four categories.
Table 2.2 lists all the categories of the observations and the corresponding counts,
or frequencies. This table is called the frequency table. In the table, sometimes it is
more convenient to list relative frequencies (or proportions) of the categories. The
relative frequency of a category is deﬁned by
relative frequency =frequency
sample size.
For the data summarized in Table 2.2, the relative frequencies of the categories
Democrat, Republican, Green Party, and Other are 0.437, 0.486, 0.053, and 0.024,
respectively. In the table, if relative frequencies, instead of frequencies, are listed,
then the table is often called the relative frequency table. Sometimes, in a frequency
table, both frequencies and relative frequencies are listed for convenience of its ap-
plications.
There are two commonly used graphical methods to describe categorical data.
One is the pie chart, by which a circle is divided into slices, each slice denotes a
category, and the slice size is proportional to the relative frequency of the category.
For the data in Table 2.2, the corresponding pie chart is shown in Figure 2.3(a). The
other popular graphical method for describing categorical data is the bar chart, by
which all the categories are listed in the x-axis, a bar is drawn above the correspond-
ing category label, and the height of the bar equals the corresponding frequency (or
relative frequency). For the data in Table 2.2, its bar chart is shown in Figure 2.3(b),
in the case when relative frequencies are used. By the way, because the positions of26 BASIC STATISTICAL CONCEPTS AND METHODS
the cate gory labels can be switched on the x-axis, the shape of a bar chart usually
does not provide any helpful information about the related data.
Democrat
RepublicanGreenOther
(a)Democrat Republican Green Otherrelative frequency
0.0 0.1 0.2 0.3 0.4
(b)
Figure 2.3: (a) Pie chart of the data shown in Table 2.2. (b) The corresponding bar chart.
2.6.2 Dot plot, stem-and-leaf plot, and box plot
In this and the next subsections, we will introduce several graphical methods for
describing numerical data. To introduce these methods, let us start with the following
example.
Example 2.4 To estimate the age distribution of all members of a recreation cen-
ter, 25 members of the center were randomly selected. Their ages were recorded as
follows.
18, 27, 56, 19, 33, 24, 19, 48, 37, 25, 20, 22, 31,
29, 65, 41, 22, 39, 37, 22, 45, 22, 43, 61, 53
For this data, it can be computed by the formulas in Section 2.5 that the sample mean
isx=34.32, the sample median is /tildewidex=31,the sample variance is s2=198.56, and
the sample standard deviation is s =14.091.
For the data in Example 2.4, the dot plot is shown in Figure 2.4, from which we
can see that a dot plot can be constructed as follows. First, draw a horizontal line and
mark it properly with a measurement scale. Then, locate each observation in the data
along the measurement scale, and represent it by a dot above the scaled line. If there
are two or more observations with the same value, stack the dots vertically. Usually,
a dot plot is appropriate for displaying a relatively small dataset, because it lists all
observations in the plot and the plot would look messy if the dataset is large. By the
dot plot, the distribution of the observed data and any unusual observations in the
data can be visually displayed.TABULAR AND GRAPHICAL METHODS FOR DESCRIBING DATA 27
Age15 25 35 45 55 65
Figure 2.4: A dot plot of the data in Example 2.4.
Thestem-and-leaf plot provides a different way to display a numerical dataset by
listing all its observations in a plot. It is constructed as follows. First, select one or
more leading digits as stems, and the remaining digits as leaves. Second, list all stem
values in a vertical column. Third, draw a vertical line on the right-hand side of the
stem values, and list the leaf of each observation beside the corresponding stem value
on the right side of the vertical line. Finally, indicate the units of the stems and leaves
somewhere in the plot (e.g., at the lower-right corner). For the data in Example 2.4,
the tens digit of each observation can be chosen as the stem, and the ones digit as its
leaf. The resulting stem-and-leaf plot is shown in Figure 2.5.
1 | 899
2 | 022224579
3 | 13779
4 | 1358
5 | 36 Stem: tens digit
6 | 15 Leaf: ones digit
Figure 2.5: A stem-and-leaf plot of the data in Example 2.4.
Instead of displaying all observations of a dataset, the box plot only displays the
following ﬁve summary values of the dataset: the minimum X(1), the ﬁrst quartile
Q1, the median/tildewideX, the third quartile Q3, and the maximum X(n). It is constructed
as follows. First, draw a horizontal line and scale it properly. Second, construct a
rectangular box with its left edge at the ﬁrst quartile and its right edge at the third
quartile. Third, draw a vertical line segment inside the box at the location of the
median. Fourth, extend horizontal line segments from each end of the box to the
smallest and the largest observations of the data. For the data in Example 2.4, the
box plot is shown in Figure 2.6.28 BASIC STATISTICAL CONCEPTS AND METHODS
Age25 35 45 55 65
Figure 2.6: The box plot of the data in Example 2.4.
Table 2.3: A frequency table of the data in Example 2.4.
Class Interval Frequency Relative Frequency
[10,20) 3 0.12
[20,30) 9 0.36
[30,40) 5 0.20
[40,50) 4 0.16
[50,60) 2 0.08
[60,70) 2 0.08
2.6.3 Frequency histogram and density histogram
If observ ations in a dataset are discrete numerical and the number of their different
values is small, then a frequency table can be constructed in the same way as that
described in Subsection 2.6.1, with each different value as a category. In cases when
the observations in a dataset are discrete but the number of different values is quite
large, or when the observations are continuous numerical, it does not make much
sense to use each different value as a category when constructing a frequency table,
because the resulting table would be too large to convey any helpful information
about the data pattern. In such cases, an alternative method is to combine certain
observation values to form class intervals, and then construct a frequency table using
the class intervals.
As a demonstration, let us use the dataset in Example 2.4. For this dataset, let us
consider the class intervals: [10,20),[20,30),[30,40),[40,50),[50,60),[60,70). The
corresponding frequency table is shown in Table 2.3.
Afrequency histogram turns a frequency table into a graph in the following way.
First, draw a horizontal line, and mark the boundaries of the class intervals on it. Sec-
ond, draw a vertical line and scale it properly to represent frequencies. Third, draw a
rectangular bar for each class interval above the corresponding interval on the x-axis,
with its height equal to the corresponding frequency. The frequency histogram for
Table 2.3 is shown in Figure 2.7. From the histogram, it can be seen that the data areTABULAR AND GRAPHICAL METHODS FOR DESCRIBING DATA 29
not symmetrically distributed. Instead, the mode (i.e., the peak) of the histogram is
closer to the left end, compared to its distance to the right end; or, the right tail of the
histogram is longer than the left tail, implying the existence of a number of relatively
large observations in the data. By the way, from the deﬁnition of relative frequencies,
a histogram using frequencies and a histogram using the corresponding relative fre-
quencies would have exactly the same shape. Their only difference would be in the
scale of the heights of the rectangular bars. The latter histogram is sometimes called
a relative frequency histogram.
AgeFrequency
10 20 30 40 50 60 700 2 4 6 8
Figure 2.7: A frequency histogram of the data in Example 2.4.
Example 2.5 To monitor an aluminum smelter, 189 observations of the content of
SiO 2in its products are obtained. The data are summarized in Table 2.4, which is a
frequency table using 15 class intervals with the same length, and the corresponding
frequency histogram is shown in Figure 2.8(a). From the histogram, it can be seen
that there are only a small number of observations larger than or equal to 1. So, we
combine the last 11 intervals into a larger interval [1,3.75). The modiﬁed class inter-
vals and the corresponding frequencies and relative frequencies are shown in Table
2.5, and the frequency histogram using the modiﬁed intervals is shown in Figure
2.8(b). By comparing the two histograms in Figure 2.8, we may have two conﬂicting
impressions about the distribution of the same dataset. By Figure 2.8(a), it seems
that the chance to have an observation of SiO 2larger than 1 is really small. How-
ever, from Figure 2.8(b), we may have a different impression that the chance to have
such an observation is not that small. The main reason for the latter impression is
that the last class interval in Figure 2.8(b) is much longer than the other class inter-
vals, and the height of the bar above that interval is determined by the frequency of
all observations in that interval, which does not take the length of the interval into
account.30 BASIC STATISTICAL CONCEPTS AND METHODS
Table 2.4 Frequency table of the aluminum smelter data discussed in Example 2.5, using class
intervals with the same length.
Class Interval Frequency Relative Frequency
[0,0.25) 22 0.116
[0.25, 0.5) 70 0.370
[0.5, 0.75) 51 0.270
[0.75, 1) 23 0.122
[1,1.25) 8 0.042
[1.25, 1.5) 5 0.026
[1.5, 1.75) 2 0.011
[1.75, 2) 3 0.016
[2,2.25) 1 0.005
[2.25, 2.5) 1 0.005
[2.5, 2.75) 2 0.011
[2.75, 3) 0 0.000
[3,3.25) 0 0.000
[3.25, 3.5) 0 0.000
[3.5, 3.75) 1 0.005
SiO 2Frequency
0 1 2 30 10 20 30 40 50 60 70
(a)SiO 2Frequency
0 1 2 30 10 20 30 40 50 60 70
(b)
Figure 2.8 (a) Frequency histogram corresponding to Table 2.4. (b) Frequency histogram cor-
responding to Table 2.5 using class intervals with different lengths.
From Figure 2.8, it can be seen that the frequency or relative frequency histogram
works well only when the class intervals have the same length. Cases when the class
intervals have different lengths may give people a wrong impression about the data
distribution. To overcome this limitation, we deﬁne the density of a class interval by
density=relative frequency
interval length.
Then, a density histogram can be constructed in the same way as that of a frequencyTABULAR AND GRAPHICAL METHODS FOR DESCRIBING DATA 31
Table 2.5 Frequency table of the aluminum smelter data discussed in Example 2.5 using class
intervals with different lengths.
Class Interval Frequency Relative Frequency Density
[0,0.25) 22 0.116 0.464
[0.25, 0.5) 70 0.370 1.480
[0.5, 0.75) 51 0.270 1.080
[0.75, 1) 23 0.122 0.488
[1,3.75) 23 0.122 0.044
or relative frequency histogram, except that the height of each rectangular bar in a
density histogram is determined by the density of the corresponding class interval,
instead of by the frequency or relative frequency. Obviously, the density histogram
has the property that summation of the areas of all its rectangular bars is 1, which is
in parallel to the property of the density curve of a population distribution that the
area under the curve is 1.
The densities of the class intervals in Table 2.5 have been computed and presented
in the last column of that table. The corresponding density histogram is presented in
Figure 2.9, in which a solid curve has been added to sketch its shape. The solid curve
is often called a smoothed histogram, which provides an estimate of the population
density curve. From Figure 2.9, it can be seen that the chance to have an observation
ofSiO 2that is larger than 1 is indeed small, even in cases when we use unequal class
intervals.
SiO 2Density
0 1 2 30.0 0.5 1.0 1.5
Figure 2.9: A density histo gram corresponding to Table 2.5 with unequal class intervals.
From the above discussion, in cases when the class intervals have the same
length, a frequency histogram, the corresponding relative frequency histogram, and
the corresponding density histogram would all have the same shape and their only
difference is in the scale of the heights of the rectangular bars. However, in cases32 BASIC STATISTICAL CONCEPTS AND METHODS
when the class intervals have different lengths, as the above example demonstrated,
the frequency or relative frequency histogram should be avoided for possible confu-
sion, and the density histogram is the one that is appropriate to use.
Figure 2.10 presents several smoothed histograms with different shapes. In plots
(a), (c), and (d), each of the smoothed histograms has a single peak (or mode). Such
histograms are called unimodal histograms. The smoothed histogram in plot (b) has
two modes, and it is called a bimodal histogram. If a smoothed histogram has more
than two modes, then it is called a multimodal histogram. The smoothed histograms
in plots (a) and (b) are symmetric, and the ones in plots (c) and (d) are unimodal and
skewed. If a unimodal histogram has a longer right tail, compared to its left tail, then
we say that it is skewed to the right, or positively skewed. If its left tail is longer than
its right tail, then we say that it is skewed to the left, or negatively skewed. So, the
one in plot (c) is skewed to the right and the one in plot (d) is skewed to the left.
(a) (b)
(c) (d)
Figure 2.10 Smoothed histo grams with different shapes. (a) Symmetric and unimodal. (b)
Symmetric and bimodal. (c) Skewed to the right and unimodal. (d) Skewed to the left and
unimodal.PARAMETRIC STATISTICAL INFERENCES 33
2.7 P arametric Statistical Inferences
As discussed in the previous two sections, a sample from a population of interest
carries useful information about the population. After a sample is obtained, the next
question is how to properly estimate the population distribution or its parameters
based on the sample. After an estimator is obtained, we also need to evaluate its
performance, so that the best one can be chosen if multiple estimators are available.
These are the major goals of statistical inference. In this section, we brieﬂy introduce
some basic concepts and methodologies of statistical inference in cases when the
population distribution has a parametric form.
2.7.1 Point estimation and sampling distribution
In cases when a population distribution has a parametric form with one or more pa-
rameters, the population distribution itself and all of its summary measures (e.g.,
mean and variance) are uniquely determined by the population distribution parame-
ters. So, in such cases, estimation of the population distribution parameters is impor-
tant. Based on a sample {X1,X2,..., Xn}, some commonly used estimators are listed
below.
•In cases when the population distribution is N(µ,σ2), the sample mean Xis a
good estimator of the population mean µ, the sample variance s2is a good es-
timator of the population variance σ2, and the sample standard deviation sis a
reasonable estimator of the population standard deviation σ.
•In cases when the population distribution is Bernoulli with πbeing the proba-
bility of success (S) (cf., Subsection 2.4.1), a good estimator of πis the sample
proportion of S, deﬁned by
p=the number of S’s in the sample
n.
The parameter πis also called the population proportion of S, as mentioned in
Section 2.5. Clearly, if we use 1 to denote S and 0 to denote F, then pis just X.
All estimators mentioned above are calculated from the sample {X1,X2,..., Xn}.
In statistics, any quantity that is calculated from the sample and uniquely determined
by the sample is called a statistic. Therefore, X,s2,s, and pare all statistics.
To estimate a speciﬁc population parameter θ(e.g., θis the population mean or
standard deviation), an appropriate statistic should be chosen as an estimator. It has
become a convention in the literature to put a hat above the parameter to denote its
estimator. So, /hatwideθis an estimator of θ. Although/hatwideθis a function of the sample, this
is often not explicit in notation, for simplicity. To estimate θby/hatwideθ, we use a single-
valued statistic calculated from the sample (i.e., /hatwideθ) for estimating a single-valued
parameter of the population (i.e., θ). This parameter estimation method is therefore
called point estimation in the literature, and the estimator is called a point estimator.
For instance, Xis a point estimator of µ, and s2is a point estimator of σ2.
Because the sample is random, any statistic computed from the sample, includ-
ing all point estimators mentioned above, is also random. Thus, a point estimator has34 BASIC STATISTICAL CONCEPTS AND METHODS
its own distribution, which is called the sampling distribution. To assess the accu-
racy of a point estimator for estimating a parameter, we need to study its sampling
distribution, especially the mean and variance of the sampling distribution.
In cases when the population distribution is N(µ,σ2), it can be proved that the
sampling distributions of the sample mean and sample variance have the properties
summarized in the box below.
Properties of the Sampling Distributions of Xands2
Assume that the population distribution is N(µ,σ2), and Xands2are the sam-
ple mean and sample variance of a simple random sample {X1,X2,..., Xn}from
the population. Then, their sampling distributions have the following properties:
(i)X∼N(µ,σ2/n),
(ii)(n−1)s2/σ2∼χ2
n−1, and
(iii)Xands2are independent of each other.
By combining all these three properties and by the deﬁnition of a tdistrib ution
(cf., Subsection 2.3.3), we have
T=X−µ
s/√n∼tn−1. (2.18)
In cases when the population distribution is unknown, the sampling distribution
ofXwould be asymptotically normal. Namely, it is asymptotically true that
X−µ
σ/√n∼N(0,1),
where “asymptotically true” means that the distribution of (X−µ)/(σ/√n)is closer
and closer toN(0,1)when the sample size nincreases. This result plays an important
role in statistics, because the population mean is often the population characteristic
that we are interested in estimating and this result gives a general conclusion about its
point estimator Xthat it is always asymptotically normal no matter what is the real
population distrib ution. Because of its importance, this result is called the Central
Limit Theorem (CLT) in the statistical literature, and it is formally stated in the box
below.
Central Limit Theorem
Assume that {X1,X2,..., Xn}is a simple random sample from a population,
andXis its sample mean. Then the sampling distribution of (X−µ)/(σ/√n)
conv erges to N(0,1)when nincreases.
The CLT provides an intuitive explanation about the phenomenon that many vari-
ables in our daily life, including height, weight, blood pressure readings, and so forth,
would roughly follow normal distributions. For instance, our height is affected by ourPARAMETRIC STATISTICAL INFERENCES 35
parents’ heights, grandparents’ heights, our food intake and other nutritional factors,
environmental factors, and many other factors. Therefore, it is a weighted average of
many different factors, similar to X, which is an average of nobservations. By the
CLT, our height would roughly have a normal distribution. The CLT also explains
why the normal distribution family is so popular in statistics. As pointed out in the
previous paragraph, many statistical inferences involve the sample mean Xfor esti-
mating the population mean µ. By the CLT, the sampling distribution of Xis close
to normal in all cases, as long as the sample size is large.
In practice, we need to determine a threshold value for the sample size n, so that
ncan be regarded as “large” and consequently the sampling distribution of Xcan be
treated as a normal distribution. Of course, the asymptotic behavior of the sampling
distribution of Xdepends on the true population distribution. Intuitively, if the true
population distrib ution is very skewed, then the sampling distribution of Xwould
be slo w in converging to a normal distribution. On the other hand, if the true popu-
lation distribution is already quite close to a normal distribution, then the sampling
distribution of Xwould be fast in converging to a normal distribution. However, the
true population distribution is usually unknown in practice, making the problem of
choosing the threshold value complicated. Based on much research, a commonly
used threshold value for nis 30. By this threshold value, the sample size can be
regarded as “large” if n≥30.
Example 2.6 Assume that {X1,X2,..., Xn}is a simple random sample from a popu-
lation with mean 2 and variance 9, and n =36. Then, X is asymptotically distributed
as N(2,1/4) by the CLT. So, we can compute different probabilities related to X. For
instance,
P(X>3) = P/parenleftbiggX−2
1/2>3−2
1/2/parenrightbigg
≈P(Z>2)= 0.0228,
where Z denotes a random variable with the standard normal distribution, and “≈ ”
denotes the asymptotic equality. As a comparison, we usually cannot easily compute
probabilities related to a distribution if we do not know its mathematical expression.
Therefore, the CLT is helpful in such cases.
In cases when the population distribution is Bernoulli with πbeing the population
proportion of S, {X1,X2,..., Xn}is a simple random sample from the population,
and S and F are represented by 1 and 0, respectively. The sampling distribution of
∑n
i=1XiisBinomial(n,π), and the sampling distribution of the sample proportion
p=X=∑n
i=1Xi/ncan be determined accordingly. When the sample size is large
in the sense that both nπandn(1−π)are large, by the CLT, the distribution of p
would be asymptotically normal. In other words, when the sample size is large, the
distribution of pcan be regarded as N(π,π(1−π)/n). In practice, the sample size
can be regarded as “large” if nπ≥10 and n(1−π)≥10.
For a given population parameter, there could be multiple point estimators. Let
us revisit Example 2.2, in which a state government wants to estimate the population
mean salary µof faculty members of high education institutes in that state. In that36 BASIC STATISTICAL CONCEPTS AND METHODS
problem, dif ferent people can come up with different point estimators of µ. For in-
stance, assume that the following three point estimators have all been proposed for
estimating µ:
•one person prefers to use the ﬁrst observation X1in the sample to estimate µ,
•another person thinks that X1+5 would be a more reasonable estimator of µ, and
•the third person has some statistical knowledge and wants to use the sample mean
Xto estimate µ.
To choose among multiple point estimators, or to convince people why one point
estimator is better than another point estimator, we need a criterion for evaluating the
performance of a point estimator. For estimating a population parameter θ, if a point
estimator/hatwideθsatisﬁes the condition that the mean of its sampling distribution, denoted
asµ/hatwideθ, equals θ, i.e.,
µ/hatwideθ=θ
for all values of θ, then/hatwideθis called an unbiased estimator ofθ. Otherwise, the esti-
mator is biased and the bias is deﬁned by
Bias/parenleftig
/hatwideθ,θ/parenrightig
=µ/hatwideθ−θ.
By the above deﬁnition, on average, an unbiased estimator equals the parameter to
estimate. Therefore, in practice, people often require a good point estimator to be
unbiased. In the faculty salary example mentioned in the previous paragraph, both
the ﬁrst and the third estimators are unbiased estimators, and the second estimator is
biased. So, by the criterion of unbiasedness, the second estimator should be avoided.
To compare two unbiased estimators, the one with a smaller variance is obviously
a better estimator, because its sampling distribution would have a smaller spread and
consequently that estimator is generally closer to the true value of the population
parameter. Therefore, among all unbiased estimators of θ, the one with the smallest
variance should be the best unbiased estimator. This estimator is often called the min-
imum variance unbiased estimator (MVUE). It can be checked that, if the population
distribution is normal, then Xis the MVUE for estimating the population mean µ.
Therefore, in the faculty salary example, if it is reasonable to assume that the popu-
lation distribution of faculty members’ salary is normal, then the estimator Xshould
be the best unbiased estimator among all unbiased estimators.
Another commonly used criterion for choosing a good point estimator is the fol-
lowing mean squared error (MSE):
MSE/parenleftig
/hatwideθ,θ/parenrightig
= E/parenleftig
/hatwideθ−θ/parenrightig2
=E/parenleftig
/hatwideθ−µ/hatwideθ+µ/hatwideθ−θ/parenrightig2
=σ2
/hatwideθ+Bias2/parenleftig
/hatwideθ,θ/parenrightig
.
The MSE criterion measures the averaged, squared distance between the point es-
timator/hatwideθand the parameter θ. By this criterion, the best point estimator has thePARAMETRIC STATISTICAL INFERENCES 37
smallest MSE value among all possible point estimators. Obviously, the MSE cri-
terion makes a trade-off between bias and variance of a point estimator. The best
point estimator by this criterion may not be unbiased, and the MVUE estimator may
not be the best point estimator either, because the MVUE estimator has the small-
est MSE value among all unbiased point estimators only, instead of among all point
estimators.
Although it is not explicit in notation, both Bias( /hatwideθ,θ)and MSE(/hatwideθ,θ)depend
on the sample size n. Generally speaking, when nis larger, the sample carries more
information about the population, so it is natural to expect that both Bias( /hatwideθ,θ)and
MSE(/hatwideθ,θ)would be smaller. If an estimator /hatwideθofθis biased but the bias converges
to zero as the sample size increases, then it is called an asymptotically unbiased
estimator. If/hatwideθsatisﬁes the condition that
lim
n→∞MSE/parenleftig
/hatwideθ,θ/parenrightig
=0,
then we say that /hatwideθisL2consistent.
“Consistency” is a kind of large-sample property of a point estimator. There are
several different versions of consistency in the literature. If the cdf of /hatwideθconverges to
the cdf of the constant θat all continuity points of the latter cdf, then /hatwideθis said to be
consistent in distribution. If for any constant ρ>0,
lim
n→∞P/parenleftig
|/hatwideθ−θ|>ρ/parenrightig
=0,
then/hatwideθis said to be consistent in probability. Another commonly used consistency is
deﬁned as follows: if
P/parenleftig
lim
n→∞/hatwideθ=θ/parenrightig
=1,
then/hatwideθis said to be almost surely (a.s.) consistent. Based on some routine mathemat-
ical manipulations, it is easy to check the following relations among the four types
of consistency deﬁned above.
•If/hatwideθis consistent in probability, then it must also be consistent in distribution.
•If/hatwideθisL2consistent or a.s. consistent, then it must also be consistent in probability.
•There are L2consistent estimators that are not a.s. consistent, and there are a.s.
consistent estimators that are not L2consistent.
For each type of consistency mentioned above, there is a convergence rate as-
sociated with it, which tells us how fast the related convergence is. For example, if
nνMSE(/hatwideθ,θ)=O(1) for some positive constant ν, then we say that /hatwideθisL2consis-
tent with the convergence rate O(n−ν). Here, the big Onotation an=O(b n)has been
used, where {an}and{bn}are two sequences of nonnegative numbers. Its formal
deﬁnition is that there exist two positive constants AandBsuch that A≤an/bn≤B.
Thus, if an=O(b n)andbnconverges to 0 as ntends to inﬁnity, then analso con-
verges to 0 with the same convergence rate. Sometimes, the small onotation will also
be used. By deﬁnition, the expression an=o(b n)means that lim n→∞an/bn=0. So,
ifan=o(b n)andbnconverges to 0 as ntends to inﬁnity, then analso converges to38 BASIC STATISTICAL CONCEPTS AND METHODS
0 with a faster rate. For other types of consistency, the convergence rate can be dis-
cussed similarly. More systematic discussion about large-sample properties of point
estimators can be found in textbooks such as Ash (1972) and Chung (2001).
2.7.2 Maximum likelihood estimation and least squares estimation
In statistics, maximum likelihood estimation andleast squares estimation provide
two general methods for deriving point estimators of population parameters, which
are brieﬂy introduced in this subsection.
Assume that a population distribution has a pdf with the parametric form
f(x;θ1,..., θr), where θ1,..., θrarerunknown population parameters. To estimate
these population parameters based on a simple random sample {X1,X2,..., Xn}, the
maximum likelihood estimation procedure is based on the following likelihood func-
tion:
L(θ1,..., θr;X1,X2,..., Xn)=Πn
i=1f(Xi;θ1,..., θr). (2.19)
The likelihood function L(θ1,..., θr;X1,X2,..., Xn)is treated as a function of
the unknown parameters θ1,..., θronly. The sample {X1,X2,..., Xn}is assumed
to be given. From the discussion about the pdf in Section 2.2, the value of
f(x;θ1,..., θr)∆xis roughly equal to P(X∈[x,x+∆x]), where ∆xis a small pos-
itive number. So the likelihood function is proportional to the likelihood that the
observations in the sample take values around the observed sample {X1,X2,..., Xn}.
The maximum likelihood estimators (MLEs)/hatwideθ1,...,/hatwideθrofθ1,..., θrare deﬁned
by the maximizers of the likelihood function L(θ1,..., θr;X1,X2,..., Xn). So, the
likelihood that the observations in the sample take values around {X1,X2,..., Xn}
reaches the maximum when the parameters equal their MLEs, which is reasonable
because the sample {X1,X2,..., Xn}is assumed to have been observed before param-
eter estimation.
In practice, it is often more convenient to work with the logarithm of the like-
lihood function because the likelihood function has an exponential form in many
cases. Then, the MLEs of θ1,..., θrare the solutions to ˜θ1,..., ˜θrof the following
maximization problem:
max
˜θ1,...,˜θr∈Rn
∑
i=1log/bracketleftbig
f(Xi;˜θ1,..., ˜θr)/bracketrightbig
. (2.20)
In cases when the population has a normal distribution N(µ,σ2), the likelihood
function is
L(µ,σ2;X1,X2,..., Xn) = Πn
i=1/bracketleftbigg1√
2πσexp/parenleftbigg
−(Xi−µ)2
2σ2/parenrightbigg/bracketrightbigg
=/parenleftbigg1√
2πσ/parenrightbiggn
exp/parenleftigg
−n
∑
i=1(Xi−µ)2
2σ2/parenrightigg
.
The log-likelihood function is
log/parenleftbig
L(µ,σ2;X1,X2,..., Xn)/parenrightbig
=−nlog/parenleftig√
2πσ/parenrightig
−n
∑
i=1(Xi−µ)2
2σ2.PARAMETRIC STATISTICAL INFERENCES 39
It is easy to check that the maximization problem (2.20) with this log-likelihood
function gives the MLEs
/hatwideµ=X,/hatwideσ2=1
nn
∑
i=1(Xi−X)2.
So,Xis both the MVUE and the MLE of µ. The sample variance s2is slightly dif-
ferent from the above MLE of σ2in that s2=n
n−1/hatwideσ2. Because s2is an unbiased
estimator of σ2,/hatwideσ2is biased, although the bias is −σ2/n, which tends to 0 when n
increases. For this reason, in practice, most people prefer to use the unbiased estima-
tors2for estimating σ2, instead of its MLE /hatwideσ2.
In cases when the population distribution is discrete, the likelihood function can
still be deﬁned by (2.19), except that the pdf needs to be replaced by the probability
distribution function. For instance, when the probability distribution is Bernoulli with
πbeing the probability of S and we use 1 to denote S and 0 to denote F, the likelihood
function is deﬁned by
L(π;X1,X2,..., Xn) = Πn
i=1/bracketleftbig
πXi(1−π)1−Xi/bracketrightbig
=π∑n
i=1Xi(1−π)n−∑n
i=1Xi.
Then, it is easy to check that the MLE of πis/hatwideπ=X, which is also the sample
proportion of S.
Besides MLE, least squares (LS) estimation is another general methodology for
estimating population parameters. Usually, LS estimation is used for parametric re-
gression modeling. Assume that there are two variables XandY, and we are inter-
ested in building a numerical relationship between them. Between XandY, assume
thatYis a variable to predict based on the built relationship, and Xis a variable to
predict from. Then, Yis often called a response variable, and Xis often called an
explanatory variable orpredictor. We further assume that XandYfollow a linear
regression model
Y=β0+β1x+ε, (2.21)
where β0+β1xis the linear regression function, which can be written as E( Y|X=
x)=β0+β1x, denoting the assumption that the mean value of Ywhen Xis given at x
is assumed to be a linear function of x,β0andβ1are regression coefﬁcients, and εis
a random error term. Now, assume that we have nobservations of (X,Y), denoted as
{(xi,Yi),i=1,2,..., n}, and they are all generated from the linear regression model
(2.21). Namely,
Yi=β0+β1xi+εi,i=1,2,..., n,
where{εi,i=1,2,..., n}are random errors at the design points {xi,i=1,2,..., n}.
For the error terms, we conventionally assume that they are i.i.d. and normally dis-
tributed, so that εi∼N(0,σ2), for all i=1,2,···,n, and the common variance σ2is
usually unknown. All these conventional assumptions can be summarized by the four
letters in LINE, where L denotes the assumption that the regression function is linear,40 BASIC STATISTICAL CONCEPTS AND METHODS
I denotes the assumption that the error terms are independent, N denotes the assump-
tion that all error terms are normally distributed, and E denotes the assumption that
all error terms have equal variance σ2.
A widely used criterion for measuring the goodness-of-ﬁt of a candidate estima-
torb0+b1xof the true linear regression function β0+β1xis the residual sum of
squares (RSS), deﬁned by
RSS(b0,b1)=n
∑
i=1[Yi−(b0+b1xi)]2.
The LS estimators of β0andβ1are deﬁned to be the minimizers of RSS(b 0,b1). They
can be calculated by the following formulas:
/hatwideβ1=∑n
i=1(xi−x)/parenleftbig
Yi−Y/parenrightbig
∑n
i=1(xi−x)2
/hatwideβ0=Y−/hatwideβ1x, (2.22)
where xandYare the sample means of xandYvalues, respectively. Then, the esti-
mated regression model is
/hatwideY=/hatwideβ0+/hatwideβ1x.
Under the four conventional assumptions (i.e., LINE), it can be checked that
/parenleftigg/hatwideβ0
/hatwideβ1/parenrightigg
∼N/parenleftigg/parenleftbigg
β0
β1/parenrightbigg
,σ2/parenleftigg
1
n+x2
sxx,−x
sxx
−x
sxx,1
sxx/parenrightigg/parenrightigg
, (2.23)
where sxx=∑n
i=1(xi−x)2. For σ2, it is often estimated by
/hatwideσ2=1
n−2n
∑
i=1/bracketleftig
Yi−/parenleftig/hatwideβ0+/hatwideβ1xi/parenrightig/bracketrightig2
, (2.24)
which is the so-called residual mean squares (RMS) of the estimated regression
model. For the variance estimator in (2.24), by (2.23), we have
(n−2)/hatwideσ2
σ2∼χ2
n−2. (2.25)
From the above description, it can be seen that the LS estimation does not use
any information about the distribution of Y, which is an advantage, compared to the
maximum likelihood estimation. Under the conventional assumptions LINE, Yi∼
N(β0+β1xi,σ2), for i=1,2,..., n. Therefore, β0,β1andσ2can also be estimated
by their MLEs. As a matter of fact, it can be checked that the LS estimators of β0
andβ1given in (2.22) are the same as their MLEs, and the MLE of σ2is
n−2
n/hatwideσ2,
where/hatwideσ2is the estimator deﬁned in (2.24). By the way, /hatwideσ2is an unbiased estimator
ofσ2, and the MLE of σ2is biased.PARAMETRIC STATISTICAL INFERENCES 41
2.7.3 Conﬁdence intervals and hypothesis testing
Besides point estimation discussed in the previous subsection, there are two other
methods of statistical inference about a population parameter. The ﬁrst method uses
conﬁdence intervals, by which a population parameter θis estimated by an interval.
Suppose that a point estimator /hatwideθofθhas a normal distribution with mean θand
variance σ2
/hatwideθ. Then,
Z=/hatwideθ−θ
σ/hatwideθ∼N(0,1)
and
P/parenleftig
/hatwideθ−Z1−α/2σ/hatwideθ<θ</hatwideθ+Z1−α/2σ/hatwideθ/parenrightig
=1−α,
where αis a given number between 0 and 1, and Z1−α/2is the(1−α/2)-th quantile
of the standard normal distribution (cf. Figure 2.1(b)), deﬁned by P(Z≤Z1−α/2)=
1−α/2. Therefore, the random interval
/parenleftig
/hatwideθ−Z1−α/2σ/hatwideθ,/hatwideθ+Z1−α/2σ/hatwideθ/parenrightig
has a 100(1 −α)% chance to cover the true value of θ. This interval is called a
100(1−α)%conﬁdence interval (CI) forθ, and the number 100(1 −α)% is called
theconﬁdence level. For simplicity, the above CI is often written as
/hatwideθ±Z1−α/2σ/hatwideθ.
Usually, the standard deviation σ/hatwideθhas some unknown population parameters, such as
the population standard deviation σ, involved. So the above CI formula can be used
only after these parameters are replaced by their point estimators. In other words, the
standard deviation σ/hatwideθneeds to be estimated by the standard error /hatwideσ/hatwideθin which the
unknown parameters have been replaced by their point estimators.
In cases when a population distribution is N(µ,σ2)and{X1,X2,..., Xn}is a
simple random sample from this population, by the discussion in Subsection 2.7.1,
X∼N(µ,σ2/n). Therefore, in cases when σis known,
Z=X−µ
σ/√n∼N(0,1), (2.26)
and the 100(1−α)% CI for µis
X±Z1−α/2σ√n.
In cases when σis unknown, it should be replaced by the sample standard deviation
sin (2.26). Because of the extra randomness added by this replacement, the resulting
statistic has a tdistribution with df equal to n−1. Namely,
T=X−µ
s/√n∼tn−1. (2.27)42 BASIC STATISTICAL CONCEPTS AND METHODS
See (2.18) and the related discussion in Subsection 2.7.1. So, based on (2.27), the
100(1−α)% CI for µis
X±t1−α/2(n−1)s√n, (2.28)
where t1−α/2(n−1)is the(1−α/2)-th quantile of the tn−1distribution.
In applications, the exact distribution of /hatwideθis often unknown for a ﬁxed sample
size. If its asymptotic distribution, which is the limit distribution of /hatwideθwhen ntends to
inﬁnity, can be derived, then the CI for θcan be constructed based on this asymptotic
distribution. Of course, in such cases it is only asymptotically true that the CI has
100(1−α)% chance to cover the true value of θ. In cases when we are interested
in estimating the population mean µ(i.e., θ=µ), if the population distribution is
unknown, or it is known but non-normal, then by the CLT, (2.26) is asymptotically
true. Namely, when the sample size nis large (i.e., n≥30), the CI formula (2.28)
can still be used, in which we can use either t1−α/2(n−1)orZ1−α/2because the
two quantities should be almost the same in such cases. See a related discussion in
Subsection 2.3.3.
In cases when the population distribution is Bernoulli with πbeing the probabil-
ity of success and when the sample size is large (i.e., n/hatwideπ≥10 and n(1−/hatwideπ)≥10),
by similar arguments to those in the previous two paragraphs, the large-sample
100(1−α)% CI for πis
/hatwideπ±Z1−α/2/radicalbigg
/hatwideπ(1−/hatwideπ)
n, (2.29)
where/hatwideπis the sample proportion of success.
Another method of statistical inference about a population parameter involves
testing hypotheses. In our daily life, we often make a statement or hypothesis about a
population parameter. For example, some reports claim that smoking would increase
the chance of lung cancer under a general circumstance. In this example, all smok-
ers constitute the population. Assume that the prevalence rate of lung cancer in this
population is an unknown parameter π, and that the prevalence rate of the same dis-
ease among all non-smokers is known to be π0. Then, the above statement basically
says that π>π0. A major goal of many research projects is to collect data for ver-
ifying such a hypothesis. If the hypothesis is supported by the data obtained from
one or more repeated experiments, then it becomes a new theory. In statistics, the
hypothesis that we want to validate is called an alternative hypothesis. Usually, an
alternative hypothesis represents a potential new theory, new method, new discovery,
and so forth. It is a competitor to a so-called null hypothesis, which often represents
existing theory, existing method, existing knowledge, and so forth. Because the null
hypothesis is usually veriﬁed in the past, it is initially assumed true. It is rejected only
in cases when the observed data from the population in question provide convincing
evidence against it.
By convention, the null hypothesis is denoted by H0, and it usually takes the
equality form
H0:θ=θ0,
where θ0is the hypothesized value of the population parameter θ. The alternativePARAMETRIC STATISTICAL INFERENCES 43
hypothesis is denoted by H1orHa, and it can take one of the following three forms:
H1:θ>θ0
H1:θ<θ0
H1:θ/ne}ationslash=θ0.
The ﬁrst form is called right-sided or right-tailed, the second one is called left-sided
or left-tailed, and the last one is called two-sided or two-tailed.
To test whether H0should be rejected in favor of H1, we need a criterion con-
structed from the observed data. To this end, assume that {X1,X2,..., Xn}is a simple
random sample from the population of interest and that /hatwideθis a point estimator of
θ. To describe how to construct a hypothesis testing procedure, let us assume that
/hatwideθ∼N(θ,σ2
/hatwideθ)and that σ2
/hatwideθdoes not include any unknown parameters. Then, in cases
when H0is true, we have
Z=/hatwideθ−θ0
σ/hatwideθ∼N(0,1).
Let us assume that the alternative hypothesis of interest is right-sided, and the ob-
served value of Zis denoted by Z∗. Then, the probability
PH0(Z≥Z∗)
would tell us the likelihood that we can observe Z∗or values of Zthat are more
inconsistent with H0when H0is assumed true, where PH0denotes the probability
under H0. The probability PH0(Z≥Z∗)is called the p-value and the statistic Zis
called a test statistic. The p-value is deﬁned by PH0(Z≤Z∗)when H1is left-sided,
and by PH0(|Z|≥|Z∗|)when H1is two-sided.
From the deﬁnition of p-value, the data provide more evidence against H0if the
p-value is smaller. Then, the question becomes: how small is small? To answer this
question, we usually compare the calculated p-value with a pre-speciﬁed signiﬁcance
level, denoted conventionally as α. If the p-value is smaller than or equal to α, then
we reject H0and conclude that the data have provided signiﬁcant evidence to support
H1. Otherwise, we fail to reject H0and conclude that there is no signiﬁcant evidence
in the data to support H1. This process of decision making is called hypothesis testing.
For a given signiﬁcance level α, an alternative approach to perform hypothesis
testing is to compare the observed value Z∗of the test statistic Zwith its α-critical
value. In the case considered above when Z=/hatwideθ−θ0
σ/hatwideθ∼N(0,1), its α-critical value is
deﬁned by Z1−αif the alternative hypothesis H1is right-sided, by ZαifH1is left-
sided, and by Z1−α/2ifH1is two-sided. Then, the null hypothesis H0is rejected
when Z∗>Z1−α,Z∗<Zα, and|Z∗|>Z1−α/2, respectively, for the three types of
H1considered above. It is easy to check that decisions made by the two approaches
are actually equivalent to each other. In applications, the p-value approach is often
preferred because it provides us decisions regarding whether H0should be rejected
at a given signiﬁcance level and gives us a quantitative measure of the strength of
evidence in the observed data that is against H0as well.44 BASIC STATISTICAL CONCEPTS AND METHODS
In our decision making using any hypothesis-testing procedure, mistakes are in-
evitable. There are two types of mistakes, or, more conventionally, two types of errors
that we can make. Type I error refers to the case in which H0is rejected when it is
actually true. Type II error refers to the case in which H0fails to be rejected when it
is actually false. The probabilities of type I and type II errors are denoted by αandβ,
respectively. Note that αis used to denote both the signiﬁcance level and the proba-
bility of type I error because these two quantities are the same in most situations.
Intuitively, an ideal hypothesis-testing procedure should have small αand small
β. However, in reality, if αis kept small, then βwould be large, and vice versa. To
handle this situation, a conventional strategy is to control αat some ﬁxed level, and
letβbe as small as possible. By this strategy, H0is protected to a certain degree
because the chance to reject it when it is actually true cannot exceed the ﬁxed level
ofα. This is reasonable in the sense that H0often represents existing methods or
knowledge, and it has been justiﬁed in the past. Selection of αusually depends on
the consequence of the type I error. If the consequence is serious, then a small α
should be chosen. Otherwise, a relatively large value could be chosen. Commonly
used αvalues include 0.1, 0.05, 0.01, 0.005, and 0.001. A default αvalue adopted
by most scientiﬁc communities is 0.05.
From the above discussion, it can be seen that a major step for solving a
hypothesis-testing problem is to ﬁnd an appropriate test statistic, which should have
the property that its distribution under H0, or its null distribution, is known or can
be computed. For a given hypothesis-testing problem, different testing procedures
are possible. In statistics, we usually only consider the procedures whose type I er-
ror probabilities are all below a given level (i.e., α). Among those procedures, the
one with the smallest type II error probability β, or equivalently the largest power,
deﬁned to be 1 −β, is the best.
A general methodology for deriving a testing procedure for a hypothesis-testing
problem is the likelihood ratio test (LRT) described below. Let L(θ;X1,X2,..., Xn)
be the likelihood function, Θ0be the set of θvalues under H0, and Θ1be the set of
θvalues under H1. Consider the following ratio of two maximum likelihoods:
Λ(X 1,X2,..., Xn)=max θ∈Θ0L(θ;X1,X2,..., Xn)
max θ∈Θ0/uniontextΘ1L(θ;X1,X2,..., Xn). (2.30)
Obviously, it is always true that 0 ≤Λ(X 1,X2,..., Xn)≤1. In cases when H0is true,
the two maximum likelihoods in (2.30) should be close to each other; consequently,
Λ(X 1,X2,..., Xn)is close to 1. Otherwise, Λ(X 1,X2,..., Xn)should be small. There-
fore, we can make decisions about the hypotheses H0andH1using the LRT statistic
Λ(X 1,X2,..., Xn), and reject H1in cases when Λ(X 1,X2,..., Xn)is too small. Wilks
(1938) showed that, under some regularity conditions, it was asymptotically true that
−2log(Λ(X 1,X2,..., Xn))H0∼χ2
d f, (2.31)
whereH0∼χ2
d fmeans “has the χ2
d fdistribution under H0,” and d fequals the differ-
ence in dimensionality of Θ0andΘ1. Then, in large sample cases, H1can be rejectedPARAMETRIC STATISTICAL INFERENCES 45
at the signiﬁcance level of αif the observed value of −2log(Λ(X 1,X2,..., Xn))is
larger than the (1−α)-th quantile of the χ2
d fdistribution. In cases when multiple
parameters are involved in the testing problem, the LRT test can be described in a
similar way. It has been demonstrated in the literature that LRT tests have certain de-
sirable statistical properties. For a related discussion, see Casella and Berger (2002)
and Lehmann and Romano (2005).
When the population distribution is N(µ,σ2), the null hypothesis is H0:µ=µ0,
andσis known, a commonly used test statistic is
Z=X−µ0
σ/√nH0∼N(0,1).
In such cases, it can be checked that
−2log(Λ(X 1,X2,..., Xn))
=∑n
i=1(xi−µ0)2−∑n
i=1(xi−X)2
σ2
=n/parenleftbiggX−µ0
σ/parenrightbigg2
=Z2.
Therefore, the test based on Zand the LRT test are exactly the same when the alter-
native hypothesis H1is two-sided. Also, the result (2.31) is exact in such cases. In
cases when σis unknown, it should be replaced by swhen deﬁning the test statistic
Z. The resulting test statistic and its null distribution are
T=X−µ0
s/√nH0∼tn−1. (2.32)
In cases when the population distribution is non-normal, the test statistic in (2.32)
can still be used, as long as the sample size nis large (i.e., n≥30), because of the
central limit theorem discussed in Subsection 2.7.1. In such cases, the asymptotic
null distribution of TisN(0,1), to which the tn−1distribution is close. Therefore,
either distribution can be used when computing the p-value.
In cases when the population distribution is Bernoulli with πbeing the probabil-
ity of success, the null hypothesis is H0:π=π0, and the sample size is large (i.e.,
nπ0≥10 and n(1−π0)≥10), a commonly used test statistic is
Z=/hatwideπ−π0/radicalbig
π0(1−π0)/nH0∼N(0,1), (2.33)
where π0is the hypothesized value of π, and/hatwideπis the sample proportion of success.
Of course, the null distribution speciﬁed in (2.33) is only asymptotically true in such
cases.
In certain applications, we need to compare two populations with regard to a
speciﬁc population characteristic (e.g., the population mean). To this end, assume46 BASIC STATISTICAL CONCEPTS AND METHODS
that{X11,X12,..., X1n1}and{X21,X22,..., X2n2}are two samples from the two pop-
ulations, respectively, and that the two samples are independent of each other. The
sample means and the sample variances of the two samples are denoted as X1,X2,s2
1,
ands2
2. Ifwe are interested in comparing the two population means µ1andµ2, then
the null and alternative hypotheses would be
H0:µ1−µ2=δ0 versus H1:µ1−µ2/ne}ationslash=δ0(>δ0,<δ0), (2.34)
where δ0is a given number, and µ1−µ2/ne}ationslash=δ0(>δ0,<δ0)denotes one of the three
forms: µ1−µ2/ne}ationslash=δ0,µ1−µ2>δ0, and µ1−µ2<δ0. In most cases, we are interested
in the case when δ0=0. In such cases, H0in (2.34) says that the two population
means are the same. To test the above hypotheses, it is natural to use X1−X2, which
is agood point estimator of µ1−µ2, according to the related discussion about the
sample mean in one-population cases (cf., Subsections 2.7.1 and 2.7.2).
In cases when the two population distributions are N(µ1,σ2
1)andN(µ2,σ2
2), it is
easy to check that
Z=(X1−X2)−(µ1−µ2)/radicalig
σ2
1/n1+σ2
2/n2∼N(0,1).
In such cases, if both σ2
1andσ2
2are known, then a 100(1 −α)% CI for µ1−µ2is
(X1−X2)±Z1−α/2/radicalig
σ2
1/n1+σ2
2/n2,
and a good test statistic for the hypotheses in (2.34) is
Z=(X1−X2)−δ0/radicalig
σ2
1/n1+σ2
2/n2H0∼N(0,1).
Of course, in practice, the two population variances σ2
1andσ2
2are often un-
known. If the two population distributions are still N(µ1,σ2
1)andN(µ2,σ2
2)and both
σ2
1andσ2
2are unknown, then we have
T=(X1−X2)−(µ1−µ2)/radicalig
s2
1/n1+s2
2/n2∼tdf, (2.35)
where
df=(V1+V2)2
V2
1/(n 1−1)+ V2
2/(n2−1), (2.36)
V1=s2
1/n1, and V2=s2
2/n2. Based on the statistic Tin (2.35), the 100(1 −α)% CI
forµ1−µ2is
(X1−X2)±t1−α/2(d f)/radicalig
s2
1/n1+s2
2/n2,PARAMETRIC STATISTICAL INFERENCES 47
where t1−α/2(d f)is the(1−α/2)-th quantile of the tdfdistribution with df deﬁned
by (2.36). For testing hypotheses in (2.34), a good test statistic is
T=(X1−X2)−δ0/radicalig
s2
1/n1+s2
2/n2H0∼tdf. (2.37)
The test using the test statistic in (2.37) is often called the two independent sample
t-test. In certain cases, it is reasonable to assume that σ2
1=σ2
2=σ2. In such cases,
we can estimate σ2by the following pooled sample variance:
s2
p=(n1−1)s2
1+(n 2−1)s2
2
n1+n2−2.
Then, the statistic in (2.35) can be replaced by
T=(X1−X2)−(µ1−µ2)
sp/radicalbig
1/n 1+1/n 2∼tn1+n2−2. (2.38)
The CI formula and the test statistic for testing the hypotheses in (2.34) can be mod-
iﬁed accordingly, using the statistic in (2.38).
In cases when the two population distributions are unknown, but both n1andn2
are large (i.e., n1≥30 and n2≥30), it is asymptotically true that
Z=(X1−X2)−(µ1−µ2)/radicalig
s2
1/n1+s2
2/n2∼N(0,1). (2.39)
In such cases, the large sample CI for µ1−µ2and the large sample testing procedure
for testing the hypotheses in (2.34) can be constructed using the statistic in (2.39).
For instance, for testing the hypotheses in (2.34), the test statistic would be the same
as that in (2.37), except that its null distribution could be approximated well by either
tdforN(0,1).
If we are interested in comparing two population proportions π1andπ2using two
independent samples from the two populations, then, in large sample cases,
Z=(/hatwideπ1−/hatwideπ2)−(π1−π2)/radicalbig
/hatwideπ1(1−/hatwideπ1)/n 1+/hatwideπ2(1−/hatwideπ2)/n 2∼N(0,1),
where/hatwideπ1and/hatwideπ2are the two sample proportions. Therefore, a 100(1 −α)% CI for
π1−π2would be
(/hatwideπ1−/hatwideπ2)±Z1−α/2/radicalig
/hatwideπ1(1−/hatwideπ1)/n 1+/hatwideπ2(1−/hatwideπ2)/n 2.
The large sample condition is satisﬁed if n1/hatwideπ1≥10,n1(1−/hatwideπ1)≥10,n2/hatwideπ2≥10, and
n2(1−/hatwideπ2)≥10. To test hypotheses
H0:π1−π2=0 versus H1:π1−π2/ne}ationslash=0(> 0,< 0),48 BASIC STATISTICAL CONCEPTS AND METHODS
a good test statistic is
Z=/hatwideπ1−/hatwideπ2/radicalbig/hatwideπp(1−/hatwideπp)/radicalbig
1/n 1+1/n 2H0∼N(0,1),
where
/hatwideπp=n1/hatwideπ1+n2/hatwideπ2
n1+n2
is the pooled sample proportion.
When we compare two populations, sometimes certain variables that may affect
the variable of interest should be taken into account. For instance, if we are inter-
ested in studying whether physical exercise can effectively control our weight, then
one possible approach is as follows. First, we specify two populations. For example,
one population could be all adults aged 20 and above who go to the gym regularly
(e.g., at least two times a week), and the other population includes all adults aged
20 and above who do not go to the gym regularly. Second, we randomly select a
group of people from each population and record the weights for all people selected.
Finally, we can use the two independent sample t-test to compare the mean weights
of the two populations. This approach seems appropriate. But, it can happen that,
in the two groups of people selected, one group includes more males than the other
group. So, the signiﬁcant difference between the two population means of weight
found by the t-test could be due to the gender difference in the two samples, instead
of the difference in physical exercise. Therefore, to make a more appropriate com-
parison, we should take into account the variables that are not our major interest but
may affect the result, such as gender, age, profession, and so forth. These variables
are often called the confounding risk factors. To avoid the impact of the confound-
ing risk factors, we can collect data in an alternative way as follows. First, we list
the major confounding risk factors that we can think of. Second, for each randomly
selected member from the ﬁrst population, we randomly select a member from all
members in the second population that match the selected member in the ﬁrst pop-
ulation by all the confounding risk factors. In that way, the two resulting samples
from the two populations are paired. Let the two samples be {X11,X12,..., X1n}and
{X21,X22,..., X2n}. Then, X11is paired with X21,X12is paired with X22, and so forth.
So, the sample sizes of the two samples must be the same. To test the hypotheses in
(2.34), we can use the difference between the two samples, by deﬁning Di=X1i−X2i,
fori=1,2,..., n. Then,{D1,D2,..., Dn}can be regarded as a simple random sample
from a “difference” population with the mean µd=µ1−µ2. Therefore, the original
two-population problem becomes a one-population problem with the hypotheses
H0:µd=δ0 versus H1:µd/ne}ationslash=δ0(>δ0,<δ0).
And, most statistical inference methods for the one-population problem can be used
here. For instance, if it is reasonable to assume that the “difference” population has
a normal distribution with an unknown variance, then a good test statistic would be
T=D−δ0
sd/√nH0∼tn−1, (2.40)PARAMETRIC STATISTICAL INFERENCES 49
where Dandsdare the sample mean and sample standard deviation of the “dif-
ference” sample {D1,D2,..., Dn}. The test based on (2.40) is often called the two
paired sample t-test. By the way, a 100(1 −α)% CI formula for µdcan be derived
accordingly, to be
D±t1−α/2(n−1)sd√n.
2.7.4 The delta method and the bootstrap method
In the previous subsection, we discussed how to construct a CI or perform a hypoth-
esis test for a population parameter θusing the exact or asymptotic distribution of its
point estimator /hatwideθ. In some cases, we are interested in statistical inferences about a
function of θ, denoted as g(θ). In such cases, it is natural to estimate g(θ)byg(/hatwideθ).
If the exact distribution of g(/hatwideθ)is available, then the related inferences can be made
accordingly. Otherwise, the method described below can be considered for deriving
the asymptotic distribution of g(/hatwideθ).
Assume that the function ghas the second-order derivative at θ, and√n(/hatwideθ−θ)
converges in distribution to N(0,σ2), written in notation as
√n/parenleftig
/hatwideθ−θ/parenrightigD→N(0,σ2). (2.41)
Then, by the Taylor’s expansion, we have
g(/hatwideθ)=g(θ)+g′(θ)/parenleftig
/hatwideθ−θ/parenrightig
+O/parenleftbigg/parenleftig
/hatwideθ−θ/parenrightig2/parenrightbigg
.
So,
√n/parenleftig
g(/hatwideθ)−g(θ)/parenrightig
=g′(θ)√n/parenleftig
/hatwideθ−θ/parenrightig
+O/parenleftbigg√n/parenleftig
/hatwideθ−θ/parenrightig2/parenrightbigg
.
The second term on the right-hand side of the above expression would converge to 0
in distribution, and by (2.41) the ﬁrst term would converge to a normal distribution.
Therefore, we have
√n/parenleftig
g(/hatwideθ)−g(θ)/parenrightigD→N/parenleftig
0,σ2[g′(θ)]2/parenrightig
. (2.42)
Then, statistical inferences about g(θ)can proceed using the result in (2.42). This
general approach of statistical inferences about g(θ)based on the Taylor’s expansion
is often called the delta method.
Example 2.7 Assume that {X1,X2,..., Xn}is a simple random sample from a popu-
lation of interest, and that we are interested in estimating g( µ)=µ(µ+1), where µ
is the population mean. Then, a reasonable point estimator of g( µ)is g(X), where X
is the sample mean. By the CLT, we have
√n/parenleftbig
X−µ/parenrightbigD→N(0,σ2),50 BASIC STATISTICAL CONCEPTS AND METHODS
where σ2is the population variance. By (2.42), we have
√n/parenleftbig
g(X)−g(µ)/parenrightbigD→N/parenleftig
0,σ2[g′(µ)]2/parenrightig
.
So, a large-sample 100(1−α)%CI for g( µ)would be
g(X)±Z1−α/2g′(X)s/√n,
where g′(X)=2X+1and s is the sample standard deviation.
In some cases, when making statistical inferences about a population parameter
θ, the exact distribution of its point estimator /hatwideθis difﬁcult to know. Furthermore,
the asymptotic distribution of /hatwideθis also difﬁcult to derive, or it is inappropriate to use
the asymptotic distribution because the sample size nin a given application is not
large enough. In all such cases, the bootstrap approach (cf., Efron (1979), Efron and
Tibshirani (1993)) is often helpful. A typical bootstrap algorithm works in several
steps as follows.
Step 1 Draw a random sample of size nfrom the observed data {X1,X2,..., Xn}with
replacement. The new sample, which is called the bootstrap sample, is denoted as
{X∗
1,X∗
2,..., X∗
n}. Compute the estimate of θfrom the bootstrap sample, and the
estimate is denoted as /hatwideθ∗.
Step 2 Repeat step 1 Btimes, and the estimates of θfrom the Bbootstrap samples
are denoted as {/hatwideθ∗
j,j=1,2,..., B}, where Bis often called the bootstrap sample
size.
Step 3 The empirical distribution of {/hatwideθ∗
j,j=1,2,..., B}(cf., the related discus-
sion in Subsection 2.8.1 below), denoted as /hatwideF/hatwideθ, is used as an estimate of the true
distribution of /hatwideθ, denoted as F/hatwideθ, for statistical inferences.
For instance, in the case when B=10,000, we can use the interval (/hatwideθ∗
(251),/hatwideθ∗
(9750))as
the 95% CI for θ, where/hatwideθ∗
(251)and/hatwideθ∗
(9750)are the 251th and 9750th order statistics
of{/hatwideθ∗
j,j=1,2,..., 10,000}.
2.8 Nonparametric Statistical Inferences
Statistical methods introduced in the previous section are appropriate to use only
when the parametric model assumption imposed on the population distribution (e.g.,
the normal distribution) is valid. In practice, however, the assumed parametric model
of the population distribution is often invalid. Statistical inferences without a para-
metric model of the population distribution are often called nonparametric statistical
inferences. In this section, we brieﬂy introduce some major methodologies in this
area. More complete discussions about this topic can be found in text books, such
as Gibbons and Chakraborti (2003), Hollander and Wolfe (1999), and Kvam and
Vidakovic (2007).NONPARAMETRIC STATISTICAL INFERENCES 51
2.8.1 Or der statistics and their properties
When a population characteristic of interest is numeric and a parametric form of the
population distribution is unavailable, statistical inferences about the population dis-
tribution are often based on the ordering (or ranking) information of the observations
in a sample. So, in such cases, the order statistics play an important role. In this
subsection, we brieﬂy discuss some basic properties of the order statistics.
Let{X1,X2,..., Xn}be a simple random sample from a population with the cdf
F, and X(1)≤X(2)≤···≤ X(n)be the order statistics. Then, {X(1),X(2),..., X(n)}is an
ordered version of {X1,X2,..., Xn}. IfXiis the Ri-th order statistic, for i=1,2,..., n,
then Ritakes its value in {1,2,..., n}and{R1,R2,..., Rn}is a permutation of
{1,2,..., n}. In the literature, Riis often called the rank ofXi. On the other hand,
ifX(i)is the Ai-th observation in the sample, for i=1,2,..., n, then Aiis often called
thei-thinverse rank, or the i-thantirank. Obviously, {A1,A2,..., An}is also a per-
mutation of {1,2,..., n}. Regarding the ranks and antiranks, they are all random
variables because they are uniquely determined by the random sample. The sam-
pling distribution of {R1,R2,..., Rn}is that it takes any permutation of {1,2,..., n}
with the probability of 1/n!, and the sampling distribution of {A1,A2,..., An}is the
same.
In the above discussion, we have assumed that there are no ties in the observed
data, which is usually true in cases when the population distribution is absolutely
continuous (i.e., it has a pdf). When there are one or more ties in the observed data,
the ranks and antiranks can also be deﬁned properly, which is demonstrated by the
following example.
Example 2.8 Assume that the observed sample consists of the following 10 numbers
2.3,1.5,3.4,1.5,0.9,1.7,1.5,1.7,2.1,0.7.
In this data, the number 1.7 is observed twice, and the number 1.5 is observed three
times. The ordered observations are
0.7,0.9,1.5,1.5,1.5,1.7,1.7,2.1,2.3,3.4.
So, R 1=9,R3=10,R5=2,R9=7, and R 10=1. However, each of R 2,R4,and R 7
can be deﬁned to be 3, 4, or 5, because (X2,X4,X7)is a tie. In such a case, we can
deﬁne R 2=R4=R7= (3+4+5)/3=4. Similarly, we can deﬁne R 6=R8=6.5.
The antiranks can be handled similarly. Of course, other solutions for handling the
ties are possible. For instance, to break the tie of (X6,X8)when deﬁning R 6and R 8,
we can draw a random number from the uniform distribution on [0,1], which has the
same chance to be any number in the interval [0,1]. If the random number is smaller
than or equal to 0.5, then we deﬁne R 6=6and R 8=7. Otherwise, we deﬁne R 6=7
and R 8=6.
For the last order statistic X(n), its cdf FX(n)can be derived easily as follows:
FX(n)(x) = P(X(n)≤x)
=P(X 1≤x,X2≤x,..., Xn≤x)
=P(X 1≤x)P(X 2≤x)···P(X n≤x)
=Fn(x).52 BASIC STATISTICAL CONCEPTS AND METHODS
Similarly, the cdf of the ﬁrst order statistic X(1), denoted as FX(1), can be derived to
be
FX(1)(x)=1−[1−F(x)]n.
For a general 1 ≤i≤n, the cdf of the i-th order statistic X(i)is
FX(i)(x)=n
∑
j=i/parenleftbigg
n
j/parenrightbigg
Fj(x)[1−F(x)]n−j.
In cases when the population distribution has a pdf f, the pdf of the i-th order
statistic X(i), denoted as fX(i), is
fX(i)(x)=i/parenleftbigg
n
i/parenrightbigg
Fi−1(x)[1−F(x)]n−if(x),
for 1≤i≤n. When i=n, the pdf of X(n)is
fX(n)(x)=nFn−1(x)f(x).
When i=1, the pdf of X(1)is
fX(1)(x)=n[1−F(x)]n−1f(x).
For a pair of order statistics (X(i1),X(i2))with 1≤i1<i2≤n, it can be checked
that their joint cdf is
FX(i1),X(i2)(x,y)=
/braceleftigg
FX(i2)(y), ifx>y
∑n!
r!s!(n−r−s)!Fr(x)[F(y)−F(x)]s[1−F(y)]n−r−s,ifx≤y,
where the summation is over the range {(r,s):i1≤r≤n,i2≤r+s≤n}. If the
population distribution has a pdf f, then the joint pdf of (X(i1),X(i2))is
fX(i1),X(i2)(x,y)=
/braceleftbigg0, ifx>y
n!
(i1−1)!(i2−i1−1)!(n−i2)!Fi1−1(x)[F(y)−F(x)]i2−i1−1[1−F(y)]n−i2,ifx≤y.
One major application of the order statistics is to construct the empirical cumu-
lative distribution function (ecdf)
Fn(x)=

0, ifx<X(1)
1/n, ifx∈[X(1),X(2))
......
(n−1)/n, ifx∈[X(n−1),X(n))
1, ifx≥X(n).(2.43)NONPARAMETRIC STATISTICAL INFERENCES 53
0.5 1.0 1.5 2.0 2.5 3.0 3.50.0 0.2 0.4 0.6 0.8 1.0
xFn(x)
Figure 2.11 The ecdf constructed from the data in Example 2.8. The dark point at the begin-
ning of each horizontal line segment denotes that the value of the ecdf at each jump position
equals the height of the dark point.
Example 2.8 (continued) For the data in Example 2.8, the ecdf is shown in Figure
2.11. From the plot, it can be seen that the ecdf is a step function with the jumps at
the observed values.
Clearly, the ecdf deﬁned in (2.43) has the property that
Fn(x)=1
nn
∑
i=1I(Xi≤x),
where I(a)is the indicator function ofa, and it equals 1 when ais “true” and 0
otherwise. So, Fn(x)is the proportion of observations in the sample that are smaller
than or equal to x; it is the cdf of the data in the observed sample and is commonly
used for estimating the population cdf F. As long as the sample {X1,X2,..., Xn}is a
simple random sample, we have the following result:
P/parenleftbigg
lim
n→∞max
x∈R|Fn(x)−F(x)|=0/parenrightbigg
=1.
This result says that Fn(x)converges to F(x)almost surely (cf., Subsection 2.7.1)
and uniformly over x∈R.54 BASIC STATISTICAL CONCEPTS AND METHODS
2.8.2 Goodness-of-ﬁt tests
In statistical process control, one major goal is to check whether a quality character-
istic of a product follows a given distribution speciﬁed by some design requirements
(cf., the related discussion in Section 1.2). This and many other applications are re-
lated to the testing of the hypotheses:
H0:F(x)=F0(x), for all x∈R
versus H1:F(x)/ne}ationslash=F0(x), for some x∈R, (2.44)
where Fdenotes the true cdf of a population, and F0is a given cdf that is assumed
completely known. If Fis assumed to have a parametric form, then the testing prob-
lem of (2.44) can be addressed by the parametric methods discussed in Subsection
2.7.3. However, in many applications, such a parametric form is unavailable. There-
fore, nonparametric testing procedures are needed. Because the hypotheses in (2.44)
mainly concern how well the actual population distribution Fcan be described by
the assumed distribution F0, tests for (2.44) are often called goodness-of-ﬁt tests.
To test the hypotheses in (2.44), one approach is to divide the number line Rinto
kintervals
(−∞, a1),[a1,a2),...,[ak−1,∞),
where a1<a2<···<ak−1are given cut points. For a simple random sample
{X1,X2,..., Xn}, let Ojbe the number of observations in the j-th interval, for
j=1,2,..., k. IfH0is true, then, on average, there should be
Ej=n[F0(aj)−F0(aj−1)], forj=1,2,..., k,
observations in the sample that fall into the j-th interval. Therefore, to test the hy-
potheses in (2.44), we can compare the observed counts {Oj,j=1,2,..., k}with
theexpected counts {Ej,j=1,2,..., k}. If H0is true, then their difference should
be small. Otherwise, it is an indication that H0is false. Based on this intuition, we
deﬁne a test statistic
X2=k
∑
j=1(Oj−Ej)2
Ej, (2.45)
which pro vides a measure of the difference between {Oj,j=1,2,..., k}and
{Ej,j=1,2,..., k}. The test based on X2in (2.45) was ﬁrst suggested by Pear-
son (1900), and is called the Pearson’s chi-square test in the literature. Under H0, the
asymptotic null distribution of X2is proved to be χ2
k−1.
After the number line Ris divided into kintervals by the cut points a1<a2<
···<ak−1, the LRT testing procedure (cf., (2.30) and (2.31)) can also be used
for testing the hypotheses in (2.44). Let πjbe the probability that a randomly se-
lected member from the population in question is included in the j-th interval, for
j=1,2,..., k. Then, the observed counts {Oj,j=1,2,..., k}of the simple random
sample{X1,X2,..., Xn}have a multinomial distribution (cf., Subsection 2.4.2), and
the likelihood function of the sample is
L(π1,π2,..., πk;X1,X2,..., Xn)=n!
O1!O2!···Ok!πO1
1πO2
2···πOk
k.NONPARAMETRIC STATISTICAL INFERENCES 55
Let
Λ=max H0L(π1,π2,..., πk;X1,X2,..., Xn)
max H0/uniontextH1L(π1,π2,..., πk;X1,X2,..., Xn)
be the ratio of two maximized likelihoods, where max H0denotes “maximization un-
derH0” and max H0/uniontextH1denotes “maximization under H0/uniontextH1.” Then, it is easy to
check that
max
H0L(π1,π2,..., πk;X1,X2,..., Xn)=n!
O1!O2!···Ok!πO1
01πO2
02···πOk
0k
and
max
H0/uniontextH1L(π1,π2,..., πk;X1,X2,..., Xn)=n!
O1!O2!···Ok!πO1
11πO2
12···πOk
1k,
where
π0j=F0(aj)−F0(aj−1)
π1j=Oj/n, forj=1,2,..., k.
Therefore
G2=−2log(Λ)= 2k
∑
j=1Ojlog(O j/Ej), (2.46)
where{Ej}are the expected counts deﬁned before. Similar to X2,G2in (2.46) has
an asymptotic null distribution of χ2
k−1.
TheX2andG2tests would give similar results when the sample size nis large. In
the literature, the sample size is considered large if each expected count is at least 5
(i.e., Ej≥5, for each j). In cases when most Ej’s are at least 5 and there are a small
number of Ej’s as small as 1, the X2test often gives a more reliable test, compared
to the G2test. To best satisfy the large sample condition, in applications, the cut
points a1<a2<···<ak−1should be chosen such that the expected counts {Ej,j=
1,2,..., k}are roughly the same, or equivalently, {π0j,j=1,2,..., k}are roughly
the same. For detailed discussion on this topic, see Koehler (1986) and Koehler and
Larntz (1980).
To test hypotheses in (2.44), it is natural to use the ecdf Fndeﬁned in (2.43). If
the difference between FnandF0is large, then we should reject H0, because Fnis a
good estimator of the true population cdf F. To this end, let us deﬁne
Dn=max
x∈R|Fn(x)−F0(x)|. (2.47)
The exact null distribution of Dnis available, although its expression is quite com-
plicated, based on which we can compute the critical value Dn,α, deﬁned to be the
smallest value satisfying P(D n≥Dn,α)≤α, for a given signiﬁcance level α. See,
e.g., Dunstan et al. (1979) for extensive tables of Dn,α. In cases when the sample
size is large, Kolmogorov (1933) and Smirnov (1939) proved that, under H0and the
condition that F0is absolutely continuous (i.e., it has a pdf),
lim
n→∞P/parenleftbig√nDn≤d/parenrightbig
=L(d),56 BASIC STATISTICAL CONCEPTS AND METHODS
Table 2.6: Critical values L αfor several commonly used values of α.
α 0.20 0.15 0.10 0.05 0.01
Lα1.07 1.14 1.22 1.36 1.63
where
L(d)=1−2∞
∑
s=1(−1)s−1exp/parenleftbig
−2s2d2/parenrightbig
.
Therefore, Dn,αcan also be approximated by /tildewideDn,α=Lα/√n, where Lαsatisﬁes
L(Lα) =1−α. For several commonly used values of α, the corresponding values
ofLαare listed in Table 2.6. In cases when n≥50 and α=0.01 or 0.05, the ratio
/tildewideDn,α/Dn,αwould be between 1 and 1.02. Therefore, /tildewideDn,αshould be good enough
for practical use. The test using Dnin (2.47) is often called the Kolmogorov-Smirnov
test.
2.8.3 Rank tests
The hypothesis testing procedures described in Subsection 2.7.3 are based on the
assumption that the related population distribution has a parametric form (e.g., the
normal distribution). In certain applications, the parametric form of the population
distribution is unavailable, but we still want to test hypotheses about a population
parameter. In such cases, an appropriate nonparametric testing procedure should be
considered. This subsection introduces several commonly used nonparametric testing
procedures.
Let us ﬁrst focus on hypothesis testing of a population location parameter. In
such cases, the population median, denoted as /tildewideµ, is more convenient to use, com-
pared to the population mean µ. Assume that we have a simple random sample
{X1,X2,..., Xn}from a population with the population median /tildewideµ, and we are in-
terested in testing
H0:/tildewideµ=/tildewideµ0 versus H1:/tildewideµ/ne}ationslash=/tildewideµ0(>/tildewideµ0,</tildewideµ0), (2.48)
where/tildewideµ0is a hypothesized value of /tildewideµ. Deﬁne a test statistic Yby
Y=the number of observations in the sample that exceeds /tildewideµ0.
Then, under H0,Y∼Binomial(n,0.5). Therefore, the hypotheses in (2.48) can be
tested using Y, with its critical value or the related p-value determined by the above
binomial distribution. This testing procedure is called the sign test. When nis large
in the sense that n≥20, the null distribution of Yis approximately normal, and
consequently we can use the test statistic
Z=Y−n/2√n/2H0∼N(0,1).NONPARAMETRIC STATISTICAL INFERENCES 57
The sign test described above only uses the number of observations in the sam-
ple that exceeds /tildewideµ0for testing the hypotheses in (2.48). It does not make use of the
ordering information among all observations in the sample. In cases when the pop-
ulation distribution is symmetric, this ordering information can be used properly in
the following two steps:
Step 1 Order all values of {|Xi−/tildewideµ0|,i=1,2,..., n}from the smallest to the largest,
and then obtain the ranks of all observations from this ordering.
Step 2 Deﬁne S+to be the summation of the ranks obtained in Step 1 that correspond
to the nonnegative values of {Xi−/tildewideµ0,i=1,2,..., n}, and S−to be the summation
of the ranks obtained in Step 1 that correspond to the negative values of {Xi−
/tildewideµ0,i=1,2,..., n}.
IfH0is true (i.e.,/tildewideµ0is the true median of the population distribution), then the
distributions of S+andS−are approximately the same. Since S++S−=1+2+
···+n=n(n+1)/2, the tests based on S+,S−orS+−S−are all asymptotically
equivalent. For simplicity, we focus on the test using S+here. Obviously, if H0is
true, then S+andS−should be close to each other. If the value of S+is too large
or too small, then it indicates that H0might be invalid. The null distribution of S+
is given by Wilcoxon et al. (1972) in cases when n≤50. Table 2.7 gives some tail
probabilities of this distribution when 5 ≤n≤20. In cases when nis large (e.g.,
n>20), the null distribution of S+can be regarded as a normal distribution with
µS+=n(n+1)/4, σ2
S+=n(n+1)(2n+1)/24.
The test described above, using either S+, orS−, orS+−S−, is called the Wilcoxon
signed-rank test.
Example 2.9 Assume that we obtain the following 20 observations from a popula-
tion with a symmetric distribution:
8.7,19.5, 12.7, 10.4, 12.6, 6.1,11.1, 0.7,2.2,12.3,
11.5, 16.2, 16.0, 13.1,−0.8,18.1, 8.1,12.8, 11.6, 12.7.
We are interested in testing
H0:/tildewideµ=10 versus H 1:/tildewideµ>10.
To perform the Wilcoxon signed-rank test, we need to ﬁnd the ranks of {|Xi−/tildewideµ0|,i=
1,2,..., n}, which are listed in Table 2.8. From Table 2.8,
S+=19+9.5+1+8+2+7+4+15+14+12+17+11+5+9.5=134.
By Table 2.7, the p-value is P H0(S+≥134)>PH0(S+≥140)= 0.101. Therefore, we
fail to reject H 0at the signiﬁcance level of 0.05.
To compare two population means µ1andµ2, if we have two paired samples from
the two populations, then the Wilcoxon signed-rank test can still be used, after the
difference between the two paired samples is computed and the two-sample problem58 BASIC STATISTICAL CONCEPTS AND METHODS
Table 2.7 Some upper-tail probabilities P H0(S+≥s+)of the null distribution of the Wilcoxon
signed-rank test statistic S +.
n s+PH0(S+≥s+)n s+ PH0(S+≥s+)n s+ PH0(S+≥s+)
5 13 0.094 11 48 0.103 16 93 0.106
14 0.062 52 0.051 94 0.096
15 0.031 55 0.027 100 0.052
6 17 0.109 59 0.009 106 0.025
20 0.031 12 56 0.102 112 0.011
21 0.016 60 0.055 113 0.009
7 22 0.109 61 0.046 116 0.005
24 0.055 64 0.026 17 104 0.103
26 0.023 68 0.010 105 0.095
28 0.008 71 0.005 112 0.049
8 28 0.098 13 64 0.108 118 0.025
30 0.055 65 0.095 125 0.010
32 0.027 69 0.055 129 0.005
34 0.012 70 0.047 18 116 0.098
35 0.008 74 0.024 124 0.049
36 0.004 78 0.011 131 0.024
9 34 0.102 79 0.009 138 0.010
37 0.049 81 0.005 143 0.005
39 0.027 14 73 0.108 19 128 0.098
42 0.010 74 0.097 136 0.052
44 0.004 79 0.052 137 0.048
10 41 0.097 84 0.025 144 0.025
44 0.053 89 0.010 152 0.010
47 0.024 92 0.005 157 0.005
50 0.010 15 83 0.104 20 140 0.101
52 0.005 84 0.094 150 0.049
89 0.053 158 0.024
90 0.047 167 0.010
95 0.024 172 0.005
100 0.011
101 0.009
104 0.005
becomes the one-sample problem, as discussed at the end of Subsection 2.7.3, as
long as it is reasonable to assume that the “difference” population has a symmetric
distribution. In cases when we have two independent samples from the two popula-
tions, there are two commonly used nonparametric tests in the literature, which are
described below.
Assume that (i) {X11,X12,..., X1n1}and{X21,X22,..., X2n2}are two samples
from the two populations, respectively, (ii) the two samples are independent of
each other, and (iii) the two population distributions have exactly the same shape
and spread and their only difference is in their means. In such cases, we are
interested in testing the hypotheses in (2.34). If H0is true, then the values ofNONPARAMETRIC STATISTICAL INFERENCES 59
Table 2.8: Ranks of{|Xi−/tildewideµ0|,i=1,2,..., n}for the observed data in Example 2.9.
Xi Xi−/tildewideµ0|Xi−/tildewideµ0|Ranks
8.7−1.3 1.3 3
19.5 9.5 9.5 19
12.7 2.7 2.7 9.5
10.4 0.4 0.4 1
12.6 2.6 2.6 8
6.1−3.9 3.9 13
11.1 1.1 1.1 2
0.7−9.3 9.3 18
2.2−7.8 7.8 16
12.3 2.3 2.3 7
11.5 1.5 1.5 4
16.2 6.2 6.2 15
16.0 6.0 6.0 14
13.1 3.1 3.1 12
−0.8−10.8 10.8 20
18.1 8.1 8.1 17
8.1−1.9 1.9 6
12.8 2.8 2.8 11
11.6 1.6 1.6 5
12.7 2.7 2.7 9.5
{X11−δ0,X12−δ0,..., X1n1−δ0}and the values of {X21,X22,..., X2n2}should be
similar to each other, and they can be regarded as two independent samples from
the same population. Otherwise, their values will be quite different. Based on this
intuition, to test the hypotheses in (2.34), we can consider the combined sample
{X11−δ0,X12−δ0,..., X1n1−δ0,X21,X22,..., X2n2}.
LetWbe the sum of the ranks of {X11−δ0,X12−δ0,..., X1n1−δ0}in the combined
sample. Then, if the value of Wis too large or too small, it implies that the values
of{X11−δ0,X12−δ0,..., X1n1−δ0}are relatively large or small, compared to the
values of {X21,X22,..., X2n2}. Consequently, the observed data provide us evidence
against H0. Again, the null distribution of Whas been tabulated by many authors,
including Dixon and Massey (1969). Some of its tail probabilities are listed in Table
2.9 in cases when 4 ≤n1≤n2≤8. When both n1andn2are larger than 8, its null
distribution can be well approximated by the normal distribution with
µW=n1(n1+n2+1)/2, σ2
W=n1n2(n1+n2+1)/12.
The test using W as its test statistic is called the Wilcoxon rank-sum test.
Under the conditions described above for the Wilcoxon rank-sum test, an alter-
native approach to test the hypotheses in (2.34) is to use the test statistic
U=n1
∑
i=1n2
∑
j=1I(X2j<X1i−δ0),60 BASIC STATISTICAL CONCEPTS AND METHODS
Table 2.9 Some upper-tail probabilities P H0(W≥w)of the null distribution of the Wilcoxon
rank-sum test statistic W.
n1n2w PH0(W≥w) n1n2w PH0(W≥w)
4 4 24 0.057 5 8 47 0.047
25 0.029 49 0.023
26 0.014 51 0.009
5 27 0.056 52 0.005
28 0.032 6 6 50 0.047
29 0.016 52 0.021
30 0.008 54 0.008
6 30 0.057 55 0.004
32 0.019 7 54 0.051
33 0.010 56 0.026
34 0.005 58 0.011
7 33 0.055 60 0.004
35 0.021 8 58 0.054
36 0.012 61 0.021
37 0.006 63 0.010
8 36 0.055 65 0.004
38 0.024 7 7 66 0.049
40 0.008 68 0.027
41 0.004 71 0.009
5 5 36 0.048 72 0.006
37 0.028 8 71 0.047
39 0.008 73 0.027
40 0.004 76 0.010
6 40 0.041 78 0.005
41 0.026 8 8 84 0.052
43 0.009 87 0.025
44 0.004 90 0.010
7 43 0.053 92 0.005
45 0.024
47 0.009
48 0.005
where I(a)is the indicator function of athat equals 1 ifa=“True” and 0 otherwise.
Similar to W, the statistic Umakes use of the ordering information between the two
samples. If the value of Uis too large or too small, then it is an indication that H0
might be invalid. This test is often called the Mann-Whitney test. As a matter of fact,
it can be checked that
U=W−n1(n1+1)/2.
Therefore, the Wilcoxon rank-sum test and the Mann-Whitney test are actually equiv-
alent.NONPARAMETRIC STATISTICAL INFERENCES 61
2.8.4 Nonpar ametric density estimation
Assume that a population distribution has a pdf f, and we are interested in estimat-
ingffrom a simple random sample {X1,X2,..., Xn}. If the pdf fhas a parametric
form, then it can be estimated by parametric methods, such as the maximum likeli-
hood estimation method discussed in Subsection 2.7.2. In this subsection, we discuss
estimation of fwhen its parametric form is not available.
In cases when fdoes not have any parametric form, one natural approach for
estimating fis to use the density histogram that is discussed in Subsection 2.6.3 (see
also Figure 2.9). However, the pdf fis usually a continuous function; but, the func-
tion represented by the density histogram is stepwise. To make the approximation
tofby the density histogram better, we can use smaller intervals when constructing
the density histogram. By this approach, the resulting histogram would have a larger
variability, which is not good either. To overcome these limitations, the approach
called kernel density estimation has been proposed in the literature (cf. Parzen, 1962;
Rosenblatt, 1956; Wand and Jones, 1995), which is described below.
For any x∈R, the kernel density estimator off(x)is deﬁned by
/hatwidef(x)=1
nhnn
∑
i=1K/parenleftbiggx−Xi
hn/parenrightbigg
, (2.49)
where hn>0 isabandwidth andKis akernel function. The kernel function Kis
often chosen to satisfy the following conditions:
(i)K(x)≥0, for any x∈R,
(ii)/integraltext∞
−∞K(x)dx=1,
(iii) K(x)is a decreasing function of xwhen x>0, and
(iv) Kis symmetric about 0 (i.e., K(x)=K(−x), for any x>0).
Therefore, the kernel function Kitself is a probability density function. From (2.49),
it can be seen that the kernel density estimator /hatwidef(x)is a weighted average of the
kernel densities K((x−Xi)/h n)at the individual observations, and the weights are
controlled by the kernel function Kand the bandwidth hn. For the aluminum smelter
data discussed in Example 2.5 of Subsection 2.6.3, the kernel density estimates of
the population pdf fare shown by the solid and dashed curves, respectively, in cases
when hn=0.05 and 0.25 and the kernel function Kis chosen to be the pdf φof the
standard normal distribution. It can be seen that when hnis chosen small, the kernel
density estimate is quite noisy, and it is smooth when hnis chosen large. For this
reason, hnis often called a smoothing parameter.
Usually, the kernel function K(x)is chosen to be a smooth density function
that is symmetric about 0 and non-decreasing on (−∞, 0]. Commonly used ker-
nel functions include the uniform kernel function K(u) = I(−1/2≤u≤1/2),
the Epanechnikov kernel function K(u) =12
11(1−u2)I(−1/2≤u≤1/2), and the
Gaussian kernel function K(u) =1√
2πexp(−u2/2)or its truncated version K(u) =
0.6171exp (−u2/2)I(−1/2≤u≤1/2), where I(a)is an indicator function deﬁned
byI(a)= 1 ifais “true” and 0 otherwise. By using the Epanechnikov kernel func-
tion or the Gaussian kernel function, observations closer to xreceive more weight in62 BASIC STATISTICAL CONCEPTS AND METHODS
0 1 2 3 40.0 0.5 1.0 1.5
SiO 2Density Estimates
Figure 2.12 Kernel density estimates of the aluminum smelter data discussed in Example 2.5
of Subsection 2.6.3. The kernel function K is chosen to be the pdf φof the standard normal
distribution. The solid curve denotes the kernel density estimate when h n=0.05, and the
dashed curve denotes the kernel density estimate when h n=0.25.
deﬁning/hatwidef(x). Selection of the bandwidth hncan be discussed in a similar way to that
discussed in the next subsection.
2.8.5 Nonparametric regression
In the regression model (2.21) discussed in Subsection 2.7.2, the regression function
is assumed to be a linear function. In many applications, the true regression function
may not be well described by a parametric function. In such cases, nonparametric
regression analysis would be more appropriate to use. Assume that bivariate obser-
vations{(xi,Yi),i=1,2,..., n}follow the regression model
Yi=f(xi)+εi, fori=1,2,..., n, (2.50)
where{xi,i=1,2,..., n}are the design points, {Yi,i=1,2,..., n}are observations
of the response variable Y,{εi,i=1,2,..., n}are i.i.d. random errors, and fis
the true regression function. For simplicity of discussion, let us further assume that
the design interval of fis[0,1]. Then, the major goal of nonparametric regression
analysis is to estimate ffrom the observed data {(xi,Yi),i=1,2,..., n}.
In cases when fis continuous in the entire design interval, intuitively, observa-
tions farther away from xprovide less information about f(x). Therefore, one natural
idea is to simply average observations in a neighborhood [x−hn/2,x+hn/2]of a
given point xand then to use this average as an estimator of f(x), where hnis the
bandwidth. The bandwidth is usually chosen relatively small, especially when the
sample size nis large. Based on this idea, f(x)can be estimated by the followingNONPARAMETRIC STATISTICAL INFERENCES 63
simple a verage (SA):
/hatwidefSA(x)=1
Nn(x)∑
xi∈[x−hn/2,x+hn/2]Yi,
where Nn(x)denotes the number of design points in [x−hn/2,x+hn/2]. Based on
(2.50), we have
/hatwidefSA(x)=1
Nn(x)∑
xi∈[x−hn/2,x+hn/2]f(xi)+1
Nn(x)∑
xi∈[x−hn/2,x+hn/2]εi. (2.51)
The estimator /hatwidefSA(x)should estimate f(x)well because of the following two facts:
•All values of f(t)fort∈[x−hn/2,x+hn/2]should be close to f(x)since fis
continuous in the design interval and hnis small. Consequently, the ﬁrst term on
the right-hand side of (2.51) is close to f(x).
•The second term on the right-hand side of (2.51) is close to zero as long as there
are enough terms in the summation, which is guaranteed by the central limit the-
orem discussed in the previous section. Intuitively, positive errors and negative
errors would be canceled out in this term, and thus, on average, the summation of
many i.i.d. error terms is close to zero.
The above function estimation procedure that results in the estimator /hatwidefSA(x)is
a simple example of data smoothing. Almost all data smoothing procedures in the
literature involve averaging observations for estimating f(x). For any given xin
the design interval, procedures that average all observations in the design interval
when estimating f(x)are referred to as global smoothing procedures in the litera-
ture. The linear regression analysis discussed in Subsection 2.7.2 is an example of
global smoothing. Other procedures only average observations in a neighborhood of
x, and are referred to as local smoothing procedures. So, /hatwidefSA(x)is an example of
local smoothing. The two facts mentioned above about the two terms on the right-
hand side of (2.51) are commonly used when studying the properties of the local
smoothing procedures.
By using/hatwidefSA(x)for estimating f(x), all observations outside the neighborhood
[x−hn/2,x+hn/2]are ignored completely, and all observations inside the neighbor-
hood are treated equally. A natural generalization of /hatwidefSA(x), which does not treat all
observations in the neighborhood equally, is
/hatwidefNW(x)=∑n
i=1YiK/parenleftig
xi−x
hn/parenrightig
∑n
i=1K/parenleftig
xi−x
hn/parenrightig, (2.52)
where Kis a kernel function that has the support of [−1/2, 1/2]. The estima-
tor/hatwidefNW(x)is simply a weighted average of the observations in the neighborhood
[x−hn/2,x+hn/2], with weights controlled by the kernel function. As in kernel
density estimation, the kernel function Kis often chosen to be a smooth density
function that is symmetric about 0 and non-decreasing in [−1/2, 0], such as those64 BASIC STATISTICAL CONCEPTS AND METHODS
listed at the end of Subsection 2.8.4. Obviously, the estimator /hatwidefSA(x)is a special case
of/hatwidefNW(x)when the uniform kernel function is used. The kernel estimator /hatwidefNW(x)
was ﬁrst suggested by Nadaraya (1964) and Watson (1964). So it is often called a
Nadaraya-Watson (NW) kernel estimator in the literature, as identiﬁed by the sub-
script of/hatwidefNW(x).
It can be easily checked that the Nadaraya-Watson kernel estimator /hatwidefNW(x)is the
solution to aof the following minimization problem:
min
a∈Rn
∑
i=1(Yi−a)2K/parenleftbiggxi−x
hn/parenrightbigg
. (2.53)
Therefore,/hatwidefNW(x)has the property that, among all constants, its weighted distance
to the observations in the neighborhood [x−hn/2,x+hn/2]is the smallest. This
is illustrated by Figure 2.13(a), in which the solid curve at the bottom denotes the
weights K((xi−x)/h n)and the dashed horizontal line denotes /hatwidefNW(x).
A natural generalization of (2.53) is the following minimization problem:
min
a,b1,...,bm∈Rn
∑
i=1[Yi−(a+b1(xi−x)+...+bm(xi−x)m)]2K/parenleftbiggxi−x
hn/parenrightbigg
, (2.54)
where mis apositive integer. Equation (2.54) is used to search for a polynomial func-
tion of order mwhose weighted distance to the observed data in the neighborhood
[x−hn/2,x+hn/2]reaches the minimum. Then, the solution to ain (2.54) can be
deﬁned as an estimator of f(x), and is called the m-th order local polynomial kernel
estimator. As a by-product, the solution to bjin (2.54) can be used as an estimator of
j!f(j)(x), for j=1,2,..., m, where f(j)(x)is the j-th order derivative of fatx. Ob-
viously, (2.53) is a special case of (2.54) when m=0. That is, the Nadaraya-Watson
kernel estimator is the zeroth order local polynomial kernel estimator, or the local
constant kernel estimator.
In applications, the most commonly used local polynomial kernel estimator is the
local linear kernel (LK) estimator, which is the solution to ain (2.54) when m=1,
and is denoted by /hatwidefLK(x). This estimator is illustrated in Figure 2.13(b) by the dashed
line. By some routine algebra, when m=1, the solutions to aandb1of (2.54) have
the following expressions:
/hatwidea(x) =n
∑
i=1w2−w1(xi−x)
w0w2−w2
1YiK/parenleftbiggxi−x
hn/parenrightbigg
/hatwideb1(x) =n
∑
i=1w0(xi−x)−w1
w0w2−w2
1YiK/parenleftbiggxi−x
hn/parenrightbigg
, (2.55)
where wj=∑n
i=1(xi−x)jK(xi−x
hn)forj=0,1and 2. Therefore, /hatwidefLK(x) =/hatwidea(x)and
/hatwidef′(x)=/hatwideb1(x).
Compared to the local constant kernel estimator, the local linear kernel estimator
deﬁned in (2.55) has the beneﬁt that the ﬁrst-order derivative (i.e., the slope) of f
would have little impact on its performance; by the deﬁnition, most of the slopeNONPARAMETRIC STATISTICAL INFERENCES 65
x□hn2 x x□hn2fNW□x□
(a)x□hn2 x x□hn2fLK□x□
(b)
Figure 2.13 (a) The Nadaraya-Watson kernel estimator of f (x)(dashed horizontal line) has
the property that, among all constants, its weighted distance to observations in the neigh-
borhood[x−hn/2,x+hn/2]is the smallest. (b) The local linear kernel estimator equals the
value of the dashed line at x. The dashed line has the property that its weighted distance to
observations in the neighborhood [x−hn/2,x+hn/2]is the smallest among all possible lines.
The little circles in each plot denote the observations. The solid curve going through the data
denotes the true regression function. The solid curve at the bottom denotes the weights that
are controlled by the kernel function.
effect has been accommodated in the estimation by ﬁtting a local linear function.
This beneﬁt makes the local linear kernel estimator /hatwidefLK(x)have the properties that
(i) its bias is not substantially larger when xis in the boundary regions [0,hn/2)and
(1−hn/2,1], compared to its bias when xis in the interior region [hn/2,1−hn/2], and
(ii) its bias is not substantially larger when the design points in [x−hn/2,x+hn/2]are
unequally distributed, compared to its bias when the design points in [x−hn/2,x+
hn/2]are equally distributed. As a comparison, the local constant kernel estimator
/hatwidefNW(x)does not have these properties.
Regarding the choice of the power mof the polynomial for local polynomial ker-
nel estimation, under some regularity conditions, it can be shown that: (i) the variance
of a(2k+1)-th order local polynomial kernel estimator is asymptotically the same
as the variance of a (2k)-th order local polynomial kernel estimator, (ii) the variance
of the(2k+1)-th order local polynomial kernel estimator increases with k, and (iii)
the bias of a higher order local polynomial kernel estimator is smaller than the bias
of a lower order estimator. By these properties, the order of a local polynomial kernel
estimator should be chosen as odd because a (2k+1)-th order estimator is generally
better than a (2k)-th order estimator. In most cases, the local linear kernel estimator
should be good enough because the bias reduction is limited by using a higher order
estimator and because the variability of a higher order estimator is often much larger.
The bandwidths used in the local polynomial kernel smoothing procedures con-
trol the size of the neighborhood around a given point used for data smoothing. If66 BASIC STATISTICAL CONCEPTS AND METHODS
they are chosen larger, then the neighborhood is larger, implying that more observa-
tions are averaged for estimating the regression function at the given point, and vice
versa. Therefore, the bandwidths also control the amount of observations used in data
smoothing. If they are chosen too large, then the estimated regression function would
become too smooth to capture local features of the true regression function, in which
case we say that the estimator oversmooths the data. If the bandwidths are chosen
too small, then the estimated regression function would capture too many details of
the data, some of which are just noise, in which case the estimator undersmooths the
data.
There are several existing procedures in the literature for choosing the band-
widths properly. We next introduce three of them: the cross-validation (CV) proce-
dure, the Mallow’s Cpcriterion, and the plug-in algorithm. For simplicity, they are
introduced only in the case of local linear kernel smoothing. Actually, these proce-
dures are quite general and can be used for selecting bandwidths and other parameters
used in most data smoothing procedures.
For bandwidth selection of the local linear kernel estimator /hatwidefLK, a natural crite-
rion is the following residual mean squares (RMS):
RMS(h n)=1
nn
∑
i=1/parenleftig
Yi−/hatwidefLK(xi)/parenrightig2
. (2.56)
Since RMS(h n)measures the distance between the observed data and the estimator,
the bandwidth hncan be chosen by minimizing RMS(h n). However, it can be easily
checked that the best bandwidth is hn=0 by this criterion, because the correspond-
ing estimator connects all the data points in such a case and thus sets RMS (hn)=0.
Obviously, this result is not what we want since no data smoothing is actually in-
volved.
We can amend this criterion to allow for data smoothing as follows. Because
/hatwidefLK(xi)is constructed by all observations in the neighborhood [xi−hn/2,xi+hn/2],
including Yi, the residual Yi−/hatwidefLK(xi)tends to be small for measuring the distance
between the estimator and the data. This is a major reason why the criterion (2.56) is
inappropriate for choosing hn. As a remedy, let /hatwidefLK,−i(xi)be the local linear kernel
estimator of f(xi)constructed from all observations in [xi−hn/2,xi+hn/2]except
Yi, for i=1,2,···,n. Then, a similar criterion to (2.56) is the following CV score:
CV(hn)=1
nn
∑
i=1/parenleftig
Yi−/hatwidefLK,−i(xi)/parenrightig2
. (2.57)
Theoptimal value of hncan be estimated by the minimizer of the CV score in (2.57).
This method for choosing the bandwidths or other procedure parameters is called the
CV procedure in the literature (Allen (1974)).
We next discuss the Mallows’ Cpcriterion. Let Y= (Y1,Y2,..., Yn)′and
(/hatwidefLK(x1),/hatwidefLK(x2),...,/hatwidefLK(xn))′=HY. Then, His called the hat matrix in regres-
sion analysis. The Mallows’ Cpcriterion (Mallows, 1973) is deﬁned by
Cp(hn)=1
σ2/bardbl(In×n−H)Y/bardbl2−n+2 tr(H),EXERCISES 67
where In×nis the n×nidentity matrix,/bardbl·/bardblis the Euclidean norm, and tr(H) is the
trace of the matrix H(i.e., the summation of all diagonal elements of H). By this
criterion, the optimal value of hnis estimated by the minimizer of Cp(hn).
The plug-in algorithm is based on the MSE criterion (cf., Subsection 2.7.1). It can
be checked that the MSE of the local linear kernel estimator /hatwidefLK(x)for estimating
f(x)is
MSE/parenleftig
/hatwidefLK(x),f(x)/parenrightig
∼/bracketleftbigg
h2
nf′′(x)K2
21−K11K31
2(K 01K21−K2
11)/bracketrightbigg2
+(nh n)−1C(K)σ2,(2.58)
where Kj1=/integraltext1/2
−1/2ujK(u)du, for j=0,1,2,3,C(K) =1
(K01K21−K11)2/integraltext1/2
−1/2(K21−
K11u)2K2(u)du, and “∼” denotes equality when certain high-order terms have been
ignored on the right-hand side of (2.58). By the criterion (2.58), the optimal value of
hnthat minimizes MSE/parenleftig
/hatwidefLK(x),f(x)/parenrightig
is asymptotically equal to
hn,opt=/parenleftbiggC1(K)σ2
n[f′′(x)]2/parenrightbigg1/5
, (2.59)
where C1(K)=C(K)(K 01K21−K2
11)2/(K2
21−K11K21)2. Because the quantity f′′(x)
is unknown, the criterion (2.59) can not be used directly for choosing hn. One way out
is the following iterative algorithm: (1) we assign an initial value for hnand estimate
f′′(x)by a local polynomial kernel estimator based on this initial bandwidth; (2) the
value of hnis updated by (2.59) after f′′(x)is replaced by its estimator; (3) we go
back to step (1) using the updated bandwidth obtained from the previous step; and
(4) steps (1)–(3) continue until some convergence criterion is satisﬁed. This plug–in
bandwidth selection procedure has several different versions. For more discussions,
read H ¨ardle et al. (1992), Ruppert et al. (1995), Loader (1999), and the references
cited therein.
2.9 Exercises
2.1 Assume that a random variable Xhas the following cdf
F(x)=

0, ifx<a
x−a
b−a,ifa≤x≤b
1, ifx>b,
where a<bare two constants. A distribution with this cdf is called the uniform
distribution on[a,b], denoted as X∼Uni f orm(a, b).
(i) Find the pdf of X.
(ii) Using (2.6) and (2.7), ﬁnd the mean and variance of X.
(iii) Describe the major features of this distribution.
(iv) If X∼Uni f orm(5, 10), ﬁnd P(7≤X≤9).68 BASIC STATISTICAL CONCEPTS AND METHODS
2.2 In Example 2.1, assume that each grade has a grade point associated with it.
LetXbe the grade and Ybe the grade point of a randomly selected student of
the introductory statistics class discussed in that example, and the relationship
between grades and grade points is described by the table below.
Grade A B C D F
Grade Points 4 3 2 1 0
(i) Does Xhave a cdf? If the answer is “yes”, ﬁnd the cdf of X.
(ii) Does Yhave a cdf? If the answer is “yes”, ﬁnd the cdf of Y.
(iii) Using (2.4) and (2.5), ﬁnd the mean and variance of Y.
2.3 Most statistical software packages can compute probabilities related to a stan-
dard normal distribution. For instance, in the software package R(see the ap-
pendix of the book for a brief description), the following commands compute
P(Z<1)andP(Z<2), where Zdenotes a random variable having the standard
normal distribution:
> pnorm(1) > pnorm(2)
[1] 0.8413447 [1] 0.9772499
From the above Rprintouts, we know that P(Z<1) = 0.8413447 and P(Z<
2)= 0.9772499. Assume that X∼N(1.5, 0.52). Find the following probabilities:
(i)P(X<2)
(ii)P(X<2.5)
(iii) P(2<X<2.5)
(iv) P(−1<X<2.5)
2.4 For the binomial distribution discussed in Subsection 2.4.2, derive the formulas
in (2.14).
2.5 If X∼Binomial(n,π), then p=X/ncan be interpreted as the proportion of
successes out of nBernoulli trials, and pis a good estimator of π(cf., the related
discussion in Subsection 2.7.1). Derive the mean and variance of p, and give
some reasonable explanations why pis a good estimator of π.
2.6 Suppose that 20% of all copies of a particular textbook fail a certain binding
strength test. Let Xdenote the number of copies among 10 randomly selected
copies that fail the test.
(i) Find the mean and variance of X.
(ii) Find the probability P(3≤X≤5).
2.7 Consider a dataset with the following 11 observations:
4, 6, 7, 6, 3, 5, 8, 2, 9, 9, 100.
(i) Compute the sample mean of the data.
(ii) Compute the sample standard deviation of the data.
(iii) Find the sample median.
(iv) Explain why the sample mean and the sample median are very different in
this case.EXERCISES 69
2.8 Consider a dataset with the following 20 observations:
10, 12, 15, 17, 20, 20, 23, 25, 28, 30,
40, 43, 45, 48, 50, 50, 59, 61, 64, 70.
(i) Find the ﬁrst quartile, median, and the third quartile of the data.
(ii) Find the inter-quartile range.
(iii) Make a box plot of the data.
2.9 A small dataset about voters’ political status contains the following 20 observa-
tions:
D, D, R, O, R, R, R, D, R, D, D, R, D, D, R, R, R, O, D, D,
where “D” denotes Democrats, “R” denotes Republicans, and “O” denotes oth-
ers.
(i) Make a frequency table of the data.
(ii) Make a pie chart of the data.
(iii) Make a bar chart of the data. Is the shape of the bar chart meaningful? Why?
2.10 A Consumer Reports article on peanut butter reported the following scores for
creamy peanut butter:
56, 44, 57, 62, 48, 53, 36, 50, 39, 53,
50, 50, 65, 45, 60, 40, 56, 68, 41, 22.
(i) Make a dot plot of the data.
(ii) Make a stem-and-leaf plot of the data.
(iii) Based on the plots made in parts (i) and (ii), describe the distribution of the
data.
2.11 A consumer group has collected data on the gas mileage (denoted as X), in
miles per gallon, of 325 cars manufactured in America. The data have been
summarized in the partial frequency table below.
Class Interval Frequency Relative Frequency Density
[5,10) 20
[10,15) 0.0277
[15,20)
[20,25) 0.2769
[25,30) 60
[30,35) 0.1077
(i) Complete the table by ﬁlling all empty entries.
(ii) Use the completed table to make a density histogram and comment on its
shape.
(iii) Estimate P(5≤X<20).
2.12 A random sample is to be selected from a population with mean µ=50 and
standard deviation σ=10.
(i) Determine the mean and the standard deviation of the sampling distribution
ofXwhen n=25.70 BASIC STATISTICAL CONCEPTS AND METHODS
(ii) Determine the approximate probability that Xwill be larger than 51 when
n=100.
2.13 Assume that the mean speed of an automobile on highways of a given state is 60
miles per hour (mph) and the standard deviation is 4 mph. Let X1,X2,..., X100
denote the highway speeds of 100 randomly selected automobiles in that state.
(1) Determine the mean and the standard deviation of the sample mean X.
(ii) What is the approximate probability that the sample mean Xexceeds 61 mph?
(iii) What is the approximate probability that the sample mean Xis between 59.2
mph and 60.4 mph?
2.14 A survey designed to obtain information on π, which denotes the proportion
of registered voters who are in favor of a constitutional amendment, results in
a sample of size n=400. Of the 400 voters sampled, 272 are in favor of the
constitutional amendment.
(i) Give a point estimate of π.
(ii) Calculate a 95% conﬁdence interval for π.
2.15 The manager of the electronics department at a large department store is inter-
ested in knowing the mean size µof the TV screens that customers purchase.
Based on industry standards it is believed that the standard deviation σ=4
inches.
(i) Determine how large a sample is needed in order to have the 90% conﬁdence
interval for µshorter than or equal to 2 inches.
(ii) If a sample of size n=49 yields a sample average TV screen size of 21.1
inches, calculate a 90% conﬁdence interval for µ.
2.16 The following summary statistics resulted from a study of the relationship be-
tween the cost of a barrel of crude oil (x ) and the price of a gallon of regular
unleaded gasoline ( Y):
n=12, ∑n
i=1xi=241.1, ∑n
i=1x2
i=4932.8, ∑n
i=1Yi=14.34,
∑n
i=1Y2
i=17.288, ∑n
i=1xiYi=291.55.
(i) Compute the estimated linear regression model using (2.22).
(ii) In linear regression analysis, the residual sum of squares (RSS), deﬁned by
RSS=n
∑
i=1/bracketleftig
Yi−/parenleftig/hatwideβ0+/hatwideβ1xi/parenrightig/bracketrightig2
=n
∑
i=1/parenleftbig
Yi−Y/parenrightbig2−/hatwideβ2
1n
∑
i=1(xi−x)2,
is used for measuring the variability in the observed data that is not explained
by the estimated regression model. The sum of squares of total (SST), deﬁned
by
SST=n
∑
i=1/parenleftbig
Yi−Y/parenrightbig2,EXERCISES 71
is used for measuring the total variability in the observed data. And, the co-
efﬁcient of determination R2, deﬁned by
R2=1−RSS
SST,
is used for measuring the proportion of the variability in the observed data
that is explained by the estimated regression model. Using the summary
statistics given above, compute SST,RSS, and R2.
2.17 A ﬁshing hook manufacturer is interested in determining whether the hook pack-
aging machine tends to overﬁll or underﬁll. Each package of hooks is supposed
to contain 100 hooks. A random sample of 49 packages of hooks is selected,
resulting in a sample average of 100.25 hooks and a sample standard deviation
of 0.7 hooks. Using α=0.05, test
H0:µ=100 versus H1:µ/ne}ationslash=100,
where µdenotes the mean number of hooks in a randomly selected package.
2.18 Let µdenote the mean cholesterol level of heart attack patients under the age of
50. Some research reports have claimed that a cholesterol level of 240 or higher
would dramatically increase the risk of heart attacks. A random sample of the
cholesterol levels of 16 heart attack patients age 50 and under yields x=247
ands=14. Using α=0.05, test
H0:µ=240 versus H1:µ>240.
In the test, what assumptions have actually been made so that the test is valid?
2.19 In a study to compare average snowfall in two different cities, measurements
were taken in each of the cities for 9 randomly selected years. Snowfall, in
inches, for the two cities is listed below. Assume the two population distribu-
tions are normal. Use α=0.05 to test whether there is a signiﬁcant difference
between the average snowfalls of the two cities.
Year 1942 1948 1954 1959 1967 1970 1975 1981 1983
City A 45 0 4 21 9 1 30 17 53
City B 40 10 2 20 7 9 33 17 50
2.20 A marching band needs to order hats for performances this summer. The hat
sizes for the 100 band members are summarized in the chart below. Make a
graph of the empirical cumulative distribution function of this data.
Size 6.7 6.8 6.9 7.0 7.1 7.2 7.3
Frequency 4 12 22 31 9 17 5
2.21 Assume that the following data are from a population with mean µ:
5.6, 2.5, 3.7, 7.9, 11.3, 6.4, 3.2, 2.7, 0.5, 5.7, 3.2, 2.4, 7.6, 3.8, 5.7, 5.8, 3.4,
5.1, 2.2, 4.0, 4.2, 4.2, 5.5, 1.5, 1.6, 6.3, 4.3, 5.0, 8.6, 6.3, 4.3, 6.4, 4.6, 2.0, 4.4.
(i) Using the delta method, construct a 95% conﬁdence interval for θ=µ(µ+1).72 BASIC STATISTICAL CONCEPTS AND METHODS
(ii) Using the bootstrap method with the bootstrap sample size B=1000, con-
struct a 95% conﬁdence interval for θ=µ(µ+1). Compare the result with
that in part (i).
2.22 For the data in the previous problem, test whether they are from a population
with the distribution N(5,32), using both the X2andG2tests and the signiﬁcance
level α=0.05. In the tests, use ﬁve intervals to group the data.
2.23 For the data in Exercise 2.21, test H0:/tildewideµ=5.5 versus H1:/tildewideµ/ne}ationslash=5.5, using α=
0.05 and
(i) the sign test,
(ii) the Wilcoxon signed-rank test.
2.24 Assume that two independent samples are obtained from two populations, re-
spectively. Observations in the two samples are listed below.
Sample 1 1.2 8.0 0.9 2.1 2.7 7.3 7.6
Sample 2 2.6 8.5 2.4 4.5 4.6 7.7 3.8 10.3
Assume that the two population distributions have the same shape and spread.
Use the Wilcoxon rank-sum test and α=0.05 to test H0:µ1−µ2=
−1 versus H1:µ1−µ2<−1, where µ1andµ2are the two population means.
2.25 For the data in Exercise 2.21, make a plot of the kernel density estimator of
the population pdf, using the Epanechnikov kernel function and the bandwidth
hn=1.0.
2.26 For the Nadaraya-Watson kernel estimator /hatwidefNW(x)deﬁned in (2.52), ﬁnd its bias,
variance, and MSE for estimating the true regression function f(x).
2.27 Intuitively explain the major reason why the bias of the local linear kernel es-
timator/hatwidefLK(x)is not substantially larger in the boundary regions [0,hn/2)and
(1−hn/2,1], compared to its bias in the interior region [hn/2,1−hn/2].Chapter 3
Univ ariate Shewhart Charts and Process
Capability
3.1 Introduction
As described brieﬂy in Section 1.3, statistical process control (SPC) of a produc-
tion process can be roughly divided into two phases. In the initial stage (i.e., phase
I), we usually do not know much about the performance of the production process
yet, and our major goal in this stage is to properly adjust the production process to
make it run stably. To this end, we usually let the production process produce a given
amount of products, and the values of the quality characteristic(s) of interest of the
manufactured products are then recorded and analyzed. From the statistical analysis
of the collected data, if we ﬁnd that the production process does not seem to run
stably, then the root causes responsible for that unfavorable performance should be
ﬁgured out and the corresponding adjustment of the production process should be
made as well. After the adjustment, another set of data needs to be collected and
analyzed, and the production process should be adjusted again if necessary. This
analysis-and-adjustment process is then repeated several times until it is conﬁrmed
by the data analysis that the performance of the production process is stable. Once
all special causes have been accounted for and the production process is in-control
(IC), we collect an IC dataset from the products manufactured under the stable op-
erating conditions, and this IC dataset is then used for estimating the IC distribution
of the quality characteristic(s) of interest. Based on the (estimated) IC distribution,
a phase II SPC control chart is designed, and it is used for online monitoring of the
production process. When it detects a signiﬁcant shift in the distribution of the qual-
ity characteristic(s) from the IC distribution, a signal is delivered and the production
process is stopped immediately for root cause identiﬁcation and removal. This online
monitoring stage of SPC is often called phase II SPC.
In both phase I and phase II SPC, many statistical tools, including histograms,
stem-and-leaf plots, regression, design of experiment, and so forth (cf., Sections 2.6
and 2.7), are helpful. Among all these methods, control charts are especially useful
because they are designed speciﬁcally for detecting any out-of-control (OC) perfor-
mance of the production process. By using a control chart, a charting statistic deter-
mined by the observed data should be chosen, and it should contain as much of the
information in the observed data about the distribution of the quality characteristic(s)
as possible and be sensitive to any distributional shift as well. In the literature, several
7374 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
different types of control charts have been developed, including the Shewhart charts,
the cumulative sum (CUSUM) control charts, the exponentially weighted moving
average (EWMA) control charts, and the control charts based on change-point de-
tection (CPD). These and some other control charts developed recently for handling
various different situations will be described in the current and later chapters of the
book.
As mentioned in Section 1.3, the ﬁrst control chart in the literature was proposed
by Walter A. Shewhart in 1931, and is called the Shewhart chart. Over the past about
80 years, many different versions of the Shewhart chart have been proposed for dif-
ferent purposes, and they are widely used in practice. In the ﬁrst part of this chapter,
some representative Shewhart charts are discussed in cases when the quality charac-
teristic in question is univariate. Shewhart charts for monitoring multivariate quality
characteristics in cases when their distributions are assumed normal will be discussed
in Chapter 7. Shewhart charts in cases when the distribution of the quality character-
istic(s) is nonparametric are discussed in Chapters 8 and 9. In the second part of this
chapter, process capability analysis is brieﬂy described.
3.2 Shewhart Charts for Numerical Variables
As discussed in Section 1.2, all quality characteristics can be classiﬁed into three
categories: continuous numerical, discrete numerical, and categorical variables. Pro-
cess control methodologies for different types of quality characteristics are different.
In this section, we describe some basic Shewhart charts for monitoring numerical
quality characteristics when their IC and OC distributions are assumed to be normal.
These control charts are especially useful when the quality characteristics are contin-
uous numerical, or when they are discrete numerical with a relatively large number
of different values. In cases when the quality characteristics are discrete but the num-
ber of different values is small, we can consider using control charts for monitoring
categorical quality characteristics, such as those described in Section 3.3.
3.2.1 The X and R charts
Let us ﬁrst discuss phase I SPC. Assume that nrandom samples are collected from
the products of a production process at nconsecutive time points. Each sample con-
tains mproducts. Measurements of the quality characteristic in question of the sam-
pled products in the i-th sample are denoted as
Xi1,Xi2,..., Xim, fori=1,2,..., n.
Based on the observed data, we would like to know whether the process is IC. For
the moment, let us assume that the IC mean µ0and the IC standard deviation σof the
quality characteristic Xare both known. Let us further assume that the only possible
shift is in the mean of X. That is, our focus is on monitoring the process mean. In
such cases, to know whether the process is IC at the i-th time point, it is natural to
consider testing the following hypotheses:
H0:µ=µ0 versus H1:µ/ne}ationslash=µ0,SHEWHART CHARTS FOR NUMERICAL V ARIABLES 75
where µdenotes the true process mean. By the discussion in Subsection 2.7.3, a good
test statistic for testing the above hypotheses is
Z=Xi−µ0
σ/√mH0∼N(0,1). (3.1)
The null hypothesis H0should be rejected at a pre-speciﬁed signiﬁcance level αif
the observed value of Z, denoted as Z∗, satisﬁes the condition that
|Z∗|>Z1−α/2, (3.2)
where Z1−α/2denotes the (1−α/2)-th quantile of the distribution N(0,1), which is
also called the α/2 critical value of the N(0,1)distribution. Based on (3.1) and (3.2),
the observed data provide us signiﬁcant evidence to conclude that the process is OC
at the i-th time point if
Xi>µ0+Z1−α/2σ√mor Xi<µ0−Z1−α/2σ√m. (3.3)
In practice, the IC parameters µ0andσare usually unknown. In such cases, they
need to be estimated from the observed data beforehand in order to make decisions
regarding the process performance using decision rules similar to (3.3). To this end,
it is natural to estimate µ0by the grand sample mean
/hatwideµ0=X=1
nn
∑
i=1Xi, (3.4)
where{X1,X2,..., Xn}are the sample means of the nsamples. T o estimate σ, instead
of the sample standard deviations, people traditionally use the sample ranges
Ri=Xi(m)−Xi(1), fori=1,2,..., n,
where Xi(1)andXi(m)denote the ﬁrst and last order statistics (cf., Section 2.5) of the i-
th sample {Xi1,Xi2,..., Xim}, because sample ranges are easier to compute compared
to sample standard deviations. This computational advantage of the sample ranges
might be negligible nowadays; but, it was substantial several decades ago when She-
whart charts were ﬁrst proposed and computers were unavailable. If the process is
IC at the i-th time point (i.e., the i-th sample is from the population distribution
N(µ0,σ2)), then
d1(m)= E/parenleftbiggRi
σ/parenrightbigg
is a constant that depends on m, which can be determined from the joint distribution
of(Xi(1),Xi(m))(cf., the related discussion in Subsection 2.8.1). When 2 ≤m≤25,
the values of d1(m)are given in Table 3.1. Then, a natural estimator of σis
/hatwideσ=R
d1(m), (3.5)76 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
Table 3.1 Constants d1(m) and d 2(m) used in constructing the X and R charts when the
sample size 2≤m≤25.
m d1(m) d2(m) m d1(m) d2(m)
2 1.128 0.853 14 3.407 0.763
3 1.693 0.888 15 3.472 0.756
4 2.059 0.880 16 3.532 0.750
5 2.326 0.864 17 3.588 0.744
6 2.534 0.848 18 3.640 0.739
7 2.704 0.833 19 3.689 0.734
8 2.847 0.820 20 3.735 0.729
9 2.970 0.808 21 3.778 0.724
10 3.078 0.797 22 3.819 0.720
11 3.173 0.787 23 3.858 0.716
12 3.258 0.778 24 3.895 0.712
13 3.336 0.770 25 3.931 0.708
where R=1
n∑n
i=1Ri.
Based on (3.3)–(3.5), we can evaluate the process performance by comparing the
sample means with the control limits given in the box below, and the resulting control
chart is called the X chart.
Control Limits of the XChart Using Sample Ranges
U=X+Z1−α/2
d1(m)√mR
C=X (3.6)
L=X−Z1−α/2
d1(m)√mR
More speciﬁcally, the Xchart consists of a center line C, anupper control limit
U, and a lower control limit L. At the i-th time point, if the i-th sample mean Xiis
beyond the two control limits, i.e.,
Xi<L or Xi>U,
then we claim that the process is OC at that time point. Otherwise, the process is
considered IC. In the formulas of the control limits UandLgiven in the above box,
the critical value Z1−α/2is usually chosen to be 3 in practice, which corresponds to
α=0.0027. Namely, by using this critical value, the Xchart would have a 0.27%
chance to give a false signal of process distributional shift when the process is actu-
ally IC.SHEWHART CHARTS FOR NUMERICAL V ARIABLES 77
TheXchart described above is mainly for monitoring the process mean. In prac-
tice, we are often concerned about the process variability as well. To monitor the
process variability, it is natural to use the sample range as the charting statistic. To
this end, for any 1 ≤i≤n, let
d2(m)=/radicaligg
Var/parenleftbiggRi
σ/parenrightbigg
.
Then, d2(m)is a constant depending on the sample size monly, and its values are
listed in Table 3.1 in cases when 2 ≤m≤25. Based on (3.5), a natural estimator of
σRiis
/hatwideσRi=d2(m)R
d1(m).
So, we can monitor the process variability by using the so-called R chart with the
control limits given in the box below. We claim that the process variability is OC at
thei-th time point if
Ri<L or Ri>U,
where LandUare the lower and upper control limits, respectively.
Control Limits of the RChart
U=R+Z1−α/2d2(m)
d1(m)R=/parenleftbigg
1+Z1−α/2d2(m)
d1(m)/parenrightbigg
R
C=R (3.7)
L=R−Z1−α/2d2(m)
d1(m)R=/parenleftbigg
1−Z1−α/2d2(m)
d1(m)/parenrightbigg
R
In practice, the XandRcharts are often used together, because both the process
mean and process variability are important to the quality of products. If one or both
charts give OC signals, then the special causes of the OC signals should be ﬁgured
out and removed. If the special causes are transient in the sense that they only affect
the products that are manufactured in a short period of time, then we can simply
delete the samples observed in that time period and compute the control limits of
theXandRcharts ag ain. Otherwise, new samples should be collected from products
produced after the special causes are removed, and new XandRcharts should be
constructed from the new data. This analysis-and-adjustment process usually needs
to be repeated several times until the production process becomes stable. Then, we
can use the control charts constructed using a phase I dataset collected under the
stable condition for phase II online process monitoring. In phase II SPC, samples
are collected sequentially over time, and the sample means and sample ranges are
plotted in the XandRcharts, respecti vely, whose control limits are determined in78 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
phase I analysis. If the sample mean or the sample range of the sample collected at
the current time point is outside their corresponding control limits, then we claim
that the process is OC and it should be stopped immediately. The process can be
re-started only after the special causes of the OC signal are ﬁgured out and removed
and the process is properly adjusted.
Example 3.1 To monitor an injection molding process, 20 samples of 5 manufac-
tured parts each are collected. The major quality characteristic of the parts is their
compressive strengths (in psi), and the summary statistics of the 5 observations of
the compressive strength in each sample are listed in the top part of Table 3.2. The
original data used in this example are from Tables 6E.11 and 6E.12 in Montgomery
(2009). To monitor this process using the X and R charts, let us assume that we use
Z1−α/2=3. From Table 3.1, for m =5, d 1(m) = 2.326, and d 2(m) = 0.864. Also,
from Table 3.2, it can be computed that
X=79.533, R=8.745.
So, by (3.6), the control limits of the X chart are
U=79.533+3
2.326∗√
5∗8.745=84.577
C=79.533
L=79.533−3
2.326∗√
5∗8.745=74.489.
By (3.7), the control limits of the R chart are
U=8.745+3∗0.864
2.326∗8.745=18.490
C=8.745
L=8.745−3∗0.864
2.326∗8.745=−1.000.
Because the sample range cannot be negative, we can modify the lower control limit
of the R chart to be 0.
TheX and R charts are demonstrated in plots (a) and (b) of Figure 3.1, r espec-
tively, in which the solid dots, connected by solid lines, denote the sample means
and sample ranges of the ﬁrst 20 samples shown in Table 3.2. From the plots, it can
be seen that both the process mean and process variability seem IC in this case, al-
though the sample ranges shown in plot (b) seem to have a decreasing trend, which
implies quality improvement. Then, we ﬁnish our phase I analysis, and use these two
charts for online monitoring of the process (i.e., phase II SPC). In phase II SPC,
new samples are collected sequentially. The summary statistics of the ﬁrst 4 phase
II samples are presented in the bottom part of Table 3.2. Their sample means and
sample ranges are plotted in the X and R charts, which are denoted by little circles
in the plots connected by dotted lines. At the 24th time point, we get a signal of mean
shift. So, the process is stopped at that time point for investigation of possible special
causes of the signal. It can be restored for manufacturing new products only in cases
when any possible special causes are removed, the production process is adjusted
properly, and we are conﬁdent that it is back to IC again. For the process adjustment
at this stage, certain phase I SPC methodologies might still be useful.SHEWHART CHARTS FOR NUMERICAL V ARIABLES 79
Table 3.2 Summary statistics of the 24 samples collected from an injection molding process.
The ﬁrst 20 samples are for setting up the control charts, and the last 4 samples are for online
process monitoring. The quality characteristic in this example is the compressive strength of
the manufactured parts.
i Xi Ri si i Xi Ri si
1 79.12 7.3 2.99 11 78.36 7.7 2.89
2 80.18 17.6 6.65 12 79.44 8 3.31
3 80.4 10.5 4.79 13 80.92 3.6 1.57
4 77.5 8.4 3.88 14 77.14 4.3 1.94
5 80.3 5.2 2.49 15 79.1 13.8 6.14
6 82.8 14.4 5.78 16 79.7 2 0.81
7 77.28 7.4 3.22 17 79.22 6.6 2.85
8 81.12 11.5 4.53 18 81.06 7.6 3.11
9 81.44 10 3.86 19 80.8 6.6 2.55
10 75.68 11 4.01 20 79.1 11.4 4.12
21 78.18 12.6 5.36 23 80.82 6.8 2.8
22 77.4 15.7 7.65 24 85.64 17.5 6.28
0 5 10 15 20 2570 75 80 85
iXi
LCU
(a)0 5 10 15 20 250 5 10 15 20 25
iRi
LCU
(b)
Figure 3.1 The X chart (plot (a)) and the R chart (plot (b)) constructed from the data of
the ﬁr st 20 samples summarized in Table 3.2 about the injection molding process. The sample
means and sample ranges of the ﬁrst 20 samples are shown by solid dots in the plots connected
by solid lines. Since the process seems IC at the ﬁrst 20 time points, the charts are then used
for phase II process monitoring. The phase II sample means and sample ranges are shown by
little circles connected by dotted lines. We get a signal of mean shift at the 24th time point,
and the process is stopped at that time point for investigation of possible special causes of the
signal.
The performance of a control chart, such as the XandRcharts, is traditionally
measured by the so-called averaged run length (ARL), described below. Let us ﬁrst
discuss the case when the production process is IC. In such cases, because the ob-
served data are random and our control charts use control limits as threshold values80 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
for making decisions regarding the process performance (i.e., IC versus OC), the
control charts could give false signals of process distributional shifts. In the hypothe-
sis testing context, this is the so-called type I error. The number of samples collected
from the initial time point of consideration to the occurrence of the false OC signal is
called the run length. In this deﬁnition, we have assumed that samples are collected
at equally spaced time points. In such cases, the run length is equivalent to the length
from the initial time point of consideration to the occurrence of a false OC signal.
Obviously, the run length is a random variable, because it is determined by the col-
lected samples, which are random. Further, its distribution does not depend on the
selection of the initial time point of consideration, as long as the process is IC during
all the time points considered and the samples at different time points are indepen-
dent of each other or they are correlated but the correlation is homogeneous over
time. The mean of the run length when the process is IC is called the IC ARL, which
is often denoted as ARL 0. In the case when the process becomes OC at a given time
point, the control chart in question would give us a signal of the shift after a certain
time period. The number of samples collected from the time of shift occurrence to
the time of signal is called OC run length, and its mean value is the OC ARL, which
is often denoted as ARL 1.
For a given control chart, of course, the ideal situation is that its ARL 0value
is large and its ARL 1value is small. But, similar to the Type I and Type II error
probabilities in the hypothesis testing context (cf., Section 2.7.3), this is difﬁcult to
achieve. In most situations, when the ARL 0value is large, the ARL 1value would also
be relatively large, and vice versa. To handle this issue, in the SPC literature, we
usually ﬁx the ARL 0value at a given level, and try to make the ARL 1value as small
as possible, which is similar to the strategy used in the hypothesis testing context to
ﬁx the Type I error probability at a given level (e.g., 0.05) and try to make the Type
II error probability as small as possible.
Next, we use the Xchart as an example to discuss computation of its ARL 0and
ARL 1values in cases of phase II SPC. Computation of the ARL 0andARL 1values of
other Shewhart charts (e.g., the Rchart) can be discussed similarly. In phase II SPC,
the IC mean µ0and the IC standard deviation σcan both be assumed known. In such
cases, the upper and lower control limits of the Xchart are those in expression (3.3),
instead of those in (3.6). It is easy to know that the distribution of the IC run length is
the geometric distribution Geom( α)(cf., Section 2.4.3). By the formulas of its mean
and variance given in Section 2.4.3, we know that
ARL 0=1
α, σ(0)
RL=√1−α
α, (3.8)
where σ(0)
RLdenotes the standard deviation of the IC run length. In most applications,
a small value of αis chosen. In such cases,√1−αis close to 1. Consequently,
ARL 0≈σ(0)
RL.
For instance, by (3.8), when α=0.0027, ARL 0=1/0.0027 =370.37 and σ(0)
RL=
369.87. The two numbers are almost the same.SHEWHART CHARTS FOR NUMERICAL V ARIABLES 81
For computing ARL 1,let us assume that the mean of the quality characteristic has
a shift of size δ=kσ(i.e., the mean shifts from µ0toµ1=µ0+kσ) at a given time
point. Then, the probability that the sample mean Xof a sample collected at a later
time point is within the upper and lower control limits is
β=P/parenleftbigg
µ0−Z1−α/2σ√m≤X≤µ0+Z1−α/2σ√m/parenrightbigg
=P/parenleftbigg
−k√m−Z1−α/2≤X−µ1
σ/√m≤−k√m+Z1−α/2/parenrightbigg
=Φ/parenleftbig
−k√m+Z1−α/2/parenrightbig
−Φ/parenleftbig
−k√m−Z1−α/2/parenrightbig
,
where Φis the cumulative distribution function (cdf) of the standard normal distri-
bution. From the above expression, it can be seen that the value of βdepends on m
andk. In cases when m=5,10, and 20, and k∈[0,3], the values of βare shown in
Figure 3.2. From the plot, it can be seen that βdecreases when kormincreases. This
is intuitively reasonable, because (i) the shift size of the process mean gets larger
when kincreases and thus the probability that Xstill stays within the control limits
would become smaller, and (ii) Xwould be closer to the true process mean µ1when
mgets larger and thus the probability value β, which measures the chance that Xis
within an interval centered at µ0, would be smaller for a given shift size.
0.0 0.5 1.0 1.5 2.0 2.5 3.00.0 0.2 0.4 0.6 0.8 1.0
kβm=5
m=10
m=20
Figure 3.2: The value ofβin cases when m =5,10, and 20, and k ∈[0,3].82 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
It isobvious that the distribution of the OC run length is the geometric distribu-
tionGeom(1−β). So,
ARL 1=1
1−β, σ(1)
RL=/radicalbig
β
1−β, (3.9)
where σ(1)
RLdenotes the standard deviation of the OC run length. In cases when m=
5,10, and 20, and k∈[0,3], the values of ARL 1andσ(1)
RLby (3.9) are shown in the
two plots of Figure 3.3, respectively. From plots (a) and (b) of Figure 3.3, it can be
seen that ARL 1decreases when kormincreases, and the value of σ(1)
RLchanges in a
similar way.
0.0 1.0 2.0 3.00 5 10 15 20 25 30
kARL 1m=5
m=10
m=20
(a)0.0 1.0 2.0 3.00 5 10 15 20 25 30
kσRL□1□m=5
m=10
m=20
(b)
Figure 3.3 The values of ARL 1(plot (a)) and σ(1)
RL(plot (b)) in cases when m =5,10, and 20,
and k∈[0,3].
For the Xchart with the control limits in (3.6), the probability for it to make a
Type I error at a single time point (i.e., the process is declared OC when it is actually
IC) is α, which is sometimes called the false alarm rate (FAR) in the literature. If we
consider an IC dataset with nsamples collected at ndifferent time points, then the
overall probability of Type I error, or the overall FAR, deﬁned to be the probability
that the process is IC at all ntime points but it is declared OC at one or more such
time points, would be
/tildewideα=1−(1−α)n. (3.10)
Table 3.3 lists the /tildewideαvalues when n=1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 50, and
100, and α=0.0001, 0.001, 0.0027, and 0.005. From the table, we can see that /tildewideα
increases quite fast when nincreases. For instance, in cases when α=0.0027 (i.e.,
the FAR is 27 per 10,000), /tildewideα=0.0267 when n=10, and 0.2369 when n=100, which
are much larger than the value of α. If we need to control the overall probability ofSHEWHART CHARTS FOR NUMERICAL V ARIABLES 83
Table 3.3 Theoverall probability of Type I error, /tildewideα, of the X chart with FAR αwhen it is
applied to an IC dataset with n samples, in cases when n and αtake various values.
n α=0.0001 α=0.001 α=0.0027 α=0.005
1 0.0001 0.0010 0.0027 0.0050
2 0.0002 0.0020 0.0054 0.0100
3 0.0003 0.0030 0.0081 0.0149
4 0.0004 0.0040 0.0108 0.0199
5 0.0005 0.0050 0.0134 0.0248
6 0.0006 0.0060 0.0161 0.0296
7 0.0007 0.0070 0.0187 0.0345
8 0.0008 0.0080 0.0214 0.0393
9 0.0009 0.0090 0.0240 0.0441
10 0.0010 0.0100 0.0267 0.0489
15 0.0015 0.0149 0.0397 0.0724
20 0.0020 0.0198 0.0526 0.0954
50 0.0050 0.0488 0.1264 0.2217
100 0.0100 0.0952 0.2369 0.3942
Type I error in a given application, then we should use equation (3.10) to choose α
properly. For instance, if we want /tildewideα=0.01 when the Xchart is applied to an IC
dataset with n=50samples, by (3.10), αshould be chosen as follows:
α=1−(1−/tildewideα)1/n=1−(1−0.01)1/50=0.0002.
Now, let us consider the Xchart presented in Figure 3.4. From the plot, it seems
that the process is IC because all the sample means are within the lower and upper
control limits. But, there are a number of obvious patterns. For instance, the ﬁrst
six sample means have an increasing trend. In the literature, such a pattern is often
called a run. So, the ﬁrst six sample means form a run of length 6, the 4th up to
the 8th sample means are all above the center line and they form a run of length 5,
and so forth. Besides the runs, there is an obvious periodic pattern in Figure 3.4. If
the production process only has common cause variation involved, then the Xchart
should demonstrate a random pattern, and the chance to have runs (especially those
with relatively long lengths) and other patterns should be small. So, when we ﬁnd a
non-random pattern in a control chart, we should try to ﬁgure out its possible special
causes, even in cases when all the charting statistic values are within the control
limits.
The Western Electric Handbook (1956) suggests a set of decision rules for detect-
ing non-random patterns on the control chart. By these rules, the process is declared
OC if one of the following cases happens:
(i)One point is outside the three-sigma control limits,
(ii)Two out of three consecutive points are outside the two-sigma control limits,
(iii) Four out of ﬁve consecutive points are at least one sigma away from the center
line, and84 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
0 5 10 15 20
iXi
LCU
Figure 3.4: TheX chart contains some non-random patterns.
(iv) Eight consecutive points are located on one side of the center line.
In the literature, some researchers have proposed alternative decision rules based on
non-random patterns. For instance, Nelson (1984) and Champ and Woodall (1987)
discussed various OC conditions when kout ofℓconsecutive points fall beyond one-,
two-, or three-sigma control limits, where 2 ≤k≤ℓ. Derman and Ross (1997) pro-
posed two additional rules. By the ﬁrst one, an OC signal is given if two consecutive
points fall outside either one of the two three-sigma control limits. By the second
one, an OC signal is given if two out of three consecutive points fall outside different
three-sigma control limits. Klein (2000) modiﬁed these two rules by requiring the
related points to exceed a same control limit.
3.2.2 The X and s charts
In the XandRcharts discussed in the previous subsection (cf., (3.6) and (3.7)), the
standard deviation σof the quality characteristic is estimated by the simple average
of the sample ranges, R. As mentioned there, a major reason to use that estimator is
its simple computation. However, this advantage of the sample ranges has become
negligible nowadays with modern computing facilities. Therefore, it is natural to
consider a more efﬁcient estimator of σbased on the sample standard deviations.
As in the previous subsection, we assume that nsamples are collected at ndiffer-
ent time points, and each sample contains mobservations of the quality characteristic.
For the i-th sample, its sample standard deviation can be computed by
si=/radicaligg
1
m−1m
∑
j=1/parenleftbig
Xi j−Xi/parenrightbig2, fori=1,2,..., n.SHEWHART CHARTS FOR NUMERICAL V ARIABLES 85
Then, a natural estimator of σis
s=1
nn
∑
i=1si.
From the discussion in Section 2.7, for each i, the sample variance s2
iis an unbiased
estimator of the variance σ2. However, the sample standard deviation siis a biased
estimator of σ, and the bias depends on the sample size m(cf. Kenney and Keeping,
1951, sec. 7.8). More speciﬁcally, let
E(si)=d3(m)σ,
where d3(m)is a constant that depends on m. Then, d3(m)has the following expres-
sion:
d3(m)=Γ/parenleftbigm
2/parenrightbig
Γ/parenleftbigm−1
2/parenrightbig/radicalbigg
2
m−1,
where Γ(x)=/integraltext∞
0ux−1e−uduis the Gamma function. By using the properties of the
Gamma function, we have
d3(m)=

2(k−1)(2k−2(k−2)!)2
(2k−3)!/radicalig
2
π(2k−1),ifm=2k
(2k−1)!
2(2k−1(k−1)!)2/radicalig
π
k, ifm=2k+1.(3.11)
Then, the bias of sifor estimating σis(d3(m)−1)σ, and si/d3(m)is an unbiased
estimator of σ. By combining all the unbiased estimators {si/d3(m), i=1,2,..., n}
ofσ, we come up with the following unbiased estimator of σ:
/hatwideσ=s
d3(m). (3.12)
TheXchart based on (3.11) and (3.12) would have the control limits presented in the
box belo w.
Control Limits of the XChart Using Sample Standard Deviations
U=X+Z1−α/2
d3(m)√ms
C=X (3.13)
L=X−Z1−α/2
d3(m)√ms
The process is declared to have a mean shift at the i-th time point if the i-th
sample mean Xiis beyond the two control limits UandL.86 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
To monitor the process variability, it is natural to use the sample standard devia-
tions{si,i=1,2,..., n}. When the process is IC, the mean of sican be estimated by
s. By Kenney and Keeping (1951), the standard deviation of sihas the expression
σsi=/radicalig
1−d2
3(m)σ.
It can be estimated by
/hatwideσsi=/radicalig
1−d2
3(m)s
d3(m).
Therefore, if siisbeyond the control limits given in the box below, then the process
variability can be declared OC. The resulting control chart is called the s chart.
Control Limits of the sChart
U=s+Z1−α/2/radicalig
1−d2
3(m)
d3(m)s=
1+Z1−α/2/radicalig
1−d2
3(m)
d3(m)
s
C=s (3.14)
L=s−Z1−α/2/radicalig
1−d2
3(m)
d3(m)s=
1−Z1−α/2/radicalig
1−d2
3(m)
d3(m)
s
Example 3.2 For the data discussed in Example 3.1, if we construct the X and s
charts with control limits in (3.13) and (3.14), using the ﬁrst 20 samples, then
X=79.533, s=3.575,
and
d3(5)=3!
2∗(21∗1!)2/radicalbigg
π
2=0.940.
When Z1−α/2is chosen to be 3, the control limits of the X chart are
U=79.533+3
0.940∗√
5∗3.575=84.636
C=79.533
L=79.533−3
0.940∗√
5∗3.575=74.430,SHEWHART CHARTS FOR NUMERICAL V ARIABLES 87
and the control limits of the s chart are
U=/parenleftigg
1+3∗√
1−0.9402
0.940/parenrightigg
∗3.575=7.468
C=3.575
L=/parenleftigg
1−3∗√
1−0.9402
0.940/parenrightigg
∗3.575=−0.318.
We notice that the lower control limit of the s chart is −0.318, which is a negative
number. However, the sample standard deviations s icannot be negative. Therefore,
we can simply replace it by 0 as the lower control limit value. The two control charts
are demonstrated in plots (a) and (b) of Figure 3.5, respectively, in which the solid
dots denote the sample means and sample standard deviations of the ﬁrst 20 samples
shown in Table 3.2, and they are connected by solid lines. From the plots, it seems
that both the process mean and the process variability are stable at the ﬁrst 20 time
points, which is consistent with the results found in Figure 3.1. Then, we use these
two charts for online monitoring of the process (i.e., the phase II SPC). The sample
means and sample standard deviations of the ﬁrst four samples collected during the
phase II SPC are denoted by little circles in the two plots connected by dotted lines.
From the plots, we can see that a signal of process variability shift is given in plot
(b) at the 22nd time point. So, the process should be stopped at that time point for
investigation of possible special causes of the signal. This signal is two time units
earlier than the one given by the X and R charts shown in Figure 3.1.
0 5 10 15 20 2570 75 80 85
iXi
LCU
(a)0 5 10 15 20 250 2 4 6 8 10
isi
LCU
(b)
Figure 3.5 TheX chart (plot (a)) and the s chart (plot (b)) constructed from the data of the
ﬁrst 20 samples summarized in Table 3.2 about the injection molding process. The sample
means and sample standard deviations of the ﬁrst 20 samples are connected by solid lines.
Since the process is IC at the ﬁrst 20 time points, the charts are used for phase II process
monitoring. The phase II sample means and sample standard deviations are shown by little
circles connected by dotted lines. We get a signal of process variability shift at the 22nd time
point, and the process should be stopped at that time point for investigation of possible special
causes of the signal.88 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
To monitor the process variability, we can also use sample variances {s2
i,i=
1,2,..., n}. Note that each individual sample variance s2
iis an unbiased estimator of
σ2. So, a natural unbiased estimator of σ2is
s2=1
nn
∑
i=1s2
i.
For the i-th sample variance s2
i, from the discussion in Section 2.7, we know that
(m−1)s2
i
σ2∼χ2
m−1
in cases when the process is IC at the i-th time point. Therefore, the process variabil-
ity can be declared OC at the i-th time point if s2
iis beyond the control limits given
in the box below, and the resulting control chart is called the s2chart.
Control Limits of the s2Chart
U=s2χ2
1−α/2,m−1
m−1
C=s2 (3.15)
L=s2χ2
α/2,m−1
m−1,
where χ2
α/2,m−1andχ2
1−α/2,m−1are the(α/2)-th and (1−α/2)-th quantiles of
theχ2
m−1distribution.
3.2.3 The X and R charts for monitoring individual observations
In the previous two subsections, we assume that the sample collected at a given
time point has mobservations of the quality characteristic in question, and m>1.
In the literature, such data are often called batch data, or grouped data. In certain
applications, however, it is more convenient to collect one observation at each time
point. Namely, the sample size mis 1 in such cases. The resulting data are often called
individual observation data. When the observed data are individual observation data,
all the Shewhart charts discussed in the previous two subsections cannot be used
because the sample ranges Rior sample standard deviations siare all 0 in such cases
and consequently the upper and lower control limits of each of these Shewhart charts
would be the same. Obviously, such control charts do not have any power for either
phase I or phase II SPC. For applications with individual observation data, one option
is to use alternative control charts that will be described in later chapters, including
the CUSUM charts, the EWMA charts, and the CPD charts. Another option is to
modify the Shewhart charts for batch data so that the modiﬁed Shewhart charts canSHEWHART CHARTS FOR NUMERICAL V ARIABLES 89
also be used for analyzing individual observation data, which is the focus of this
subsection.
To use Shewhart charts for analyzing individual observation data, one natural
idea is to “create” grouped data, by grouping observations collected at consecutive
time points. Assume that the sample size of each group is /tildewidem>1. Then, the ﬁrst /tildewidem
observations can form the ﬁrst group, the second /tildewidemobservations can form the second
group, and so forth. If we “create” grouped data in this way, then the Shewhart charts
discussed before can be used as usual. One problem with this idea is that the gap
between two consecutive groups is /tildewidemtime points apart. Therefore, by analyzing such
grouped data, it is difﬁcult for us to know the process behavior at each time point.
To overcome this difﬁculty, in the literature, most people adopt the idea of moving
windows. With the window size /tildewidem, this idea “creates” the grouped data as follows.
Assume that the original observations are
X1,X2,..., Xn.
Then, the grouped data are deﬁned by
Group 1: X1,X2,..., X/tildewidem
Group 2: X2,X3,..., X/tildewidem+1
......
Group n−/tildewidem+1: Xn−/tildewidem+1,Xn−/tildewidem+2,..., Xn.
LetXbe the sample mean of the original observations, MR 1,MR2,..., MR n−/tildewidem+1be
the sample ranges of the n−/tildewidem+1 groups of data, and MR=1
n−/tildewidem+1∑n−/tildewidem+1
i=1MR i.
Then, by (3.5), we can estimate σby
MR
d1(/tildewidem),
and the control limits of the Xchart for monitoring individual observations become
the ones in the box below.
Control Limits of the XChart for Monitoring Individual Observations
U=X+Z1−α/2
d1(/tildewidem)MR
C=X (3.16)
L=X−Z1−α/2
d1(/tildewidem)MR
By this chart, we get a signal of process mean shift at the i-th time point if
Xi<L or Xi>U.90 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
Similarly, the control limits of the Rchart for monitoring individual observations can
be deﬁned by the ones in the box below.
Control Limits of the RChart f or Monitoring Individual Observations
U=/parenleftbigg
1+Z1−α/2d2(/tildewidem)
d1(/tildewidem)/parenrightbigg
MR
C=MR (3.17)
L=/parenleftbigg
1−Z1−α/2d2(/tildewidem)
d1(/tildewidem)/parenrightbigg
MR
By this chart, we get a signal of process variability shift at the i-thtime point if
MR i<L or MR i>U.
In such cases, we should check the production process at all time points that belong to
thei-th created group (i.e., from the i-th to the (i+/tildewidem−1)-th time points) for special
causes of the shift. Other Shewhart charts can be modiﬁed similarly for monitoring
individual observations.
Example 3.3 Twenty observations on concentration (in g/l) of the active ingredient
in a liquid cleaner produced by a chemical process are given in the second column
of Table 3.4. This is an individual observation dataset, and it is modiﬁed from the
data in Table 6E.24 of Montgomery (2009). To construct the X and R charts using
the idea of moving windows, let us consider the window size /tildewidem=2. In such cases,
the sample ranges of the 19 “created” groups are presented in the third column of
Table 3.4. To construct the control charts, let us assume that we use Z 1−α/2=3.
From Table 3.1, for window size /tildewidem=2, d 1(/tildewidem) =1.128, and d 2(/tildewidem) = 0.853. From
Table 3.4, X=72.38 andMR=8.72.
Then, the control limits of the X chart are
U=72.38+3
1.128∗8.72=95.571
C=72.38
L=72.38−3
1.128∗8.72=49.189.
The control limits of the R chart are
U=/parenleftbigg
1+3∗0.853
1.128/parenrightbigg
∗8.72=28.502
C=8.72
L=/parenleftbigg
1−3∗0.853
1.128/parenrightbigg
∗8.72=−11.062.SHEWHART CHARTS FOR CATEGORICAL V ARIABLES 91
Table 3.4 Twenty observations (labeled by X i) on concentration (in g/l) of the active ingredient
in a liquid cleaner produced by a chemical process, and the sample ranges (labeled by MR i)
of the moving windows with window size /tildewidem=2.
i Xi MR i
1 78.7 5.9
2 72.8 5.6
3 78.4 1.2
4 79.6 19.2
5 60.4 9.1
6 69.5 4.6
7 64.9 10.6
8 75.5 5.1
9 70.4 2.3
10 68.1 10.3
11 78.4 0.2
12 78.2 18.2
13 60 14.7
14 74.7 1.1
15 75.8 0.8
16 76.6 8.2
17 68.4 14.7
18 83.1 22.0
19 61.1 11.9
20 73.0
X=72.38 MR=8.72
Since the sample ranges are always nonnegative, we change the lower contr ol limit
of the R chart from −11.062 to 0. The X and R charts are shown in Figure 3.6, which
do not give any signals of process mean shift or process variability shift.
3.3 Shewhart Charts for Categorical Variables
The Shewhart charts discussed in the previous section are for monitoring production
processes with numerical quality characteristics. In many applications, the quality
characteristics of interest are categorical. In this section, we describe several She-
whart charts for monitoring production processes with categorical quality character-
istics.
3.3.1 The p chart and mp chart
In certain applications, it is inconvenient to monitor the original quality character-
istics of products directly. Instead, after certain products are randomly chosen for
monitoring purposes, they can be classiﬁed into conforming and non-conforming
products based on the designed requirements on the original quality characteristics,
and then we can monitor the proportion of non-conforming products over time. As-
sume that the true proportion of non-conforming products of a production process is92 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
0 5 10 15 2050 60 70 80 90 100
iXi
LCU
(a)0 5 10 15 200 5 10 15 20 25 30
iMR i
LCU
(b)
Figure 3.6 The X chart (plot (a)) and the R chart (plot (b)) for monitoring 20 individual
observations on concentration (in g/l) of the active ingredient in a liquid cleaner produced by
a chemical process.
πwhen the process is IC, and we obtain a random sample of mproducts at a given
time point. Let Xbe the number of non-conforming products in the sample. Then, by
the discussion in Subsection 2.4.1, it is obvious that
X∼Binomial(m,π).
Namely, Xhas a binomial distribution with two parameters mandπ. By (2.14), we
have
µX=mπ, σ2
X=mπ(1−π).
The distribution of the sample proportion of non-conforming products, denoted as
p=X/m, can be determined accordingly, and it is obvious that
µp=π, σ2
p=π(1−π)
m.
From the discussion in Subsection 2.7.1, in cases when the sample size is large, the
distribution of pcan be well approximated by the following normal distribution:
N/parenleftbigg
π,π(1−π)
m/parenrightbigg
.
In such cases, the process can be declared OC if the observed value of pis beyond
the control limits
L=π−Z1−α/2/radicalbigg
π(1−π)
m, U=π+Z1−α/2/radicalbigg
π(1−π)
m, (3.18)
where Z1−α/2is the(1−α/2)-th quantile of the N(0,1)distribution.SHEWHART CHARTS FOR CATEGORICAL V ARIABLES 93
In practice, the value of πis often unknown and it should be estimated from the
observed data. To this end, assume that we have collected nrandom samples at n
different time points, and each sample contains mproducts. The numbers of non-
conforming products in the nsamples are denoted as X1,X2,..., Xn, respectively, and
the corresponding sample proportions are p1=X1/m,p2=X2/m,..., pn=Xn/m.
Then, πcan be estimated by
p=1
nn
∑
i=1pi.
Therefore, in large sample cases, we can evaluate the process performance at the n
time points by comparing the sample proportions {pi,i=1,2,..., n}with the control
limits given in the box below, and the resulting control chart is called the p chart.
Control Limits of the pChart in Large-Sample Cases
U=p+Z1−α/2/radicalbigg
p(1−p)
m
C=p (3.19)
L=p−Z1−α/2/radicalbigg
p(1−p)
m
At the i-th time point, for i=1,2,..., n, the production process is declared OC if
pi<L or pi>U.
The control limits in (3.19) are appropriate to use only in cases when the sam-
ple size mis large. In Subsection 2.7.1, it is mentioned that the sample size can be
regarded as “large” if mπ≥10 and m(1−π)≥10. Namely, the expected numbers
of “successes” and “failures” are both at least 10 in each sample. In the literature,
some statisticians think that the normal distribution approximation to the binomial
distribution should be reliable even in cases when mπ≥5 and m(1−π)≥5. See
related discussion in Brown et al. (2001). In practice, πis often unknown, and it can
be estimated by p. Then, the resulting large-sample conditions become
mp≥5, m(1−p)≥5. (3.20)
In this chapter, we will use the less restrictive conditions in (3.20) to judge whether
control charts based on the normal distribution approximation are appropriate to use
or not in a speciﬁc application.
Example 3.4 Assume that 20 random samples are obtained from the products of a
production process, and each sample contains 50 randomly chosen products. The
numbers of non-conforming products in the 20 samples are presented in Table 3.5,
along with the sample proportions of non-conforming products. From the table, it94 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
Table 3.5 Number s of non-conforming products in 20 samples along with the sample propor-
tions of non-conforming products.
i 1 2 3 4 5 6 7 8 9 10
Xi7 3 10 1 8 5 4 9 3 9
pi0.14 0.06 0.20 0.02 0.16 0.10 0.08 0.18 0.06 0.18
i 11 12 13 14 15 16 17 18 19 20
Xi5 7 2 10 4 6 9 3 11 5
pi0.10 0.14 0.04 0.20 0.08 0.12 0.18 0.06 0.22 0.10
can be computed that p=0.121. So, m p=6.05>5and m(1−p)=43.95>5. The
large-sample conditions in (3.20) are satisﬁed, and the p chart (3.19) is appropriate
to use in this case. If we choose Z 1−α/2=3in the chart, then its control limits are
U=0.121+3∗/radicalbigg
0.121∗(1−0.121)
50=0.259
C=0.121
L=0.121−3∗/radicalbigg
0.121∗(1−0.121)
50=−0.017.
Because the sample proportions are nonnegative, the lower control limit L can be
changed to 0. The resulting p chart is shown in Figure 3.7. It can be seen from the
plot that the process seems to be IC at all 20 time points.
0 5 10 15 200.00 0.10 0.20
ipi
LCU
Figure 3.7: The p chart for monitoring the data in Table 3.5.
In cases when the sample size of a random sample collected at a given time point
is small, but we still use a control chart based on the normal distribution approxi-
mation, a direct consequence is that the actual Type I error probability, denoted as
/tildewideα, could be quite different from the nominal Type I error probability α, which is
demonstrated in the example below.SHEWHART CHARTS FOR CATEGORICAL V ARIABLES 95
Example 3.5 Assume that the sample size m equals 25 or 50, the true proportion
of non-conforming products from a production process is π, which changes its value
from 0.01 to 0.99 with a step size of 0.01, the nominal Type I error probability αis
0.01 or 0.001, and we use the large-sample control limits in (3.18) to monitor the
process by assuming πis known beforehand. Then, the values of the actual Type I
error probability /tildewideαin different cases are shown in Figure 3.8. From the four plots of
the ﬁgure, it can be seen that /tildewideαcould be substantially different from α, especially in
cases when m is small and πis close to 0 or 1. As an example, assume that α=0.01
and/tildewideα=0.02. Then, a direct implication of the difference between αand/tildewideαin this
case is that the actual false alarm rate of the control chart is two times the nominal
false alarm rate. Consequently, the production process would be mistakenly stopped
for investigating potential special causes of the false signals of shift twice as often as
it should be, and much time and resources would be wasted.
0.0 0.2 0.4 0.6 0.8 1.00.00 0.01 0.02 0.03 0.04
πα~
(a)0.0 0.2 0.4 0.6 0.8 1.00.00 0.01 0.02 0.03 0.04
πα~
(b)
0.0 0.2 0.4 0.6 0.8 1.00.00 0.01 0.02 0.03 0.04
πα~
(c)0.0 0.2 0.4 0.6 0.8 1.00.00 0.01 0.02 0.03 0.04
πα~
(d)
Figure 3.8 The actual Type I error probability /tildewideαin different cases. Plot (a): m =25and
α=0.01. Plot (b): m =50andα=0.01. Plot (c): m =25andα=0.001. Plot (d): m =50
andα=0.001. The dashed horizontal line in each plot denotes the value of α.96 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
In cases when the large-sample conditions in (3.20) are not satisﬁed, one option to
set up more appropriate control limits of the pchart is to use the discrete distribution
of the sample proportion of non-conforming products directly. In cases when the
true proportion of non-conforming products πis known and the nominal Type I error
probability is α, let
L∗=max{a :P(X≤a)≤α/2}
m, U∗=min{ a:P(X≥a)≤α/2}
m,(3.21)
where Xis arandom variable having the Binomial(n,π)distribution. Then, L∗and
U∗in (3.21) can be used as the lower and upper control limits of the pchart, and the
process can be declared OC at the i-th time point if
pi<L∗or pi>U∗.
Because of the discreteness of the binomial distribution, the actual Type I error prob-
ability/tildewideαmay not be exactly α. But,/tildewideαcan be computed beforehand to be
/tildewideα=P(X<mL∗)+P(X>mU∗).
Therefore, we should be able to know the actual Type I error probability before pro-
cess monitoring, which is much better than the situation in which /tildewideαis mistakenly
assumed to be α. In cases when πis unknown, then it should be replaced by its
estimator pin all the related computation.
In the literature, there are some alternative approximations to the binomial dis-
tribution besides the normal approximation. For related discussion, see Agresti and
Coull (1998), Brown et al. (2001), Ross (2003), and the references cited therein. For
instance, by using the approximation suggested by Agresti and Coull (1998), the
control limits of the pchart should be
U=/tildewidep+Z1−α/2/radicalbigg
/tildewidep(1−/tildewidep)
/tildewidem
C=/tildewidep (3.22)
L=/tildewidep−Z1−α/2/radicalbigg
/tildewidep(1−/tildewidep)
/tildewidem
where
/tildewidem=m+Z2
1−α/2,/tildewidep=X+Z2
1−α/2/2
/tildewidem.
Instead of monitoring the sample proportions of non-conforming products
{pi,i=1,2,..., n}, people sometimes prefer to monitor the frequencies of non-
conforming products {Xi,i=1,2,..., n}, although the two different versions of pro-
cess monitoring should be theoretically equivalent. In large-sample cases, the corre-
sponding control limits for monitoring frequencies are given in the box below, and
the resulting control chart is often called the mp chart.SHEWHART CHARTS FOR CATEGORICAL V ARIABLES 97
Control Limits of the mpChart in Large-Sample Cases
U=X+Z1−α/2/radicalbig
mp(1−p)
C=X (3.23)
L=X−Z1−α/2/radicalbig
mp(1−p),
where X=1
n∑n
i=1Xi.
At the i-th time point, for i=1,2,..., n, the production process is declared OC if
Xi<L or Xi>U.
It is obvious that X=mp. Therefore, the large-sample conditions in (3.20) become
X≥5, m−X≥5.
Control limits in small-sample cases can be discussed in a similar way to that for
monitoring the sample proportions, using the relationships that Xi=mpi, for i=
1,2,..., n, and X=mp.
3.3.2 The c chart, u chart, and D chart
The pchart and mpchart discussed in the previous subsection are for monitoring
proportions or numbers of non-conforming products in samples collected over dif-
ferent time points. In some applications, a product containing a certain number of
nonessential defects would not be labeled as a non-conforming product as long as
the quality of the product is still good enough to meet the customer’s requirement.
For instance, most new cars have small scratches on the surface and other minor de-
fects. As long as a new car’s major functions work well and its price is reasonable,
customers would still be happy to buy it. However, from the manufacturers’ view-
point, it is important to monitor the occurrence of defects over time in order to keep
and improve the quality of the products, which is the focus of this subsection.
In the new car example mentioned above, the number of scratches on the surface
of a new car obviously depends on the area of the surface that is inspected: the num-
ber would be larger if the area of inspection is larger. For instance, the number of
scratches found in the front part of a new car is not comparable with the number of
scratches found on the entire body of another new car. Therefore, to properly discuss
the occurrence of defects, the inspection unit should be relevant. An inspection unit
may be comprised of one or more than one product. It may also be comprised of
certain given parts of one or more than one product.
Letcbe the number of defects found in an inspection unit, then it is appropriate
to describe the distribution of cby a Poisson distribution (cf., the related discussion
in Subsection 2.4.5). Assume that
c∼Poisson( λ),98 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
where λ>0 is a parameter. Then, by (2.16), we have
µc=λ, σ2
c=λ.
The above Poisson distribution is appropriate to use in cases when there is only
one type of defect involved. In many applications, however, people are concerned
about multiple types of defects. By the properties of the Poisson distribution (cf.,
Subsection 2.4.5), as long as different types of defects are well speciﬁed beforehand
so that the number of different types of defects is given and unchanged over time and
the occurrence of different types of defects is independent, the total number of all
types of defects still follows a Poisson distribution. In such cases, the above Poisson
distribution is still appropriate to use.
To make a decision whether the number of defects cis OC, the control limits
usually used in the literature are
L=λ−Z1−α/2√
λ, U=λ+Z1−α/2√
λ.
In practice, the value of λis often unknown, and it needs to be estimated from
the observed data. In such cases, assume that ninspection units of the same size
are randomly selected at ntime points, and the observed numbers of defects are
c1,c2,..., cn, respectively. Let c=1
n∑n
i=1ci. Then, after λis replaced by c, the cor-
responding control limits are given in the box below, and the resulting control chart
is called the c chart.
Control Limits of the cChart
U=c+Z1−α/2√
c
C=c (3.24)
L=c−Z1−α/2√
c
By (3.24), the production process is declared OC at the i-th time point if
ci<L or ci>U.
Example 3.6 Surface defects have been counted on 15 rectangular steel plates, and
the numbers of defects found on the 15 plates are
2,7,4,3,9,2,5,2,6,1,8,3,5,10,2.
From the observed data, c is computed to be 4.6. So, by (3.24), if we choose Z 1−α/2=
3, the control limits of the c chart are
U=4.6+3∗√
4.6=11.034
C=4.6
L=4.6−3∗√
4.6=−1.834.SHEWHART CHARTS FOR CATEGORICAL V ARIABLES 99
Since the number of defects is nonnegative, the lower control limit can be changed
from−1.834 to 0. The graph of the c chart is shown in Figure 3.9, from which it can
be seen that the process producing the steel plates is IC at all 15 time points.
0 5 10 150 2 4 6 8 10
ici
LCU
Figure 3.9 The c chart for monitoring the numbers of defects found on 15 selected steel plates.
Similar to the control limits of the pchart given in (3.19), the control limits of
thecchart given in (3.24) are based on the normal approximation of the Poisson dis-
tribution. Theoretically speaking, when λincreases, the Poisson( λ)distribution gets
closer and closer to the N(λ,λ)distribution. For this reason, people often approxi-
mate the Poisson( λ)distribution by the N(λ,λ)distribution. However, this approxi-
mation is reasonably good only in cases when λis reasonably large (e.g., λ≥10). In
cases when λis small, the Poisson( λ)distribution is heavily skewed to the right. In
such cases, the control limits given in (3.24) may not be appropriate to use, because
the actual Type I error probability could be substantially different from the nominal
Type I error probability α, similar to the phenomenon demonstrated in Figure 3.8.
In such cases, we can use the (α/2)-th quantile and the (1−α/2)-th quantile of
thePoisson( c)distribution as the lower and upper control limits, respectively. We
can also use some alternative approximations to the Poisson distribution. For more
discussion on the latter topic, see Lesch and Jeske (2009).
The derivation of the control limits of the cchart given in (3.24) is based on the
assumption that all ninspection units have the same size. In certain applications,
however, different inspection units may have different sizes. For instance, assume
that the inspection unit in an application is the shipment of products. Then, it is com-
mon in practice that different shipments may contain different numbers of products.
In certain other applications, the size of the inspection unit might be related to its
spatial area, and different inspection units might have different areas. In all such
cases, the cchart with the control limits speciﬁed in (3.24) would not be appropri-
ate to use because the numbers of defects found in different inspection units are not100 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
comparable. T o overcome this difﬁculty, one natural idea is to consider
ui=ci
mi, fori=1,2,..., n,
where miis the number of products contained in the i-th inspection unit or another
size metric of the i-th inspection unit. Obviously, uiis the averaged number of defects
per size unit within the i-th inspection unit. Assume that the number of defects per
size unit follows the Poisson(/tildewideλ)distribution. Then, the number of defects within
thei-th inspection unit, ci, would follow the Poisson(m i/tildewideλ)distribution. Therefore,
µci=mi/tildewideλandσ2
ci=mi/tildewideλ. Consequently, we have
µui=/tildewideλ, σ2
ui=/tildewideλ
mi.
After/tildewideλis replaced by its estimator
u=∑n
i=1ci
∑n
i=1mi,
it isnatural to consider the control limits presented in the box below for monitoring
{ui,i=1,2,..., n}, and the resulting control chart is called the u chart.
Control Limits of the uChart
U=u+Z1−α/2/radicalbigg
u
mi
C=u (3.25)
L=u−Z1−α/2/radicalbigg
u
mi
Again, the control limits in (3.25) are appropriate to use only in cases when
{µci=mi/tildewideλ,i=1,2,..., n}are all large, because they are based on the normal
approximation to the related Poisson distributions. In cases when some or all of
{µci=mi/tildewideλ,i=1,2,..., n}are small, the alternative approaches described above for
constructing the control limits of the cchart can also be considered here.
In cases when different types of defects are present in the products, as mentioned
above, the Poisson distribution is still appropriate for describing the total number of
defects, c, found in an inspection unit, under some regularity conditions. However,
when computing the value of c, all types of defects are treated equally. In practice,
however, certain types of defects might be more essential to the quality of products,
compared to some others. In the new car example mentioned at the beginning of this
subsection, the defects in the engine system might be more serious than the minorSHEWHART CHARTS FOR CATEGORICAL V ARIABLES 101
scratches on the car surface. In such cases, it is natural to treat different types of
defects differently. To this end, one option is to build separate control charts for
different groups of defects. The defects within a group are believed to have similar
impact on the quality of products, and thus they can be treated equally. Another
option is to combine the defects in different groups by a weighted sum. Assume that
all defects are classiﬁed into kgroups. The numbers of defects in the kgroups are
denoted as c∗
1,c∗
2,..., c∗
k. Then, we deﬁne the weighted number of defects to be
D=k
∑
j=1wjc∗
j, (3.26)
where{wj,j=1,2,..., k}are the nonnegative and pre-speciﬁed weights. Speciﬁ-
cation of the weights should reﬂect the relative importance of different types of de-
fects. Obviously, it is reasonable to assume that c∗
j, for j=1,2,..., k, follows the
Poisson( λ∗
j)distribution, where λ∗
j>0 is a parameter, and that {c∗
j,j=1,2,..., k}
are independent of each other. Therefore, the mean and variance of Ddeﬁned in
(3.26) would be
µD=k
∑
j=1wjλ∗
j, σ2
D=k
∑
j=1w2
jλ∗
j. (3.27)
In cases when we have ninspection units of the same size involved, and the
observed number of defects belonging to the j-th group within the i-th inspection
unit is c∗
i j, fori=1,2,..., nandj=1,2,..., k. Then, the weighted number of defects
in the i-th inspection unit is
Di=k
∑
j=1wjc∗
i j, fori=1,2,..., n.
From (3.27), we need to estimate {λ∗
j,j=1,2,..., k}properly in order to know the
mean and variance of each Di. An obvious estimator of λ∗
j, for j=1,2,..., k, is
c∗
j=1
nn
∑
i=1c∗
i j.
Then, by (3.27), µDcan be estimated by
D=1
nn
∑
i=1Di=1
nn
∑
i=1k
∑
j=1wjc∗
i j=k
∑
j=1wjc∗
j,
andσ2
Dcan be estimated by
k
∑
j=1w2
jc∗
j.
To monitor the weighted numbers of defects {Di,i=1,2,..., n}, it is therefore rea-
sonable to use the control limits in the box below, and the corresponding control chart
is often called the D chart.102 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
Control Limits of the DChart
U=D+Z1−α/2/radicaltp/radicalvertex/radicalvertex/radicalbtk
∑
j=1w2
jc∗
j
C=D (3.28)
L=D−Z1−α/2/radicaltp/radicalvertex/radicalvertex/radicalbtk
∑
j=1w2
jc∗
j
It should be pointed out that the control limits in (3.28) are appropriate to use
only in cases when {λ∗
j,j=1,2,..., k}are all reasonably large, and the ninspection
units have the same size. Setup of the control limits of the Dchart in other cases can
be discussed similarly to the discussion about the control limits of the cchart, and is
thus omitted here.
3.4 Process Capability Analysis
3.4.1 Process capability and its measurement
As described in Section 1.2, for a given product, we often have various requirements
on its quality, based on customers’ needs, engineering tolerances, and so forth. For
simplicity, assume that Xis the quality characteristic of interest, and it is univari-
ate. Then, our requirement on the product quality is usually speciﬁed by the lower
speciﬁcation limit (LSL) and the upper speciﬁcation limit (USL). If the value of Xis
between the two limits, i.e., LSL≤X≤USL , then the product is acceptable and it
is classiﬁed as a conforming product. Otherwise, it is classiﬁed as a non-conforming
product. Process capability analysis of a production process is mainly for measuring
its capability of manufacturing conforming products, by analyzing certain observed
data that are representative of its production.
To perform a process capability analysis, the values of LSL and USL should be
determined beforehand. Also, a dataset reﬂecting the IC production of the process
should be available. In order to reﬂect the IC production of the process, the data
should be collected after the process is adjusted properly during the phase I SPC so
that the process is believed to be in statistical control. Distribution of the data should
also estimate the population distribution of all products of the IC process well. To
this end, observations in the data should be obtained by a random sampling scheme,
and the sample size should be reasonably large as well, especially in cases when
the data distribution is obviously non-normal (e.g., skewed). The following example
demonstrates the process capability analysis of an injection molding process.
Example 3.7 For an injection molding process, compressive strength (in psi) of its
manufactured parts is our major concern about the quality of products. Based onPROCESS CAPABILITY ANALYSIS 103
various consider ations, it is determined that LSL =75and USL =85for this vari-
able. After a phase I SPC, the process is believed to be IC. Then, 50 manufactured
parts are randomly selected, and their compressive strengths are recorded. The den-
sity histogram of the 50 observations is shown in Figure 3.10, from which it can be
seen that the data are roughly normally distributed. The sample mean and sample
standard deviation are computed to be
X=80.194, s=2.775.
Then, the process capability can be measured by the probability P(LSL ≤X≤USL),
where X denotes the compressive strength of a randomly selected manufactured part.
This probability can be computed as follows:
P(LSL≤X≤USL) = P/parenleftbiggLSL−80.194
2.775≤X−80.194
2.775≤USL−80.194
2.775/parenrightbigg
≈P(−1.872≤Z≤1.732)
=0.928,
where Z denotes a random variable with the standard normal distribution. Based on
this measure, we know that about 92.8% of manufactured parts of the process are
conforming products, and about 7.2% of manufactured parts are non-conforming
products.
The process capability analysis can also be made based on a control chart directly
in cases when the control chart conﬁrms that the related production process is IC. For
instance, in the case of Example 3.2 in Subsection 3.2.2, the Xchart constructed from
the ﬁrst 20 samples of size 5 each conﬁrms that the related injection molding process
is IC at the ﬁrst 20 time points. In Example 3.2, it has been computed that
X=79.533, s=3.575, d3(5)=0.940.
So, by (3.12), the mean and standard deviation of the quality characteristic Xcan be
estimated by
/hatwideµX=X=79.533,/hatwideσX=s
d3(5)=3.575
0.940=3.803.
If we still use LSL=75 and USL=85, as in Example 3.7, and assume that Xhas a
normal distribution, then
P(LSL≤X≤USL) = P/parenleftbiggLSL−79.533
3.803≤X−79.533
3.803≤USL−79.533
3.803/parenrightbigg
=P(−1.192≤Z≤1.438)
=0.808.
3.4.2 Process capability ratios
To measure the process capability, many process capability ratios (PCRs) have been
proposed in the literature. Next, we describe a number of basic PCRs and their major104 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
Compressive StrengthDensity
74 76 78 80 82 84 86 880.00 0.04 0.08 0.12
Figure 3.10 Density histo gram of the compressive strengths of 50 randomly selected manu-
factured parts of an injection molding process. The solid curve is the estimated density curve
of the data.
properties in cases when the distribution of the quality characteristic Xis assumed
normal. For overviews and bibliographies on this topic, see Kotz and Johnson (2002),
Spiring et al. (2003), and Yum and Kim (2011).
As in the previous subsection, assume that the mean and standard deviation of X
areµandσ, and the lower and upper speciﬁcation limits are LSL andUSL . Then,
one of the earliest PCRs is deﬁned by
Cp=USL−LSL
6σ. (3.29)
In cases when X∼N(µ,σ2), we know that
P(µ−3σ≤X≤µ+3σ)=0.9977.
In such cases, only about 0.23% of observations of Xwould be outside the interval
(µ−3σ,µ+3σ). Obviously, 6 σin (3.29) is the length of this interval, and Cpis
the ratio of the length of the speciﬁcation interval (LSL,USL)to 6σ. In cases when
the center Tof the speciﬁcation interval (LSL,USL)is the same as the center µof
the distribution of X, if the value of Cpis larger, then the chance for the observations
ofXto be outside the speciﬁcation interval (LSL,USL)would be smaller, which is
demonstrated by Figure 3.11(a). In the plot, two distributions of Xare consideredPROCESS CAPABILITY ANALYSIS 105
and the y are shown in the plot by the solid and dashed curves, respectively. It can be
seen that the two distributions have the same center, but the one shown by the dashed
curve has a smaller spread. In such cases, the Cpvalue for the distribution shown
by the dashed curve would be larger than the Cpvalue for the distribution shown by
the solid curve (see Example 3.8 below for details), which implies that the quality of
the production process in the former scenario would be better than the quality of the
production process in the latter scenario.
−3 −1 0 1 3LSL T USL
(a)−3 −1 0 1 3LSL T USL
(b)
Figure 3.11 (a) The distributions shown by the solid and dashed curves have the same center,
but the one shown by the dashed curve has a smaller spread than the one shown by the solid
curve. (b) The two distributions shown by the solid and dashed curves have different centers,
but they have the same spread. In each plot, LSL and USL on the top denote the lower and
upper speciﬁcation limits, and T is their center.
From its deﬁnition in (3.29), it can be seen that the PCR Cpconsiders the spread
of the distribution of X. However, it does not take into account the center of the
distribution. Let us consider the two cases shown in Figure 3.11(b) where the two
distributions of Xshown by the solid and dashed curves have the same spread but
they have different centers. By the deﬁnition in (3.29), the Cpvalues in the two cases
are the same. But, it is obvious that the probability P(LSL≤X≤USL)would be
smaller in the case with the distribution shown by the dashed curve, compared to the
case with the distribution shown by the solid curve.
To overcome the limitation of Cpdescribed above, some alternative PCRs have
been proposed. One of them is deﬁned as follows.
Cpk=min/parenleftbig
Cpl,Cpu/parenrightbig
, (3.30)
where
Cpl=µ−LSL
3σ, Cpu=USL−µ
3σ. (3.31)106 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
The PCRs CplandCpudeﬁned in (3.31) are the two one-sided PCRs: Cplis the lower-
side PCR and Cpuis the upper-side PCR. The PCR Cpkdeﬁned in (3.30) takes the
smaller value of them. Obviously, Cpkhas taken into account both the center and
spread of the distribution of X.
In mathematics, we have the simple fact that, for any two nonnegative numbers
aandb, we have
min(a, b)=(a+b)−|a−b|
2.
By using this fact, we have the following results:
Cpk=min/parenleftbig
Cpl,Cpu/parenrightbig
=1
2/bracketleftbig
(Cpl+Cpu)−|Cpl−Cpu|/bracketrightbig
=1
2/bracketleftbiggUSL−LSL
3σ−|USL+LSL−2µ|
3σ/bracketrightbigg
=Cp−|T−µ|
3σ
=/bracketleftbigg
1−|T−µ|
d/bracketrightbigg
Cp, (3.32)
where d=(USL−LSL)/2 is the half length of the speciﬁcation interval [LSL,USL].
The expression (3.32) implies that
(i)Cpk≤Cpand the equality holds if and only if µ=T, and
(ii)Cpkdecreases when |µ−T|increases.
By these results, the Cpkvalue in the case with the distribution of Xshown by the
dashed curve in Figure 3.11(b) would be smaller than its value in the case with the
distribution shown by the solid curve in the same plot, which is intuitively reasonable.
Example 3.8 In Figure 3.11(a), we consider two distributions of X, N (0,1)and
N(0,0.52), shown by the solid and dashed curves, respectively. In both cases, as-
sume that LSL =−3and USL =3. Then, it is easy to compute the following values:
In the case with N (0,1),
Cp=[3−(−3)]/(6∗1)= 1,
Cpl=Cpu=Cpk=3/3=1.
In the case with N (0,0.52),
Cp=[3−(−3)]/(6∗0.5)= 2,
Cpl=Cpu=Cpk=3/(3∗0.5)= 2.
In both cases, we have
Cp=Cpl=Cpu=Cpk. (3.33)
The results in (3.33) are not just a coincidence. As a matter of fact, as long as µ=
T , they must be true. Therefore, in such cases, all the PCRs C p, Cpl, Cpu, and C pkPROCESS CAPABILITY ANALYSIS 107
areequivalent, and any one of them is reasonable to use for measuring the process
capability. To compare the two cases, all four PCRs show that the process is more
capable of producing conforming products in the case with N (0,0.52), compared to
the case with N (0,1).
In Figure 3.11(b), the two distributions of X are N (0,1)and N(1,1). They have
the same spread, but their centers are different. Let us still assume that LSL =−3and
USL=3. Then, it is easy to compute the following values: In the case with N (0,1),
Cp=[3−(−3)]/(6∗1)= 1,
Cpl=Cpu=Cpk=3/3=1.
In the case with N (1,1),
Cp=[3−(−3)]/(6∗1)= 1,
Cpl=[1−(−3)]/(3∗1)= 1.333,
Cpu=(3−1)/(3∗1)= 0.667,
Cpk=min( Cpl,Cpu)=0.667.
It can be seen that the value of C pequals 1 in both cases. So, this PCR is not
appropriate to use in cases when µand T are different. On the other hand, the
value of C pkis smaller in the case with N (1,1)than its value in the case with
N(0,1). Therefore, it has indeed taken into account the center of the distribution
of X, and is thus more appropriate to use than C pin cases when µand T are
different. As a veriﬁcation, by using the relationship between C pand C pkestab-
lished in (3.32), in the case with N (1,1), we have T =0,µ=1, and d=3. Thus,
Cpk=(1−|T−µ|/d)Cp=2Cp/3=0.667, which is the same as its value computed
above from the deﬁnition of C pk.
Another alternative PCR that takes into account the center of the distribution of
Xis deﬁned by
Cpm=USL−LSL
6τ, (3.34)
where
τ=/radicalig
E[(X−T)2].
Obviously,
τ2=E/bracketleftbig
(X−T)2/bracketrightbig
=E/bracketleftbig
(X−µ)2/bracketrightbig
+(µ−T)2
=σ2+(µ−T)2. (3.35)
Namely, τ2is the mean squared distance between Xand its target T. By combining
(3.34) and (3.35), we have
Cpm=USL−LSL
6/radicalbig
σ2+(µ−T)2
=Cp/radicalbigg
1+/parenleftig
µ−T
σ/parenrightig2. (3.36)108 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
From (3.36), it can be seen that
(i)Cpm≤Cpand the equality holds if and only if µ=T, and
(ii)Cpmdecreases when |µ−T|increases.
These two properties conﬁrm that Cpmindeed takes into account the center µof the
distribution of X, and its value would be smaller when µis farther away from the
target value T.
To increase the sensitivity to the difference between µandT, we can also com-
bine the two PCRs CpkandCpm, by replacing Cpin (3.36) with Cpk. The resulting
PCR is
Cpkm=Cpk/radicalbigg
1+/parenleftig
µ−T
σ/parenrightig2. (3.37)
Example 3.8 (continued) In the case when X ∼N(1,1), LSL=−3, and USL =
3considered in Example 3.8 (i.e., the case shown by the dashed curve in Figure
3.11(b)), it can be computed by (3.36) and (3.37) that
Cpm=1/radicalig
1+/parenleftbig1−0
1/parenrightbig2=0.707
and
Cpkm=0.667/radicalig
1+/parenleftbig1−0
1/parenrightbig2=0.471.
Indeed, Cpkmis more sensitive to the departure of µfrom T , compared to both C pk
and C pm.
In the deﬁnitions of all the PCRs Cp,Cpl,Cpu,Cpk,Cpm, and Cpkmdescribed
above, the population parameters µandσare involved, which are often unknown
in practice. In such cases, to use these PCRs for measuring process capability, a
dataset reﬂecting the IC performance of the production process should be collected
beforehand, as in cases considered in the previous subsection. Then, µandσcan be
estimated by the sample mean xand the sample standard deviation sof the collected
IC dataset, respectively. After they are replaced by their estimators, the resulting es-
timators of Cp,Cpl,Cpu,Cpk,Cpm, and Cpkmcan be obtained, which are denoted as
/hatwideCp,/hatwideCpl,/hatwideCpu,/hatwideCpk,/hatwideCpm, and/hatwideCpkm, respectively. In the case of Example 3.7, it can bePROCESS CAPABILITY ANALYSIS 109
computed that
/hatwideCp=USL−LSL
6s=85−75
6∗2.775=0.601,
/hatwideCpl=x−LSL
3s=80.194−75
3∗2.775=0.624,
/hatwideCpu=USL−x
3s=85−80.194
3∗2.775=0.577,
/hatwideCpk=min/parenleftig
/hatwideCpl,/hatwideCpu/parenrightig
=0.577,
/hatwideCpm=/hatwideCp/radicalig
1+/parenleftbigx−T
s/parenrightbig2=0.601/radicalig
1+/parenleftbig80.194−80
2.775/parenrightbig2=0.600,
/hatwideCpkm=/hatwideCpk/radicalig
1+/parenleftbigx−T
s/parenrightbig2=0.577/radicalig
1+/parenleftbig80.194−80
2.775/parenrightbig2=0.576.
Besides point estimators, it is also possible to derive conﬁdence intervals (CIs)
for the PCRs. For instance, from Subsection 2.7.1, we know that
(m−1)s2
σ2∼χ2
m−1,
where s2is the sample variance of an IC dataset of size m. Then, by the relationship
s/σ=Cp//hatwideCp, we have
P/parenleftbigg
χ2
α/2,m−1≤(m−1)s2
σ2≤χ2
1−α/2,m−1/parenrightbigg
=1−α
⇐⇒ P
/hatwideCp/radicaligg
χ2
α/2,m−1
m−1≤Cp≤/hatwideCp/radicaligg
χ2
1−α/2,m−1
m−1
=1−α
where χ2
α/2,m−1andχ2
1−α/2,m−1are the(α/2)-th and (1−α/2)-th quantiles of the
χ2
m−1distribution. So, the 100(1 −α)% CI for Cpis

/hatwideCp/radicaligg
χ2
α/2,m−1
m−1,/hatwideCp/radicaligg
χ2
1−α/2,m−1
m−1
. (3.38)
The CIs forCpkandCpmcan be obtained from (3.38), by using the relationships
between Cpand both CpkandCpmestablished in (3.32) and (3.36), after µandσ
in the related formulas are replaced by Xands. Such CIs should be reliable to use
when the sample size mof the IC data is reasonably large and the distribution of Xis
normal. In the literature, alternative CIs have been proposed for CpkandCpm, along
with CIs for some other PCRs. Interested readers can see Kotz and Lovelace (1998),
Pearn et al. (1992), Zhang et al. (1990), and the references cited therein.110 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
Readers are reminded that all the PCRs described above are based on the assump-
tion that the distribution of Xis normal. In cases when the distribution of Xis not
normal, it might be misleading to use these PCRs to measure the process capabil-
ity, because they do not take into account the shape of the distribution of Xin their
deﬁnitions. In such cases, one possible approach is to transform Xﬁrst such that the
distribution of the transformed Xis close to normal, and then we can compute the
PCRs in the transformed scale. Such a transformation can be searched based on an
IC data of the process collected beforehand. Another option is to develop PCRs that
are appropriate for non-normal distributions. In the literature, there has been much
existing research on this latter approach. See, for instance, Levinson (2010), Luce ˜no
(1996), Rodriguez (1992), Yeh and Bhattacharya (1998), and Yeh and Chen (2001).
3.5 Some Discussions
We have described some basic Shewhart charts for monitoring production processes
when the quality characteristic of interest Xis univariate. These Shewhart charts
make decisions about the process performance at a given time point using the ob-
served data at that time point only, under a similar framework to hypothesis testing.
In cases when Xis numerical, the related Shewhart charts (e.g., the X,R,andscharts)
are based on the assumption that the distribution of Xis normal. In cases when Xis
categorical, the related Shewhart charts (e.g., the p,c,anducharts) are constructed
based on the binomial or Poisson distribution model. They are simple to construct,
and convenient to use. Therefore, they are popular in practice.
Because the Shewhart charts evaluate the process performance based on the ob-
served data at each individual time point, they are good at detecting relatively large
and transient shifts in the distribution of X. They are less efﬁcient in detecting rela-
tively small and persistent shifts, compared to the CUSUM, EWMA, and other con-
trol charts that will be discussed in later chapters. For this reason, the Shewhart charts
are especially popular in phase I SPC, because relatively large and transient shifts are
common in phase I SPC and less common in phase II SPC.
The X,R,andscharts discussed in Section 3.2 are appropriate to use only in
cases when the distribution of Xis normal. In cases when the distribution of Xis
non-normal, their actual Type I error probabilities could be substantially different
from the nominal level α. If the actual Type I error probability of a Shewhart chart is
larger than α, then the control chart would give false signals of shift more often than
expected. Consequently, much time and many resources would be wasted in investi-
gating possible root causes of the false signals and in adjusting the related production
process. If the actual Type I error probability of a Shewhart chart is smaller than α,
then real shifts would be missed by the control chart more often than expected and
consequently many non-conforming products could be manufactured. In cases when
the distribution of Xis non-normal but the sample size mof the sample collected at
each time point is large, the problem described above would not be serious, because
the central limit theorem (cf., Subsection 2.7.1) guarantees that the distributions of
the related statistics (e.g., the sample mean) would be approximately normal. In cases
when the distribution of Xis non-normal and mis small, one option to use the re-SOME DISCUSSIONS 111
lated She whart charts properly is to transform the observed data to normal and then
apply the Shewhart charts to the transformed data. To this end, there is some existing
research. See, for instance, Chou et al. (1998) and Yourstone and Zimmer (1992).
Another option is to use the Shewhart charts that are designed for monitoring pro-
cesses with non-normal data, which will be discussed in Chapter 8 in detail.
If the performance of the Shewhart charts is evaluated by the IC ARL value ARL 0
and OC ARL value ARL 1, then these performance measures are also affected by the
possible correlation among the data collected at different time points. Note that the
formulas (3.8) and (3.9) for computing ARL 0andARL 1are derived based on the
assumption that samples obtained at different time points are independent of each
other. In cases when this assumption is violated, these formulas become invalid, and
the actual ARL 0andARL 1values could be affected by the correlation among different
samples, as demonstrated by many authors, including Alwan (1992), Black et al.
(2011), and English et al. (2000). In such cases, the correlation should be handled
properly when computing the actual ARL 0andARL 1values.
Thepandmpcharts discussed in Subsection 3.3.1 are for monitoring the propor-
tion of non-conforming products over time. In this case, the status of each product is
binary: conforming or non-conforming. In certain applications, however, the status of
a product might have more than two possible categories. For instance, the quality of
a product can be classiﬁed into three or more categories, and the products in different
categories of quality can be sold at different prices. In such cases, the observed num-
bers of products in a sample that belong to different categories have a multinomial
distribution. Much research has been done in recent years on SPC of multinomial
data. See Topalidou and Psarakis (2009) for an overview. In our description of the p,
mp,c,u, and Dcharts in Section 3.3, the control charts are constructed based solely
on the related binomial or Poisson distribution model. In practice, however, the vari-
ability of the observed data is often larger than that computed from these distribution
models. This is the so-called overdispersion phenomenon. An intuitive explanation
of this phenomenon is that the quality characteristic Xis often affected by many vari-
ables or factors that are not considered in our study. Such variables or factors would
contribute to the variability of X, making the variance of Xlarger. In the literature,
there is a limited discussion on this issue. See, for instance, Albers (2011) and Grigg
et al. (2009).
In Section 3.4, we brieﬂy discuss the topic of process capability analysis. From
the discussion, it can be seen that the process capability could be poor even when
the related process is IC. Therefore, although the major goal of most control charts
described in this book is to detect distributional shifts in the quality characteristic(s)
of interest and to make sure that the related process runs stably, the ultimate goal of
quality control and management is to improve the quality of manufactured products,
by keeping the mean of the quality characteristic(s) close to its target and by con-
stantly reducing the variability of the quality characteristic(s). To achieve the goal of
quality control and improvement, SPC charts play an important role. However, many
other statistical tools, such as design of experiment, regression, acceptance sampling,
and so forth, are also important, although they are not discussed in detail in this book.112 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
3.6 Exer cises
3.1 For the hypothesis testing problem discussed at the beginning of Subsection
3.2.1 with the hypotheses
H0:µ=µ0 versus H1:µ/ne}ationslash=µ0,
verify that, for the testing procedure with the test statistic in (3.1), H0can be
rejected at the signiﬁcance level αifXisatisﬁes the conditions in (3.3). See
related discussion in Subsection 2.7.3 about this testing procedure.
3.2 For the point estimator /hatwideµ0of the IC mean µ0deﬁned in (3.4),
(i) show that/hatwideµ0is an unbiased estimator of µ0in cases when all samples are
collected from an IC process, and
(ii) specify the sampling distribution of /hatwideµ0in such cases.
3.3 Assume that the process mean shifts from µ0toµ1=µ0+δat the τ-th time
point, with δ/ne}ationslash=0 and 1<τ≤n. Namely, the process mean is µ0at the i-th time
point when i<τ, and is µ1when i≥τ. All other properties of the distribution
of the quality characteristic Xare unchanged before and after the shift. For the
point estimator /hatwideµ0of the IC mean µ0deﬁned in (3.4), do the following problems.
(i) Is/hatwideµ0still an unbiased estimator of µ0? Why?
(ii) Specify the sampling distribution of /hatwideµ0in such cases.
3.4 The values of d1(m) andd2(m) presented in Table 3.1 can be obtained by a
simulation study described below. First, generate nrandom samples from the
distribution N(0,1)with each sample having mobservations. Second, compute
the sample ranges of the nsamples. Third, the value of d1(m)can be estimated by
the sample mean of the nsample ranges, and the value of d2(m)can be estimated
by their sample standard deviation.
(i) Using the simulation study described above, verify the values of d1(m)and
d2(m)that are presented in Table 3.1 in cases when m=2,5,10, and 20. In
your simulation study, use n=1,000 and n=10,000, respectively, to obtain
two sets of results. Compare these two sets of results, and summarize your
ﬁndings.
(ii) In cases when the IC distribution of the quality characteristic XisN(µ0,σ2),
show that d1(m)andd2(m)do not depend on µ0andσ.
3.5 Assume that we have collected 10 samples of size 5 each from a process pro-
ducing bearings. The quality characteristic of interest Xis the inside diameter
measurements of the bearings. The original observed data of Xalong with the
sample means and sample ranges are given in the table below.EXERCISES 113
Sample x1 x2 x3 x4 x5 X R
1 34.09 36.30 35.76 35.01 36.50 35.53 2.41
2 36.11 34.39 35.15 36.76 37.63 36.01 3.24
3 33.43 35.41 34.00 35.20 35.67 34.74 2.24
4 36.79 35.96 35.62 34.48 33.63 35.30 3.16
5 36.46 35.89 35.83 35.43 35.40 35.80 1.06
6 33.59 34.76 33.98 34.35 35.39 34.41 1.80
7 36.17 36.20 34.60 34.97 34.83 35.35 1.60
8 34.66 35.05 36.08 34.99 35.15 35.19 1.42
9 35.95 34.18 35.02 35.32 34.77 35.05 1.77
10 35.62 35.18 34.93 36.35 36.24 35.66 1.42
(i) Construct the XandRcharts using α=0.0027. Does the process seem to be
in statistical control?
(ii) Assume that the manufacturing process is IC, and the observed dataset shown
in the above table is an IC dataset. Provide estimates for the IC mean µ0and
the IC standard deviation σofX.
(iii) Using the results in parts (i) and (ii), compute the probability that the sample
mean of a new sample of size 5 would give a signal of mean shift in the X
chart constructed in part (i) in cases when the true process mean is not shifted.
(iv) Compute the ARL 0value of the Xchart constructed in part (i), and its ARL 1
value when detecting a mean shift of size 1 (i.e., the shifted mean µ1=µ0+
1).
3.6 The sample standard deviations of the observed data presented in Exercise 3.5
are computed to be
0.99, 1.28, 0.97, 1.25, 0.43, 0.70, 0.77, 0.53, 0.66, 0.63
(i) Construct the Xandscharts using α=0.0027 (cf., (3.13) and (3.14)). Does
the process seem to be in statistical control?
(ii) Compare the control charts in part (i) and the control charts obtained in part
(i) of Exercise 3.5, and summarize your ﬁndings.
(iii) The standard deviation σof the quality characteristic Xcan be estimated by
(3.5) based on the sample ranges. It can also be estimated by (3.12) based
on the sample standard deviations. Further, it can be estimated by the sample
standard deviation of the combined sample (i.e., all samples are combined
into a single sample). Discuss the strengths and limitations of the three es-
timators of σfor the purpose of SPC, and compute their values using the
observed data given in Exercise 3.5.
3.7 To monitor a production process, assume that nrandom samples of size meach
are collected at ndifferent time points. Based on the observed data, an Xchart
is constructed for monitoring the process mean. In order to guarantee the overall
probability of Type I error at all ntime points to be /tildewideα, the signiﬁcance level α
used at a single time point when constructing the Xchart should be chosen by
the formula (3.10).114 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
(i) When/tildewideα=0.001, determine the values of αin cases when (a) n=10 and (b)
n=100. Discuss the difference between the values of αin the two different
cases, and its impact on the Xchart.
(ii) When/tildewideα=0.0001, redo the problem in part (i). Compare the results here with
those obtained in part (i), and summarize your major ﬁndings.
3.8 Assume that we have collected 14 samples of size 5 each from an injection
molding process. The sample means and sample standard deviations of the com-
pressive strength measurements of the sampled parts are listed below.
Sample 1 2 3 4 5 6 7
Xi 80.22 78.31 81.40 78.53 81.32 80.54 77.33
si 3.99 5.35 4.79 4.68 3.79 5.78 3.52
Sample 8 9 10 11 12 13 14
Xi 79.24 81.44 77.76 79.48 76.74 81.12 86.79
si 4.51 5.16 4.81 4.56 7.35 3.91 6.31
(i) Use the ﬁrst 10 samples to construct the Xandscharts (cf., (3.13) and (3.14)).
Does the process seem to be in statistical control? If the answer is positive,
then use the constructed control charts to monitor the last 4 samples, which
are treated as phase II data. Describe your ﬁndings of the phase II SPC.
(ii) Use the ﬁrst 10 samples to construct the s2chart (cf., (3.15)). If the process
variability seems to be in statistical control at the ﬁrst 10 time points, then
use the constructed control chart to monitor the process variability at the last
4 time points by treating the last 4 samples as phase II data. Describe your
ﬁndings of the phase II SPC.
(iii) Note that by taking the squared root of the lower and upper control limits of
thes2chart, we obtain the lower and upper control limits of a new version of
theschart. Compare this version of the schart with the schart constructed in
part (i) for both phase I and phase II analyses.
3.9 The data given below are measurements of the tensile strength of the sampled
papers manufactured by a production process. This is an individual observation
dataset. At each time point, only one observation is obtained, and different ob-
servations are obtained at equally spaced time points.
25,24,39,26,25,22,24,21,28,24,24,22,16,26,25,26,21,25,23,24
Construct the XandRcharts (cf., (3.16) and (3.17)) using moving windows of
size/tildewidemeach with (i)/tildewidem=2, and (ii)/tildewidem=5. Compare the two sets of control
charts, and summarize your major ﬁndings.
3.10 Assume that X∼Binomial(m,π). In practice, people often approximate the dis-
tribution Binomial(m,π)using the normal distribution N(mπ,mπ(1−π)). Use
the original binomial distribution and its normal approximation to compute the
following probabilities, respectively. Compare the two sets of results, and sum-
marize your major ﬁndings.
(i)P(X≤3)when m=20 and π=0.1.EXERCISES 115
(ii)P(X≤3)when m=20 and π=0.4.
(iii) P(X≤3)when m=100 and π=0.1.
(iv) P(X≤3)when m=100 and π=0.4.
3.11 To control the proportion of non-conforming products manufactured by a pro-
duction process, 20 samples of size m=100 each are obtained. The numbers of
nonconforming products in the 20 samples are listed below.
10,15,31,18,24,12,23,15,19,21,16,24,28,15,23,19,14,27,20,18
(i) Construct the pchart using the above data and α=0.0027. Does the process
seem to be in statistical control?
(ii) If the true proportion of non-conforming products is π=0.19 when the pro-
cess is IC, what would be the minimum value of the sample size min order to
detect a shift in pfrom 0.19 to 0.29 with a 90% chance, using a pchart with
the control limits speciﬁed in (3.19) and α=0.0027?
3.12 Reproduce the results shown in Figure 3.8.
3.13 The numbers of non-conforming products in 20 samples of size m=50 each are
listed below.
4,3,4,2,4,4,4,2,3,5,5,5,8,1,4,3,6,7,4,4
(i) Construct the pchart using the control limits speciﬁed in (3.19) and α=
0.0027. Does the process seem to be in statistical control?
(ii) For the above data, it can be computed that mp=4.1. So, the large-sample
conditions in (3.20) are not satisﬁed. Consequently, the pchart constructed in
part (i) may not be appropriate to use. In such cases, one alternative method
is to use (3.21) to specify the control limits of the pchart, after πis estimated
byp=0.082. Construct the pchart using this method, and compare this chart
with the chart constructed in part (i).
(iii) Because of the discreteness of the binomial distribution, the actual Type I
error probability α′of the chart constructed in part (ii) may not be exactly α.
Compute the value of α′of that control chart.
(iv) Construct the pchart using the control limits speciﬁed in (3.22) and α=
0.0027. Compare this chart with the charts constructed in parts (i) and (ii),
and summarize your major ﬁndings.
3.14 For the data in Exercise 3.11, construct the mpchart using the control limits
speciﬁed in (3.23) and α=0.0027. Is this control chart equivalent to the control
chart constructed in part (i) of Exercise 3.11?
3.15 Assume that the number of defects, c, found in an inspection unit follows the
Poisson( λ)distribution. When deriving the control limits of the cchart listed in
(3.24), the Poisson( λ)distribution is approximated by the N(λ,λ)distribution.
Use the original Poisson distribution and its normal approximation to compute
the following probabilities. Compare the two sets of results, and summarize your
major ﬁndings.116 UNIV ARIATE SHEWHART CHARTS AND PROCESS CAPABILITY
(i)P(c≤3)when λ=5.
(ii)P(c≤3)when λ=10.
(iii) P(c≤3)when λ=100.
(iv) P(c≤20)when λ=100.
3.16 Surface defects have been counted on 10 rectangular steel plates, and the num-
bers of defects on the 10 plates are as follows.
10,10,5,10,14,9,16,12,8,10,6,9,13,10,8,9,10,13,10,7
Set up a cchart for monitoring the number of defects using these data and α=
0.0027. Does the process producing the plates appear to be in statistical control?
3.17 To monitor a production process, 10 inspection units are chosen. The number of
products in the i-th inspection unit, mi, and the number of defects found on those
products, ci, for i=1,2,..., 10, are listed below.
i 1 2 3 4 5 6 7 8 9 10
mi79 57 83 67 59 73 65 59 66 75
ci44 32 59 35 24 34 51 32 38 43
Set up a uchart using these data and α=0.0027. Does the production process
appear to be in statistical control?
3.18 Assume that we are mainly concerned about three types of defects on the electric
components manufactured by a production process. Twenty inspection units of
the same size are randomly chosen, and the numbers of defects of the three
different types found in these units are listed below.
i 1 2 3 4 5 6 7 8 9 10
c∗
i15 6 3 4 2 4 8 7 1 5
c∗
i211 11 7 17 10 8 8 15 9 7
c∗
i321 19 17 23 29 30 14 36 26 24
i 11 12 13 14 15 16 17 18 19 20
c∗
i14 8 8 6 2 3 1 4 3 6
c∗
i26 7 12 11 6 9 9 8 10 13
c∗
i315 18 23 28 21 22 18 17 27 28
Considering different impacts of the three types of defects on the product qual-
ity, the weights w1=0.6,w2=0.3, and w3=0.1 are used when deﬁning the
weighted numbers of detects in the 20 inspection units using (3.26). Construct
theDchart using the control limits speciﬁed in (3.28) and α=0.0027. Does the
production process appear to be in statistical control?
3.19 Assume that the observed data in Exercise 3.5 are obtained from an IC process,
each of the 10 samples is a simple random sample, and the 10 samples are in-
dependent of each other. So, for the process capability analysis, the 10 samples
can be combined into a single sample.
(i) Check for the normality of the combined sample.
(ii) Assume that the lower and upper speciﬁcation limits are LSL=33 and USL=EXERCISES 117
38 for the quality characteristic X. Estimate the probability P(LSL≤X≤
USL)using the combined sample.
(iii) With the same lower and upper speciﬁcation limits as those in part (ii), es-
timate the probability P(LSL≤X≤USL)based on the control charts con-
structed in part (i) of Exercise 3.5.
3.20 Assume that a quality characteristic Xhas a normal distribution when a related
production process is IC, and the speciﬁcation limits on XareLSL=2100 and
USL=2300. A random sample of size 50 obtained from the IC process results
inX=2250 and s=50.
(i) Compute point estimates of Cp,Cpk, and Cpm. Between CpandCpk, which
one is more appropriate to use in this case? Why?
(ii) Construct a 95% conﬁdence interval for Cp.
(iii) Based on the provided information, compute the probability that a randomly
selected product from the IC process would be a defective product.
3.21 Using the conﬁdence interval formula (3.38) and the relationships between Cp
and both CpkandCpmestablished in (3.32) and (3.36), derive the conﬁdence
interval formulas for CpkandCpm. Then, construct 95% conﬁdence intervals for
CpkandCpmin the case considered in Exercise 3.20.Chapter 4
Univ ariate CUSUM Charts
4.1 Introduction
Assume that we want to monitor a univariate quality characteristic Xof a produc-
tion process. The Shewhart charts described in the previous chapter make decisions
about the process performance at a given time point based solely on the observed
data at that single time point. Their decision rules are constructed in a similar way
to those of the hypothesis testing procedures, by which the process is declared OC
if the observed value of the charting statistic of a Shewhart chart is beyond its lower
and upper control limits at the given time point, and the process is declared IC oth-
erwise. For simplicity of perception, let us further assume that we are interested in
monitoring the process mean in a given application, and other distributional proper-
ties of Xwould not change after a mean shift. In such cases, the distribution of Xis
F0before the mean shift, it changes to another distribution F1after the shift, and the
only difference between F0andF1is their means. At a given time point n, if there
is no shift before n, then all observations obtained before nshould provide useful
information about the IC process performance. In cases when the mean shift occurs
before n, all observations obtained between the occurrence of the shift and the time
nshould all provide useful information about the OC process performance. In both
cases, the history data obtained before ncontain useful information for process mon-
itoring; but, the Shewhart charts do not make use of such information at all. For this
reason, they would not be effective for detecting persistent shifts, especially in cases
when the shifts are relatively small, which is demonstrated in the following example.
Example 4.1 Assume that 10 samples of size 5 each are generated from the N (0,1)
distribution, and another 10 samples of size 5 each are generated from the N (0.2, 1)
distribution. These samples can be regarded as observed data collected at 20 con-
secutive time points from a production process, the IC distribution of the process is
N(0,1), and the process has a mean shift of size 0.2 at the 11th time point. Figure
4.1(a) shows the X chart constructed from the 20 samples with the control limits
computed by the formulas in (3.6). In the plot, the ﬁrst 10 sample means are denoted
by solid dots and they are connected by solid lines, and the second 10 sample means
are denoted by little circles and they are connected by dotted lines. This chart can
be used for a phase I SPC. From the plot, it can be seen that the true mean shift at
the 11th time point is not detected by the chart. Figure 4.1(b) shows an alternative
X chart for a phase II SPC, in which the IC process distribution is assumed to be
known N(0,1), the lower and upper control limits of the chart are set to −3/√
5and
119120 UNIV ARIA TE CUSUM CHARTS
3/√
5, respectively, and all the symbols and notations in the plot have the same inter-
pretation as those in Figure 4.1(a). From the plot, it can be seen that the alternative
X chart cannot detect the true mean shift at the 11th time point either.
0 5 10 15 20−1.5 −0.5 0.5 1.5
iXi
LCU
(a)0 5 10 15 20−1.5 −0.5 0.5 1.5
iXi
LCU
(b)
Figure 4.1 (a) The X chart constructed from all 20 samples with the control limits computed
by the formulas in (3.6). (b) An alternative X chart for a phase II SPC, in which the IC process
distribution is assumed to be known N (0,1)and the lower and upper control limits of the
chart are set to be −3/√
5and3/√
5, respectively. In each plot, the ﬁrst 10 sample means are
denoted by solid dots and they are connected by solid lines, and the second 10 sample means
are denoted by little circles and they are connected by dotted lines. The dashed horizontal lines
labeled U, C, and L denote the upper control limit, the center line, and the lower control limit,
respectively.
From the above example, it can be seen that the Xchart is indeed ineffective in
detecting small and persistent mean shifts. As mentioned above, the major reason
for this limitation of the Shewhart charts is that they use observed data at a single
time point alone to evaluate the process performance at that time point. To overcome
this limitation, many alternative control charts have been proposed in the literature.
The major ones will be described in this and later chapters of the book. This chap-
ter focuses on cumulative sum (CUSUM) control charts that were ﬁrst proposed by
Page (1954) and then discussed by many authors, including Bissell (1969, 1984b),
Ewan (1963), Gan (1991a, 1993a), Goel and Wu (1971), Hawkins (1981, 1993a),
Hawkins and Olwell (1998), Johnson and Leone (1962), Lucas (1973), Montgomery
(2009), Page (1961), and Woodall and Adams (1993). Our discussion here focuses
on cases when the quality characteristic of interest is univariate, its IC distribution
has a parametric form, and the potential shift is in one or more distribution parame-
ters. CUSUM charts for monitoring multiple quality characteristics will be discussed
in Chapter 7. CUSUM charts for handling cases when the IC process distribution is
nonparametric will be discussed in Chapters 8 and 9.
At the end of this section, we would like to mention that the Shewhart charts de-
scribed in Chapter 3 are popular in practice, mainly because of their simplicity. DueMONITORING THE MEAN OF A NORMAL PROCESS 121
to the facts that they are good at detecting relatively large and transient shifts and
such shifts are common in phase I SPC, they provide a reasonably good statistical
tool for phase I SPC. As a comparison, the CUSUM charts discussed in this chapter
and some other alternative control charts discussed in later chapters are mainly for
phase II SPC, because relatively small and persistent shifts are often our major con-
cern in phase II SPC. For this reason, our description about the CUSUM charts and
the other alternative charts is mainly in the context of phase II SPC, although on sev-
eral occasions we will also brieﬂy discuss how to use some of them for phase I SPC.
Also, when constructing Shewhart charts, we often use batch data (see the related
discussion in Subsection 3.2.3). When constructing the CUSUM and other alterna-
tive control charts, however, individual observation data are often used. Although
these control charts can generally be applied to batch data as well, it is usually more
efﬁcient to use them with the individual observation data, in the sense that fewer ob-
servations are required in the latter case to detect a given shift with given levels of IC
and OC ARLs.
4.2 Monitoring the Mean of a Normal Process
In this section, we discuss cases when the quality characteristic of interest Xis uni-
variate, its IC distribution is N(µ0,σ2), and the potential shift in the production pro-
cess is in the mean of Xonly. This might be the most popular SPC problem in the
literature because the mean of Xis often the most relevant quantity to the quality of
products and people in the SPC community routinely assume that Xhas normal dis-
tributions before and after a mean shift. Our discussion in this section is divided into
four parts. In Subsection 4.2.1, different forms of the CUSUM chart are described.
Then, its design and implementation are discussed in Subsection 4.2.2. In these two
subsections, observations at different time points are assumed to be independent. The
case when observations at different time points are correlated is discussed in Sub-
section 4.2.3. Finally, the optimality properties of the CUSUM chart and a general
method for constructing a CUSUM chart in different cases are discussed in Subsec-
tion 4.2.4.
4.2.1 The V-mask and decision interval forms of the CUSUM chart
Assume that {X1,X2,...} are individual observation data obtained online at con-
secutive time points from a production process for phase II SPC, the observations
are independent and identically distributed (i.i.d.) with a common IC distribution
N(µ0,σ2)before a process mean shift, and they are i.i.d. with a common OC distri-
bution N(µ1,σ2)after the mean shift, where µ1/ne}ationslash=µ0andδ=µ1−µ0is the shift
size. It has been demonstrated in Example 4.1 that it is inefﬁcient to detect the mean
shift at a given time point using the observed data at that time point alone. A natural
idea to overcome this limitation is to use the observation at the current time point
and all history data as well for shift detection, as described in the ﬁrst paragraph of122 UNIV ARIA TE CUSUM CHARTS
Section 4.1. To this end, it is natural to consider the charting statistic
Cn=n
∑
i=1(Xi−µ0), (4.1)
where n≥1 denotes the current time point. It is obvious that
Cn=Cn−1+(X n−µ0),
where C0=0. Therefore, Cnis a cumulative sum of the deviations {Xi−µ0,i=
1,2,..., n}. When the process is IC up to the time point n, it is easy to check that
Cn∼N/parenleftbig
0,nσ2/parenrightbig
. (4.2)
On the other hand, when the process has a mean shift from µ0toµ1at the time point
1≤τ≤n(i.e., the process mean becomes µ1starting from the time point τ), we
have, for n≥τ,
Cn∼N/parenleftbig
(n−τ+1)δ,nσ2/parenrightbig
. (4.3)
From (4.1)–(4.3), it can be seen that Cnis a summation of i.i.d. zero-mean random
variables in cases when there is no mean shift up to the time point n(i.e., Cnis the
so-called random walk in such cases), and its mean starts to change linearly with
the slope δafter a process mean shift of size δatτ. Therefore, Cncontains useful
information for shift detection, and it is an indication of a positive (or negative) shift
if its mean increases (or decreases) after a speciﬁc time point.
Example 4.2 For the data considered in Example 4.1, let Xndenote the sample mean
of the n-th sample. Then, the IC distribution of Xnis N(0,1/5), its OC distribution is
N(0.2, 1/5), and the mean shift occurs at n =11. Figure 4.2 shows the sequence
Cn=Cn−1+/parenleftbig
Xn−0/parenrightbig
, for n=1,2,..., 20.
From the plot, it can be seen that C ndoes increase linearly with a slope around 0.2
after the shift time τ=11.
In practice, we usually do not know whether a mean shift has occurred or not
by the current time point. A major goal of SPC is to detect the ﬁrst potential mean
shift from all observed data. From (4.3) and Figure 4.2, it can be seen that, if the
statistic Cnchanges linearly with a slope δafter a time point, then it is an indication
of a mean shift of size δ. However, the expression (4.3) shows that the variance of
Cnincreases with nas well, making the identiﬁcation of a linear trend in the mean of
Cnchallenging. To overcome this difﬁculty, the V-mask form of the cumulative sum
(CUSUM) control chart is constructed as follows. Intuitively, if a positive mean shift
of size δoccurs at τ, then Cn, when n≥τ, should be all above a half-line starting
at(τ,Cτ−h)with a slope k=δ/2, where h>0 is a constant, as demonstrated in
Figure 4.3(a). The inclusion of the constant hand the slope k(instead of the slope
δ=2k) is for accommodating the increasing variability of Cnover n. In practice,
τis unknown; so, the above half-line cannot actually be used for shift detection.MONITORING THE MEAN OF A NORMAL PROCESS 123
0 5 10 15 20−2 −1 0 1 2
nCn
Figure 4.2 Values of the statistic C ncomputed from the data considered in Example 4.1. In the
plot, the ﬁrst 10 values of C nare denoted by solid dots and they are connected by solid lines,
and the second 10 values of C nare denoted by little circles and they are connected by dotted
lines. A process mean shift of size 0.2 occurs at the time τ=11.
But, we can consider a half-line starting at (n,Cn−h)and going backwards with
a slope k=δ/2, as demonstrated in Figure 4.3(b) by the bottom solid line of the
shaded region around n=20. If a mean shift of size δoccurs before n, then there
should be some values of the charting statistic falling below that half-line. Similarly,
for detecting a negative mean shift of size −δ, we can consider another half-line
starting at (n,Cn+h)and going backwards with a slope −k, as demonstrated by the
upper dashed line of the shaded region in Figure 4.3(b). Therefore, to detect a mean
shift at the current time point n, we can use a truncated V-mask, as demonstrated by
the shaded region in Figure 4.3(b). If there are some values of the charting statistic
located outside that mask, then we can conclude that a mean shift has occurred before
n. In the case of Figure 4.3(b), some values of the charting statistic are located below
the V-mask, indicating an upward mean shift.
From the V-mask form of the CUSUM chart, after obtaining a signal of mean
shift, we can also obtain point estimates of the shift time τand the shift size δas
follows. If there is only one point of the CUSUM charting statistic located below the
V-mask, then the corresponding time point of that point can be used for estimating
τ. If there is more than one point below the V-mask, then we can choose the time
point of the point that is farthest away from the mask as the estimate of τ. After the
estimate of τ, denoted as/hatwideτ, is obtained, δcan be estimated by
/hatwideδ=Cn−C/hatwideτ
n−/hatwideτ. (4.4)124 UNIV ARIA TE CUSUM CHARTS
0 5 10 15 20−3 −2 −1 0 1 2 3 4
nCn
(a)0 5 10 15 20−3 −2 −1 0 1 2 3 4
nCn
(b)
Figure 4.3 (a) Values of the charting statistic C ncomputed fr om the data considered in Exam-
ple 4.1 are denoted by solid dots that are connected by solid lines, where an upward process
mean shift of size δ=0.2occurs at τ=11. When n ≥τ, Cnare all above the solid half-line
that starts at (τ,Cτ−h)with a slope of k =δ/2. (b) Values of the charting statistic C nare the
same as those in plot (a). The shaded region denotes a truncated V-mask that can be used for
mean shift detection at n =20. A mean shift occurred before n is detected if some values of
{Ci,i<n}are located outside the V-mask.
Of course, a better estimate of δwould be the slope of the least squares line obtained
from all observed values of the charting statistic in the time range [/hatwideτ,n]. But, the one
given by (4.4) is easier to compute; thus, it is commonly used in practice.
Page (1954) might be the ﬁrst paper that formally discussed the CUSUM chart
and its ability to detect small and persistent shifts. To detect an upward (positive)
mean shift, Page’s CUSUM charting statistic is deﬁned by
P+
n=P+
n−1+(Xn−µ0)−k, forn≥1, (4.5)
where P+
0=0, and k>0 is a parameter called the reference value orallowance. This
chart indicates an upward mean shift if
P+
n−min
0≤m<nP+
m>h, (4.6)
where h>0 is a parameter called the control limit ordecision interval. It is not
difﬁcult to check that the CUSUM chart deﬁned by (4.5) and (4.6) is equivalent to
the CUSUM chart with the charting statistic
C+
n=max/parenleftbig
0,C+
n−1+(Xn−µ0)−k/parenrightbig
, (4.7)
where C+
0=0. The decision rule of this chart is that it gives a signal of an upward
mean shift when
C+
n>h. (4.8)MONITORING THE MEAN OF A NORMAL PROCESS 125
The form of the CUSUM chart deﬁned by (4.7) and (4.8) is called the decision inter-
val (DI) form. This form reveals the re-starting mechanism of the CUSUM chart that
its charting statistic C+
nis reset to 0 every time when C+
n−1+(X n−µ0)<k. In such
cases, there is little evidence in the observed data that is in favor of an upward mean
shift. Van Dobben de Bruyn (1968) showed that the DI form of the CUSUM chart
is equivalent to the V-mask form of the CUSUM chart described earlier (cf., Figure
4.3(b)) in cases when the two forms use the same values of handk.
It is obvious that detection of a downward shift of size −δin the original quality
characteristic Xis equivalent to detection of an upward shift of size δin−X. By this
relationship, to detect a downward (or negative) mean shift in X, the DI form of the
CUSUM chart would have the charting statistic
C−
n=min/parenleftbig
0,C−
n−1+(Xn−µ0)+k/parenrightbig
, (4.9)
where C−
0=0. This chart gives a signal of a downward mean shift if
C−
n<−h. (4.10)
Both the CUSUM chart (4.7)–(4.8) and the CUSUM chart (4.9)–(4.10) are one-
sided: the chart (4.7)–(4.8) is for detecting an upward mean shift and the chart (4.9)–
(4.10) is for detecting a downward mean shift. To detect an arbitrary mean shift, we
can consider a two-sided version of the CUSUM chart, which is a combination of
the two one-sided CUSUM charts. By the two-sided version, a signal of mean shift
is given once (4.8) or (4.10) or both hold.
The CUSUM charts (4.7)–(4.8) and (4.9)–(4.10) are designed for analyzing
individual-observation data. If batch data are involved and we have mobservations at
each time point, then the CUSUM charts can be constructed in the same way, except
that the sample mean X(n)should be used to replace the individual observation Xnat
each observ ation time.
In the literature, the DI form of the CUSUM chart is often preferred because
it is easier to use, compared to the V-mask form. The control limits hand−hfor
C+
nandC−
nare constants over time, similar to the control limits of the Shewhart
charts. However, the V-mask form has its own advantages. For instance, if mean
shifts of different sizes need to be detected, then we can simply use V-masks of
different slopes in the same CUSUM chart for that purpose. With the DI form, to
detect different mean shifts, the value of kshould be chosen differently (see related
discussion in the next subsection). However, if the value of kchanges, the entire
CUSUM chart needs to be re-constructed, making the DI form inconvenient to use in
such cases. As in most other books and research papers, we mainly use the DI form
in our discussion about different CUSUM charts in the remaining part of this book.
Example 4.2 (continued) For the data considered in Example 4.1, values of the
charting statistic C+
ncomputed by (4.7) are shown in Figure 4.4 by the black dots.
In the chart, k is set at 0.25 and h is set at 5.597, so that the ARL 0value of the
chart is 200. See Table 4.1 and the related discussion in the next subsection for the
relationship among k ,h, and ARL 0. By the way, the original data are batch data
with batch size of 5. Therefore, when computing C+
n, the standardized sample means
X(n)/(1/√
5)have been used in (4.7).126 UNIV ARIA TE CUSUM CHARTS
0 5 10 15 200 1 2 3 4 5 6
nCn+
Figure 4.4 Values of the charting statistic C+n, computed by (4.7) from the data considered in
Example 4.1, are shown by the black dots. In the chart, k and h are chosen to be 0.25 and
5.597, respectively, so that the ARL 0value of the chart is 200.
4.2.2 Design and implementation of the CUSUM chart
In the CUSUM chart (4.7)–(4.8), there are two parameters handkto choose before
the chart can actually be used for process monitoring. In this subsection, we discuss
the selection of handkfor the chart (4.7)–(4.8) in cases when µ0=0 and σ=1.
This is sufﬁcient because in cases with arbitrary values of µ0andσwe can consider
the corresponding CUSUM chart for the standardized observations
Xn−µ0
σ, forn≥1.
Parameter selection of the chart (4.9)–(4.10) and of the two-sided version of the
CUSUM chart can be discussed in a similar way.
Obviously, the values of handkwould affect the performance of the chart (4.7)–
(4.8). As discussed in Subsection 3.2.1, performance of a control chart can be mea-
sured by the IC ARL value ARL 0and the OC ARL value ARL 1. Usually, the value
ofARL 0is speciﬁed beforehand, to be the minimum tolerable ARL 0value. Then, for
detecting a given shift δ, the chart performs better if its ARL 1value is smaller.
For given values of handk, there are some theoretical methods for studying the
properties of the CUSUM chart (see the related discussion in Section 4.6), based on
which some formulas have been derived in the literature for approximating the ARL 0MONITORING THE MEAN OF A NORMAL PROCESS 127
value. F or instance, Siegmund (1985) developed the following formula:
ARL 0≈exp(2k(h+1.166))−2k(h+1.166)−1
2k2. (4.11)
It has been shown that this formula provides quite an accurate approximation to the
true value of ARL 0in cases when kis small to moderate (e.g., k≤1). Its approx-
imation could be poor in cases when kis large. Related discussion can be found
in papers such as Brook and Evans (1972), Fellner (1990), Goel and Wu (1971),
Hawkins (1992a), and Woodall and Adams (1993).
To compute ARL 0values of the CUSUM chart (4.7)–(4.8), we can also use Monte
Carlo simulations. Because various powerful computing facilities are available nowa-
days, this might be a more appropriate approach to use, compared to the approach
using approximation formulas (e.g., (4.11)). Results from the simulation approach
are usually more accurate, and this approach is also ﬂexible enough to handle a va-
riety of different scenarios. For given values of handk, the ARL 0value of the chart
(4.7)–(4.8) can be computed by an algorithm described by the pseudo code in the
box below.
Pseudo Code to Compute an Estimate of the ARL 0Value
LetMbethe number of replicated simulations. It can be chosen as a large
positive integer (e.g., M=105).
Step 1 In the j-th replicated simulation, for 1 ≤j≤M, compute the run length
RL(j)by the following loop: for n≥1
•generate the observation Xnfrom N(0,1)
•compute the value of C+
nby (4.7)
•if (4.8) holds, then let RL(j)=nand stop the loop; otherwise, let n=n+1 and
continue the loop.
Step 2 TheARL 0value can be estimated by the simple average of the Mrun length
values{RL(j),j=1,2,..., M}.
In the above pseudo code, observations at different time points within a simula-
tion should be independent of each other. They are independent of each other among
different simulations as well. Although it is rare, theoretically it can happen that a
small number of simulations might require extremely long sequences of observa-
tions, which could cause some practical inconvenience. To prevent the occurrence of
this situation, we can set the maximum length of the sequences to be a given posi-
tive integer N. If the j-th simulation does not stop by the time point n=N, then we
can simply stop the corresponding loop and ignore that simulation when computing
the ﬁnal estimate of the ARL 0value. To minimize the impact of this modiﬁcation, a
large Nshould be chosen (e.g., N=104). In the literature, a number of numerical
algorithms based on Monte Carlo simulations for estimating the value of ARL 0have
been developed (e.g., Hawkins and Olwell (1998)). Some existing Rpackages for
that purpose are described in Appendix A.2.128 UNIV ARIA TE CUSUM CHARTS
In cases when k=0,0.25, 0.5,0.75 and h=1,1.5,2,2.5,3,3.5,4, the computed
ARL 0values of the CUSUM chart (4.7)–(4.8) by the Rpackagespc(see its introduc-
tion in the appendix) are shown in Figure 4.5. From the plot, it can be seen that (i)
ARL 0increases with the value of k, and (ii) ARL 0increases with the value of has
well. These results can be easily explained using the V-mask form of the CUSUM
chart. From Figure 4.3(b), when kis larger or his larger, the chance that the charting
statistic C+
nis located below the bottom solid line of the truncated V-mask would be
smaller. Consequently, the ARL 0value would be larger in such cases.
1.0 1.5 2.0 2.5 3.0 3.5 4.0
hARL 0
0 5 15 50 200 1000k=0
k=0.25
k=0.5
k=0.75
Figure 4.5 ARL 0values of the CUSUM chart (4.7)–(4.8) in cases when k =0,0.25,0.5,0.75,
and h=1,1.5,2,2.5,3,3.5,4. To better demonstrate the difference among different cases, the
y-axis is in natural log scale.
From Figure 4.5, it can be seen that the value of ARL 0indeed depends on the
values of handk. As mentioned earlier, in practice, the value of ARL 0is often pre-
speciﬁed. Therefore, to use the control chart (4.7)–(4.8), its parameters handkshould
be chosen to reach the pre-speciﬁed ARL 0value. To this end, Page (1954) pointed out
that to detect a mean shift of size δ, the chart (4.7)–(4.8) would have an optimal per-
formance if kwas chosen as δ/2. So, if we have a target shift size δin mind in
a speciﬁc application, then we should choose k=δ/2. In certain applications, it is
possible to ﬁgure out a meaningful target shift for this purpose. As an example, as-
sume that a machine consists of 10 components. Its productivity would lose 10% if
one component goes out of order. When all components work stably, assume that
the productivity of the machine can be ﬁgured out to be a, based on our past expe-
rience or engineering knowledge. Then, a meaningful target shift in this case wouldMONITORING THE MEAN OF A NORMAL PROCESS 129
be 0.1∗awhen one component of the machine goes out of order. However, in most
applications, the shift size can be any value in an interval, and a speciﬁc target shift
cannot be obtained using our engineering or scientiﬁc knowledge about the produc-
tion process. In such cases, we can specify a target shift that is desired to be detected
as soon as possible, which is usually the one that is small enough that it cannot be
noticed easily by our naked eyes and large enough to have a meaningful impact on
the quality of products.
After the values of ARL 0andkare given, the value of hcan be determined by a
searching algorithm such that the given ARL 0value is reached to a certain accuracy.
A pseudo code of such a searching algorithm based on the bisection searching is
described in the box below.
Pseudo Code to Search for the Value of h
LetA0be the pre-speciﬁed ARL 0value,[hL,hU]be the interval from which h
is searched, ρ>0 be a small number denoting the required estimation accuracy,
andMbe the maximum number of iterations involved in the search. Then, the
search is performed iteratively as follows. In the j-th iteration, for 1 ≤j≤M, do
the following two steps:
Step 1 Leth=(h L+hU)/2. Compute the ARL 0value of the chart (4.7)–(4.8) with
thishvalue and the given kvalue.
Step 2 If the ARL 0value computed in Step 1 is included in [A0−ρ,A0+ρ], then
the algorithm is stopped, and the searched value of his set to be the one used in
Step 1. Otherwise, deﬁne
/braceleftbigg
hL=hL,hU=(h L+hU)/2 if ARL 0>A0
hL=(h L+hU)/2,hU=hU ifARL 0<A0,
and return to Step 1.
If the above algorithm does not stop before or at the M-th iteration and the
ARL 0value computed in the M-th iteration is still outside the interval [A0−ρ,A0+
ρ], print a statement that the estimation accuracy speciﬁed by ρcannot be reached,
and set the hvalue deﬁned in the M-th iteration as the searched value of h.
In the above pseudo code, the initial value of hLshould be chosen small enough
such that the ARL 0value when h=hLis smaller than A0, and the initial value of
hUshould be chosen large enough such that the ARL 0value when h=hUis larger
than A0. For most ARL 0andkvalues, it should be good enough to choose hL=0 and
hU=15. In the pseudo code, we have used the bisection searching method. Some
modiﬁcations of this method for a faster computation are possible. For instance, in-
stead of deﬁning h= (h L+hU)/2 in Step 1, we can use the linear interpolation
method to deﬁne
h=hL+A0−ARL 0(hL)
ARL 0(hU)−ARL 0(hL)(hU−hL),130 UNIV ARIA TE CUSUM CHARTS
Table 4.1 Computed h values of the CUSUM chart (4.7)–(4.8) for some commonly used ARL 0
and k values.
k
ARL 0 0.1 0.25 0.5 0.75 1.0 1.25 1.5
50 4.567 3.340 2.225 1.601 1.181 0.854 0.570
100 6.361 4.418 2.849 2.037 1.532 1.164 0.860
200 8.520 5.597 3.502 2.481 1.874 1.458 1.131
300 9.943 6.324 3.892 2.745 2.073 1.624 1.282
370 10.722 6.708 4.095 2.882 2.175 1.709 1.359
400 11.019 6.852 4.171 2.933 2.214 1.741 1.387
500 11.890 7.267 4.389 3.080 2.323 1.830 1.466
1000 14.764 8.585 5.071 3.538 2.665 2.105 1.708
where ARL 0(hL)andARL 0(hU)denote the ARL 0values of the chart (4.7)–(4.8) with
h=hLandh=hU, respectively. In the pseudo code, ρcontrols the estimation error
of the algorithm. A small positive number, such as 0.5, 0.1, and 0.01, should be
good enough to use in practice. Because the bisection search is fast to converge,
the maximum number of iterations, M, can be chosen as a relatively small integer
number like 20 or 50.
By theR-package spc, the computed hvalues for some commonly used ARL 0
andkvalues are presented in Table 4.1. From the table, we can see that, as a function
ofARL 0andk,hdecreases with kand increases with ARL 0.
To design the control chart (4.7)–(4.8), only the ARL 0,h, and kvalues are in-
volved. To evaluate the performance of the chart when detecting a speciﬁc shift, we
need to compute its ARL 1value, as described earlier. Assume that the process distri-
bution changes from N(µ0,σ2)to
N/parenleftbig
µ0+δ,λ2σ2/parenrightbig
,
starting at the initial observation time point, where δ,λ>0 are two given numbers.
Then, the mean of the process distribution has a shift of size δ, and its standard
deviation has a shift of size (λ−1)σ. In such cases, equation (4.7) can be written as
C+
n
λσ=max/bracketleftigg
0,C+
n−1
λσ+/parenleftbiggXn
λσ−µ0+δ
λσ/parenrightbigg
−k−δ
λσ/bracketrightigg
.
If we denote C∗
n=C+
n/(λσ), then it is easy to see that C∗
nis just the conven-
tional charting statistic of the upward CUSUM chart when its allowance is k∗=
(k−δ)/(λσ), its control limit is h∗=h/(λσ), and the process IC distribution is
N(0,1). Based on this relationship, we have the conclusion stated in the box below.MONITORING THE MEAN OF A NORMAL PROCESS 131
Relationship Between ARL 0andARL 1Values
Assume that the process distribution shifts at the initial time point from
N(µ0,σ2)toN(µ0+δ,λ2σ2). Then, the ARL 1value of the chart (4.7)–(4.8) with
parameters handkequals the ARL 0value of the chart when the allowance is cho-
sen to be k∗=(k−δ)/(λσ), the control limit is chosen to be h∗=h/(λσ), and
the process IC distribution is N(0,1).
Example 4.3 Assume that the IC process distribution is N (0,1). We would like to
compute the ARL 1values of the chart (4.7)–(4.8) with k =0.5and h=3.502, whose
ARL 0value is 200 by Table 4.1, in cases when the process distribution shifts at the
initial observation time point to one of the following four distributions:
(i)N(0.25, 1),
(ii)N(−0.25, 1),
(iii) N(0,22), and
(iv) N(0.25, 22).
In case (i), by the results given in the above box, the ARL 1value of the chart
(4.7)–(4.8) equals the ARL 0value of the same chart when the allowance is k∗=k−
δ=0.5−0.25=0.25, the control limit is h∗=h=3.502, and the IC distribution is
N(0,1). By the approximation formula (4.11), this ARL 1value can be approximated
by
exp(2k∗(h∗+1.166))−2k∗(h∗+1.166)−1
2(k∗)2=55.881.
In case (ii), the ARL 1value of the chart (4.7)–(4.8) equals the ARL 0value of
the same chart when the allowance is k∗=0.5+0.25=0.75, the control limit is
h∗=h=3.502, and the IC distribution is N (0,1). Again, by (4.11), this ARL 1value
can be approximated by 969.624. Obviously, this ARL 1value is much larger than
the assumed ARL 0value (i.e., 200). This situation often happens when a mean shift
is downward but the control chart used is designed for detecting upward shifts (e.g.,
the chart (4.7)–(4.8)), or the mean shift is upward but the control chart is designed for
detecting downward shifts (e.g., the chart (4.9)–(4.10)). This is the so-called biasness
phenomenon of the one-sided control charts.
In case (iii), the ARL 1value of the chart (4.7)–(4.8) equals the ARL 0value
of the same chart when the allowance is k∗=k/(λσ) =0.5/2=0.25, the con-
trol limit is h∗=h/(λσ) =3.502/2=1.751, and the IC distribution is N (0,1).
By (4.11), this value can be approximated by 14.728. Similarly, in case (iv), the
ARL 1value of the chart (4.7)–(4.8) equals the ARL 0value of the same chart when
the allowance is k∗= (k−δ)/(λσ) = (0.5−0.25)/2=0.125, the control limit is
h∗=h/(λσ)=3.502/2=1.751, and the IC distribution is N (0,1). This ARL 1value
can be approximated by 11.017.
In the above discussion of the ARL 1value, we assume that the potential shift oc-
curs at the initial observation time point. In cases when the shift occurs at a later time
point, then the computed ARL 1value could be different from the one when the shift
occurs at the initial observation time point, because the distribution of the charting
statistic C+
ndepends on n. This is also true for the ARL 0value. In the literature, this132 UNIV ARIA TE CUSUM CHARTS
phenomenon has been well discussed (e.g., Hawkins and Olwell, 1998, Subsection
3.3.4). From the deﬁnition of C+
n,C+
0=0,C+
1has the probability of P(X 1≤k)to be
0 and the probability of P(X 1>k)to be in the interval (0,∞),C+
2has the probability
of
P(X 1≤k)P(X 2≤k)+P(X 1>k)P(X 1+X2≤2k|X1>k)
to be 0 and the remaining probability to be in the interval (0,∞), and so forth. In
cases when the IC process distribution is N(0,1)andk=0,C+
1has the probability
of 0.5 to be 0, C+
2has the probability of 3/8 to be 0, and so forth, when the process
is IC. So, the distributions of C+
nwhen nis small are all different. However, when
nincreases, the distribution of C+
ntends to a steady-state distribution, although we
cannot derive its closed-form expression yet. For this reason, the ARL 0value com-
puted from the run lengths recorded from the initial observation time point and the
one computed from the run lengths recorded from a given time point n∗, with n∗
being a large positive integer, could be different. To distinguish them, the former is
often called the zero-state ARL 0value, and the latter the steady-state ARL 0value.
Similarly, the ARL 1value is called the zero-state ARL 1if the shift occurs at the initial
observation time point, and it is called the steady-state ARL 1if the shift occurs at the
time n∗with n∗being a relatively large positive integer. In practice, n∗can be chosen
as 100, or as small as 50, to approximate the steady-state distribution by the distri-
bution of C+
n∗. Without further speciﬁcation, the ARL 0andARL 1values discussed in
this and other chapters, including the ARL 0values presented in Figure 4.5 and Table
4.1, are computed under the zero-state condition.
In Table 4.2, the left part presents the zero-state (ZS) ARL 0values, the steady-
state (SS) ARL 0values, and their relative differences (i.e., (ZS−SS)/ZS ) of the chart
(4.7)–(4.8) in cases when k=0.5 and h=2,2.5,3,3.5,4,4.5,5, which are computed
using the functions xcusum.ad() andxcusum.arl() in theR-package spc. The right
part of the table presents the ZS and SS ARL 1values and their relative differences
of the same chart for detecting a mean shift of size δ=1. From the table, it can be
seen that (i) the ZS and the corresponding SS ARL 0(orARL 1) values are indeed dif-
ferent, and (ii) the relative difference seems bigger for the ARL 1values. The intuitive
explanation of the second result is that ARL 0values are usually large. Consequently,
they are not affected much by different ways of computation (i.e., ZS versus SS). As
a comparison, ARL 1values are usually small. So, they are affected more seriously
by different ways of computation. The fact that the relative differences for both the
ARL 0andARL 1values decrease when hincreases (except the case for the ARL 1val-
ues when h=2.0) can be explained in a similar way.
Example 4.4 For the control chart (4.7)–(4.8), let us consider cases when k =
0.25, 0.5, or 0.75, and the assumed ARL 0value is 200. By Table 4.1, the h values
in these cases are 5.597, 3.502, and 2.481, respectively. When the chart is used for
detecting a mean shift of size δoccurring at the initial observation time, where δ
changes its value from 0 to 2 with a step of 0.1, its ARL 1values computed by the
functionxcusum.arl() in theR-package spcare shown in Figure 4.6. From the ﬁg-
ure, it can be seen that the chart with k =0.25 performs the best when δis small
(e.g., δ≤0.6), it performs the best in a region around δ=1when k is 0.5, and itsMONITORING THE MEAN OF A NORMAL PROCESS 133
Table 4.2 Theleft part presents the zero-state (ZS) ARL 0values, the steady-state (SS) ARL 0
values, and their relative differences (ZS−SS)/ZS of the chart (4.7)–(4.8) when k =0.5and
h=2,2.5,3,3.5,4,4.5,5. The right part presents the ZS ARL 1values, the SS ARL 1values, and
their relative differences of the same chart for detecting a mean shift of size δ=1.
ARL 0 ARL 1
h ZS SS (ZS−SS)/ZS ZS SS (ZS−SS)/ZS
2.0 38.548 37.262 0.033 4.449 4.079 0.083
2.5 68.186 66.253 0.028 5.423 4.951 0.087
3.0 117.596 114.953 0.022 6.404 5.853 0.086
3.5 199.574 196.167 0.017 7.391 6.778 0.083
4.0 335.368 331.143 0.013 8.383 7.722 0.079
4.5 559.947 554.863 0.009 9.379 8.680 0.074
5.0 930.887 924.908 0.006 10.376 9.650 0.070
performance for detecting large shifts (e.g., δ≥1.4) is the best when k is 0.75. This
example conﬁrms the general conclusions stated in the box below.
0.0 0.5 1.0 1.5 2.0
δARL 1
0 5 15 50 200k=0.25
k=0.5
k=0.75
Figure 4.6 ARL 1values of the CUSUM chart (4.7)–(4.8) in cases when k =0.25,0.5,0.75,
the assumed ARL 0value is 200, and the shift size δchanges its value from 0 to 2 with a step
of 0.1. To better demonstrate the difference among different cases, the y-axis is in natural log
scale.134 UNIV ARIA TE CUSUM CHARTS
General Guidelines for Selecting k
For the CUSUM chart (4.7)–(4.8), small kvalues are ideal for detecting rel-
atively small upward mean shifts, and large kvalues are ideal for detecting rela-
tively large upward mean shifts. The chart is optimal for detecting a target shift
of size δ=2k, in the sense that its ARL 1value is the shortest among the ARL 1
values of all control charts with the same ARL 0value.
So far, our discussion in this subsection focuses on the CUSUM chart (4.7)–(4.8),
which is designed for detecting upward mean shifts. By the relationship between the
upward CUSUM chart (4.7)–(4.8) and the downward CUSUM chart (4.9)–(4.10) (as
described in the paragraph containing the equation (4.9) in Subsection 4.2.1), design,
implementation, and computation of the ARL 0andARL 1values of the downward
CUSUM chart (4.9)–(4.10) can be done in a similar way to that with the upward
CUSUM chart (4.7)–(4.8). Regarding the two-sided version of the CUSUM chart
described in Subsection 4.2.1, it is a combination of the upward CUSUM chart and
the downward CUSUM chart. For given handkvalues, assume that the ARL values
of the two one-sided charts are ARL+andARL−, respectively. Then, Van Dobben de
Bruyn (1968) showed that the ARL value of the two-sided version, denoted as ARL∗,
would follow the equation
1
ARL∗=1
ARL++1
ARL−. (4.12)
The equation (4.12) is true for both IC and OC ARL values. So, it can be used for the
design of the two-sided CUSUM chart and for computing its ARL 0andARL 1values.
For instance, if we would like to use k=0.5 in the two-sided CUSUM chart and its
ARL 0is speciﬁed to be 200, then by (4.12), each of the two one-sided CUSUM charts
should have ARL 0value of 400. By Table 4.1, the upward CUSUM chart should use
the control limit h=4.171 and the downward CUSUM chart should use the con-
trol limit −h=−4.171. As another example, in Example 4.3, the upward CUSUM
chart is used for detecting both the upward shift of size 0.25 and the downward
shift of size −0.25. The ARL 1values in these two cases are computed to be 55.881
and 969.624, respectively. By (4.12) and the relationship between the two one-sided
CUSUM charts, the ARL 1value of the two-sided CUSUM chart for detecting a shift
of size 0.25 or −0.25 would be
/parenleftbigg1
55.881+1
969.624/parenrightbigg−1
=52.836.
This result shows that the ARL 1value of the two-sided CUSUM chart is smaller than
theARL 1values of the two one-sided CUSUM charts. As a matter of fact, this isMONITORING THE MEAN OF A NORMAL PROCESS 135
always true because the equation (4.12) implies the following results:
1
ARL∗>1
ARL+,
1
ARL∗>1
ARL−,
ARL∗<min/parenleftbig
ARL+,ARL−/parenrightbig
,
and
min(ARL+,ARL−)
2≤ARL∗≤max(ARL+,ARL−)
2.
At the end of this subsection, we would like to mention that the Shewhart charts
discussed in the previous chapter can be considered as special CUSUM charts. To
demonstrate the connection between the two types of control charts, let us consider
the case when the Xchart is used for detecting process mean shifts, we have m
observations at each time point, and the IC process mean µ0and the IC process
standard deviation σare both known. In such cases, by the Xchart, a signal of an
upward mean shift is delivered at the n-th time point, for any n≥1, if
Xn−µ0
σ/√m>Z1−α/2, (4.13)
where the critical value Z1−α/2is often chosen to be 3, corresponding to the signif-
icance level of α=0.0027. Obviously, the decision rule (4.13) is equivalent to the
rule that a signal is given at the n-th time point if
S+
n>0, (4.14)
where
S+
n=max/parenleftbigg
0,S+
n−1+Xn−µ0
σ/√m−Z1−α/2/parenrightbigg
andS+
0=0. The decision rule (4.14) is exactly an upward CUSUM chart applied
to the standardized data {(Xn−µ0)/(σ/√m),n≥1}with k=Z1−α/2andh=0.
From the discussion in Subsection 3.2.1, the Xchart (4.13) has an ARL 0value of
2/α. By the equivalence of (4.13) and (4.14) and by the optimality properties of the
CUSUM chart (4.14), we know that the Shewhart chart (4.13) also has the optimality
properties for detecting a mean shift of size 2Z 1−α/2among all control charts with
ARL 0=2/α. In cases when Z1−α/2=3, the corresponding Xchart would be optimal
for detecting a mean shift of size 6 among all control charts with ARL 0=2/0.0027 =
740.741. So, it is true that Shewhart charts are good for detecting large shifts.
4.2.3 Cases with correlated observations
Design and implementation of the CUSUM chart (4.7)–(4.8) discussed in the previ-
ous subsection is based on the following assumptions:136 UNIV ARIA TE CUSUM CHARTS
(i)Process observations are independent and identically distributed (i.i.d.) before
and after a potential mean shift,
(ii)Both the IC and OC process distributions are normal, and
(iii) Parameters of the IC distribution are known.
In practice, all these assumptions can be invalid. In this subsection, we discuss the
cases when process observations collected at different time points are correlated (i.e.,
the assumption (i) is invalid). Cases when the process distributions are non-normal
(i.e., the assumption (ii) is invalid) will be discussed in Section 4.4 and Chapter 8.
Cases when the parameters of the IC distribution are unknown (i.e., the assumption
(iii) is invalid) will be discussed in Section 4.5.
As discussed in Section 3.5, possible correlation among observations collected at
different time points would affect the actual IC and OC ARL values of the Shewhart
charts. Similarly, such possible correlation could affect the IC and OC ARL values
of the CUSUM chart (4.7)–(4.8), as demonstrated by the example below.
Example 4.5 For the upward CUSUM chart (4.7)–(4.8), let us consider cases when
(k,h)=(0.25, 5.597),(0.5, 3.502), and (0.75, 2.481). From Table 4.1, it can be seen
that the ARL 0values of the chart in these three different cases are all 200 when
process observations are independent of each other. Now, let us consider the scenario
when process observations are actually generated from the following auto-regressive
model of order 1, denoted as AR(1): for n ≥1,
Xn=µ0+φ(Xn−1−µ0)+en, (4.15)
where X 0=µ0,µ0=0is the IC mean, φis the model coefﬁcient, and {en,n≥1}are
the white noise with σe=1(i.e., they are i.i.d. with a common distribution N (0,σ2
e)).
In such cases, we know that the correlation coefﬁcient between X nand X n−jisφj,
for j=1,2,..., n−1. When φ=−0.5,−0.25,−0.1,0,0.1,0.25, or 0.5, the actual
ARL 0values of the chart (4.7)–(4.8) are presented in the left part of Table 4.3. These
values are computed by an algorithm written by the author in R, which is the same as
the one described by the pseudo code in the previous subsection, except that process
observations are generated from the model (4.15) in this example. It can be seen that
they are quite different from each other in cases with a same set of (k,h)but different
values of φ. For instance, when (k,h)=(0.25, 5.597) andφ=−0.5, the actual ARL 0
value is about 4 times the nominal ARL 0value of 200, while the actual ARL 0value
is only about 20% of the nominal ARL 0in the case when (k,h)remain the same but
φ=0.5. Now, let us consider the scenario when a mean shift of size δ=0.5occurs
at the initial observation time. In this scenario, the actual ARL 1values of the chart
(4.7)–(4.8) in various cases are presented in the right half of Table 4.3, which are
calculated by a numerical algorithm that is similar to the one for calculating the
ARL 0values. From the table, we can see that the actual ARL 1values are also quite
different in cases with a same set of (k,h)but different values of φ.
Example 4.5 demonstrates that correlation among observed data could have a
substantial impact on the IC and OC behavior of the CUSUM charts. Therefore, it
should be taken into account when designing the CUSUM charts. Otherwise, results
from a CUSUM chart designed for independent observations could be misleading
when the chart is applied to a production process with correlated data. As an example,MONITORING THE MEAN OF A NORMAL PROCESS 137
Table 4.3 Theleft part presents the actual ARL 0values of the chart (4.7)–(4.8) when (k,h)=
(0.25,5.597),(0.5,3.502), or(0.75,2.481) (so that its nominal ARL 0values are 200 in all
three cases) and when the process observations are correlated and follow the AR(1) model
(4.15) with the coefﬁcient φ. The right part presents the actual ARL 1values of the chart when
a mean shift of size δ=0.5occurs at the initial observation time in various cases considered.
δ=0 δ=0.5
φ k=0.25 k=0.5k=0.75 k=0.25 k=0.5k=0.75
−0.5 818.620 743.026 326.828 19.575 28.169 39.633
−0.25 509.875 537.801 410.570 19.686 25.481 35.447
−0.1 295.254 308.936 284.428 19.417 23.210 30.094
0 199.623 199.258 202.063 19.188 21.681 26.908
0.1 139.672 134.461 139.602 18.815 20.276 24.067
0.25 85.464 78.179 83.084 18.134 18.108 20.411
0.5 42.827 38.390 40.020 16.847 15.652 16.386
in the case when (k,h)are chosen to be(0.5, 3.502) in the CUSUM chart (4.7)–(4.8),
its nominal ARL 0value is 200 when process observations are independent of each
other, which is conﬁrmed by the calculated actual ARL 0value of 199.258 presented
in Table 4.3 in the entry with δ=0,k=0.5, and φ=0. However, by the same
CUSUM chart, if the observed data have a negative auto-correlation with φ=−0.5,
for example, its actual ARL 0value becomes 743.026, which is more than 3 times the
nominal ARL 0value. A direct consequence of this difference between the actual and
nominal ARL 0values is that the chart would not be sensitive enough to process mean
shifts. As shown in the right part of Table 4.3, when detecting a mean shift of size
δ=0.5, the chart is supposed to have an ARL 1value of 21.681 when the observations
are independent. But, its actual ARL 1value is 28.169 when the data are negatively
correlated with φ=−0.5, which is a delay of about one week if the time unit is
one day. Remember that products produced after the mean shift are mostly defective
products and usually cannot be sold. Therefore, many resources would be wasted
in this scenario. Now, let us consider the case when the same chart is applied to a
process having positively correlated observations with φ=0.5. In such a case, the
actual ARL 0value is 38.390, which is substantially smaller than the nominal ARL 0
value of 200. A direct consequence of this difference is that the chart would deliver
too many false signals and the production process would be unnecessarily stopped
too many times for engineers to ﬁgure out the root causes of the signals. Thus, many
resources would be wasted in this scenario as well.
To accommodate the possible correlation among observed data, one commonly
used approach in practice is to group neighboring observations into batches and then
apply the conventional CUSUM charts for independent data to the batch means. More
speciﬁcally, if the batch size is m, then the observed data are grouped in the following
way:
Batch 1: X1,X2,..., Xm;
Batch 2: Xm+1,Xm+2,..., X2m;
......138 UNIV ARIA TE CUSUM CHARTS
LetYj=1
m∑m
i=1X(j−1)m+ibe the sample mean of the j-th batch, for j=1,2,.... Then,
the conventional CUSUM charts can be applied to the data {Yj,j=1,2,...}. A major
reasoning behind this method is that possible correlation in the original data could be
mostly eliminated in the new data {Yj,j=1,2,...} when mis large (cf., Runger and
Willemain, 1996). Although this approach is intuitively appealing, it should be used
with care, as explained below. Let us reconsider the scenarios discussed in Example
4.5, where the original observations are generated from the AR(1) model (4.15) with
the coefﬁcient φ. Instead of working on the original observations, this time let us
group them into batches of size m=5 each, and apply the conventional CUSUM
chart (4.7)–(4.8) to the standardized batch means
Yj
1/√m, forj≥1.
Inthe CUSUM chart (4.7)–(4.8), (k,h)are still chosen to be (0.25,5.597), (0.5,3.502),
or (0.75,2.481), so that its nominal ARL 0value is 200 when φ=0 (i.e., no correla-
tion in the observed data) in each of the three cases. Other setups remain the same
as those in Example 4.5. Then, the actual ARL 0values of the chart (4.7)–(4.8) when
φ=−0.5,−0.25,−0.1,0,0.1,0.25, or 0.5 are presented in Table 4.4. From the ta-
ble, it can be seen that the actual ARL 0values are close to 200 when φ=0 in all
three cases, as expected. But, in cases when φ/ne}ationslash=0, we can see that the actual ARL 0
values are even farther away from the nominal ARL 0value of 200, compared to the
corresponding actual ARL 0values in Table 4.3, which is contradictory to our in-
tuition that the difference between the actual and nominal ARL 0values should be
smaller in this case, compared to the case considered in Table 4.3. To further in-
vestigate this phenomenon, let us focus on the case when (k,h)=(0.25, 5.597) and
φ=0.5. In such a case, the sample correlation coefﬁcient between two consecu-
tive observations in the original data (i.e., the sample correlation computed from the
pairs{(X n−1,Xn),n≥2}) is about 0.5, and the corresponding sample correlation
coefﬁcient in the batch data (i.e., the sample correlation computed from the pairs
{(Yj−1,Yj),j≥2}) is about 0.148. Therefore, it is true that the pairwise correlation
between two consecutive data points is greatly reduced by grouping. On the other
hand, the sample standard deviation of the original data is about 1.155, which is
different from 1 due to the positive autocorrelation in the data and which partially
explains the reason why the actual ARL 0value in the entry of k=0.25 and φ=0.5
in Table 4.3 is different from the nominal ARL 0value. For the batch data, the sam-
ple standard deviation of the standardized group means {Yj/(1/√m),j=1,2,...} is
about 1.723, which is much larger than the sample standard deviation of the original
data. This explains the reason the actual ARL 0value computed from the batch data
is even farther away from the nominal ARL 0value. To overcome this limitation of
the grouping approach, we need to scale the group means properly, which is difﬁcult
to achieve in practice unless we know how observations in the original data are cor-
related. See Kim et al. (2007) and Runger and Willemain (1995, 1996) for a related
discussion.
Besides the limitation described above, the grouping approach has another disad-
vantage that the resulting control chart may not be able to react to a shift promptly,MONITORING THE MEAN OF A NORMAL PROCESS 139
Table 4.4 Actual ARL 0values of the chart (4.7)–(4.8) when (k,h) = (0. 25,5.597),
(0.5,3.502), or (0.75,2.481) (so that its nominal ARL 0values are 200 in all three cases)
and when the process observations are grouped into batches of size m =5each. The original
process observations are correlated and follow the AR(1) model (4.15) with the coefﬁcient φ.
φ k=0.25 k=0.5k=0.75
−0.5 926.588 956.284 953.297
−0.25 607.130 722.284 743.046
−0.1 330.990 372.706 389.072
0 200.505 199.555 200.630
0.1 127.086 111.815 106.165
0.25 67.261 52.725 46.801
0.5 26.307 18.839 15.981
due to the data averaging and due to the fact that a signal of shift can only be de-
livered after all observations within a group are obtained. Another related approach
to handle correlated data is to use a subset of the original data, and two consecutive
observations in the subset are wtime points apart in the original data, where w≥1 is
an integer. By this approach, the correlation among observations in the subset could
be smaller than the correlation among observations in the original data, especially
in cases when wis chosen to be relatively large. However, much information in the
original data is ignored, and the process performance between two consecutive ob-
servations in the subset cannot be evaluated.
An alternative strategy to handle the possible correlation among process observa-
tions is to describe the correlation by a statistical model. Because most data involved
in SPC are time series, statistical models for time series analysis are especially use-
ful here (e.g., Box et al., 2008; Brockwell and Davis, 2009). A commonly used and
also quite ﬂexible time series model is the following auto-regressive moving average
(ARMA) model:
Xn=ξ+φ1Xn−1+φ2Xn−2+...+φpXn−p+
en+ψ1en−1+ψ2en−2+...+ψqen−q, (4.16)
where ξ,φ1,φ2,..., φp,ψ1,ψ2,..., ψqare coefﬁcients, and {en,n≥1}are the white
noise with variance σ2
e. This model, which is often denoted as ARMA( p,q), assumes
thatXndepends on all previous data through the previous pobservations and through
the random noise at the previous qtime points as well. When q=0, the model (4.16)
becomes the AR model of order p, denoted as AR(p). When p=0, it becomes the
so-called moving average (MA) model of order q, denoted as MA(q). In time series
analysis, model estimation, model selection, and model goodness-of-ﬁt testing of the
model (4.16) have been well discussed, and they can be easily accomplished in most
statistical software packages. For instance, in R, functions such as ar(), arima(),
acf(), pacf(), Box.test(), and so forth are all for these purposes.
A special case of the model (4.16) is the AR(1) model (4.15), in which we assume
thatXndepends on all previous data through Xn−1only. For the model (4.15), it is140 UNIV ARIA TE CUSUM CHARTS
easy to check that Xnhas the mean µ0and the variance
σ2
Xn=σ2
e
1−φ2. (4.17)
By (4.17), the variance of Xnwould be augmented by any autocorrelation in the
data. It is also easy to check that the correlation coefﬁcient between XnandXn−jis
φj, for j=1,2,..., n−1. Namely, the autocorrelation between XnandXn−jwould
exponentially decay when jincreases, which could describe the autocorrelation in
the data of many real applications well. Because of its simplicity, the AR(1) model is
popular in the SPC literature (e.g., Lu and Reynolds, 1999; Runger and Willemain,
1995).
After a time series model (e.g., the AR(1) model (4.15)) is chosen and estimated
by certain routine model selection, model estimation, and model diagnostics proce-
dures in time series analysis, we can deﬁne the residuals of the ﬁtted model by
/hatwideen=Xn−/hatwideXn, forn≥1,
where/hatwideXnis the ﬁtted value of Xn. If the chosen time series model describes the
observed IC data adequately and the production process is IC up to the time point
n, then{/hatwideen,n≥1}should be approximately i.i.d. with a common normal distribu-
tionN(0,/hatwideσ2
e), where/hatwideσ2
eis an appropriate estimator of σ2
e. Then, we can apply the
conventional CUSUM chart (4.7)–(4.8) (or other alternative control charts) to these
residuals. A signal from the control chart would detect a shift from the IC model (i.e.,
the time series model chosen for describing the IC observations of a production pro-
cess). However, it should be pointed out that the signal may not be caused solely by a
process mean shift. To explain this, let us use the AR(1) model as an example. In this
model, the mean of Xn, the mean of the noise term en, and the coefﬁcient φcan all
shift either simultaneously or separately, besides the possible shifts in the variances
ofXnanden. If the mean of Xnshifts from µ0toµ1with the size δ=µ1−µ0, then
the mean of enwould shift from 0 to δ, and the means of all subsequent noise terms
would shift from 0 to δ∗=(1−φ)δ. Ifenhas a mean shift from 0 to δ∗at the time
point n, then the mean of Xn+j, for j≥0, would shift from µ0to
µ0+δ∗j
∑
k=0φk=µ0+δ∗1−φj+1
1−φ,
which is approximately µ0+δ∗/(1−φ). Therefore, the CUSUM chart (4.7)–(4.8)
with k=δ∗/2 would be asymptotically optimal for detecting a mean shift in Xnof
sizeδ∗/(1−φ), instead of just δ∗. Related discussion on model-based control charts
for monitoring autocorrelated processes can be found in Jiang et al. (2000), Johnson
and Bagshaw (1974), Lu and Reynolds (1999, 2001), Montgomery and Mastrangelo
(1991), Timmer et al. (1998), Yashchin (1993a), and so forth.
Example 4.6 To monitor the production of an aluminum smelter, 189 observations
of the content of MgO in its products are collected over a period of time. The originalMONITORING THE MEAN OF A NORMAL PROCESS 141
observations ar e shown in Figure 4.7(a). A more detailed description of this data can
be found in Qiu and Hawkins (2001). By using the ar()function in R, it can be found
that the data are auto-correlated, and the following AR(1) model is appropriate to
describe the autocorrelation:
Xn=12.972+0.546(Xn−1−12.972)+ en, for1≤n≤189,
where X 0=12.972. The residuals {/hatwideen,2≤n≤189} from this ﬁtted model are pre-
sented in Figure 4.7(b). The Shapiro-Wilk test (cf., Shapiro and Wilk, 1965) for testing
the normality of the original data gives a p-value of 0.044, and the same test on the
residuals gives a p-value of 0.276, which conﬁrms that the original data may not be
normally distributed but the distribution of the residuals is not signiﬁcantly different
from a normal distribution. After the data standardization (i.e., ﬁrst subtracting the
sample mean and then dividing by the sample standard deviation), the CUSUM chart
(4.7)–(4.8) with (k,h)=(0.25, 5.597) (note: its nominal ARL 0is 200) is applied to
both the original data and the residuals. The two control charts are shown in Figure
4.7(c)–(d), respectively. From the plots, it can be seen that the chart for the original
data has signals very early (at the 15th and 16th time points), and the chart for the
residuals does not give signals until the 64th time point. Based on our discussion
above, the early signal of the former chart might be due to the autocorrelation in the
original data that is not accommodated in that chart.
4.2.4 Optimality of the CUSUM chart
Assume that the probability density function (pdf) or the probability mass function
(pmf) (see Section 2.2 for their deﬁnitions) of a population is f(x;θ), where θis a
parameter. And, we are interested in testing the hypotheses
H0:θ=θ0 versus H1:θ=θ1, (4.18)
where θ0/ne}ationslash=θ1are two given numbers. Then, the well-known sequential probability
ratio test (SPRT) is constructed as follows. Let {X1,X2,..., Xn}beni.i.d. observa-
tions collected from the population for testing the hypotheses in (4.18). Then, the
likelihood function (see its deﬁnition in Subsection 2.7.2) based on the simple ran-
dom sample {X1,X2,..., Xn}is
L(θ;X1,X2,..., Xn)=Πn
i=1f(Xi;θ),
which provides a measure of the likelihood that the parameter θtakes different values
on the number line. To compare the likelihoods of θ=θ0andθ=θ1, let us consider
the likelihood ratio
Λn=L(θ1;X1,X2,..., Xn)
L(θ0;X1,X2,..., Xn)=Πn
i=1f(Xi;θ1)
f(Xi;θ0).
In practice, it is often more convenient to work on the logarithm of Λn
log(Λn)=n
∑
i=1Ψi,142 UNIV ARIA TE CUSUM CHARTS
0 50 100 15010 11 12 13 14 15
nXn
(a)0 50 100 150−2.0 −1.0 0.0 1.0
nen
(b)
0 50 100 1500 5 10 15 20
nCn+
(c)0 50 100 1500 5 10 15 20
nCn+
(d)
Figure 4.7 (a) Original data. (b) Residuals of the ﬁtted AR(1) model. (c) Control chart (4.7)–
(4.8) with (k,h)=(0. 25,5.597) when it is applied to the standardized original data. (d) Con-
trol chart (4.7)–(4.8) with (k,h)=(0. 25,5.597) when it is applied to the standardized residu-
als.
where
Ψi=log/parenleftbiggf(Xi;θ1)
f(Xi;θ0)/parenrightbigg
.
Without loss of generality, let us assume that θ1>θ0. Then, in cases when
L(θ;X1,X2,..., Xn)is a non-decreasing function of θ, the SPRT has the following
decision rule:
(i)fail to reject H0if log(Λ n)≤A,
(ii)reject H0if log(Λ n)≥B, and
(iii) need one more observation to make a decision if A<log(Λ n)<B,
where A<Bare two threshold values. The SPRT was ﬁrst suggested by Wald (1945).
It was proved in Wald and Wolfowitz (1948) that this test has the following optimal-
ity property: among all testing procedures whose Type I error probabilities are belowMONITORING THE MEAN OF A NORMAL PROCESS 143
a giv en level, under some regularity conditions, the SPRT requires a minimum ex-
pected number of observations to reach a decision (i.e., to reject H0or fail to reject
H0). Related discussion can be found in Ferguson (1967) and Simons (1976).
Now, let us focus on the case when the population distribution is N(µ,σ2), and
we are interested in testing
H0:µ=µ0 versus H1:µ=µ1,
where µ0<µ1are two given values. In such cases,
Ψi=µ1−µ0
σ2[(Xi−µ0)−k],
and
log(Λn)=µ1−µ0
σ2n
∑
i=1[(Xi−µ0)−k],
where k=(µ1−µ0)/2. Let/tildewideC+
n=σ2
µ1−µ0log(Λ n). Then, we have, for n≥1,
/tildewideC+
n=n
∑
i=1[(Xi−µ0)−k]
=/tildewideC+
n−1+[(X n−µ0)−k], (4.19)
where/tildewideC+
0=0. By comparing /tildewideC+
nin (4.19) with C+
nin (4.7), we can see that they
are very similar. The only difference is that when C+
n−1+[(X n−µ0)−k]is negative,
which is in favor of H0so that H0should not be rejected at the n-th time point, C+
n
is re-started from 0, while /tildewideC+
ndoes not have this re-starting mechanism involved.
The re-starting mechanism is reasonable to use in the SPC problem, because the
sequential process in SPC should be stopped only when H0is rejected (i.e., H1is
accepted). In the case when H0is accepted, the process should be continued. By the
re-starting mechanism, the charting statistic C+
nof the CUSUM chart (4.7)–(4.8) is
reset to 0 each time when it is negative, making the chart more effective in detecting
upward process mean shifts.
Based on the connection described above between the SPRT test and the CUSUM
chart, several authors, including Lorden (1971), Moustakides (1986), Ritov (1990),
and Yashchin (1993b), derived various optimality properties of the CUSUM chart.
For instance, Moustakides (1986) proved that among all control charts with a ﬁxed
ARL 0value, the CUSUM chart with an allowance kwould have the shortest ARL 1
value for detecting a persistent shift of size δ=2k.
The SPRT connection also provides a general way to construct CUSUM charts,
summarized in the box below.144 UNIV ARIA TE CUSUM CHARTS
General Formula for the DI Form of the CUSUM Chart
Assume that the IC and OC pdf’s (or pmf’s) of the process observations are f0
andf1, respectively, and {X1,X2,...}are independent observations obtained from
the process. Then, the charting statistic of the DI form of the CUSUM chart for
detecting the distributional shift from f0tof1is deﬁned as follows: for n≥1,
Gn=max/parenleftig
0,Gn−1+/tildewideΨn/parenrightig
, (4.20)
where G0=0 and/tildewideΨn=log(f1(Xn)/f0(Xn)).
Note that the description in the above box about the CUSUM chart is more gen-
eral than the description in the remaining part of this subsection, in that both f0and
f1are not restricted to parametric functions here, while they are assumed paramet-
ric and their only difference is in the parameter values in the remaining part of this
subsection. The major purpose of this generalization is that the resulting CUSUM
chart (4.20) is also available to certain applications in which the process observation
distributions are nonparametric, or f0andf1are parametric but their difference is not
just in the parameter values.
4.3 Monitoring the Variance of a Normal Process
Variability of process observations is another key characteristic that affects the qual-
ity of products. In this section, we discuss monitoring of the process variability when
the process is univariate and the process distribution is normal. Our discussion is
divided into three parts. In Subsection 4.3.1, we explain why the process variability
is important to the quality of products and the possible impact of a shift in process
variability on the performance of a CUSUM chart for monitoring the process mean.
Then, some CUSUM charts for monitoring the process variability are described in
Subsection 4.3.2. The problem of monitoring both the process mean and the process
variability is discussed in Subsection 4.3.3.
4.3.1 Process variability and quality of products
In Section 3.4, we mentioned that our requirement on product quality is usually spec-
iﬁed by a lower speciﬁcation limit (LSL) and an upper speciﬁcation limit (USL)
in cases when a univariate numerical quality characteristic Xis our only concern.
A product is classiﬁed as a conforming product when its value of Xis between
LSL and USL. Otherwise, it is classiﬁed as a non-conforming product. The over-
all quality of the related production process can be measured by the probability
P(LSL≤X≤USL), which is also a measure of the process capability. (Note that
the term “quality” here actually means the quality of conformance, instead of the
quality of design. See related description in Section 1.2 for their difference). In this
chapter, we assume that the distribution of Xis normal. In such cases, the quality of
the production process is uniquely determined by the mean and standard deviation ofMONITORING THE V ARIANCE OF A NORMAL PROCESS 145
X. Therefore, the product quality would be affected if the mean or standard deviation
ofXshifts at a certain time point during the manufacturing of the products, which is
demonstrated in the example below.
Example 4.7 For an injection molding process, our major concern about the quality
of its products is the compressive strength (in psi), denoted as X. Assume that when
the production process works stably, X would follow the distribution of N (80,2.52).
To deﬁne conforming and non-conforming products, LSL=75 and USL=85 have been
speciﬁed, so that the production process has the probability of P(75 ≤X≤85) =
0.954 to produce conforming products when it works stably. Now, assume that at a
certain time point of production, the mean or the standard deviation of X shifts, and
the shift belongs to the following four cases:
(i)only the mean shifts to the value of 82.5,
(ii)only the standard deviation shifts to the value of 4,
(iii) the mean shifts to the value of 82.5, and the standard deviation shifts to the
value of 4, and
(iv) only the standard deviation shifts to the value of 2.
In case (i), after the mean shift, the production process has the following probability
to manufacture conforming products:
P(75≤X≤85)
=P/parenleftbigg75−82.5
2.5≤Z≤85−82.5
2.5/parenrightbigg
=P(−3≤Z≤1)= 0.840,
where Z denotes a random variable with the standard normal distribution. In cases
(ii)–(iv), the corresponding probability values can be computed in a similar way to
be 0.789, 0.704, and 0.988, respectively.
From case (i) in the above example, it can be seen that the process capability
would decrease if the process mean shifts and the process standard deviation remains
unchanged. When the process mean remains unchanged, but the process standard de-
viation increases (i.e., case (ii) in the example), the process capability would decrease
as well. Therefore, the quality of products is indeed affected by the shift in the pro-
cess variability. From case (iii), it can be seen that the situation would become worse
if the process standard deviation increases and the process mean changes at the same
time. However, case (iv) demonstrates that the process capability does not always
decrease when the process variance shifts. As a matter of fact, it is even improved
in cases when the process mean remains unchanged but the process standard devi-
ation decreases, which is intuitively reasonable because more products would meet
the designed requirements in such cases. Therefore, in practice, we are usually con-
cerned about upward shifts in process variability only. Downward shifts in process
variability would become an issue only when the cost of production needs to be re-
duced, because good quality of products often implies high cost of production and
downward shifts in process variability mean that the cost of production might have
been elevated, or the cost has room to be reduced. These points are summarized in
the box below.146 UNIV ARIA TE CUSUM CHARTS
Process Variance Shifts and the Quality of a Production Process
Upward process variance shifts would generally downgrade the quality of con-
formance of the related production process, and downward shifts would generally
improve the quality of conformance. Therefore, we are mainly concerned about
upward variance shifts in practice. Downward shifts are concerned only in cases
when we want to cut the cost of production and so forth.
4.3.2 CUSUM charts for monitoring process variance
In this subsection, we describe several control charts for detecting shifts in process
variance. Assume that the distribution of the quality characteristic of concern Xis
N(µ0,σ2
0)when the production process is in IC, and it changes to N(µ0,σ2
1)after the
process becomes OC at an unknown time point, where µ0is the IC mean, σ2
0/ne}ationslash=σ2
1
are the IC and OC variances. First, we investigate the performance of the CUSUM
chart (4.7)–(4.8), which is designed for detecting process mean shifts, in cases when
the process variance shifts. To this end, let us discuss the example below.
Example 4.8 Figure 4.8(a) shows 100 observations, the ﬁrst 50 observations are
i.i.d. from the distribution N (0,1), the second 50 observations are i.i.d. from the dis-
tribution N (0,22), and the two halves of the data are independent of each other. So,
these data simulate a production process with an IC distribution of N (0,1)which
has an upward variance shift at the 51st time point. We then apply the conventional
CUSUM chart (4.7)–(4.8) to these data, in which (k,h)are chosen to be (0.25, 5.597)
so that its ARL 0is 200 (cf., Table 4.1). The CUSUM chart is shown in Figure 4.8(b),
from which it can be seen that the charting statistic crosses the control limit h sev-
eral times after the variance shift with the ﬁrst signal at the 53rd time point, and
the variability of the charting statistic is much larger for the second half of the data.
Figure 4.8(c) shows another 100 observations, generated in the same way as that for
the observations in Figure 4.8(a), except that the second half of the data in Figure
4.8(c) are i.i.d. from the distribution N (0,0.52). Therefore, these data simulate a pro-
duction process with an IC distribution of N (0,1), which has a downward variance
shift at the 51st time point. The CUSUM chart (4.7)–(4.8) with (k,h)=(0.25, 5.597)
for these data is shown in Figure 4.8(d). Apparently, the variability of the charting
statistic is much smaller for the second half of the data in this case.
Example 4.8 shows that the process variance shift would change the distribution
of the charting statistic of the CUSUM chart (4.7)–(4.8). An upward variance shift
would increase the variability of the charting statistic and consequently the chart
(4.7)–(4.8) has a certain ability to detect the shift, while a downward shift would de-
crease the variability of the charting statistic and the chart (4.7)–(4.8) does not have
any ability to detect the shift. By the relationship among the upward CUSUM chart
(4.7)–(4.8), the downward CUSUM chart (4.9)–(4.10), and their two-sided version,
these results should also be true for the other two versions of the CUSUM chart.
A direct implication of these results is that when a process mean shift is our major
concern and the process variability changes at an early time point (e.g., at the initial
observation time point), the actual ARL 0value of a control chart designed for detect-MONITORING THE V ARIANCE OF A NORMAL PROCESS 147
0 20 40 60 80 100−4 −2 0 2 4
nXn
(a)0 20 40 60 80 1000 2 4 6 8 10 12
nCn+
(b)
0 20 40 60 80 100−4 −2 0 2 4
nXn
(c)0 20 40 60 80 1000 2 4 6 8 10 12
nCn+
(d)
Figure 4.8 (a) A dataset with 100 observations among which the ﬁrst 50 observations are
from the distribution N (0,1), the second 50 observations are from the distribution N (0,22),
and all observations are independent. (b) Control chart (4.7)–(4.8) with (k,h)=(0. 25,5.597)
when it is applied to the data in plot (a). (c) A dataset with 100 observations among which
the ﬁrst 50 observations are from the distribution N (0,1), the second 50 observations are from
the distribution N (0,0.52), and all observations are independent. (d) Control chart (4.7)–(4.8)
with(k,h)=(0. 25,5.597) when it is applied to the data in plot (c).
ing mean shifts, such as the chart (4.7)–(4.8), would be affected by the variance shift.
Usually, when the variance shift is upward, the actual ARL 0value would be smaller
than the nominal ARL 0value; the actual ARL 0value would be larger than the nominal
ARL 0value if the variance shift is downward.
It should be pointed out that although the CUSUM charts designed for detecting
process mean shifts have a certain ability in detecting upward process variability
shifts, they are not effective enough in detecting variance shifts. Therefore, CUSUM
charts that are designed speciﬁcally for detecting variability shifts are still needed,
and are described below. Let us ﬁrst discuss the case when the process variance shifts
upward from σ2
0toσ2
1(i.e., σ2
1>σ2
0). In such cases, according to the general formula148 UNIV ARIA TE CUSUM CHARTS
(4.20), the DI form of the optimal CUSUM chart is
Gn=max/parenleftig
0,Gn−1+/tildewideΨn/parenrightig
,
where G0=0,/tildewideΨn=log(f1(Xn)/f0(Xn)), and f0and f1are the pdf’s of the IC and
OC distributions, respectively. By the pdf formula (2.12) of a normal distribution in
Subsection 2.3.1, it can be checked that
/tildewideΨn=log/parenleftbiggσ0
σ1/parenrightbigg
+1
2/bracketleftigg
1−/parenleftbiggσ0
σ1/parenrightbigg2/bracketrightigg/parenleftbiggXn−µ0
σ0/parenrightbigg2
.
Forn≥0, let
C+
n=Gn/slashigg/braceleftigg
1
2/bracketleftigg
1−/parenleftbiggσ0
σ1/parenrightbigg2/bracketrightigg/bracerightigg
.
Then, the CUSUM chart is
C+
n=max/parenleftigg
0,C+
n−1+/parenleftbiggXn−µ0
σ0/parenrightbigg2
−k+/parenrightigg
, (4.21)
where C+
0=0, and
k+=2log(σ0/σ1)
(σ0/σ1)2−1.
This chart gives a signal of upward variance shift if
C+
n>hU, (4.22)
where hU>0 is a control limit that is chosen to reach a pre-speciﬁed ARL 0value.
Similarly, we can derive an optimal CUSUM chart for detecting a downward
variance shift from σ2
0toσ2
1(i.e., the case when σ2
1<σ2
0) as follows. By the general
formula (4.20), the DI form of the optimal CUSUM chart can be written as
−Gn=min/parenleftig
0,−Gn−1−/tildewideΨn/parenrightig
=min/parenleftigg
0,−Gn−1−log/parenleftbiggσ0
σ1/parenrightbigg
+1
2/bracketleftigg/parenleftbiggσ0
σ1/parenrightbigg2
−1/bracketrightigg/parenleftbiggXn−µ0
σ0/parenrightbigg2/parenrightigg
.
In the second equation of the above expression, the expression for /tildewideΨngiven in the
previous paragraph has been used. For n≥0, let
C−
n=−Gn/slashigg/braceleftigg
1
2/bracketleftigg/parenleftbiggσ0
σ1/parenrightbigg2
−1/bracketrightigg/bracerightigg
.
Then, the charting statistic of the optimal CUSUM chart for detecting the downward
variance shift is deﬁned by
C−
n=min/parenleftigg
0,C−
n−1+/parenleftbiggXn−µ0
σ0/parenrightbigg2
−k−/parenrightigg
, forn≥1, (4.23)MONITORING THE V ARIANCE OF A NORMAL PROCESS 149
where C−
0=0, and k−hasthe same expression as that of k+. This chart gives a signal
of downward variance shift when
C−
n<hL, (4.24)
where hL<0 is a control limit that is chosen to reach a pre-speciﬁed ARL 0value.
Example 4.8 (continued) For the data shown in Figure 4.8(a), an upward process
variance shift occurs at the 51st time point, and the IC and OC process variances
areσ2
0=1andσ2
1=22, respectively. To apply the optimal CUSUM chart (4.21)–
(4.22), k+should be chosen as 2log(1/2)/[(1/2)2−1]= 1.848. If we choose ARL 0=
200, then by the software package ANYGETH.EXE provided by Hawkins and Olwell
(1998) (see its description in the appendix), the control limit is computed to be h U=
7.416. The CUSUM chart is shown in Figure 4.9(a). It can be seen that the ﬁrst signal
is given by this chart at the 54th time point. For the data shown in Figure 4.8(c),
a downward process variance shift occurs at the 51st time point, and the IC and
OC process variances are σ2
0=1andσ2
1=0.52, respectively. To apply the optimal
CUSUM chart (4.23)–(4.24), k−should be chosen as 2log(1/0.5)/[(1/0.5)2−1]=
0.462. When ARL 0=200, by the software package ANYGETH.EXE, the control
limit is computed to be h L=−2.446. The corresponding CUSUM chart is shown in
Figure 4.9(b), and the ﬁrst signal is given by this chart at the 63rd time point.
0 20 40 60 80 1000 20 40 60 80 100
nCn+
(a)0 20 40 60 80 100−12 −8 −6 −4 −2 0
nCn−
(b)
Figure 4.9 (a) C USUM chart (4.21)–(4.22) when it is applied to the data shown in Figure
4.8(a) and when k+=1.848 and h U=7.416 (shown by the dashed horizontal line). (b)
CUSUM chart (4.23)–(4.24) when it is applied to the data shown in Figure 4.8(c) and when
k−=0.462and h L=−2.446(shown by the dashed horizontal line).
To detect process variance shifts, batch data are commonly used. Assume that the
batch size is mat each time point. Then, for n≥1, we have mobservations at the
n-th time point
Xn1,Xn2,..., Xnm.
Let Xnand s2
nbe the sample mean and sample variance of these observa-
tions. Then, we know that, for estimating (µ,σ2)of the population distribution150 UNIV ARIA TE CUSUM CHARTS
N(µ,σ2), we would not lose any useful information to replace the original sample
{Xn1,Xn2,..., Xnm}by(Xn,s2
n)(i.e.,(Xn,s2
n)are sufﬁcient statistics for estimating
(µ.σ2), see Lehmann and Casella (1998)). To monitor the process variability, we
can simply use the sample variance s2
n, which has the following distribution:
(m−1)s2
n
σ2∼χ2
m−1.
By the pdf formula of the chi-square distribution given in Subsection 2.3.2, it can be
checked that the pdf of s2
nis
f(s2
n)=1
2(m−1)/2Γ((m−1)/2)/bracketleftbigg(m−1)
σ2s2
n/bracketrightbigg(m−1)/2−1(m−1)
σ2e−(m−1)
2σ2s2
n.
By the general formula (4.20), the DI form of the optimal CUSUM chart is
Gn=max/parenleftig
0,Gn−1+/tildewideΨn/parenrightig
,
where G0=0,
/tildewideΨn=log/parenleftbiggf1(s2
n)
f0(s2n)/parenrightbigg
=m−1
2log/parenleftbig
σ2
0/σ2
1/parenrightbig
+(σ2
1−σ2
0)(m−1)
2σ2
0σ2
1s2
n,
andf0andf1are the pdf’s of the IC and OC distributions of s2
n, respectively. Assume
that the shift in process variability is upward (i.e., σ2
1>σ2
0). In such cases, σ2
1−σ2
0>
0. For n≥0, let
C+
n=Gn/slashbigg/braceleftbigg(σ2
1−σ2
0)(m−1)
2σ2
0σ2
1/bracerightbigg
.
Then, the CUSUM charting statistic for detecting the upward process variance shift
is
C+
n=max/parenleftbig
0,C+
n−1+s2
n−k+/parenrightbig
, (4.25)
where C+
0=0, and
k+=2log(σ1/σ0)σ2
0σ2
1
σ2
1−σ2
0.
This chart gives a signal of upward variance shift if
C+
n>hU, (4.26)
where hU>0 is a control limit that is chosen to reach a pre-speciﬁed ARL 0value. We
can deﬁne a CUSUM chart for detecting a downward process variance shift based on
batch data in a similar way.
Comparing the chart (4.21)–(4.22) with the chart (4.25)–(4.26), the former would
be sensitive to process mean shifts besides its ability in detecting process variance
shifts, while the latter is for detecting process variance shifts only and it is immune to
possible process mean shifts. That is because the charting statistic deﬁned in (4.21)
depends on the true process mean, but the one deﬁned in (4.25) does not.MONITORING THE V ARIANCE OF A NORMAL PROCESS 151
4.3.3 J oint monitoring of process mean and variance
As mentioned earlier, shifts in both the process mean and process variance would
have an impact on the quality of products. Therefore, in practice, we often need to
monitor process mean and process variance simultaneously. To this end, with the
Shewhart charts discussed in Chapter 3, a Shewhart chart designed for monitoring
the process mean (e.g., the Xchart) and a Shewhart chart designed for monitoring
the process variance (e.g., the Rchart) are usually used as a pair. With the CUSUM
charts, we can jointly monitor the process mean and variance in a similar way, as
brieﬂy described below.
Let us ﬁrst focus on the case discussed at the end of the previous subsection about
batch data. At each time point, we have a sample of size m,{Xn1,Xn2,..., Xnm},
forn≥1. Then, a CUSUM chart can be constructed based on the sample means
{Xn,n≥1}for monitoring the process mean (cf., Example 4.2(continued) at the
end of Subsection 4.2.1), and another CUSUM chart can be constructed based on
the sample variances {s2
n,n≥1}for monitoring the process variance (cf., formulas
(4.25) and (4.26)). For simplicity of presentation, in this subsection, the CUSUM
chart for monitoring the process mean is called the CUSUM-M chart, and the one
for monitoring the process variance is called the CUSUM-V chart. To jointly mon-
itor the process mean and variance, the two charts CUSUM-M and CUSUM-V can
be used as a pair. A signal for joint monitoring is given when either one of the two
charts gives a signal, and the status of a potential shift (i.e., a mean shift versus a vari-
ance shift) can be judged from the speciﬁc chart that gives the signal. If the signal of
joint monitoring is due to a signal from the CUSUM-M chart, then we can conclude
that the process mean has shifted. Otherwise, we can conclude that process variance
has shifted. The two control charts in the pair can be designed separately, although
it is often a good idea to make their ARL 0values the same, unless we have differ-
ent preference regarding detection of the mean shift versus detection of the variance
shift. In the current setup with batch data, the charting statistics of the CUSUM-M
and CUSUM-V charts are independent, because the sample mean and sample vari-
ance are independent at each time point. Let SM(n)andSV(n)be the events that the
CUSUM-M and CUSUM-V charts have signals at the n-th time point, respectively.
Then, the probability that the joint monitoring scheme gives a signal is
P(S M(n)orSV(n)) = P(S M(n))+ P(S V(n))−P(S M(n))P(S V(n))
≈P(S M(n))+ P(S V(n)), (4.27)
where “≈” means “approximately equal,” and the term P(S M(n))P(S V(n)) is omitted
in the second line because it is often much smaller than both P(S M(n)) andP(S V(n)).
In Subsection 4.2.2, it is mentioned that in cases when a process is IC, the distribution
of the charting statistic of a CUSUM chart would approach a steady-state distribution
when ngets large. Therefore, the three probabilities P(S M(n)orSV(n)), P(S M(n)),
andP(S V(n)) in (4.27) will approach three constants. By these results and the result
that the IC ARL of a CUSUM chart can be reasonably approximated by the mean
of a geometric distribution (cf., Gan, 1993a; Goel and Wu, 1971; Hawkins, 1992b;
Vance, 1986; Waldmann, 1986; Woodall, 1983), the ARL 0value of the joint monitor-152 UNIV ARIA TE CUSUM CHARTS
ing scheme can be approximated well using the following formula:
1
ARL 0,J≈1
ARL 0,M+1
ARL 0,V, (4.28)
where ARL 0,J,ARL 0,M,andARL 0,Vdenote the ARL 0values of the joint monitoring
scheme, the CUSUM-M, and the CUSUM-V charts, respectively. A considerable
amount of approximation error could get involved if a similar formula to (4.28) is
used for approximating the ARL 1values of the joint monitoring scheme.
Example 4.9 Assume that 10 samples of size 5 each are generated from the N (0,1)
distribution, and another 10 samples of size 5 each are generated from the N (1,1)
distribution. These samples can be regarded as observed batch data from a produc-
tion process that has a mean shift of size 1 at the 11th time point. The sample means
{Xn,n=1,2,...,20}are shown in Figure 4.10(a). To monitor the production pro-
cess, a joint monitoring scheme for monitoring both the process mean and the process
variance is used, in which the CUSUM-M chart is the CUSUM chart (4.7)–(4.8) for
detecting upward mean shifts with X nin (4.7) replaced by Xn, and the CUSUM-V
chart is the CUSUM chart (4.25)–(4.26) for detecting upward variance shifts. In the
CUSUM-M chart, (k,h)are chosen to be (0.5, 0.881) such that its ARL 0is 400. This
chart is optimal for detecting a mean shift of size 1. In the CUSUM-V chart, (k+,hU)
are chosen to be (1.848, 2.533) so that its ARL 0is 400 as well. This chart is optimal
for detecting a variance shift from σ2
0=1toσ2
1=22. By (4.28), the ARL 0value of
the joint monitoring scheme is about 200. The two control charts are shown in Fig-
ure 4.10(b)–(c), respectively. It can be seen that the CUSUM-M chart gives a signal
at the 11th time point, and consequently the joint monitoring scheme signals at this
time point as well. We then consider another scenario in which the ﬁrst 10 samples of
size 5 each are generated from the N (0,1)distribution, and the second 10 samples of
size 5 each are generated from the N (0,22)distribution. These samples simulate the
observed batch data from a production process that has a variance shift from σ2
0=1
toσ2
1=22at the 11th time point. The sample means are shown in Figure 4.10(d),
and the CUSUM-M and CUSUM-V charts are shown in Figure 4.10(e)–(f). It can
be seen that the CUSUM-M chart does not give any signal, although its charting
statistic has a larger variability after the variance shift, the CUSUM-V chart gives a
signal at the 12th time point, and consequently the joint monitoring scheme signals
at the 12th time point as well.
For individual observation data, a CUSUM chart designed mainly for monitoring
the process mean (e.g., the one (4.7)–(4.8)) and a CUSUM chart designed mainly
for monitoring the process variance can also be used as a pair to jointly monitor the
process mean and variance. In such cases, the formula (4.28) for approximating the
ARL 0value of the joint monitoring scheme may not be valid, because the charting
statistics of the two individual CUSUM charts are usually correlated. However, the
ARL 0value of the joint monitoring scheme can be computed easily by a numeri-
cal algorithm similar to the one described by the pseudo code in the box below the
expression (4.11).
Some authors have proposed some speciﬁc control charts for joint monitoring of
the process mean and variance. For instance, Hawkins (1981) proposed a joint mon-
itoring scheme described as follows. Assume that the IC distribution of a productionMONITORING THE V ARIANCE OF A NORMAL PROCESS 153
0 5 10 15 20−2 −1 0 1 2
nXn
(a)
0 5 10 15 200 1 2 3 4 5 6
nCn+
(b)
0 5 10 15 200 5 10 15
nCn+
(c)0 5 10 15 20−2 −1 0 1 2
nXn
(d)
0 5 10 15 200 1 2 3 4 5 6
nCn+
(e)
0 5 10 15 200 5 10 15
nCn+
(f)
Figure 4.10 (a) Sample means of 20 samples of size 5 each with the ﬁrst 10 samples from
the N(0,1)distribution, the second 10 samples from the N (1,1)distribution, and all samples
independent of each other. (b) CUSUM-M chart with (k,h)=(0. 5,0.881) for the data shown
in plot (a). (c) CUSUM-V chart with (k+,hU) = (1. 848, 2.533) for the data shown in plot
(a). (d) Sample means of 20 samples of size 5 each with the ﬁrst 10 samples from the N (0,1)
distribution, the second 10 samples from the N (0,22)distribution, and all samples independent
of each other. (e) CUSUM-M chart with (k,h) = (0. 5,0.881) for the data shown in plot (d).
(f) CUSUM-V chart with (k+,hU)=(1. 848, 2.533) for the data shown in plot (d). The dashed
horizontal lines in plots (b), (c), (e), and (f) are control limits of the related control charts.154 UNIV ARIA TE CUSUM CHARTS
process is N(µ0,σ2
0), and an individual observation Xnis observed at the n-th time
point, for n≥1. Then, we can construct a CUSUM chart for detecting process mean
shifts based on the standardized observations
Zn=Xn−µ0
σ0, forn≥1,
using formulas (4.7) and (4.8) with Xn−µ0in (4.7) replaced by (Xn−µ0)/σ0. This
is the CUSUM-M chart used in the joint monitoring scheme. To monitor the process
variability, Hawkins proposed using the transformed observations
Wn=/radicalbig
|Zn|−0.822
0.349.
When the process is IC at the n-th time point, the distribution of Wnis close to N(0,1).
If the process has an upward (downward) variance shift at the n-th time point, then
the mean of Wnwould increase (decrease). Therefore, detection of variance shift in
Xncan be achieved by detecting the mean shift in Wn. The latter task can be achieved
by using a CUSUM chart constructed using the formulas (4.7) and (4.8) with Xn−µ0
in (4.7) replaced by Wn. This chart is used as the CUSUM-V chart in the joint mon-
itoring scheme. Note that ZnandWnhave approximately the same IC distribution.
Therefore, the two charting statistics would have similar scales as well when the pro-
cess is IC, which makes it possible to include the two charts in a single plot. Yeh
et al. (2004b) proposed another joint monitoring scheme based on batch data. The
CUSUM-M and CUSUM-V charts in that scheme are based on two statistics that
both have the Uni f orm(0, 1)distribution when the process is IC, so that they can be
shown in a single plot as well.
As discussed in Sections 3.5 and 4.1, the Shewhart charts are good for detecting
relatively large and transient shifts in the distribution of the quality characteristic X,
and the CUSUM charts are good for detecting relatively small and persistent shifts
in the distribution of X. In practice, it is often our interest to detect both transient and
persistent shifts. To this end, it has become a common practice to use a joint mon-
itoring scheme that consists of a Shewhart chart and a CUSUM chart (e.g., Lucas,
1982; Wu et al., 2008b). For instance, if batch data are available, then the X-chart de-
ﬁned in (3.6) can be used for detecting transient process mean shifts and the CUSUM
chart (4.7)–(4.8) constructed from sample means can be used for detecting persistent
process mean shifts. Detailed discussion about the design of such joint monitoring
schemes can be found in Wu et al. (2008b) and the references cited there.
4.4 CUSUM Charts for Distributions in Exponential Family
In the previous section, CUSUM charts for monitoring process mean and/or variance
are described in cases when the distribution of the quality characteristic of interest
Xis normal. In practice, the distribution of Xis often not normal. In Subsection
4.2.4, we have provided a formula for constructing optimal CUSUM charts in gen-
eral cases when the IC and OC process distributions are speciﬁed. In cases when
the process distributions are parametric and they belong to the so-called exponentialCUSUM CHARTS FOR DISTRIBUTIONS IN EXPONENTIAL FAMILY 155
family (see its deﬁnition in Subsection 4.4.1 below), the optimal CUSUM charts can
be computed using simpler formulas. Because the exponential family contains many
commonly used parametric distributions, this section discusses construction of opti-
mal CUSUM charts for some important parametric distributions in this family. Our
discussion is divided into two parts. Some cases when Xis continuous numerical and
its distribution belongs to the exponential family (e.g., the gamma and Weibull distri-
butions) are discussed in Subsection 4.4.1. Cases when Xfollows several commonly
used discrete distributions that belong to the exponential family (e.g., the binomial
and Poisson distributions) are discussed in Subsection 4.4.2.
4.4.1 Cases with some continuous distributions in the exponential family
Assume that the distribution of Xbelongs to the one-parameter exponential family.
Then, its probability density function (pdf) or probability mass function (pmf) has
the expression
f(x;θ)=h(x)exp(η(θ)T(x)+A(θ)), (4.29)
where h(x),T(x),η(θ),andA(θ)are known functions. If we are interested in de-
tecting a shift in θfrom θ0toθ1based on the independent observations {X1,X2,...}
obtained from a related production process, then by the general formula (4.20) given
in Subsection 4.2.4, the optimal CUSUM chart has the charting statistic
Gn=max/parenleftig
0,Gn−1+/tildewideΨn/parenrightig
, (4.30)
where G0=0,/tildewideΨn=log(f1(Xn)/f0(Xn)), and f0and f1are the pdf’s (or pmf’s) of
the IC and OC distributions of X, respectively. From (4.29), when the distribution of
Xbelongs to the one-parameter exponential family, we have
/tildewideΨn=[η(θ1)−η(θ0)]T(Xn)+[A(θ1)−A(θ0)]. (4.31)
In cases when η(θ1)−η(θ0)>0, let us deﬁne
C+
n=Gn/slashbig
[η(θ1)−η(θ0)].
Then, by (4.30) and (4.31), the charting statistic of the optimal CUSUM chart can be
deﬁned by
C+
n=max/parenleftbig
0,C+
n−1+T(Xn)−k+/parenrightbig
, (4.32)
where C+
0=0, and
k+=−A(θ1)−A(θ0)
η(θ1)−η(θ0). (4.33)
The chart gives a signal when C+
n>h+, where h+is a control limit chosen to achieve
a pre-speciﬁed ARL 0value. In cases when η(θ1)−η(θ0)<0, let us deﬁne
C−
n=−Gn/slashbig
[η(θ0)−η(θ1)].156 UNIV ARIA TE CUSUM CHARTS
Then, the charting statistic of the optimal CUSUM chart can be deﬁned by
C−
n=min/parenleftbig
0,C−
n−1+T(Xn)−k−/parenrightbig
, (4.34)
where C−
0=0, and k−has the same expression as that of k+in (4.33). This chart
gives a signal when C−
n<h−, where h−is a control limit chosen to achieve a pre-
speciﬁed ARL 0value as well.
Next, we discuss several special continuous distributions that belong to the one-
parameter exponential family (4.29), and give the formulas of the corresponding op-
timal CUSUM charts. It should be pointed out that monitoring the mean of a normal
process and monitoring its variability are also special cases of the monitoring prob-
lem discussed here, because the normal distribution is an important distribution in
the exponential family. They have been discussed in detail in Subsections 4.2.4 and
4.3.2, respectively.
Let us ﬁrst discuss the case when Xhas a gamma distribution with the following
pdf: for x>0,
f(x;α,β) =xα−1
βαΓ(α)e−x/β
=exp/bracketleftbigg
(α−1)log(x)−x
β−αlog(β)−log(Γ(α))/bracketrightbigg
,(4.35)
where α>0 is a shape parameter, and β>0 is a scale parameter. This distribution is
often denoted as Γ(α,β). It can be checked (cf., (2.6) and (2.7)) that, if X∼Γ(α,β),
then
µX=αβ, σ2
X=αβ2.
If we are interested in detecting shifts in the shape parameter α, then βcan be
regarded as known and thus f(x;α,β)in (4.35) can be regarded as a special case of
the one-parameter exponential family (4.29) with
θ=α, η(θ)=α−1, T(x)=log(x),
A(θ)=−αlog(β)−log(Γ(α)).
The optimal CUSUM chart can be constructed by (4.32) or (4.34). For instance, if
we are interested in detecting an upward shift in αfrom α0toα1with α0<α1, then
the charting statistic of the optimal CUSUM chart is deﬁned by
C+
n=max/parenleftbig
0,C+
n−1+log(X n)−k+/parenrightbig
, (4.36)
where C+
0=0, and
k+=log/parenleftbigg1
β/parenrightbigg
+log(Γ(α0)/Γ( α1))
α1−α0. (4.37)
The formulas (4.36) and (4.37) are derived from (4.32) and (4.33), respectively. The
optimal CUSUM chart for detecting a downward shift in αcan be constructed by
(4.34) in a similar way.CUSUM CHARTS FOR DISTRIBUTIONS IN EXPONENTIAL FAMILY 157
It is easy to check that the distribution of Γ(k/2,2)is the same as the chi-
square distribution χ2
k(cf., its deﬁnition in Subsection 2.3.2). By this connection,
the CUSUM charts for detecting shifts in αof the Γ(α,β)distribution can also be
used for detecting shifts in kof the related chi-square distribution, as long as we set
α=k/2 and β=2.
To detect shifts in the scale parameter βof the Γ(α,β)distribution, the shape
parameter αcan be regarded as known and thus f(x;α,β)in (4.35) can also be
regarded as a special case of the one-parameter exponential family (4.29) with
θ=β, η(θ)=−1/β, T(x)=x,
A(θ)=−αlog(β).
Because η(θ)is an increasing function of θin this case, the optimal CUSUM chart
for detecting upward shifts in βcan be constructed by (4.32) and the one for detecting
downward shifts can be constructed by (4.34). For instance, if we are interested in
detecting an upward shift in βfrom β0toβ1with β0<β1, then the charting statistic
of the optimal CUSUM chart is deﬁned by
C+
n=max/parenleftbig
0,C+
n−1+Xn−k+/parenrightbig
, (4.38)
where C+
0=0, and
k+=αβ0β1log(β0/β1)
β1−β0. (4.39)
When α=1, the distribution of Γ(1, β)is the same as the exponential distribution
with a rate parameter λ=1/β, denoted as Exponential (λ), which is commonly
used in practice to describe the survival time of a biological or mechanical system.
Therefore, the CUSUM chart for detecting shifts in βof the Γ(α,β)distribution can
also be used for detecting shifts in λof the related exponential distribution, as long
as we set α=1 and β=1/λ.
Detection of normal variance shifts can also be regarded as a special case of
detection of shifts in the scale parameter βof the Γ(α,β)distribution. Let us ﬁrst
look at the CUSUM chart (4.21)–(4.22) for detecting upward normal variance shifts.
From (4.21), it can be seen that the chart actually uses the transformed data
Yn=/parenleftbiggXn−µ0
σ0/parenrightbigg2
.
When the process is IC, the distribution of Ynisχ2
1, which is equivalent to Γ(1/2, 2).
After an upward shift of the process variance from σ2
0toσ2
1with σ2
0<σ2
1, the dis-
tribution of Ynbecomes Γ(1/2, 2σ2
1/σ2
0). Therefore, detection of the upward normal
variance shift from σ2
0toσ2
1can also be achieved by detecting the upward shift in
βfrom 2 to 2 σ2
1/σ2
0in the Γ(1/2, β)distribution. It can be checked that the control
chart (4.38)–(4.39) in such a case is exactly the same as the one deﬁned by (4.21)–
(4.22). In a similar way, the CUSUM chart (4.25)–(4.26) that is constructed from
batch data can also be derived as a CUSUM chart for detecting shifts in βof the
Γ((m−1)/2, β)distribution.158 UNIV ARIA TE CUSUM CHARTS
As described in Subsection 2.3.5, in life science and reliability analysis, the
Weibull distribution plays an important role for describing the distribution of the
lifetimes of products. If X∼Weibull(a,b), then its pdf has the expression
f(x;a,b) =b
a/parenleftigx
a/parenrightigb−1
e−(x/a)b, forx≥0,
=exp/bracketleftbigg
(b−1)log(x)−xb
ab+log(b)−blog(a)/bracketrightbigg
, (4.40)
where a>0 is a scale parameter and b>0 is a shape parameter. If we are interested
in detecting shifts in the scale parameter a, then bcan be regarded as known and
f(x;a,b)in (4.40) is obviously a member of the one-parameter exponential family
(4.29) with
θ=a, η(θ)=−a−b, T(x)=xb,
A(θ)=log(b)−blog(a).
The function η(θ)is an increasing function of θ. So, to detect an upward shift in a
from a0toa1with a0<a1, the optimal CUSUM chart can be constructed by (4.32)
with the charting statistic
C+
n=max/parenleftig
0,C+
n−1+Xb
n−k+/parenrightig
,
where C+
0=0, and
k+=blog(a1/a0)
a−b
1−a−b
0.
The optimal CUSUM chart for detecting a downward shift can be constructed by
(4.34) in a similar way.
It is obvious that the distribution of Weibull(a,1)is equivalent to the distribution
ofExponential (λ)with λ=1/a. Therefore, the CUSUM charts discussed above for
detecting shifts in the scale parameter aof the distribution Weibull(a,b)can also be
used for detecting shifts in λof the Exponential (λ)distribution.
CUSUM charts for cases with other continuous distributions in the exponential
family, such as the beta, the log-normal, and the inverse normal distributions (cf., Ex-
ercise 4.17 in Section 4.8 below), can be discussed in a similar way. Olteanu (2010)
discussed construction of CUSUM charts for monitoring censored reliability data,
where Weibull and log-normal distributions are widely used. Related discussion can
also be found in Steiner and MacKay (2000) and Zhang and Chen (2004).
4.4.2 Cases with discrete distributions in the exponential family
If we randomly select mproducts at each of a sequence of equally spaced time
points of a production process and classify each product as either a conforming or
a non-conforming product by certain design requirements, then the number of non-
conforming products Xof the sample collected at a single time point would haveCUSUM CHARTS FOR DISTRIBUTIONS IN EXPONENTIAL FAMILY 159
theBinomial(m,π)distribution, where πis the true proportion of non-conforming
products. See Subsection 2.4.2 for a detailed description about the binomial distribu-
tion and its properties. For many applications, it is important to monitor the related
production processes to make sure that πis stable over time. For these applications,
we are interested in detecting shifts in π.
By (2.13), when X∼Binomial(m,π), its probability mass function (pmf) is, for
x=0,1,2,..., m,
f(x;m,π) = P(X=x)
=/parenleftbigg
m
x/parenrightbigg
πx(1−π)m−x
=exp/bracketleftbigg
log/parenleftbigg
m
x/parenrightbigg
+xlog/parenleftbiggπ
1−π/parenrightbigg
+mlog(1−π)/bracketrightbigg
.
Obviously, this is a member of the one-parameter exponential family (4.29) with
θ=π, η(θ)=log/parenleftbiggπ
1−π/parenrightbigg
, T(x)=x,
A(θ)=mlog(1−π).
Now, assume that we would like to monitor a production process based on its ob-
served data {X1,X2,...}, and Xnis the number of non-conforming products out of m
products collected at the n-th time point, for n≥1. If we are interested in detecting
an upward shift in πfrom π0toπ1with 0≤π0<π1≤1, then, because η(θ)is
an increasing function of θ, the optimal CUSUM chart can be constructed by (4.32)
with the charting statistic
C+
n=max/parenleftbig
0,C+
n−1+Xn−k+/parenrightbig
, (4.41)
where C+
0=0, and
k+=−mlog((1−π1)/(1−π0))
log/bracketleftig/parenleftig
π1
1−π1/parenrightig/slashig/parenleftig
π0
1−π0/parenrightig/bracketrightig.
This chart signals a shift when
C+
n>h+, (4.42)
where h+>0 is a control limit chosen to achieve a pre-speciﬁed ARL 0value. Simi-
larly, to detect a downward shift in πfrom π0toπ1with 0≤π1<π0≤1, the optimal
CUSUM chart can be constructed by (4.34) with the charting statistic
C−
n=min/parenleftbig
0,C−
n−1+Xn−k−/parenrightbig
, (4.43)
where C−
0=0, and k−has the same expression as that of k+.
Example 4.10 Assume that the proportion of non-conforming products is known to
beπ0=0.1when a production process is IC, and we are interested in detecting
an upward shift from π0=0.1toπ1=0.2based on samples of size m =100each160 UNIV ARIA TE CUSUM CHARTS
Table 4.5 The actual ARL 0values of the chart (4.41)–(4.42) for detecting an upward shift
from π0=0.1toπ1=0.2based on samples of size m =100each collected at consecutive
time points. The value of k+is computed to be 14.524 by the formula given immediately below
(4.41).
h+ARL 0 h+ARL 0 h+ARL 0
3.0 93.94 3.7 171.21 4.4 193.42
3.1 93.94 3.8 171.21 4.5 193.42
3.2 93.94 3.9 171.21 4.6 350.32
3.3 93.94 4.0 193.42 4.7 350.32
3.4 93.94 4.1 193.42 4.8 350.32
3.5 93.94 4.2 193.42 4.9 350.32
3.6 171.21 4.3 193.42 5.0 412.93
collected at consecutive time points. In this case, we should use the upward CUSUM
chart (4.41)–(4.42) with
k+=−100log((1−0.2)/(1−0.1))
log/bracketleftig/parenleftig
0.2
1−0.2/parenrightig/slashig/parenleftig
0.1
1−0.1/parenrightig/bracketrightig=14.524.
When h+changes its value from 3.0 to 5.0 with a step of 0.1, the actual ARL 0value
of this CUSUM chart is presented in Table 4.5. From the table, it can be seen that
the CUSUM chart cannot have all possible ARL 0values. As a matter of fact, when
h+∈[3.0, 5.0], it can only have 5 discrete ARL 0values 93.94, 171.21, 193.42, 350.32,
and 412.93.
Based on Table 4.5, assume that we decide to use h+=4.0with ARL 0=193.42.
If the observed numbers of non-conforming products in the ﬁrst 15 samples are
8,17,10,8,11,14,8,16,8,13,21,15,20,18,17,
then the CUSUM chart (4.41)–(4.42) is presented in Figure 4.11. From the plot, it
can be seen that a signal is given by the chart at the 11th time point.
Example 4.10 demonstrates that the CUSUM chart (4.41)–(4.42) can only take
certain discrete ARL 0values when the value of k+is given. That is because its chart-
ing statistic C+
ndeﬁned in (4.41) can only take discrete values {C+
n−1−k+,C+
n−1+
1−k+,..., C+
n−1+n−k+}when both Cn−1andk+are given. This is true for the
downward CUSUM chart with the charting statistic C−
ndeﬁned in (4.43) as well. As
a matter of fact, this phenomenon is generally true for cases with other discrete dis-
tributions and other types of control charts (e.g., Shewhart charts). Therefore, when
we monitor processes with discrete distributions, we should be aware of this phe-
nomenon and only specify the ARL 0values that are achievable. These issues are
summarized in the box below.CUSUM CHARTS FOR DISTRIBUTIONS IN EXPONENTIAL FAMILY 161
0 5 10 150 5 10 15 20
nCn+
Figure 4.11 The C USUM chart (4.41)–(4.42) with k+=14.524and h+=4.0when it is ap-
plied to the data in Example 4.10
Discreteness of the ARL 0Values
When monitoring a production process with a discrete distribution, the ARL 0
value of a related control chart is usually discrete as well. In such cases, when
designing the control chart, we should specify an ARL 0value that is achievable.
Another widely used discrete distribution in practice is the Poisson distrib ution.
See Subsection 2.4.5 for its deﬁnition and major properties. As described in Subsec-
tion 3.3.2, if Xdenotes the number of defects found in a randomly selected inspection
unit, then the distribution of Xcan be described reasonably well by the Poisson( λ)
distribution, where λ>0 is a rate parameter, denoting the average number of defects
in a randomly selected inspection unit. More generally, the Poisson( λ)distribution
is often a reasonable probability model for describing the number of events (e.g.,
defects in a product, trafﬁc accidents on a road) that occurred in a unit time interval
or within a unit space.
By (2.15), if X∼Poisson( λ), then its pmf is, for x=0,1,2,...,
f(x;λ) = P(X=x)
=λxe−x
x!
=exp[xlog(λ)−λ−log(x !)].162 UNIV ARIA TE CUSUM CHARTS
This pmf is also a member of the one-parameter exponential family (4.29) with
θ=λ, η(θ)=log(λ), T(x)=x,
A(θ)=−λ.
Assume that we are interested in detecting a shift in λof a production process
with the Poisson( λ)distribution. The observed data from the process are denoted
as{X1,X2,...}, as usual. Then, because η(θ)is an increasing function of θin this
case, the optimal CUSUM chart for detecting an upward shift in λfrom λ0toλ1with
0<λ0<λ1can be constructed by (4.32) with the charting statistic
C+
n=max/parenleftbig
0,C+
n−1+Xn−k+/parenrightbig
, (4.44)
where C+
0=0, and
k+=λ1−λ0
log(λ1)−log(λ0).
This chart gives a signal when
C+
n>h+, (4.45)
where h+>0 is a control limit chosen to achieve a pre-speciﬁed ARL 0value. Be-
cause Xntakes nonnegative integer values only, for given values of C+
n−1andk+,
the possible values of C+
nare discrete. Therefore, the possible ARL 0values of the
CUSUM chart (4.44)–(4.45) are discrete as well. Optimal CUSUM charts for detect-
ing downward shifts in λcan be constructed similarly by (4.34).
In the literature, there has been much discussion on monitoring of processes with
the above two or some other discrete distributions that belong to the exponential fam-
ily. Interested readers are referred to papers such as Bourke (2001), Gan (1993b),
Megahed et al. (2011a), Mousavi and Reynolds (2009), Reynolds and Stoumbos
(2000), Wu et al. (2008a), and Xie et al. (2002, 1998).
4.5 Self-Starting and Adaptive CUSUM Charts
This section discusses two topics. In Subsection 4.5.1, we describe the ﬁrst topic
about self-starting CUSUM charts for handling cases when the IC parameters are
unknown. Then, in Subsection 4.5.2, we describe the second topic, about adaptive
CUSUM charts that choose the allowance parameter kadaptively based on recursive
estimation of the size of a potential shift.
4.5.1 Self-Starting CUSUM charts
In the previous sections when we describe different CUSUM charts, the IC mean
µ0and the IC variance σ2
0are assumed to be known. In practice, µ0andσ2
0are
rarely known. Instead, they need to be estimated from a sample obtained at the end
of the phase I analysis after it is assured that the related process is IC. This sample
is called an IC dataset hereafter. Therefore, instead of the true values of µ0and
σ2
0, we only have their estimators /hatwideµ0and/hatwideσ2
0in most real cases. As discussed inSELF-STARTING AND ADAPTIVE CUSUM CHARTS 163
Subsection 2.7.1, estimators constructed from a random sample are random variables.
Does the randomness in /hatwideµ0and/hatwideσ2
0affect the performance of the CUSUM charts in
a substantial way? If the answer is positive, how can we eliminate such an impact?
Hawkins (1987) explored these research questions in detail. His major ﬁndings are
described in this section. The ﬁrst question is addressed in the example below.
Example 4.11 Assume that the true IC distribution of a production process is
N(0,1), which is unknown to us. Instead, it needs to be estimated from an IC dataset
of size 100. From Subsection 2.7.1, we know that µ0andσ2
0can be estimated by the
sample mean and sample variance of the IC dataset, denoted as /hatwideµ0and/hatwideσ2
0, and their
sampling distributions are
/hatwideµ0∼N(0,0.01), 99/hatwideσ2
0∼χ2
99.
On one occasion, the values of /hatwideµ0and/hatwideσ2
0computed from an IC dataset of size 100
are 0.1 and 1.21, respectively. We then use these two values as the assumed IC mean
and IC variance in designing a CUSUM chart for detecting upward mean shifts. To
use the results in Table 4.1, we consider the normalized version of the CUSUM chart
(4.7)–(4.8), with the charting statistic
C+
n=max/parenleftbigg
0,C+
n−1+Xn−/hatwideµ0
/hatwideσ0−k+/parenrightbigg
, for n≥1, (4.46)
where C+
0=0and k+>0is the allowance. The chart gives a signal of an upward
mean shift when
C+
n>h+, (4.47)
where h+>0is a control limit. When we choose ARL 0=200and k+=0.5, by Table
4.1, h+should be 3.502. Now, we use the chart (4.46)–(4.47) to monitor the process
in question. Remember that the actual IC distribution of the process is N (0,1). When
the process is IC, the actual distribution of (Xn−/hatwideµ0)//hatwideσ0is N(−/hatwideµ0//hatwideσ0,1//hatwideσ2
0) =
N(−0.091, 0.826). So, the chart (4.46)–(4.47) in such a case is equivalent to the chart
(4.7)–(4.8) for detecting a distributional shift from N (0,1)to N(−0.091, 0.826). By
this connection, the actual ARL 0value of the chart (4.46)–(4.47) is computed to be
785.49. Now, if there is a true upward mean shift of size δ=0.2, the actual ARL 1
value of the chart (4.46)–(4.47) is the same as the ARL 1value of the chart (4.7)–
(4.8) for detecting a distributional shift from N (0,1)to N(0.091, 0.826), which is
computed to be 210.99. These results and the results in cases with several other
values of/hatwideµ0and/hatwideσ0are presented in Table 4.6. Note that all the values of /hatwideµ0and/hatwideσ0
listed in Table 4.6 are typical ones in the current setup.
From Example 4.11, it can be seen that the randomness of the estimators /hatwideµ0
and/hatwideσ2
0could have a substantial impact on the performance of the CUSUM chart
(4.46)–(4.47). For instance, in cases when µ0andσ0are known beforehand, which
corresponds to the case when /hatwideµ0=0 and/hatwideσ0=1.0 in Table 4.6, the ARL 0value is
199.99, and the ARL 1value for detecting a mean shift of size 0.2 is 70.12. However,
in the case when the values of /hatwideµ0and/hatwideσ0are 0.1 and 1.1, respectively, the actual ARL 0
value of the chart becomes 785.49, which is much larger than the nominal ARL 0value
of 200. Consequently, the chart is ineffective for detecting the real upward mean shift164 UNIV ARIA TE CUSUM CHARTS
Table 4.6 The actual ARL 0values of the chart (4.46)–(4.47) in cases with several estimated
values of the IC mean µ0and IC standard deviation σ0, along with its actual ARL 1values
for detecting a mean shift of size 0.2. In the chart (4.46)–(4.47), the parameters (k+,h+)are
chosen to be (0.5,3.502), so that its nominal ARL 0is 200.
/hatwideµ0/hatwideσ0 ARL 0 ARL 1
−0.1 0.9 67.22 30.15
−0.1 1.0 115.46 44.96
−0.1 1.1 210.99 70.06
0 0.9 107.58 43.97
0 1.0 199.99 70.12
0 1.1 398.01 117.98
0.1 0.9 179.58 67.22
0.1 1.0 362.26 115.46
0.1 1.1 785.49 210.99
of 0.2 in such a case, because its actual ARL 1value of 210.99 is much larger than the
ARL 1value of 70.12 that it is supposed to have. In the case when values of /hatwideµ0and
/hatwideσ0are−0.1 and 0.9, respectively, the actual ARL 0value of the chart becomes 67.22,
indicating that the actual false alarm rate of the chart is much higher than its nominal
false alarm rate and therefore results of the chart may not be reliable. Several authors,
including Jensen et al. (2006), Jones et al. (2004), and Castagliola and Maravelakis
(2011), have studied the impact of the randomness of the estimated IC parameters on
the performance of the CUSUM charts more systematically. These authors conﬁrmed
that the estimated IC parameters could have a substantial impact on the performance
of the CUSUM charts, unless we have a large IC dataset.
In many applications, however, we cannot have a large IC dataset. To overcome
this difﬁculty, Hawkins (1987) suggested the so-called self-starting CUSUM charts,
which try to estimate the IC parameters from the data observed in phase II SPC. They
are described below in cases when we are interested in detecting upward shifts in the
process mean and the process IC and OC distributions are normal. In such cases,
the IC process distribution is N(µ0,σ2), the OC process distribution is N(µ1,σ2),
µ0<µ1, and the IC parameters µ0andσ2are unknown. In cases when µ0andσ2
can be estimated accurately from an IC dataset, the CUSUM chart (4.46)–(4.47) is
natural to use. When they cannot be estimated accurately from an IC dataset due to
the unavailability of a large IC dataset, we try to estimate them from the available
observations collected in the phase II SPC as follows. Assume that at the (n−1)-
th time point, no signal of mean shift is given by the related control chart. A new
observation Xnis thus collected at the n-th time point and we want to make a decision
whether a signal of mean shift should be given at this time point. Because no signal
is given at the (n−1)-th time point, all observations collected at that time point and
before, i.e., the observations Xn−1,Xn−2,..., X1, can be regarded as IC observations.
Therefore, µ0andσ2can be estimated by their sample mean and sample variance,SELF-STARTING AND ADAPTIVE CUSUM CHARTS 165
denoted as Xn−1ands2
n−1, respecti vely, as long as n≥3. Then, it is natural to use
Tn=Xn−Xn−1
sn−1
to replace (Xn−/hatwideµ0)//hatwideσ0in (4.46) for constructing a CUSUM chart. In cases when
{X1,X2,..., Xn}are i.i.d., which is true when the process is IC up to the n-th time
point, it is easy to check that
/radicalbigg
n−1
nTn∼tn−2,
because Xn∼N(µ0,σ2),Xn−1∼N(µ0,σ2/(n−1)),(n−2)s2
n−1/σ2∼χ2
n−2, and
(Xn,Xn−1,s2
n−1)are independent of each other (cf., the related discussion in Subsec-
tion 2.7.1). Also, Hawkins (1969) showed that {Tn,n≥1}are independent of each
other. Therefore, in such cases,
Zn=Φ−1/bracketleftigg
ϒn−2/parenleftigg/radicalbigg
n−1
nTn/parenrightigg/bracketrightigg
(4.48)
would be i.i.d. with the N(0,1)distribution, where Φis the cdf of the N(0,1)dis-
tribution, and ϒn−2is the cdf of the tn−2distribution. Because both Φ−1andϒn−2
are increasing functions, a mean shift in the original observations Xnoccurs if and
only if a mean shift in the transformed observations Znoccurs. Therefore, detection
of a normal mean shift in the original observations Xncan be accomplished by de-
tecting a mean shift in the transformed observations Zn, and the latter are i.i.d. with
theN(0,1)distribution when the process is IC. The self-starting CUSUM chart for
detecting normal mean shifts is then summarized in the box below.
Self-Starting CUSUM Chart for Detecting Normal Mean Shifts
For detecting normal mean shifts when the IC parameters are unknown, the
self-starting CUSUM chart is just the conventional CUSUM chart constructed
from the transformed observations {Zn,n≥3}that are i.i.d. with the N(0,1)dis-
tribution when the process is IC. The self-starting CUSUM chart requires at least
2 IC observations for phase II process monitoring.
Example 4.12 Assume that {Xn,n=1,2,..., 10}listed in the 2nd column of Table
4.7 are the ﬁrst 10 observations obtained from a production process for phase II SPC.
In this application, we are interested in detecting upward mean shifts. Based on the
historical data, it is reasonable to assume the process distribution to be normal, but
the IC parameters µ0andσ2are unknown. So, in this example, we want to con-
struct a self-starting CUSUM chart for detecting upward mean shifts. The computed
sample means Xn, for n≥1,the sample standard deviations s n, for n≥2, and the
transformed observations Z n, for n≥3, are listed in the 3rd, 4th, and 5th columns of166 UNIV ARIA TE CUSUM CHARTS
Table 4.7: The ﬁrst 10 values of X n,Xn, sn, Zn, and C+
n,SS, respectively.
n Xn Xn sn ZnC+
n,SS
1−0.502−0.502 0.000 0.000 0.000
2 0.132−0.185 0.448 0.000 0.000
3−0.079−0.150 0.323 0.153 0.000
4 0.887 0.109 0.581 1.605 1.355
5 0.117 0.111 0.504 0.011 1.115
6 0.319 0.145 0.458 0.351 1.216
7−0.582 0.042 0.501 −1.277 0.000
8 0.715 0.126 0.521 1.138 0.888
9−0.825 0.020 0.581 −1.518 0.000
10−0.360−0.018 0.561 −0.594 0.000
Table 4.7. Then, the charting statistic of the self-starting CUSUM c hart for detecting
upward mean shifts is deﬁned by
C+
n,SS=max/parenleftig
0,C+
n−1,SS+Zn−k/parenrightig
, for n≥3, (4.49)
where C+
1,SS=C+
2,SS=0, and k >0is the allowance parameter. When k =0.25,
{C+
n,SS,n=1,2,..., 10}are presented in the last column of Table 4.7.
We then collect another 30 observations from the same production process. The
self-starting CUSUM chart (4.49) with (k,h) = (0.25, 5.597) (note: its ARL 0value
is 200 according to Table 4.1) constructed from all 40 observations is presented in
Figure 4.12 by the solid curve. It gives a signal at the 20th time point. The ﬁrst 10 ob-
servations used in this example are actually generated from the N (0,1)distribution,
and the remaining 30 observations are generated from the N (0.5, 1)distribution.
Therefore, a true mean shift occurs at the 11th time point. For comparison purposes,
the conventional CUSUM chart (4.7)–(4.8) using the same values of (k,h)is also
plotted in Figure 4.12 by the dotted curve. In this chart, both µ0andσare assumed
to be known with values 0 and 1, respectively. This chart gives a signal at the 22nd
time point.
Example 4.12 demonstrates that the self-starting CUSUM chart can indeed detect
mean shifts in an effective way without knowing the IC parameter values. However,
Figure 4.12 also shows that, unlike the conventional CUSUM chart whose signal of
mean shift is persistent and gets stronger and stronger over time, the signal of mean
shifts from the self-starting CUSUM chart cannot last quite as long, which can be
explained intuitively as follows. Assume that a mean shift occurs at the time point τ.
Then, when n≥τ, the mean of Xn−Xn−1is
E/parenleftbig
Xn−Xn−1/parenrightbig
=τ−1
n−1(µ1−µ0). (4.50)
From (4.48) and (4.49), it can be seen that the mean shift affects the performance of
the self-starting CUSUM chart through Xn−Xn−1. Therefore, from the expressionSELF-STARTING AND ADAPTIVE CUSUM CHARTS 167
0 10 20 30 400 2 4 6 8 10 12
n
Figure 4.12 The self-starting CUSUM chart (4.49) with (k,h)=(0. 25,5.597) is shown by the
solid curve. The conventional CUSUM chart (4.7)–(4.8) with the same values of (k,h)is shown
by the dotted curve. The dashed horizontal line denotes the control limit h for both charts.
(4.50), it can be seen that such an effect is strong when n−τis relatively small. As n
increases, the mean of Xn−Xn−1tends to 0, making the signal of mean shifts from
the self-starting CUSUM chart disappear gradually. Thus, in practice, it is important
to react to the signal from the self-starting CUSUM chart quickly. Otherwise, even a
persistent mean shift can be missed by it. The expression (4.50) also implies that the
impact of the mean shift on the self-starting CUSUM chart would be weak when τis
small. Therefore, it is a good idea to collect a dozen or more IC observations before
the self-starting CUSUM chart is used.
If we are interested in detecting shifts in both process mean and process variance,
then we can use a pair of self-starting CUSUM charts. One is constructed from Zn, as
in Example 4.12, for detecting mean shifts, and the other one is constructed from Z2
n
for detecting variance shifts. These two CUSUM charts are correlated. A mean shift
would affect not only the ﬁrst chart, but also the second chart. Similarly, a variance
shift would affect both charts as well. For detailed discussion on construction of
self-starting CUSUM charts for detecting normal variance shifts, see Section 7.3 of
Hawkins and Olwell (1998).
Nowadays, self-starting control charts are popular in the literature. See, for in-
stance, Chatterjee and Qiu (2009), Hawkins and Maboudou-Tchao (2007), and Sul-
livan and Jones (2002). Some of the control charts discussed in these papers will be
described in later chapters.168 UNIV ARIA TE CUSUM CHARTS
4.5.2 Adaptive CUSUM charts
The conventional CUSUM chart (4.7)–(4.8) has an allowance parameter kinvolved.
For a potential upward mean shift of size δ, it has been mentioned in Subsection
4.2.2 that the chart is optimal for detecting that shift when kis set to equal δ/2. In
practice, however, δis often unknown at the time when we design the CUSUM chart.
In such cases, how can kbe chosen properly? Sparks (2000) addressed this issue
carefully, and proposed two approaches to solve the problem, which are described
below. For simplicity of presentation, our discussion here is on the speciﬁc case for
detecting upward normal mean shifts by the CUSUM chart (4.7)–(4.8), although
Sparks’ adaptive CUSUM idea is quite general and it can be applied to other cases
as well. Also, without loss of generality, we assume that the IC mean µ0=0 and the
IC variance σ2=1. Otherwise, standardized observations {(X n−µ0)/σ,n≥1}can
be used for constructing the related CUSUM charts.
Sparks’ ﬁrst proposal is to use several CUSUM charts simultaneously, and these
charts use different kvalues so that mean shifts of different sizes are targeted si-
multaneously by the joint control scheme. Assume that pCUSUM charts are used
jointly, and the j-th CUSUM chart uses (kj,hj)as its allowance and control limit, for
j=1,2,..., p. Then, the joint control scheme has a signal if and only if at least one
of the pindividual CUSUM charts has a signal. In his paper, Sparks suggested using
p=3 if we are interested in detecting moderate shifts in the range δ∈[0.5, 2]. In such
cases, he suggested using k1=0.375, k2=0.5,andk3=0.75. Then, {hj,j=1,2,3}
can be chosen accordingly, such that the ARL 0values of the three charts are the same
and the overall ARL 0of the joint control scheme equals a pre-speciﬁed value. Based
on his numerical results, such a joint control scheme is especially effective for detect-
ing shifts in the range [0.6, 1.75]. Of course, if we have some prior information about
the potential mean shifts, then such prior information should be accommodated in
choosing kjandARL 0values of the individual CUSUM charts.
Sparks’ second proposal is to estimate the shift size δrecursively at each time
point, and then choose kaccordingly. To this end, let us ﬁrst re-write the charting
statistic of the conventional CUSUM chart (4.7)–(4.8) as
/tildewideC+
n=max/bracketleftig
0,/tildewideC+
n−1+(X n−k)/h/bracketrightig
, forn≥1,
where/tildewideC+
n=C+
n/h, and/tildewideC+
0=0. Then, the chart gives a signal when /tildewideC+
n>1. At the
n-th time point, if δcan be estimated by/hatwideδn, then it is natural to deﬁne the charting
statistic of the upward CUSUM chart by
C+
n,A=max/bracketleftig
0,C+
n−1,A+/parenleftig
Xn−/hatwideδn/2/parenrightig/slashig
h(/hatwideδn)/bracketrightig
, forn≥1, (4.51)
where C+
0,A=0 and h(/hatwideδn)is the control limit. Namely, in the control chart (4.51),
kis chosen as/hatwideδn/2, which can change its value at different time points. So can the
control limit h(/hatwideδn). Sparks proposed the following recursive formula for estimating
δ:
/hatwideδn=max/parenleftig
δmin,λXn+(1−λ)/hatwideδn−1/parenrightig
, forn≥1, (4.52)SOME THEORY FOR COMPUTING ARL V ALUES 169
where/hatwideδ0=δmin,δmin≥0 is the minimum shift size that we are interested in de-
tecting, and λ∈(0,1]is a weighting parameter. In (4.52), we need to specify the
minimum shift size δmin, so that the selected kcould make the CUSUM chart (4.51)
effective in detecting upward mean shifts with sizes equal to or larger than δmin. In
practice, if shifts of all sizes need to be detected, then we can simply set δmin=0.
From (4.52), it can be seen that process observations contribute to the estimator/hatwideδn
through the weighted average λXn+(1−λ)/hatwideδn−1. This weighted average, which is
the so-called exponentially weighted moving average and which will be described
in detail in the next chapter, guarantees that more recent observations receive more
weight in the average. Based on the numerical study in Sparks (2000), the value of λ
can be chosen between 0.1 and 0.2.
Because the chosen kdepends on/hatwideδn, the control limit h(/hatwideδn)of the chart (4.51)
should also depend on/hatwideδn, in order to reach a pre-speciﬁed ARL 0value. Then, the
chart (4.51) gives a signal of an upward mean shift at the n-th time point if
C+
n,A>1. (4.53)
Based on a large simulation study, Sparks provided formulas for approximating h(/hatwideδn)
in cases with different ARL 0values. For instance, when ARL 0=200, he suggested
approximating h(/hatwideδn)by
−4.3883+25.4353/slashbigg/radicalig
1+8.895/hatwideδn−0.8525/hatwideδ2n+0.7295/hatwideδn
−1.5652/hatwideδ2
n+1.5065/hatwideδ3
n−0.7262/hatwideδ4
n+0.1730/hatwideδ5
n−0.0163/hatwideδ6
n.
Based on a Markov chain model, Shu and Jiang (2006) provided the following alter-
native formula for approximating h(/hatwideδn):
h(/hatwideδn)≈log/parenleftig
1+2/hatwideδ2
nARL 0+2.332/hatwideδn/parenrightig
2/hatwideδn−1.166. (4.54)
Note that the formula (4.54) can be used for all values of ARL 0. In their paper, Shu
and Jiang pointed out that this formula provided an accurate approximation to h(/hatwideδn)
in cases when/hatwideδnARL 0≫h(/hatwideδn), which is true in most applications.
4.6 Some Theory for Computing ARL Values
In the literature, there are some theoretical results for computing ARL values of
CUSUM charts, based on which some numerical algorithms have been developed
(e.g., some functions in the Rpackagespc). In this section, two major theoretical
methodologies for computing the ARL values are described. The method by the
Markov chain approach is discussed in Subsection 4.6.1, and the method by the inte-
gral equations is discussed in Subsection 4.6.2. Our discussion focuses on the upward
CUSUM chart (4.7)–(4.8), although similar theoretical results are also available for
some other CUSUM charts.170 UNIV ARIA TE CUSUM CHARTS
4.6.1 The Markov chain approach
A sequence of discrete random variables ξ1,ξ2,...is called a Markov chain if
(i)all possible values of {ξn,n≥1}form a countable set Ω, called the state space
of the chain, and
(ii)the sequence has the Markov property that for any n≥1,
P(ξn+1=un+1|ξ1=u1,ξ2=u2,..., ξn=un)=P(ξn+1=un+1|ξn=un),
for any u1,u2,..., un,un+1∈Ω.
The Markov property says that ξn+1depends on all previous observations through ξn.
In other words, conditional on ξn,ξn+1and all other history data {ξ1,ξ2,..., ξn−1}
are independent. The Markov chain is called a stationary Markov chain if it has the
time-homogeneous property that, for any n≥2 and any u,v∈Ω,
P(ξn+1=u|ξn=v)=P(ξn=u|ξn−1=v).
If{ξ1,ξ2,...}is a stationary Markov chain and its state space ΩhasNstates
{ω1,ω2,..., ωN}, then the probability
pi j=P(ξn+1=ωj|ξn=ωi), for any n≥1
is called a (single-step) transition probability from the i-th state to the j-th state, for
alli,j=1,2,..., N. The N×Nmatrix P=(pi j)is called the (single-step) transition
probability matrix. For detailed discussion about Markov chains and their properties,
see the classic references Doob (1953) and Hoel et al. (1972).
To compute the ARL values of the CUSUM chart (4.7)–(4.8), Brook and Evans
(1972) made a connection between this chart and a Markov chain. Let us ﬁrst assume
that process observations {X1,X2,...} take integer values, and so do the parameters
kandh. In such cases, the charting statistic C+
n, for any n≥1, can only take h+
1 integer values in the state space Ω={0,1,2,..., h}. When C+
n=h, a signal is
delivered and the process is stopped. So, the last state his also called the absorbing
state. When the value of C+
nis given, C+
n+1depends only on Xn+1, and thus it is
independent of {C+
1,C+
2,..., C+
n−1}, for any n≥1. Also, when the process is IC, it is
obvious that the conditional distribution of C+
n+1|C+
ndoes not depend on n. Therefore,
the sequence {C+
n,n≥1}is a stationary Markov chain with the state space Ω. Its
(single-step) transition probabilities are, for i=0,1,2,..., h−1, and j=1,2,..., h−
1,
pi0=P/parenleftbig
C+
n=0|C+
n−1=i/parenrightbig
=P(X n≤k−i),
pi j=P/parenleftbig
C+
n=j|C+
n−1=i/parenrightbig
=P(X n=k+j−i),
pih=P/parenleftbig
C+
n=h|C+
n−1=i/parenrightbig
=P(X n≥k+h−i), (4.55)
ph0=P/parenleftbig
C+
n=0|C+
n−1=h/parenrightbig
=0,
ph j=P/parenleftbig
C+
n=j|C+
n−1=h/parenrightbig
=0,
phh=P/parenleftbig
C+
n=h|C+
n−1=h/parenrightbig
=1.SOME THEORY FOR COMPUTING ARL V ALUES 171
LetP= (pij)be the(h+1)×(h+1)transition matrix, Rbe the sub-matrix of P
consisting of the ﬁrst hrows and the ﬁrst hcolumns of P, and Tibe the number of
steps taken from the state ito the absorbing state h, for i=0,1,..., h−1. Then, for
i=0,1,..., h−1,
µTi=E(T i)
=∞
∑
r=1rP(T i=r)
=∞
∑
r=1rh
∑
j=0pi jP(T j=r−1)
=h−1
∑
j=0pi j/parenleftig
µTj+1/parenrightig
+pih. (4.56)
The last equation of (4.56) can be explained intuitively as follows. The event from
the state ito the absorbing state hcan be accomplished in two stages. First, the state i
at the current time point is transited to the state jat the next time point; and then the
state jat the next time point is transited to the absorbing state h. So, if µTjdenotes the
average number of steps taken from the state jat the next time point to the absorbing
state h, then µTj+1 is the average number of steps taken from the state iat the current
time point to the absorbing state h, given the condition that the chain is in the state j
at the next time point. When j=h, it is obvious that µTj+1=1. Thus, that equation
is true. The last equation of (4.56) can be written in matrix notation as
(I−R)µT=1, (4.57)
where Iis the h×hidentity matrix, µT=(µT0,µT1,..., µTh−1)′, and 1=(1, 1,..., 1)′.
It can be seen that µT0is just the ARL value of the chart (4.7)–(4.8) in cases
when process observations and both kandhare discrete. If the probabilities deﬁned
in (4.55) are calculated from the IC process distribution, then µT0is the ARL 0value
of that chart. Therefore, the ARL value of the chart (4.7)–(4.8) can be computed
from (4.57). As a by-product, we can also compute µTi, for i=1,2,..., h−1, from
(4.57). These are the ARL values of the chart (4.7)–(4.8) when the initial value of its
charting statistic is deﬁned to be C+
0=i. The resulting CUSUM chart is the so-called
fast initial response (FIR) CUSUM chart that was systematically studied by Lucas
and Crosier (1982a).
When the process distribution is continuous with a cdf F, the charting statistic
C+
ncan take values in [0,∞). In such cases, we can categorize C+
nby dividing [0,∞)
intoM+2 groups:
0,(0,h/M],(h/M,2h/M],...,((M−1)h/M,h],(h,∞).
These M+2 groups constitute the discrete states of C+
n, among which the last state
(h,∞)is the absorbing state. Then, the transition probabilities can be computed sim-
ilarly to those in (4.55), by various different approximations. For instance, to handle
the condition that C+
n−1∈((i−1)h/M,ih/M], for i=1,2,..., M, when computing172 UNIV ARIA TE CUSUM CHARTS
the transition probabilities, Brook and Evans (1972) suggested an approximation
by replacing C+
n−1by the mid-point of the interval ((i−1)h/M,ih/M]. Hawkins
(1992a) suggested a more accurate approximation, by which the conditional prob-
ability P(a<C+
n≤b|c<C+
n−1≤d), for any intervals (a,b]and(c,d], that needs to
be handled when computing the transition probabilities, is approximated by
1
6{[F(b−c+k)+4F(b−(c+d)/2+k)+F(b−d+k)]
−[F(a−c+k)+4F(a−(c+d)/2+k)+F(a−d+k)]}.
4.6.2 The integral equations approach
The integral equations approach for computing the ARL of a CUSUM chart was
ﬁrst suggested by Page (1954). This approach is also discussed quite extensively by
Van Dobben de Bruyn (1968). Let L(z)be the ARL of the CUSUM chart (4.7)–(4.8)
with the allowance parameter kand the control limit hwhen the chart starts with
C+
0=z, where z∈(0,h]is the so-called head start value of the chart. As mentioned
in the previous subsection, this is the FIR version of the CUSUM chart. When z=0,
the FIR version is just the conventional CUSUM chart deﬁned in (4.7)–(4.8). To
make the distinction between the two different versions, sometimes the conventional
CUSUM chart is called the CUSUM chart with zero-start. Let us further assume
that the process distribution has the cdf F(x)and the pdf f(x). Then, after the ﬁrst
observation X1is obtained, one of the following three events will happen:
E1=/parenleftbig
C+
1=0/parenrightbig
, E2=/parenleftbig
C+
1∈(0,h]/parenrightbig
, E3=/parenleftbig
C+
1>h/parenrightbig
.
Then, it is easy to see that
L(z)= 1+L(0)P(E 1)+/integraldisplayh
0L(x)dFC+
1(x),
where FC+
1(x)denotes the cdf of C+
1given E2. On the right-hand side of the above
expression, the ﬁrst term “1” denotes the one-unit time lag from C+
0toC+
1,L(0)in the
second term denotes the ARL value counting from X1in cases when E1occurs, L(x)
in the third term denotes the ARL value counting from X1in cases when E2occurs
and when C+
1=x, and dFC+
1(x)in the third term provides a measure of likelihood of
the event C+
1=xgiven E2. It is obvious that
P(E 1)=P(C+
1=0)= P(z+X1−k≤0)= P(X 1≤k−z)= F(k−z),
and for x∈(0,h]
FC+
1(x)=P(C+
1≤x|C+
1∈(0,h])= P(z+X1−k≤x)=F(x+k−z).
Therefore, we have the integral equation
L(z)= 1+L(0)F(k−z)+/integraldisplayh
0L(x)f(x+k−z)dx. (4.58)SOME DISCUSSIONS 173
Tocompute L(z), we need to solve the integral equation (4.58). To this end, some
numerical algorithms are available. See, for instance, Gan (1992a), Goel and Wu
(1971), Luce ˜no and Puig-Pey (2000), and Woodall (1983) for related discussion.
4.7 Some Discussions
In this chapter, we have described some CUSUM charts for monitoring the mean
and/or variance of a univariate normal process. These CUSUM charts enjoy certain
optimality properties, as described in Subsection 4.2.4, when detecting persistent
mean and/or variance shifts. However, the optimality properties are achievable only
when the IC parameters and the mean/variance shift sizes are known. When the IC
parameters are unknown, we can use the self-starting CUSUM charts described in
Subsection 4.5.1, which recursively estimate the IC parameters during online moni-
toring of the process. They perform reasonably well as long as there are one dozen or
more IC observations collected before the phase II process monitoring. Also, we need
to react to their signals quickly. Otherwise, even a persistent shift could be missed.
The adaptive CUSUM charts described in Subsection 4.5.2 are designed for handling
the cases when the target shift size is unknown. They try to estimate the size of a po-
tential shift at each time point, and constantly update the procedure parameters based
on the estimated shift size.
When the IC and OC pdf’s (or pmf’s) of process observations can be speciﬁed
properly, a general formula for constructing a CUSUM chart was given in Subsection
4.2.4. By this formula, some optimal CUSUM charts were derived in Sections 4.3 and
4.4 in certain cases when the process distributions belong to the one-parameter ex-
ponential family. However, most of these CUSUM charts are designed for detecting
shifts in one speciﬁc parameter of the process distribution. In many cases, a shift in
that parameter would change both the mean and variance of the process distribution.
As an example, assume that the process distribution is χ2
k. Then, the mean and vari-
ance of this distribution are kand 2k , respectively. Therefore, the optimal CUSUM
chart discussed in Subsection 4.4.1 for detecting a shift in kis actually not designed
for detecting a shift in either the mean alone or the variance alone of the process dis-
tribution. In applications, however, we are often concerned about shifts in the process
mean and/or variance. To this end, we need to introduce a location or scale parameter
when it is necessary, and derive the CUSUM chart using the general formula (4.20)
based on that parameter. In such cases, the process distribution, in terms of the intro-
duced parameter, may not belong to the one-parameter exponential family any more.
Construction of appropriate CUSUM charts for handling such cases requires further
research.
Some interesting univariate CUSUM charting techniques have not been discussed
in this chapter yet. For instance, when designing the upward CUSUM chart (4.7)–
(4.8), we need to specify a target shift size δsuch that its allowance constant kcan
be chosen as δ/2. In many applications, however, the single target shift size δis
difﬁcult to specify. Instead, based on our past experience and engineering or scientiﬁc
knowledge about the related production process, it is more convenient to specify a
range[a,b]for the potential shift size δ. In the literature, there is much discussion174 UNIV ARIA TE CUSUM CHARTS
on designing appropriate CUSUM monitoring schemes for jointly detecting a range
of mean/variance shifts. Most of such joint monitoring schemes are combinations of
two or more individual CUSUM charts that are properly designed to achieve good
overall performance. Interested readers are referred to papers including Han et al.
(2007), Lorden (1971), Sparks (2000), and Zhao et al. (2005). A related methodology
constructs a CUSUM chart by accommodating a prior distribution on the potential
shift size δ. See, for instance, Liu (2010) and Ryu et al. (1995).
In this chapter, we only discuss how to detect step shifts in the process mean
and/or variance. In practice, the process mean and/or variance often changes grad-
ually with or without a parametric pattern, after the process becomes OC. For in-
stance, the surface ﬁnish or physical size of the parts produced by a machine could
change gradually due to tool wear. When the mean shift follows a linear model (i.e.,
the case with the so-called linear drift), design and implementation of the CUSUM
charts have been discussed by several authors, including Bissell (1984a,b), Davis and
Woodall (1988), and Gan (1992b). Shu et al. (2008) proposed a CUSUM chart for
detecting gradual mean shifts that follow a parametric model.
In recent years, CUSUM charts with variable sampling rate (VSR) have received
much attention in the literature (e.g., Costa, 1998; Luo et al., 2009; Reynolds and
Arnold, 2001; Reynolds et al., 1990; Wu et al., 2007). By using a VSR CUSUM
chart, the sampling rate changes over time based on all observed data. There are
several possible ways to change the sampling rate, including the variable sampling
intervals (VSI), the variable sample sizes (VSS), and the variable sample sizes and
sampling intervals (VSSI) approaches. One major advantage of the VSR CUSUM
charts, compared to the ﬁxed sampling rate (FSR) CUSUM charts, is that VSR charts
often provide faster detection of small to moderate process mean/variance shifts, for
a given ARL 0value and a given IC average sampling rate. The sampling scheme of a
conventional VSI CUSUM chart involves sampling intervals of two different lengths.
A longer sampling interval should be used to collect the next sample in cases when
the charting statistic value at the current time point is far away from the control limits
and falls into the so-called central region, and a shorter sampling interval should be
used to collect the next sample in cases when the charting statistic value is close to
but does not exceed the control limits and is within the so-called warning region. In
cases when the charting statistic value exceeds the control limits (i.e., it falls into
the so-called action region), the process is considered OC and stopped immediately.
Recently, Li et al. (2013b) and Li and Qiu (2013) suggested implementing a CUSUM
chart using statistical p-values (cf., Subsection 2.7.3), based on which the concept
of dynamic sampling was proposed. By a dynamic sampling scheme, the sampling
interval to collect the next sample can have an arbitrary length (instead of just two
different lengths), determined by the p-value of the charting statistic at the current
time point.
4.8 Exercises
4.1 Generate 10 samples of size 5 each from the N(0,1)distribution and another
10 samples of size 5 each from the N(0.2, 1)distribution. Repeat the analysisEXERCISES 175
described in Example 4.1. Are your results similar to those presented in Example
4.1? Note that your results would not be exactly the same as those in Example
4.1, due to the randomness of the samples.
4.2 Assume that we obtain the following 20 observations from a production process
whose IC distribution is N(0,1):
n 1 2 3 4 5 6 7 8 9 10
Xn1.68−0.15−0.76−1.31−1.23 0.83 0.51 −0.26−0.50−0.62
n11 12 13 14 15 16 17 18 19 20
Xn1.20 2.19 1.77 1.40 2.61 −0.19 1.88 2.45 1.55 1.29
(i) Use the V-mask form of the CUSUM chart with the charting statistic Cnde-
ﬁned in (4.1), k=0.5, and h=3.502 to detect a potential upward mean shift.
Does your CUSUM chart give any signal? If yes, provide estimates of the
shift location and shift size?
(ii) Use the CUSUM chart (4.7)–(4.8) to detect a potential upward mean shift.
Compare the results with those in part (i).
4.3 Show that the CUSUM chart (4.5)–(4.6) and the CUSUM chart (4.7)–(4.8) are
equivalent to each other.
4.4 For the CUSUM chart (4.7)–(4.8), assume that kandhtake several different
pairs of values listed below. Compute the ARL 0values of the chart in these cases
when the IC process distribution is assumed to be N(0,1)using an algorithm
described by the pseudo code given in Subsection 4.2.2. In the algorithm, use
M=105.
(i)k=0.25, h=3.5,
(ii)k=0.25, h=5.5,
(iii) k=0.5,h=3.5.
Based on the computed results, describe your major ﬁndings about the relation-
ship among ARL 0,k, and h.
4.5 For the CUSUM chart (4.7)–(4.8), assume that the IC process distribution is
N(0,1), its ARL 0andktake the values listed below. Search for the values of its
control limit hin these cases, using an algorithm described by the pseudo code
given in Subsection 4.2.2. In the algorithm, use ρ=0.5.
(i)ARL 0=350, k=0.25,
(ii)ARL 0=350, k=0.5,
(iii) ARL 0=550, k=0.5.
Based on the computed results, describe your major ﬁndings about the relation-
ship among ARL 0,k, and h.
4.6 Redo the calculation in Exercise 4.4 using the Rpackagespcor other software
packages that are available to you.
4.7 Redo the calculation in Exercise 4.5 using the Rpackagespcor other software
packages that are available to you.176 UNIV ARIA TE CUSUM CHARTS
4.8 Redo the calculation in Exercise 4.4 using the approximation formula (4.11).
Compare the results here with those obtained in Exercise 4.4.
4.9 Assume that the IC process distribution is N(0,1). Using the relationship be-
tween the ARL 0andARL 1values that is summarized in Subsection 4.2.2 and the
approximation formula (4.11), compute the ARL 1values of the chart (4.7)–(4.8)
with k=0.5 and h=4.095 (note: its ARL 0value is 200 by Table 4.1), in cases
when the process distribution shifts at the initial observation time point to one
of the following six distributions:
(i)N(0.5, 1),
(ii)N(1,1),
(iii) N(−1,1),
(iv) N(0,22),
(v)N(0,0.52),
(vi) N(1,22).
Summarize your results in terms of the relationship between ARL 1and the shift
size in the process mean and/or the shift size in the process variance.
4.10 Using the relationship between ARL 0andARL 1values that is summarized in
Subsection 4.2.2 and the approximation formula (4.11), reproduce the results in
Example 4.4.
4.11 In the two-sided version of the CUSUM chart for detecting arbitrary mean shifts,
assume that we use (k,h)=(0.5, 3.08) in both the upward CUSUM chart (4.7)–
(4.8) and the downward CUSUM chart (4.9)–(4.10).
(i) Compute the ARL 0value of the two-sided CUSUM chart.
(ii) To detect a mean shift of size δ=1.2, what will be the zero-state ARL 1values
of the two-sided CUSUM chart and the two one-sided CUSUM charts?
(iii) To detect a mean shift of size δ=−1.2, what will be the zero-state ARL 1
values of the two-sided CUSUM chart and the two one-sided CUSUM charts?
(iv) Summarize your major ﬁndings from the results in parts (ii) and (iii) regard-
ing the ARL 1values of the three different versions of the CUSUM charting
techniques.
4.12 Assume that process observations follow the AR(1) model (4.15). Use a numer-
ical method to compute the actual ARL 0values of the CUSUM chart (4.7)–(4.8)
with(k,h) = (0.5, 4.095) (note: by Table 4.1, the nominal ARL 0value of the
chart is 370) in cases when φ=−0.5,0, and 0.5, respectively.
4.13 Assume that the IC process distribution is N(0,σ2
0), the process variance
changes to σ2
1after the process becomes OC, and the process mean remains
unchanged. Then, the CUSUM charts (4.21)–(4.22) and (4.23)–(4.24) are opti-
mal for detecting upward and downward variance shifts, respectively. In each of
the following three cases, design an optimal CUSUM chart (i.e., determine the
optimal values of (k+,hU)or(k−,hL)):
(i)σ0=1,σ1=2, and ARL 0=370,
(ii)σ0=1,σ1=0.5, and ARL 0=370,EXERCISES 177
(iii) σ0=0.5,σ1=1, and ARL 0=370.
Note that the hUorhLvalue in each of the three cases can be approximated by a
numerical algorithm.
4.14 The data given in Exercise 3.5 contain 10 samples of size 5 each from a pro-
cess producing bearings. Based on our experience, it is assumed that the IC
process distribution is N(35.5, 1). For this process, we are mainly concerned
about downward variance shifts. Design a CUSUM chart for this purpose with
ARL 0=200 and a target OC variance of σ2
1=0.25. Then, apply the designed
CUSUM chart to the observed data, and summarize your results.
4.15 For a production process, its IC distribution is assumed to be N(1,0.52), and
we are concerned about both upward mean shifts and upward variance shifts.
The sample means and sample standard deviations of 24 independent random
samples of size m=5 each collected at 24 consecutive time points from the
process are listed in the table below. Design a CUSUM joint monitoring scheme
with the target OC mean of µ1=2, the target OC variance of σ2
1=1, and the
ARL 0value of the joint monitoring scheme to be 200. Apply the joint monitoring
scheme to the observed data, and summarize your results.
n 1 2 3 4 5 6 7 8
Xn1.06 0.93 1.08 1.15 1.05 0.82 1.07 1.24
sn0.25 0.32 0.17 0.62 0.36 0.31 0.47 0.27
n 9 10 11 12 13 14 15 16
Xn0.96 1.04 0.76 1.19 2.40 1.99 1.56 1.63
sn0.60 0.67 0.82 0.71 1.23 0.49 1.47 1.21
n 17 18 19 20 21 22 23 24
Xn1.66 2.50 1.66 1.93 1.99 1.92 1.61 2.44
sn1.25 0.79 1.02 1.55 1.12 0.78 0.68 0.84
4.16 The exponential distribution with a rate parameter λ>0, denoted as
Exponential (λ), has a pdf with the following expression:
f(x;λ)=λe−λx, forx≥0.
In Subsection 4.4.1, it is pointed out that this distribution is equivalent to the
Γ(1, 1/λ)distribution. It is also equivalent to the Weibull(1/λ,1)distribution.
In Subsection 4.4.1, we have derived optimal CUSUM charts for detecting shifts
inβof the Γ(α,β)distribution and shifts in aof the Weibull(a,b)distribu-
tion in cases when observations of a production process follow one of these
two distributions. Therefore, if observations of a production process follow the
Exponential (λ)distribution and we are interested in detecting an upward shift
inλ, then the optimal CUSUM chart can be derived using either the connection
between the exponential and Gamma distributions or the connection between the
exponential and Weibull distributions. Show that the resulting CUSUM charts by
the two approaches are actually the same.178 UNIV ARIA TE CUSUM CHARTS
4.17 A distribution is called a log-normal distribution if it has a pdf with the following
expression:
f(x;µ,σ)=1
xσ√
2πe−[log(x)−µ]2
2σ2, forx>0,
where µandσare two parameters. If a random variable Xhas the above log-
normal distribution, denoted as X∼LN(µ,σ2), then log(X )has the N(µ,σ2)
distribution. The log-normal distribution is often appropriate for describing the
distribution of a variable that is a multiplicative product of many independent
and positive random variables. For a production process, assume that its obser-
vations follow the LN(µ0,σ2
0)distribution when it is IC.
(i) Derive an optimal CUSUM chart for detecting an upward shift in µ, from µ0
toµ1with µ1>µ0, while the other parameter stays unchanged.
(ii) Derive an optimal CUSUM chart for detecting a downward shift in σ2, from
σ2
0toσ2
1with σ2
1<σ2
0, while the other parameter stays unchanged.
4.18 To control the proportion of non-conforming products manufactured by a pro-
duction process, 20 samples of size m=100 each are obtained. The numbers of
nonconforming products in the 20 samples are listed below.
10,15,31,18,24,12,23,15,19,21,16,24,28,15,23,19,14,27,20,18
When the process is IC, it is known that the true proportion of non-conforming
products is π=0.19.
(i) Design an optimal CUSUM chart for detecting an upward shift in πfrom
0.19 to 0.29, with the ARL 0value to be the smallest achievable one that is
bigger than or equal to 370.
(i) The data considered here are also considered in Exercise 3.11, where a p
chart is used for a similar purpose. Compare the two charting techniques, and
discuss their strengths and limitations.
4.19 A faculty member in a university usually receives an average of 10 junk emails
per day. He complains that this rate has doubled recently. To support his com-
plaint, the numbers of junk emails that he received in the past 30 days were
recorded as follows.
14,10,6,10,9,7,17,9,13,10,22,21,15,25,27,
26,20,26,26,17,23,16,18,22,15,23,19,15,18,13
Design a CUSUM chart to detect an upward shift in the average number of
junk emails received by this faculty member, using an ARL 0value around 200.
Summarize your ﬁndings after applying the CUSUM chart to the observed data.
4.20 The IC distribution of a production process is assumed to be N(µ0,σ2
0). Because
both µ0andσ0are unknown, an IC dataset has been collected in the phase I
SPC. The estimates of µ0andσ0from the IC data are 11.5 and 1.5, respectively.
Then, these values are regarded as the true values of µ0andσ0, and they areEXERCISES 179
used for standardizing the phase II observations for online process monitoring.
The CUSUM chart (4.46)–(4.47) with (k+,h+) = (0.5, 3.502) is then used for
detecting an upward mean shift, with a nominal ARL 0value of 200. We know
that the estimates of µ0andσ0from the IC data would not equal the true values
ofµ0andσ0due to the randomness involved in the observed IC data. Conse-
quently, the actual ARL 0value of the chart (4.46)–(4.47) would be different from
the nominal value of 200. Compute the actual ARL 0values of the chart in cases
when µ0andσ0take the following true values:
(i)µ0=10 and σ0=1.0,
(ii)µ0=10 and σ0=1.5,
(iii) µ0=11.5 and σ0=1.0,
(iv) µ0=13 and σ0=2.0.
Summarize your major ﬁndings from the computed actual ARL 0values.
4.21 Observations from a production process are believed to follow a normal distri-
bution when it is IC. But, the IC mean and variance are unknown. For online
monitoring, the process has been adjusted properly in the phase I analysis, and
10 IC observations have been collected at the end of the phase I analysis. These
10 observations along with 20 phase II observations are listed below. Use the
self-starting CUSUM chart (4.49) with (k,h)=(0.5, 3.502) to monitor the pro-
cess. Summarize your results.
8.9, 9.4, 10.8, 8.5, 9.3, 8.2, 9.2, 10.9, 8.5, 7.9
10.0, 12.0, 9.1, 8.3, 11.6, 9.8, 9.9, 12.6, 11.0, 8.8
13.8, 14.4, 12.4, 17.0, 14.2, 15.1, 12.3, 16.6, 14.1, 16.4
4.22 For the production process discussed in Exercise 4.21, assume that the IC dis-
tribution is N(10,1.52). Use the adaptive CUSUM chart (4.51)–(4.54) with
ARL 0=200 to monitor the 30 observations listed in that exercise. In (4.51) and
(4.52), you need to replace Xnby the standardized observations (Xn−10)/1.5.
Also, you need to specify δminandλin (4.52). Try the following three sets of
values for δminandλ, and summarize the major differences among the three sets
of results:
(i)δmin=0 and λ=0.1,
(ii)δmin=0 and λ=0.5,
(iii) δmin=2.0 and λ=0.1.Chapter 5
Univ ariate EWMA Charts
5.1 Introduction
In Section 4.1, we have explained that Shewhart charts are not effective for detecting
small and persistent shifts because they evaluate the process performance based on
observed data at a single time point alone. To overcome this limitation, the CUSUM
charts described in the previous chapter try to make use of all observed data available
at the current time point, including those observed at the current time point and all
historical data that are observed before the current time point, to evaluate the process
performance. One major feature of the CUSUM charts is their re-starting mechanism,
which is that their charting statistics reset to the initial state every time when evidence
of a shift in the observed data is smaller than a threshold. As it has been described in
Subsection 4.2.4, they have certain optimality properties under some regularity con-
ditions. However, they are relatively complicated to construct and use. Is there a more
convenient way to construct control charts that have similar performance? Roberts
(1959) provided an answer to this question by proposing the so-called exponentially
weighted moving average (EWMA) control chart. This chart is constructed based on
a weighted average of all observed data available at the current time point. Thus, it
is easy to perceive. In the literature, there has been an extensive discussion about
its design, implementation, and properties. See, for instance, Capizzi and Masarotto
(2003), Crowder (1987a,b, 1989), Gan (1995), Han and Tsung (2004), Knoth (2007),
Lucas and Saccucci (1990), and Reynolds and Stoumbos (2005, 2006), among many
others. From all these discussions, it can be seen that the EWMA charts have similar
performance to the CUSUM charts.
In this chapter, we describe some major EWMA charts for detecting mean and/or
variance shifts of univariate processes. Our discussion will mainly focus on the case
when the IC and OC process distributions are normal, although cases with several
major non-normal parametric distributions will also be brieﬂy discussed in Section
5.5. Process monitoring by EWMA charts in cases when the processes are multivari-
ate will be discussed in Chapter 7. Cases when the process distribution is nonpara-
metric will be discussed in Chapters 8 and 9. Also, similar to the CUSUM charts,
the EWMA charts are mainly for phase II SPC, because their major strength is in ef-
fectively detecting small and persistent shifts. It will be more economic to use them
with individual observation data as well, although they can easily be applied to batch
data.
181182 UNIV ARIA TE EWMA CHARTS
5.2 Monitoring the Mean of a Normal Process
In this section, we discuss the basic idea of the EWMA charting technique, and the
design and implementation of an EWMA control chart, in cases when the quality
characteristic of interest Xis univariate, its IC distribution is N(µ0,σ2), and the po-
tential shift in its distribution is in the mean of Xonly. Our discussion is divided
into three parts. In Subsection 5.2.1, formulation, design, and implementation of an
EWMA control chart for detecting mean shifts of normal processes is discussed in
the conventional case when observations at different time points are independent.
The case when the observations at different time points are correlated is discussed
in Subsection 5.2.2. Finally, comparison between the CUSUM and EWMA control
charts is discussed in Subsection 5.2.3.
5.2.1 Design and implementation of the EWMA chart
Assume that {X1,X2,...} are independent observations obtained from a univariate
process at consecutive time points for phase II SPC. They have a common IC distri-
bution N(µ0,σ2)when the process is IC, and their distribution changes to N(µ1,σ2)
after the process becomes OC, where µ0/ne}ationslash=µ1are the IC and OC process means.
To detect the mean shift from µ0toµ1, the CUSUM chart uses the cumulative sum
Cn=∑n
i=1(Xi−µ0). From (4.2) and (4.3), it can be seen that, when the mean shift
occurs at 1 ≤τ≤n, the mean of Cnwould increase linearly with n. So would the
variance of Cn. Therefore, Cncarries useful information about the mean shift; but,
the increasing variance makes it difﬁcult to detect the mean shift based on Cndi-
rectly. To overcome this difﬁculty, the CUSUM chart uses the V-masks to detect the
mean shift in its V-mask form (cf., Figure 4.3(b)), or the re-starting mechanism in its
DI form (cf., (4.7)). The re-starting mechanism makes the variance of the resulting
charting statistic C+
ndeﬁned in (4.7) stable when the process is IC, because the IC
distribution of C+
nconverges to its steady-state distribution when nincreases. See
Subsection 4.2.2 for a related discussion. Is there an alternative charting statistic that
makes use of all observed data, contains useful information about the mean shift, and
has a stable variance when nincreases? Roberts (1959) gave a positive answer to this
question with the following charting statistic: for n≥1,
En=λXn+(1−λ)En−1, (5.1)
where E0=µ0, and λ∈(0,1]is a weighting parameter. Obviously, the charting
statistic Enin (5.1) is a weighted average of the observation Xnat the current time
point and the charting statistic at the previous time point, and the weight is controlled
by the parameter λ.
From (5.1), it is easy to see that
En=λXn+λ(1−λ)Xn−1+···+λ(1−λ)n−1X1+(1−λ)nµ0
=λn
∑
i=1(1−λ)n−iXi+(1−λ)nµ0.MONITORING THE MEAN OF A NORMAL PROCESS 183
Further, we can check that
λn
∑
i=1(1−λ)n−i+(1−λ)n=1.
Therefore, Enis a weighted average of µ0and all available observations
{Xn,Xn−1,..., X1}up to the time point n, and the weight λ(1−λ)n−ireceived by
thei-th observation decays exponentially when imoves away from n. That is the rea-
son the control chart based on Enis called the EWMA chart. From (5.1), we can see
that if λis chosen to be larger, then more weight is assigned to the current observa-
tionXnand less weight is assigned to its previous observations. On the other hand, if
λis chosen to be smaller, then less weight is assigned to the current observation Xn
and more weights are assigned to its previous observations. In the special case when
λ=1,En=Xn. In such cases, the control chart based on Enis just a Shewhart chart.
In cases when the process is IC up to the time point n, we can check that
µEn=µ0,
and
σ2
En=λ
2−λ/bracketleftbig
1−(1−λ)2n/bracketrightbig
σ2. (5.2)
Therefore, in such cases,
En∼N/parenleftbigg
µ0,λ
2−λ/bracketleftbig
1−(1−λ)2n/bracketrightbig
σ2/parenrightbigg
. (5.3)
In cases when the process has a mean shift from µ0toµ1at the time point 1 ≤τ≤n,
the variance of Enis still the one in (5.2), but its mean becomes
µEn,τ= (1−λ)n−τ+1µ0+/bracketleftbig
1−(1−λ)n−τ+1/bracketrightbig
µ1
=µ0+/bracketleftbig
1−(1−λ)n−τ+1/bracketrightbig
(µ1−µ0). (5.4)
From (5.4), we can see that the OC mean of Enis a weighted average of µ0and
µ1, and the weight of µ1is larger when nis larger. Therefore, the statistic Enindeed
contains useful information about the mean shift. On the other hand, from (5.2), it
can be seen that the variance of Enconverges to
/tildewideσ2
0,λ=λ
2−λσ2. (5.5)
In cases when σ2=1,λ=0.05, 0.1, or 0.2, and nchanges from 1 to 30, the values
ofσ2
Enare shown in Figure 5.1. From the plot, we can see that σ2
Enis small when
nis small, and it converges to /tildewideσ2
0,λquickly, especially when λis relatively large.
Ifλ=0.05, which is regarded as small, then σ2
Enis close to/tildewideσ2
0,λwhen n≥20. If
λ=0.2, which is regarded as relatively large, σ2
Enis already very close to /tildewideσ2
0,λwhen
n≥10. Therefore, the variability of the statistic Enis stable when nis medium to
large.184 UNIV ARIA TE EWMA CHARTS
0 5 10 15 20 25 30
nσEn2
0.00 0.04 0.08 0.12lambda=0.2
lambda=0.1
lambda=0.05
Figure 5.1 Values of σ2
Enin cases when σ2=1,λ=0.05,0.1, or 0.2, and n changes from 1
to 30.
From the above discussion, we can see that the statistic Enmakes use of all avail-
able observations up to the current time point n, it contains useful information about
the mean shift, and its variance is stable. Therefore, it should be a reasonable charting
statistic for detecting the mean shift. Based on its IC distribution given in (5.3), the
resulting EWMA control chart for detecting an arbitrary mean shift is summarized
in the box below.
Control Limits of the EWMA Chart for Detecting a Mean Shift
U=µ0+ρ/radicalbigg
λ
2−λ[1−(1−λ)2n]σ
C=µ0 (5.6)
L=µ0−ρ/radicalbigg
λ
2−λ[1−(1−λ)2n]σ,
where ρ>0 is a parameter.
More speciﬁcally, the EWMA chart deﬁned by (5.1) and (5.6) has a center line
C,an upper control limit U, and a lower control limit L. To use this chart, at theMONITORING THE MEAN OF A NORMAL PROCESS 185
time point n, we compare the charting statistic Enwith the two control limits. If En
is within the interval [L,U], then we conclude that the process is IC up to the time
point n. Otherwise, a signal of mean shift is given.
Example 5.1 Assume that the IC distribution of a univariate production process is
N(10,22), and the ﬁrst 30 observations obtained at the ﬁrst 30 consecutive time
points are listed below.
6.15, 11.36, 10.66, 9.16, 11.26, 7.45, 10.20, 13.20, 6.74, 11.19,
9.63, 5.43, 10.20, 8.60, 10.22, 14.36, 10.85, 13.70, 10.67, 14.40,
17.80, 12.22, 12.29, 12.72, 11.85, 12.91, 11.65, 14.17, 11.99, 12.48
In the EWMA chart deﬁned by (5.1) and (5.6), assume that we choose λ=0.1and
ρ=2.703. Then, its charting statistic E nand the control limits are shown in Figure
5.2. From the plot, the chart gives a signal of mean shift at the 21st time point.
0 5 10 15 20 25 308 9 10 11 12
nEn
Figure 5.2 The EWMA chart with λ=0.1andρ=2.703(black dots connected by a solid
line) when it is applied to the data in Example 5.1. The two dashed lines denote the upper
control limit U and the lower control limit L, and the dotted line denotes the center line C.
In practice, people often use the asymptotic variance of En, i.e.,/tildewideσ2
0,λgiven in
(5.5), to construct the EWMA chart. In such cases, its control limits become
U=µ0+ρ/radicalbigg
λ
2−λσ
C=µ0 (5.7)
L=µ0−ρ/radicalbigg
λ
2−λσ.186 UNIV ARIA TE EWMA CHARTS
It can be seen that both UandLin (5.7) are constants. Therefore, the resulting control
chart would be easier to use, and its properties would also be easier to study. Because
σ2
Enconverges to/tildewideσ2
0,λquickly for a given λvalue, as demonstrated by Figure 5.1, the
two versions of the EWMA chart would have similar performance, as long as the po-
tential mean shift does not occur very early in the process monitoring. For simplicity,
most software packages, including those used in this chapter, use the simpler control
limits deﬁned in (5.7). For applications, we recommend using the ones deﬁned in
(5.6) because they could give slightly more reliable results, although the chart would
be a little more complicated to use.
The EWMA chart deﬁned by (5.1) and (5.6) is a two-sided control chart for de-
tecting an arbitrary mean shift. If we are interested in detecting upward mean shifts
only in a given application, then we can just use the upper control limit Uand the
resulting upward EWMA chart gives a signal at the n-th time point if En>U. Simi-
larly, if we are interested in detecting downward mean shifts only, then we can con-
sider using a downward EWMA chart which gives a signal at the n-th time point if
En<L. For constructing the upward or downward EWMA chart, we can also adopt
the re-starting mechanism of the CUSUM charts. To detect upward mean shifts, the
charting statistic of the upward EWMA chart with the re-starting mechanism can be
deﬁned by
E+
n=max/parenleftbig
0,λ(Xn−µ0)+(1−λ)E+
n−1/parenrightbig
, (5.8)
where E+
0=0, and the chart gives a signal of upward mean shift when
E+
n>ρU/radicalbigg
λ
2−λσ, (5.9)
where ρU>0 is a parameter chosen to achieve a pre-speciﬁed ARL 0value. Similarly,
the charting statistic of the downward EWMA chart with the re-starting mechanism
is deﬁned by
E−
n=min/parenleftbig
0,λ(Xn−µ0)+(1−λ)E−
n−1/parenrightbig
, (5.10)
where E−
0=0, and a signal of downward mean shift is given when
E−
n<−ρL/radicalbigg
λ
2−λσ, (5.11)
where ρL>0 is a parameter chosen to achieve a given ARL 0value.
In the above discussion, we assume that the observed data are single observation
data. In some applications, if a random sample of size mis collected at each time
point, then the EWMA chart deﬁned in (5.1) and (5.6) can still be used, after Xnin
(5.1) is replaced by the mean X(n)of the sample collected at the n-th time point
andσin (5.6) is replaced by σ/√m. The one-sided EWMA charts deﬁned by (5.8)–
(5.11) can be modiﬁed in a similar way, by replacing Xn−µ0in (5.8) and (5.10) by
X(n)−µ0and replacing σin (5.9) and (5.11) by σ/√m.
Next, we discuss the design of the two-sided EWMA chart deﬁned by (5.1) and
(5.7). The design of the one-sided EWMA charts can be discussed similarly. From
the construction of the two-sided EWMA chart, its performance would depend on theMONITORING THE MEAN OF A NORMAL PROCESS 187
values of the two parameters λandρ. In cases when the IC process distribution is
N(0,1),λ=0.05, 0.1,0.2,or 0.3, and ρchanges from 1.0 to 3.0 with a step of 0.5, its
zero-state ARL 0values computed using the function xewma.arl() in theR-package
spcthat is described in the appendix are presented in Figure 5.3. From the plot, it
can be seen that the ARL 0value of the EWMA chart increases when ρincreases, and
decreases when λincreases.
1.0 1.5 2.0 2.5 3.0
ρARL 0
0 5 15 50 200 1000lambda=0.05
lambda=0.1
lambda=0.2
lambda=0.3
Figure 5.3 ARL 0values of the EWMA chart deﬁned by (5.1) and (5.7) in cases when the IC
process distribution is N (0,1),λ=0.05,0.1,0.2,or0.3, and ρchanges from 1.0 to 3.0 with
a step of 0.5.
For the two-sided EWMA chart, the λvalue is usually speciﬁed beforehand, and
the value of ρis then determined to reach a pre-speciﬁed ARL 0value. For some
commonly used ARL 0andλvalues, the corresponding ρvalues computed by the
functionxewma.crit() in theR-package spcare presented in Table 5.1. From the
table, it can be seen that a larger ρshould be chosen if ARL 0orλis larger.
It should be pointed out that Monte Carlo simulations by computer algorithms
similar to those described by the pseudo codes given in Subsection 4.2.2 can also
be used to compute the ARL 0value of the EWMA chart when λandρare given,
or to search for the value of ρwhen ARL 0andλare given. As a matter of fact,
with various powerful computing facilities available nowadays, this might be a better188 UNIV ARIA TE EWMA CHARTS
Table 5.1 Computed ρvalues of the EWMA chart deﬁned by (5.1) and (5.7) for some com-
monly used ARL 0andλvalues.
λ
ARL 0 0.01 0.05 0.1 0.2 0.3 0.4 0.5 0.75
50 0.845 1.520 1.811 2.054 2.166 2.229 2.268 2.315
100 1.152 1.879 2.148 2.360 2.453 2.504 2.534 2.568
200 1.500 2.216 2.454 2.635 2.713 2.754 2.777 2.802
300 1.710 2.399 2.619 2.785 2.854 2.890 2.911 2.931
370 1.819 2.490 2.701 2.859 2.925 2.959 2.978 2.996
400 1.859 2.523 2.731 2.886 2.950 2.984 3.002 3.020
500 1.973 2.615 2.814 2.962 3.023 3.054 3.071 3.087
1000 2.308 2.884 3.059 3.187 3.238 3.263 3.277 3.289
approach to use, as long as it properly simulates the scenario in question, because it
often gives more accurate results and is more ﬂexible for handling different scenarios.
Functions in spcand other R-packages are convenient to use, but they usually make
the computation using numerical approximations offered by the Markov chain, inte-
gral equations, and other theoretical approaches that have various model assumptions
(cf., Section 4.6 and Section 5.6 for a related discussion). Besides the approximation
error, their results may not be reliable when their model assumptions are violated.
Therefore, we should use them with care.
To study the impact of the λvalue on the performance of the EWMA chart,
let us consider cases when the IC process distribution is N(0,1),ARL 0=200, λ=
0.05, 0.1,or 0.2, and the shift size δ=µ1−µ0changes from 0 to 2.0 with a step of
0.1. By Table 5.1, the ρvalues should be 2.216, 2.454, and 2.635, respectively. The
computed ARL 1values of the EWMA chart are presented in Figure 5.4. From the
plot, it can be seen that the chart with λ=0.05 performs the best for detecting small
mean shifts (e.g., shifts with δsmaller than 0.5), the chart with λ=0.1 performs the
best for detecting medium mean shifts (e.g., shifts with δbetween 0.6 and 0.8), and
the chart with λ=0.2 performs the best for detecting large mean shifts (e.g., shifts
with δlarger than 1.0). Therefore, a relatively large λshould be chosen for detecting
large shifts, and a relatively small λshould be chosen for detecting small shifts.
To use the EWMA chart in practice, we need to choose the ARL 0andλvalues
properly beforehand and then search for the value of ρsuch that the pre-speciﬁed
ARL 0value is reached. As mentioned in Subsection 4.4.2, the value of ARL 0is often
chosen to be the minimum tolerable ARL 0. Some economic considerations, includ-
ing the cost related to a false alarm and the resulting process downtime, are often
associated with this decision. To choose the value of λproperly, we need to specify
a target shift size ﬁrst. To this end, some practical guidelines have been described in
the paragraph immediately below Figure 4.5 in Subsection 4.2.2. After a target shift
size is chosen, we can search for a λvalue and the corresponding ρvalue such that
the pre-speciﬁed ARL 0value is reached while the ARL 1value for detecting the target
shift is minimized. This and the other practical guidelines on choosing λare sum-MONITORING THE MEAN OF A NORMAL PROCESS 189
0.0 0.5 1.0 1.5 2.0
δARL 1
0 5 15 50 200lambda=0.05
lambda=0.1
lambda=0.2
Figure 5.4 ARL 1values of the EWMA chart deﬁned by (5.1) and (5.7) in cases when the IC
process distribution is N (0,1), ARL 0=200, λ=0.05,0.1,or0.2, and the shift size δchanges
from 0 to 2.0 with a step of 0.1.
marized in the box below. For a more detailed discussion on this issue, see Crowder
(1989).
General Guidelines for Selecting λ
For the EWMA chart deﬁned in (5.1) and (5.7) (or (5.6)), small λvalues are
good for detecting relatively small mean shifts, and large λvalues are good for
detecting relatively large mean shifts. For a given target shift, λcan be chosen
such that the ARL 1value for detecting the target shift is minimized.
In the above discussion, we assume that the process distribution is normal. In
the literature, some researchers have demonstrated that the EWMA chart is actually
quite robust to the normality assumption (e.g., Borror et al., 1999). To see this, let us
consider the following example.
Example 5.2 The IC distribution of a production process is assumed to be N (0,1),
but it is actually the standardized version with mean 0 and variance 1 of the χ2
df
distribution, where d f is its degrees of freedom. Therefore, the actual IC process
distribution is skewed to the right, and it is closer to the N (0,1)distribution when d f
gets larger. The EWMA chart deﬁned by (5.1) and (5.7) is then applied to the process.190 UNIV ARIA TE EWMA CHARTS
The parameters (λ,ρ)are chosen to be (0.05, 2.216),(0.1, 2.454), or (0.2, 2.635).
By Table 5.1, the nominal ARL 0values of the chart are 200 in all three cases if the
IC process distribution is N (0,1). The actual ARL 0values of the chart are computed
by a computer algorithm written by the author in cases when d f changes from 1 to
10, and they are shown in Figure 5.5.
2 4 6 8 10
dfARL 0
100 150 200 250lambda=0.05
lambda=0.1
lambda=0.2
Figure 5.5 Actual ARL 0values of the EWMA chart deﬁned by (5.1) and (5.7) in cases when
the actual IC process distribution is the standardized version with mean 0 and variance 1
of the χ2
dfdistribution, where d f changes from 1 to 10. In the EWMA chart, the parameters
(λ,ρ)are chosen to be (0.05,2.216),(0.1,2.454), or(0.2,2.635) (so that the nominal ARL 0
values of the chart are 200 in all three cases when the IC process distribution is N (0,1)), and
the corresponding results are shown by the solid, dashed, and dotted curves, respectively. The
dot-dashed horizontal line denotes the nominal ARL 0value.
From Figure 5.5, it can be seen that the actual ARL 0values of the EWMA chart
are quite different from the nominal ARL 0value of 200 in cases when λ=0.2 and
when df is quite small (i.e., the actual IC process distribution is quite skewed). Such a
difference gets smaller when λis chosen smaller, which can be explained intuitively
as follows. As pointed out earlier, when λis chosen smaller, the charting statistic En
would get more previous observations of Xninvolved in a substantial way. Therefore,
by the central limit theorem, the distribution of Enwould be closer to normal. Based
on this result, many people believe that the EWMA chart is robust to the normality
assumption, as long as a small λis chosen.
We would like to remind readers that the robustness property of the EWMA chart
should be used with care, for the following two major reasons. First, from the numer-MONITORING THE MEAN OF A NORMAL PROCESS 191
ical results presented in Example 5.2 and in Borror et al. (1999) and other research
papers, it seems that it depends on the magnitude of the difference between the ac-
tual IC process distribution and a normal distribution to decide how small the λvalue
should be chosen in order to have the robustness property. In many applications, it
is difﬁcult to measure such a difference. Second, if a small λis chosen in order to
keep the actual ARL 0value of the EWMA chart close to the nominal ARL 0value in
many different cases, then the resulting chart would be ineffective for detecting rela-
tively large shifts. For instance, Borror et al. (1999) suggested choosing λ=0.05 to
have the robustness property. In such cases, Figure 5.4 shows that the corresponding
EWMA chart would be ineffective in detecting mean shifts that are larger than 1.0 σ.
In cases when the actual IC process distribution is non-normal, we suggest using the
nonparametric (or distribution-free) control charts that will be discussed in Chapter
8, unless it is known beforehand that the IC process distribution is quite close to
normal.
5.2.2 Cases with correlated observations
As discussed in Sections 3.5 and 4.2, possible correlation among observations col-
lected at different time points could affect the actual IC and OC performance of the
Shewhart and CUSUM charts. In this subsection, we discuss the impact of the pos-
sible correlation among observations on the EWMA charts. To this end, let us ﬁrst
discuss the example below.
Example 5.3 As in Example 4.5, assume that process observations follow the AR(1)
model
Xn=µ0+φ(Xn−1−µ0)+en, for n≥1,
where X 0=µ0,µ0=0is the IC process mean, φis the model coefﬁcient, and
{en,n≥1}are white noise with σe=1(i.e., they are i.i.d. with the common dis-
tribution N (0,1)). In such cases, the correlation coefﬁcient between X nand X n−j
isφj, for j=1,2,..., n−1. To monitor the process, the EWMA chart deﬁned by
(5.1) and (5.7) is used, in which (λ,ρ)are chosen to be (0.05, 2.216),(0.1, 2.454),
or(0.2, 2.635). By Table 5.1, the ARL 0value of the chart in all three cases is 200
when φ=0(i.e., when process observations are i.i.d. with the common distribution
N(0,1)). In cases when φ=−0.5,−0.25,−0.1,0,0.1,0.25, and 0.5, the actual ARL 0
values of the chart are presented in the left part of Table 5.2. From the table, it can
be seen that they are quite different from each other within each column of the table.
Therefore, different correlation among observed data has a substantially different
impact on the IC performance of the EWMA chart. By comparing the actual ARL 0
values presented in columns 2–4 of the table, it seems that the impact of the corre-
lation among observed data is less serious when λis chosen smaller. In Example
5.2, we have shown that the EWMA chart is more robust to the normality assump-
tion in such cases. This example shows that the EWMA chart is more robust to the
independence assumption as well when λis chosen smaller.
To investigate the possible impact of the correlation among process observations
on the OC performance of the EWMA chart deﬁned by (5.1) and (5.7), we consider
the case when a mean shift of size δ=0.5occurs at the initial observation time and
all other setups remain unchanged from those described in the previous paragraph.192 UNIV ARIA TE EWMA CHARTS
Table 5.2 The left part presents the actual ARL 0values of the EWMA chart deﬁned by (5.1)
and (5.7) when (λ,ρ)are chosen to be (0.05,2.216),(0.1,2.454), or(0.2,2.635) (so that its
nominal ARL 0value is 200 in all three cases) and when the process observations are corre-
lated and follow the AR(1) model with the coefﬁcient φ. The right part presents the actual
ARL 1values of the chart when a mean shift of size δ=0.5occurs at the initial observation
time in various cases considered.
δ=0 δ=0.5
φ λ=0.05 λ=0.1 λ=0.2 λ=0.05 λ=0.1 λ=0.2
−0.5 833.919 876.351 856.938 21.862 24.398 35.860
−0.25 532.279 582.474 591.485 22.085 24.013 32.091
−0.1 306.152 320.821 325.913 22.150 23.336 29.099
0 200.594 201.873 199.618 22.181 22.825 27.074
0.1 135.913 127.683 123.492 22.137 22.264 24.980
0.25 77.784 68.757 63.276 21.938 21.305 22.335
0.5 33.729 28.069 25.143 20.218 17.997 17.052
The actual ARL 1values of the chart in various cases are presented in the right half
of Table 5.2. From the table, it can be seen that the correlation among process ob-
servations does have an impact on the OC performance of the chart, and the impact
seems less serious in cases when λis chosen smaller.
Example 5.3 shows that the possible correlation among the observed data at dif-
ferent time points would have a substantial impact on the IC and OC performance of
the EWMA chart deﬁned by (5.1) and (5.7). To accommodate the correlation among
the observed data, in Subsection 4.2.3 we discussed several possible approaches, in-
cluding the one to group consecutive observations into batches and then apply the
conventional control charts to the batch means. All these approaches can also be
considered here. In Subsection 4.2.3, we already pointed out two major limitations
of the grouping approach. One is that the variability of the batch means depends
on how the original observations are correlated, which is hard to know in practice
and which makes the grouping approach impractical. Another limitation is that the
resulting control chart of this approach cannot react to a shift promptly because a
signal of shift can only be delivered after all observations in a group are obtained.
The second limitation is also shared by the alternative approach to use a subset of the
original data in the way that two consecutive observations in the subset are certain
time points apart in the original data. Further, much information in the original data
is ignored by this alternative approach. For these reasons, the grouping approach and
the subset approach are not recommended for practical use.
Another possible approach to accommodate the possible correlation among the
observed data is to describe the association by a time series model, obtain residuals
from the ﬁtted time series model, and then apply the conventional control charts
to the residuals, as discussed in Subsection 4.2.3. A major reasoning behind this
approach is that the residuals are roughly i.i.d. when the original process is IC and
any mean shift in the distribution of the original observations will result in a shift
in the distribution of the residuals (e.g., Alwan and Roberts, 1988; Wardell et al.,
1994; Zhang, 1997). However, some researchers have demonstrated that residuals areMONITORING THE MEAN OF A NORMAL PROCESS 193
actually autocorrelated due to model estimation errors, which can have a substantial
impact on the actual IC ARL value of the residual-based control charts (e.g., Adams
and Tseng, 1998; Apley and Shi, 1999). To overcome this difﬁculty, Apley and Lee
(2003) proposed a procedure to adjust the control limits of a residual-based EWMA
chart properly in cases when an ARMA model (cf., the expression (4.16)) is used for
describing the correlation among the observed data.
Instead of using residual-based EWMA charts in cases when process observa-
tions are correlated, some researchers suggest applying the EWMA charts directly
to the original data, but adjusting their control limits properly to reﬂect the impact
of the correlated observations (e.g., Wardell et al., 1994; Zhang, 1998). Next, we de-
scribe this approach by introducing the method proposed by Zhang (1998). Assume
that when a process is IC, its observations are correlated with a constant mean µ0and
the following stationary covariance function:
ξ(s)= Cov(X n,Xn−s)=E[(Xn−µ0)(Xn−s−µ0)].
Note that ξ(s)does not depend on n. Therefore, the correlation between XnandXn−s
depends only on how many time points are between them. It is easy to check that the
AR(1) model (4.15) when |φ|<1 has this property. Let
η(s)=ξ(s)
ξ(0)=Cov(Xn,Xn−s)/radicalbig
Var(X n)Var(X n−s)
be the correlation function. Then, it is not difﬁcult to check that the variance of the
EWMA charting statistic Enhas the expression
σ2
En=λ
2−λ/braceleftigg
1−(1−λ)2n+2n−1
∑
i=1η(i)(1−λ)i/bracketleftig
1−(1−λ)2(n−i)/bracketrightig/bracerightigg
ξ(0),
which converges to a positive constant when nincreases. Therefore, in practice, it
can be approximated by
σ2
En,M=λ
2−λ/braceleftigg
1+2M
∑
i=1η(i)(1−λ)i/bracketleftig
1−(1−λ)2(M−i)/bracketrightig/bracerightigg
ξ(0),
where M>0 is an integer number. Then, the lower and upper control limits of the
EWMA chart can be adjusted respectively to
µ0−ρσEn,M, µ0+ρσEn,M.
In practice, the correlation function η(s)needs to be estimated from an IC dataset of
sizeN. Zhang pointed out that Nshould be at least 50 to make the estimator of η(s)
reliable and Mshould be chosen near the upper end in the range [1,N/4].
5.2.3 Comparison with CUSUM charts
As discussed earlier, both the CUSUM and EWMA charts are proposed as alterna-
tives to the Shewhart charts for detecting small and persistent distributional shifts of194 UNIV ARIA TE EWMA CHARTS
a production process. In this subsection, we brieﬂy summarize the major properties
of the two types of control charts and make a comparison between them as well. For
simplicity, our discussion will focus on the case when the process distribution is nor-
mal and we are interested in detecting process mean shifts, although the discussion in
some other cases can be made in a similar way. Also, the CUSUM chart (4.7)–(4.8)
and the EWMA chart deﬁned by (5.1) and (5.7) are used as representatives of the two
types of control charts in some of our discussion here for convenience. Most state-
ments in this subsection should also be appropriate for other CUSUM and EWMA
charts.
First, both the CUSUM and EWMA charts are mainly for phase II process mon-
itoring, although they can also be used for phase I analysis. That is mainly because
both types of control charts are good for detecting small and persistent shifts and
detection of such shifts is our major concern in phase II process monitoring. As a
comparison, in phase I analysis, shifts can be relatively large and transient. In such
cases, the Shewhart charts are often preferred.
Second, both the CUSUM and EWMA charts are mainly for monitoring pro-
cesses with individual observation data, although they can both be easily applied to
cases with batch data. The main reason why individual observation data are preferred
when using the CUSUM or EWMA charts, compared to batch data, is that less ob-
servations will be required to detect a given shift if individual observation data are
used. To demonstrate this, let us consider the next example.
Example 5.4 Assume that 50 observations are generated from the N (0,1)distri-
bution, and another 50 observations are generated from the N (0.5, 1)distribution.
These observations can be regarded as observed data collected at 100 consecutive
time points from a production process, the IC distribution is N (0,1), and the process
becomes OC at the 51st time point with the OC distribution N (0.5, 1). Let us ﬁrst
use the upward CUSUM chart (4.7)–(4.8) to monitor the process. In the chart, (k,h)
are chosen to be (0.25, 5.597) so that its ARL 0value is 200. The chart is presented
in Figure 5.6(a), from which we can see that a signal is ﬁrst given at the 64th time
point. Now, let us treat the ﬁrst 50 observations as 10 samples of size 5 each, and
the last 50 observations as another 10 samples of size 5 each. Then, these 20 sam-
ples can be regarded as observed batch data at 20 consecutive time points from a
production process whose IC distribution is N (0,1). This process becomes OC at the
11th time point with the OC distribution N (0.5, 1). We then compute the 20 stan-
dardized sample means (i.e., each sample mean is standardized by dividing it by its
standard deviation 1/√
5). The same CUSUM chart mentioned above is applied to
these standar dized sample means, and the chart is presented in Figure 5.6(b). From
the plot, a signal is ﬁrst given at the 18th time point. By comparing the two differ-
ent sampling schemes, the CUSUM chart with the ﬁrst sampling scheme requires 14
extra observations to give a signal that an upward mean shift of size 0.5 occurred
at the 51st time point. With the second sampling scheme, the CUSUM chart requires
8∗5=40extra observations to give a signal of the shift. Therefore, fewer extra ob-
servations are needed for the chart to give a signal in the case with the individual
observation data. With the two sampling schemes described above, we also apply
the EWMA chart deﬁned by (5.1) and (5.7) with (λ,ρ)=(0.1, 2.454) to the related
data. By Table 5.1, the EWMA chart has an ARL 0value of 200 as well. It is shown
in Figure 5.6(c)–(d) in the two cases considered. We can have similar conclusionsMONITORING THE MEAN OF A NORMAL PROCESS 195
in this scenario regarding the numbers of extra observations needed by the chart to
give a signal of mean shift in cases with the two different sampling schemes.
0 20 40 60 80 1000 2 4 6 8 10 12
nCn+
(a)0 5 10 15 200 2 4 6 8 10 12
nCn+
(b)
0 20 40 60 80 100−1.0 −0.5 0.0 0.5 1.0
nEn
(c)0 5 10 15 20−1.0 −0.5 0.0 0.5 1.0
nEn
(d)
Figure 5.6 (a) Control chart (4.7)–(4.8) with (k,h)=(0. 25,5.597) when it is applied to 100
individual observations collected from a production process that has an upward mean shift of
size 0.5 at the 51st time point. (b) The same chart when it is applied to the standardized sample
means of 20 samples of size 5 each collected from a production process that has an upward
mean shift of size 0.5 at the 11th time point. Plots (c) and (d) are the same as plots (a) and (b),
except that the CUSUM chart is replaced by the EWMA chart deﬁned by (5.1) and (5.7) with
(λ,ρ)=(0. 1,2.454).
Third, the CUSUM chart (4.7)–(4.8) has two parameters kandhinvolved. For
a given target shift of size δ,kis chosen to be δ/2, and his chosen to reach a pre-
speciﬁed ARL 0value. Such a CUSUM chart would have some optimality properties.
See Subsection 4.2.4 for a related discussion. As a comparison, the EWMA chart
deﬁned by (5.1) and (5.7) also has two parameters λandρinvolved. Usually, λis
chosen to be one of several commonly used values, such as 0.05, 0.1, and 0.2, and ρ
is chosen to reach a pre-speciﬁed ARL 0value. With the EWMA chart, we only know196 UNIV ARIA TE EWMA CHARTS
that the chart is good for detecting relatively small shifts when λis chosen small, and
it is good for detecting relatively large shifts when λis chosen large. However, we do
not have an explicit formula about the relationship between λand a target shift size
δunder which the chart would perform optimally, although such a relationship can
be tabulated for certain special cases through Monte Carlo simulations (cf., Crowder,
1989).
Fourth, both the CUSUM chart (4.7)–(4.8) and the EWMA chart deﬁned by (5.1)
and (5.7) try to make a trade-off between the use of all historical data and the elim-
ination of the negative impact of the historical data on the sensitivity of the control
charts to process mean shifts. The CUSUM chart assigns equal weights to all previ-
ous observations when it accumulates all useful information in the historical data, and
eliminates the dampening effect of the historical data by using a re-starting mecha-
nism. As a comparison, the EWMA chart simply uses a weighted average of all
available observations as its charting statistic, and the dampening effect of the histor-
ical data is mostly eliminated by the exponentially decaying weights assigned to the
historical data. Its control limits have a similar form to those of the Shewhart charts.
Therefore, to most users, the EWMA chart is easier to understand and implement.
However, the CUSUM chart has been proven to have some optimality properties, as
discussed in Subsection 4.2.4, and a similar theoretical background of the EWMA
chart is still lacking. In the SPC literature, it has been demonstrated by several au-
thors that the two types of control charts have similar performance (e.g., Lucas and
Saccucci, 1990). To further investigate their relative performance, let us consider the
cases when the IC process distribution is N(0,1), and the process has an upward
mean shift with size δat the initial time point, where δchanges its value from 0.1
to 2.0 with a step of 0.1. The upward CUSUM chart (4.7)–(4.8) and the upward
EWMA chart deﬁned by (5.1) with the upper control limit in (5.7) are considered for
monitoring the process. In the EWMA chart, the optimal λvalue is searched with a
precision of 0.001 for each shift size such that the ARL 1value of the chart reaches
the minimum. Its ρvalue is chosen such that its ARL 0value is 200 in each case.
For the CUSUM chart, the allowance constant kis chosen to be δ/2, and its hvalue
is chosen such that ARL 0=200. All the computation is accomplished by using the
related functions in the R-package spc. The ARL 1values of the two charts and the
corresponding parameter values are presented in Table 5.3. From the table, we can
see that the optimal performance of the two charts is indeed quite similar in the cases
considered.
Finally, we will demonstrate in Chapter 8 that the CUSUM charts are not robust
to the normality assumption. In the literature, people tend to think that the EWMA
charts are robust to the normality assumption because their charting statistics are
weighted averages of the current and all previous observations. As a matter of fact,
the charting statistic Endeﬁned in (5.1) gets many observations involved only when
λis very small. To demonstrate this, let us consider the case when n=100. In such
a case, from the description in Subsection 5.2.1, we know that the i-th observation Xi
receives a weight of
wi=λ(1−λ)n−i
inEn, for i=1,2,..., n. In cases when λ=0.05, 0.1,0.2, and 0.5, these weightsMONITORING THE MEAN OF A NORMAL PROCESS 197
Table 5.3 Optimal ARL 1values and the related parameter values of the upward CUSUM chart
(4.7)–(4.8) and the upward EWMA chart deﬁned by (5.1) with the upper control limit in (5.7)
in cases when the IC process distribution is N (0,1), and the process has an upward mean shift
of size δat the initial time point, where δchanges its value from 0.1 to 2.0 with a step of 0.1.
EWMA CUSUM
δ λ ρ ARL 1 k h ARL 1
0.1 0.009 1.397 92.916 0.05 10.297 92.815
0.2 0.020 1.764 54.303 0.1 8.520 54.063
0.3 0.034 1.991 36.062 0.15 7.262 35.746
0.4 0.051 2.147 25.937 0.2 6.325 25.592
0.5 0.069 2.252 19.694 0.25 5.597 19.343
0.6 0.089 2.332 15.550 0.3 5.015 15.206
0.7 0.111 2.394 12.647 0.35 4.537 12.314
0.8 0.135 2.444 10.526 0.4 4.136 10.207
0.9 0.159 2.482 8.925 0.45 3.796 8.621
1.0 0.185 2.514 7.684 0.5 3.502 7.395
1.1 0.212 2.540 6.701 0.55 3.246 6.426
1.2 0.239 2.560 5.908 0.6 3.020 5.646
1.3 0.267 2.577 5.258 0.65 2.820 5.009
1.4 0.297 2.592 4.718 0.7 2.641 4.481
1.5 0.327 2.603 4.264 0.75 2.481 4.038
1.6 0.358 2.613 3.877 0.8 2.336 3.662
1.7 0.391 2.621 3.545 0.85 2.205 3.340
1.8 0.425 2.627 3.257 0.9 2.085 3.063
1.9 0.460 2.632 3.004 0.95 1.975 2.821
2.0 0.496 2.636 2.781 1.0 1.874 2.610
are shown in Figure 5.7(a)–(d). From plot (d), it can be seen that Enactually only
gets 3 or 4 previous observations substantially involved in the case when λ=0.5.
When λis chosen smaller, it is true that more previous observations are involved
inEn. From plots (a)–(c), it seems that about 40, 20, and 10 previous observations
receive meaningful weights in Enin cases when λ=0.05, 0.1, and 0.2, respectively.
However, the weights received by different previous observations are dramatically
different in their magnitudes, which greatly reduces the effectiveness of the Central
Limit Theorem (cf., Subsection 2.7.1 for a related discussion). Even when all the
weights in a weighted average are the same, a conventional opinion in the statistical
literature is that at least 30 independent observations are needed to make their sim-
ple average to be approximately normally distributed (cf., Peck and Devore, 2012,
Section 8.2). Further, when λis chosen small, as pointed out in Subsection 5.2.1, the
resulting EWMA chart is good for detecting small mean shifts only. For instance,
when λ=0.05, from Table 5.3, the resulting EWMA chart is good for detecting
mean shifts around 0.4, and it will not be good for detecting mean shifts as large as
1. Therefore, we think that the robustness property of the EWMA chart should be
used with care.198 UNIV ARIA TE EWMA CHARTS
0 20 40 60 80 1000.00 0.01 0.02 0.03 0.04 0.05
iwi
(a)0 20 40 60 80 1000.00 0.02 0.04 0.06 0.08 0.10
iwi
(b)
0 20 40 60 80 1000.00 0.05 0.10 0.15 0.20
iwi
(c)0 20 40 60 80 1000.0 0.1 0.2 0.3 0.4 0.5
iwi
(d)
Figure 5.7 The w eights w i=λ(1−λ)n−i, for i=1,2,..., n, received by the i-th observation
Xiin E nwhen n=100, λ=0.05(plot (a)), λ=0.1(plot (b)), λ=0.2(plot (c)), or λ=0.5
(plot (d)).
5.3 Monitoring the Variance of a Normal Process
As discussed in Subsection 4.3.1, process variability is related to the quality of con-
formance of the related production process. Generally speaking, an upward process
variability shift would downgrade the quality of conformance, while a downward
process variability shift would improve the quality of conformance. Therefore, in
practice, we are also interested in detecting shifts in process variability. More specif-
ically, we are mainly concerned about upward process variability shifts in practice.
Downward shifts are of concern only in cases when we want to cut production cost
or we have some other considerations. In this section, we discuss how to detect pro-
cess variability shifts using the EWMA charts. Our discussion is divided into two
parts: Monitoring of the process variability alone is discussed in Subsection 5.3.1,
and joint monitoring of both the process mean and process variability is discussed in
Subsection 5.3.2.MONITORING THE V ARIANCE OF A NORMAL PROCESS 199
5.3.1 Monitoring the process variance
A shift in the process variability would change the distribution of the charting statistic
Enof the EWMA chart deﬁned by (5.1) and (5.7) that is originally designed for
detecting process mean shifts. Therefore, that EWMA chart also has a certain ability
to detect process variance shifts, which can be seen from the example below.
Example 5.5 Let us reconsider the two scenarios discussed in Example 4.8. In the
ﬁrst scenario, 100 observations are generated as follows. The ﬁrst 50 observations
are generated from the N (0,1)distribution, and the second 50 observations are
generated from the N (0,22)distribution. This scenario simulates a production pro-
cess with the IC distribution N (0,1)and it becomes OC with an upward variance
shift from 1 to 22at the 51st time point. The observed data are shown in Figure
5.8(a). Then, we apply the EWMA chart deﬁned by (5.1) and (5.7) with λ=0.2and
ρ=2.635 to the dataset. From Table 5.1, it can be seen that the ARL 0value of the
chart is 200. The EWMA chart is shown in Figure 5.8(b), from which we can see that
its charting statistic E nhas a larger variability after the process variance shift, it
brieﬂy touches the lower control limit at the 25th time point, and gives several quite
convincing signals at a number of time points after the variance shift. In the second
scenario, the ﬁrst 50 observations are still generated from the N (0,1)distribution,
but the remaining 50 observations are generated from the N (0,0.52)distribution.
This scenario simulates a production process with the IC distribution N (0,1)that
becomes OC with a downward variance shift from 1 to 0.52at the 51st time point.
The data are shown in Figure 5.8(c), and the EWMA chart with the same setup as
that in Figure 5.8(b) when it is applied to the data here is shown in Figure 5.8(d). It
can be seen from the plot that a downward variance shift would decrease the vari-
ability of the charting statistic E nand thus it cannot be detected by the EWMA chart
designed for detecting mean shifts.
Although the EWMA chart deﬁned by (5.1) and (5.7) that is designed for de-
tecting process mean shifts has certain power for detecting process variance shifts, it
may not be efﬁcient for that purpose, as demonstrated in Subsection 4.3.2 with the
CUSUM chart (4.7)–(4.8). In cases when the IC process distribution is N(µ0,σ2
0)
and one observation is collected at each time point (i.e., the case with individual ob-
servation data), the optimal CUSUM chart (4.21)–(4.24) for detecting process vari-
ance shifts is based on squares of the standardized observations [(Xn−µ0)/σ0]2. It
is therefore natural to consider the following EWMA charting statistic in such cases:
En=λ/parenleftbiggXn−µ0
σ0/parenrightbigg2
+(1−λ)En−1, (5.12)
where E0=1, and λ∈(0,1]is a weighting parameter. In cases when the process is
IC up to the n-th time point, we have
Yi=/parenleftbiggXi−µ0
σ0/parenrightbigg2
∼χ2
1, fori≤n.
Therefore, in such cases,
µYi=1, σ2
Yi=2.200 UNIV ARIA TE EWMA CHARTS
0 20 40 60 80 100−4 −2 0 2 4
nXn
(a)0 20 40 60 80 100−1.5 −0.5 0.5 1.0 1.5
nEn
(b)
0 20 40 60 80 100−4 −2 0 2 4
nXn
(c)0 20 40 60 80 100−1.5 −0.5 0.5 1.0 1.5
nEn
(d)
Figure 5.8 (a) A dataset of 100 observations with the ﬁrst 50 observations from the distribu-
tion N(0,1), the second 50 observations from the distribution N (0,22), and all observations
being independent. (b) The EWMA chart deﬁned by (5.1) and (5.7) with (λ,ρ)=(0. 2,2.635)
for the data in plot (a). (c) A dataset of 100 observations with the ﬁrst 50 observations
from the distribution N (0,1), the second 50 observations from the distribution N (0,0.52),
and all observations being independent. (d) The EWMA chart deﬁned by (5.1) and (5.7) with
(λ,ρ)=(0. 2,2.635) when it is applied to the data in plot (c).
Similar to (5.2)–(5.5), it can be checked that, in cases when the process is IC up to
then-th time point, we have
µEn=1, σ2
En=2λ
2−λ/bracketleftbig
1−(1−λ)2n/bracketrightbig
. (5.13)MONITORING THE V ARIANCE OF A NORMAL PROCESS 201
In cases when the process has a variance shift from σ2
0toσ2
1at the time point 1 ≤
τ≤nand its mean remains unchanged, we have
µEn,τ=λτ−1
∑
i=1(1−λ)n−i+λn
∑
i=τ(1−λ)n−i/parenleftbiggσ1
σ0/parenrightbigg2
=1+λn
∑
i=τ(1−λ)n−i/bracketleftigg/parenleftbiggσ1
σ0/parenrightbigg2
−1/bracketrightigg
, (5.14)
and
σ2
En,τ
=2λ2τ−1
∑
i=1(1−λ)2(n−i)+2λ2n
∑
i=τ(1−λ)2(n−i)/parenleftbiggσ1
σ0/parenrightbigg4
=2λ
2−λ/bracketleftbig
1−(1−λ)2n/bracketrightbig
+2λ2n
∑
i=τ(1−λ)2(n−i)/bracketleftigg/parenleftbiggσ1
σ0/parenrightbigg4
−1/bracketrightigg
.(5.15)
From (5.14), we can see that, if the process variance shifts upward (i.e., σ2
1>σ2
0)
atτ, then the mean of Enalso shifts upward at τ, the initial shift size is λ[(σ1/σ0)2−
1], and the shift size increases with nand converges to [(σ1/σ0)2−1]. From (5.15),
we can see that the upward process variance shift will also cause an upward variance
shift in En. Both results suggest the following decision rule for detecting upward
process variance shifts. A signal of upward process variance shift is given at the n-th
time point if
En>U=1+ρU/radicalbigg
2λ
2−λ[1−(1−λ)2n], (5.16)
where ρU>0 is a parameter chosen to achieve a pre-speciﬁed ARL 0value. Similarly,
if the process variance shifts downward (i.e., σ2
1<σ2
0) atτ, then both the mean and
variance of Enwould shift downward. In such cases, a reasonable decision rule is
that a signal of downward process variance shift is given at the n-th time point if
En<L=1−ρL/radicalbigg
2λ
2−λ[1−(1−λ)2n], (5.17)
where ρL>0 is a parameter chosen to achieve a pre-speciﬁed ARL 0value.
Regarding the upward EWMA chart deﬁned by (5.12) and (5.16) and the down-
ward EWMA chart deﬁned by (5.12) and (5.17), we would like to make two remarks.
First, the IC variance of Endeﬁned in (5.13) converges to
/tildewideσ2
0,λ=2λ
2−λ.
If this asymptotic variance of Enis used when deﬁning the upper and lower control
limits, then they become
U=1+ρU/radicalbigg
2λ
2−λ, L=1−ρL/radicalbigg
2λ
2−λ, (5.18)202 UNIV ARIA TE EWMA CHARTS
Table 5.4 Computed ρUandρLvalues of the upward and downward EWMA charts deﬁned
by (5.12) and (5.18) for some commonly used ARL 0andλvalues. In the entry with a “∗ ”, the
actual ARL 0value is moderately different from the assumed ARL 0. For the two entries with a
“-” symbol, the assumed ARL 0value cannot be reached.
ρU ρL
ARL 0λ=0.05 0.1 0.2 0.3 λ=0.05 0.1 0.2 0.3
50 0.901 1.380 1.916 2.259 0.865 1.100 1.195 1.166
100 1.455 1.988 2.606 2.996 1.201 1.366 1.360 1.273
200 2.017 2.595 3.258 3.702 1.510 1.580 1.480 1.349
300 2.342 2.944 3.655 4.132 1.670 1.682 1.538 1.384
370 2.518 3.133 3.854 4.354 1.746 1.731 1.563 1.401
400 2.588 3.199 3.935 4.440 1.774 1.750 1.574 1.407
500 2.796 3.419 4.184 4.722 1.862 1.808 1.605 1.426
1000 5.122 5.822 7.788 8.467 2.569 2.452∗ - -
which do not depend on n. Second, for a given value of ARL 0, the two parameters ρU
andρLin the two charts are usually different. That is mainly because the IC distribu-
tion of Enis skewed to the right. For some commonly used ARL 0andλvalues, the
corresponding ρUandρLvalues computed by an Rcode written by the author are
presented in Table 5.4. In the code, each ρUorρLvalue is computed based on 10,000
replicated simulations. Except the last three entries in the last row of the table, the
computed actual ARL 0values of the EWMA charts with the presented parameter val-
ues are all within 0.5 of the assumed ARL 0values. In cases when ARL 0=1000 and
λ=0.1, although the computed ρLvalue is presented in the last row of the table to
be 2.452, the computed actual ARL 0value is 981.349, which is moderately different
from the assumed ARL 0value 1000. In cases with the last two entries in the last row
of the table, the assumed ARL 0value 1000 cannot be reached. From the table, we
can make several conclusions. First, ρUincreases when either ARL 0orλincreases.
Second, ρLis indeed quite different from ρU. It seems that ρLincreases when ARL 0
increases. But, when λincreases, ρLﬁrst increases and then decreases in cases when
ARL 0≤300. In cases when ARL 0>300, ρUdecreases when λincreases.
To use each of the two one-sided charts, we can ﬁrst pre-specify the value of λ,
and then search for the value of ρUorρLto reach a pre-speciﬁed ARL 0value. Table
5.4 should be helpful for this purpose. The two one-sided charts can also be used
simultaneously as a two-sided EWMA chart for detecting arbitrary variance shifts.
In the two-sided chart, if the ARL 0values of the two one-sided charts are chosen to
be the same, then the values of ρUandρLare usually different, as demonstrated in
Table 5.4.
Example 5.5 (continued) The data shown in Figure 5.8(a) are collected from a pro-
duction process that has an upward variance shift from 1 to 22at the 51st time point.
To detect the variance shift, we consider the upward EWMA chart deﬁned by (5.12)
and (5.18), in which λis chosen to be 0.1 and ARL 0is chosen to be 200. By Table
5.4,ρUis chosen to be 2.595. The chart is shown in Figure 5.9(a), and it gives a
ﬁrst signal of upward variance shift at the 54th time point. Similarly, for the dataMONITORING THE V ARIANCE OF A NORMAL PROCESS 203
shown in Figure 5.8(c), we consider the downward EWMA chart deﬁned by (5.12)
and (5.18), in which λand ARL 0are chosen respectively to be 0.1 and 200 as well.
By Table 5.4, ρLis chosen to be 1.580. The chart is shown in Figure 5.9(b), and it
gives a ﬁrst signal of downward variance shift at the 63rd time point.
0 20 40 60 80 1000 1 2 3 4 5
nEn
(a)0 20 40 60 80 1000.0 0.5 1.0 1.5 2.0
nEn
(b)
Figure 5.9 (a) Upwar d EWMA chart deﬁned by (5.12) and (5.18) when it is applied to the
data shown in Figure 5.8(a) and when λ=0.1andρU=2.595(the dashed horizontal line
denotes the upper control limit U =1.842). (b) Downward EWMA chart deﬁned by (5.12) and
(5.18) when it is applied to the data shown in Figure 5.8(c) and when λ=0.1andρL=1.580
(the dashed horizontal line denotes the lower control limit L =0.487).
In the literature, there are some different versions of the EWMA charts based on
Yn=[(X n−µ0)/σ0]2. For instance, Domangue and Patch (1991) proposed a family
of the so-called omnibus EWMA schemes with the charting statistics
En,a=λYa/2
n+(1−λ)En−1, (5.19)
where ais a given constant, and λ∈(0,1]is a weighting parameter. The initial value
E0,ais often chosen to be µ∗
E,a=limn→∞µ(0)
En,a, where µ(0)
En,ais the IC mean of En,a.
Obviously, the family of the charting statistics deﬁned by (5.19) includes the one
deﬁned by (5.12) as a special case when a=2. However, the numerical study in
Domangue and Patch (1991) shows that the chart when a=2 often performs well,
compared to the other charts in the family. For related discussions, see papers includ-
ing Huwang et al. (2009), MacGregor and Harris (1993), Reynolds and Stoumbos
(2006), Yeh et al. (2010), and the references cited therein.
As discussed in Subsection 4.3.2, batch data are commonly used for monitoring
the process variability. Assume that a sample of size mis collected at each time point.
At the n-th time point, for n≥1, let the sample mean and sample variance be Xnand
s2
n, respecti vely. Then, when the process is IC at the n-th time point, we have
(m−1)s2
n
σ2
0∼χ2
m−1.204 UNIV ARIA TE EWMA CHARTS
In such cases, it is natural to consider the following EWMA charting statistic:
En=λs2
n
σ2
0+(1−λ)En−1, (5.20)
where E0=1 and λ∈(0,1]is a weighting parameter. If the process is IC up to the
n-th time point, then we have
µEn=1, σ2
En=2λ
(2−λ)(m−1)/bracketleftbig
1−(1−λ)2n/bracketrightbig
. (5.21)
By comparing the expressions in (5.21) and those in (5.13), it can be seen that every-
thing is the same except that there is a factor 1/(m −1)inσ2
Enwhen batch data with
the batch size of mare used. Therefore, all the formulas (5.16)–(5.18) are still valid
in this case, after the factor 1/(m −1)is included. For instance, to detect an upward
variance shift, we can deﬁne the upward EWMA chart as follows. The chart gives a
signal of an upward variance shift at the n-th time point if
En>U=1+ρU/radicaligg
2λ
(2−λ)(m−1)[1−(1−λ)2n], (5.22)
where ρU>0 is a parameter chosen to reach a pre-speciﬁed ARL 0value. If the
asymptotic variance of Enis used, then the upper control limit Ucan be deﬁned
by
U=1+ρU/radicaligg
2λ
(2−λ)(m−1). (5.23)
The downward EWMA chart can be deﬁned in a similar way.
Similar to the case with the CUSUM charts discussed in Subsection 4.3.2, the
EWMA chart deﬁned by (5.20) and (5.22) (or (5.23)) would not be affected by a
possible mean shift in the process considered, while the EWMA chart deﬁned by
(5.12) and (5.16) (or (5.18)) is sensitive to such a mean shift. Therefore, if process
variance shifts are our only concern, then the EWMA charts based on batch data are
desirable. If both process mean shifts and process variance shifts are concerned, then
the chart deﬁned by (5.12) and (5.16) (or (5.18)) can be considered, although more
effective charting schemes are available for that purpose. See Subsection 5.3.2 below
for details.
From the above description, it can be seen that the upward and downward
EWMA charts behave quite differently, because of the skewness of the distribution
of[(Xn−µ0)/σ0]2ors2
n/σ2
0. For instance, Table 5.4 shows that the values of ρU
andρLshould be chosen quite differently for the two types of charts in cases when
λandARL 0are given. In the literature, there is much existing research in address-
ing this issue (e.g., Crowder and Hamilton, 1992; Huwang et al., 2010; Maravelakis
and Castagliola, 2009; Shu and Jiang, 2008). Next, we brieﬂy introduce the method
proposed by Crowder and Hamilton (1992) in cases when batch data are available.
To handle the asymmetry of the distribution of s2
n/σ2
0, a natural idea is to con-
sider Wn=log(s2
n/σ2
0), because the distribution of Wnwould be closer to normal,MONITORING THE V ARIANCE OF A NORMAL PROCESS 205
compared to the distribution of s2
n/σ2
0. To this end, Crowder and Hamilton (1992)
proposed the EWMA charting statistic
E+
n=max(0,λWn+(1−λ)En−1)
for detecting upward process variance shifts, where E+
0=0 and λ∈(0,1]is a weight-
ing parameter. An intuitive explanation of this statistic is that, if the process variance
shifts from σ2
0toσ2
1with σ2
1>σ2
0at the n-th time point, then s2
n/σ2
0≈σ2
1/σ2
0>1.
Consequently, Wnwould be larger than 0. On the other hand, in cases when the pro-
cess is IC at the n-th time point, Wnwould be close to 0. The restarting mechanism
adopted here is similar to that used in the DI form of a CUSUM chart (cf., the ex-
pression (4.7) in Subsection 4.2.1). It can be checked that
σ2
Wn≈σ2
W=2
m−1+2
(m−1)2+4
3(m−1)3−16
15(m−1)5.
Therefore, the EWMA chart by Crowder and Hamilton (1992) gives a signal of an
upward variance shift at the n-th time point if
E+
n>ρU/radicalbigg
λ
2−λσW,
where ρU>0 is a parameter chosen to reach a pre-speciﬁed ARL 0value. To detect
downward variance shifts, Crowder and Hamilton (1992) suggested using
E−
n=min(0,λWn+(1−λ)En−1),
where E−
0=0. The chart gives a signal if
E−
n<−ρL/radicalbigg
λ
2−λσW,
where ρL>0 is a parameter chosen to reach a pre-speciﬁed ARL 0value.
5.3.2 Joint monitoring of the process mean and variance
In applications, we are often interested in monitoring both the process mean and the
process variance, because both of them are key to the quality of products. To this
end, Example 5.5 shows that the conventional EWMA chart deﬁned by (5.1) and
(5.7), which is designed for detecting process mean shifts, has a certain ability to
detect process variance shifts as well. However, that example also demonstrates that
only the upward variance shifts can be signaled by that control chart. Further, with
an OC signal from this chart alone, it is difﬁcult to know whether the signal is due to
a process mean shift or a process variance shift. For these reasons, that chart alone
may not be appropriate for the joint monitoring of the process mean and variance.
To monitor both the process mean and variance, another possible approach is to
use the omnibus EWMA schemes proposed by Domangue and Patch (1991), which
have their charting statistics deﬁned by (5.19). Among all omnibus EWMA schemes,206 UNIV ARIA TE EWMA CHARTS
most people focus on the two when a=0.5 and 2. Between the two charts, Domangue
and Patch (1991) and several other papers (e.g., Gan, 1995) show that the one with
a=2 often performs better in various cases. Therefore, here we focus on the one
with a=2, which is equivalent to the chart with the charting statistic Endeﬁned by
(5.12). The main reason the chart (5.12) can detect variance shifts is that the mean
ofEnwould increase (decrease) if there is an upward (downward) variance shift at
or before the n-th time point, as shown by (5.14). Now, if the process in question has
an arbitrary mean shift from µ0toµ1at the n-th time point and the variance remains
unchanged, we have
Yn=/parenleftbiggXn−µ0
σ0/parenrightbigg2
=/parenleftbiggXn−µ1
σ0/parenrightbigg2
+2/parenleftbiggXn−µ1
σ0/parenrightbigg/parenleftbiggµ1−µ0
σ0/parenrightbigg
+/parenleftbiggµ1−µ0
σ0/parenrightbigg2
.
Therefore,
µYn=1+/parenleftbiggµ1−µ0
σ0/parenrightbigg2
. (5.24)
The equation (5.24) implies that an arbitrary mean shift in the original observations
would result in an upward mean shift in Yn. For these reasons, if we are only con-
cerned about arbitrary mean shifts and upward variance shifts, then we can consider
using the upward EWMA chart with the charting statistic Endeﬁned by (5.12). Such
a control chart would have no power for detecting downward variance shifts though,
as justiﬁed by the expressions (5.14) and (5.15). Therefore, if downward variance
shifts are also our concern, then we should consider using a two-sided version of this
chart. All these results are demonstrated in the example below.
Example 5.6 Let us consider four different situations in which the ﬁrst 50 observa-
tions are generated from the N (0,1)distribution and the remaining 50 observations
are generated from one of the following four distributions:
(i)N(1,1),
(ii)N(0,22),
(iii) N(1,22), and
(iv) N(0,0.52).
These four situations simulate four different production processes whose IC distri-
butions are all N (0,1)and who have mean and/or variance shifts at the 51st time
point. More speciﬁcally, the ﬁrst process has an upward mean shift of size 1, the sec-
ond process has an upward variance shift of size 22−1=3, the third process has
both an upward mean shift of size 1 and an upward variance shift of size 3, and the
fourth process has a downward variance shift of size 0.52−1=−0.75. One set of
data in each situation is shown in Figure 5.10(a),(c),(e),(g), respectively. We then
consider applying the upward EWMA chart deﬁned by (5.12) and the upper control
limit U in (5.18) with λ=0.1andρU=2.595 to the four datasets. By Table 5.4, this
chart has an ARL 0value of 200. The chart in the four situations is shown in Figure
5.10(b),(d),(f),(h), respectively. It can be seen that the chart can indeed detect theMONITORING THE V ARIANCE OF A NORMAL PROCESS 207
mean shift in situation (i), the upward variance shift in situation (ii), and the mean
and the upward variance shifts in situation (iii). In situation (iii) when both the mean
shift and the upward variance shift are present, the signal from the chart is obvi-
ously much more convincing, compared to the signals in situations (i) and (ii). From
plot (h), it can be seen that the chart has no power to detect the downward variance
shift.
Next, we consider applying the two-sided version of the EWMA chart deﬁned by
(5.12) and (5.18). In the chart, we choose λ=0.1,ρU=3.199, and ρL=1.750. By
Table 5.4, the two one-sided EWMA charts with these parameter values both have
ARL 0value of 400. Therefore, the two-sided EWMA chart would have an ARL 0value
of 200, which has been conﬁrmed by a numerical study. The two-sided EWMA chart
in the four situations considered is shown in the four plots of Figure 5.11. It can be
seen that this chart can indeed detect arbitrary mean shifts and arbitrary variance
shifts.
Although the upward or the two-sided version of the EWMA chart with the chart-
ing statistic deﬁned by (5.12) can detect shifts in both the process mean and process
variance, as demonstrated in Example 5.6, they have one fundamental limitation that
they cannot distinguish mean shifts from variance shifts after signaling. To distin-
guish the two types of shifts, one possible approach is to use two control charts
simultaneously, with at least one of them sensitive to the process mean or variance
shifts only. To this end, for n≥1, assume that we have mobservations at the n-th
time point
Xn1,Xn2,..., Xnm,
and the sample mean and sample variance of these observations are Xnands2
n, re-
specti vely. Then, we can use an EWMA chart with the charting statistic
En,M=λXn+(1−λ)En−1,M,
to detect process mean shifts, where E0,M=µ0. Similarly, we can use the EWMA
chart with the charting statistic deﬁned by (5.20) based on the sample variance s2
nfor
detecting process variance shifts. To distinguish the two charts, the charting statistic
deﬁned by (5.20) is denoted as En,V. Because Xnands2
nare independent of each
other, the two charts would also behave independently. Each chart can be designed
properly for detecting upward, downward, or arbitrary mean or variance shifts. The
joint monitoring scheme can be designed for detecting any combination of a speciﬁc
type of mean shifts and a speciﬁc type of variance shifts. The next example provides
a demonstration.
Example 5.7 Let us reconsider the four cases that are discussed in Example 5.6.
This time, instead of a single observation collected at each time point, we assume
that a sample of size m =5is collected at each time point. The sample means of
four datasets corresponding to the four cases are shown in the ﬁrst column of Figure
5.12. For the EWMA chart based on Xn, let us consider using a two-sided version
with λ=0.1and ARL 0=400. In such cases, if the asymptotic variance of E n,Mis
used, then its upper and lower control limits are
U=µ0+ρ/radicalbigg
λ
2−λσ0
m, L=µ0+ρ/radicalbigg
λ
2−λσ0
m,208 UNIV ARIA TE EWMA CHARTS
0 20 40 60 80 100−4 −2 0 2 4
nXn
(a)0 20 40 60 80 1000 2 4 6 8
nEn
(b)
0 20 40 60 80 100−4 −2 0 2 4
nXn
(c)0 20 40 60 80 1000 2 4 6 8
nEn
(d)
0 20 40 60 80 100−4 −2 0 2 4
nXn
(e)0 20 40 60 80 1000 2 4 6 8
nEn
(f)
0 20 40 60 80 100−4 −2 0 2 4
nXn
(g)0 20 40 60 80 1000 1 2 3 4 5 6
nEn
(h)
Figure 5.10 Four dif ferent situations are considered, in each of which the ﬁrst 50 observations
are generated from the N (0,1)distribution and the remaining 50 observations are generated
from one of the following four distributions: N (1,1), N(0,22), N(1,22), and N(0,0.52). Plots
(a), (c), (e), and (g) show four sets of data in the four situations, respectively. Plots (b), (d), (f),
and (h) show the corresponding upward EWMA chart deﬁned by (5.12) and the upper control
limit U in (5.18) with λ=0.1andρU=2.595.MONITORING THE V ARIANCE OF A NORMAL PROCESS 209
0 20 40 60 80 1000 2 4 6 8
nEn
(a)0 20 40 60 80 1000 2 4 6 8
nEn
(b)
0 20 40 60 80 1000 2 4 6 8
nEn
(c)0 20 40 60 80 1000 1 2 3 4 5 6
nEn
(d)
Figure 5.11 The two-sided EWMA chart deﬁned by (5.12) and (5.18) with λ=0.1,ρU=
3.199, and ρL=1.750when it is applied to the four datasets shown in Figure 5.10(a), (c), (e),
(g).
where ρ=2.731. For the EWMA chart based on s2
n, let us consider using the upward
version with λ=0.1and ARL 0=400. In such cases, its upper control limit U is
deﬁned in (5.23) with ρU=2.836, which is computed by the author using a numerical
algorithm similar to the one used in the computation of Table 5.4. By using these two
charts simultaneously, the joint monitoring scheme would have an ARL 0value of 200,
and it should be able to detect arbitrary mean shifts and upward variance shifts. The
two charts when they are applied to the four datasets are shown in the second and
third columns of Figure 5.12. From the plots in the ﬁgure, it can be seen that the mean
shifts are all detected by the chart based on Xn, and the upward variance shifts are
all detected by the chart based on s2
n. The downward variance shift in the fourth case
is not detected by either chart. If downward variance shifts are also our concern,
then we should use a two-sided version of the EWMA chart based on s2
n.210 UNIV ARIA TE EWMA CHARTS
0 20 40 60 80 100−2 0 1 2 3 4
nXn
(a)0 20 40 60 80 100−2 −1 0 1 2
nEn
(b)0 20 40 60 80 1000 1 2 3 4 5
nEn
(c)
0 20 40 60 80 100−2 0 1 2 3 4
nXn
(d)0 20 40 60 80 100−2 −1 0 1 2
nEn
(e)0 20 40 60 80 1000 1 2 3 4 5
nEn
(f)
0 20 40 60 80 100−2 0 1 2 3 4
nXn
(g)0 20 40 60 80 100−2 −1 0 1 2
nEn
(h)0 20 40 60 80 1000 1 2 3 4 5
nEn
(i)
0 20 40 60 80 100−2 0 1 2 3 4
nXn
(j)0 20 40 60 80 100−2 −1 0 1 2
nEn
(k)0 20 40 60 80 1000 1 2 3 4 5
nEn
(l)
Figure 5.12 Four dif ferent situations are considered, in each of which the ﬁrst 50 samples of
size 5 each are generated from the N (0,1)distribution and the remaining 50 samples of size
5 each are generated from one of the following four distributions: N (1,1)(plot (a)), N (0,22)
(plot (d)), N (1,22)(plot (g)), and N (0,0.52)(plot (j)). Plots in the ﬁrst column show the
sample means, plots in the second column show the two-sided EWMA charts with the charting
statistic E n,Mthat is based on the sample means, and plots in the third column show the
upward EWMA charts with the charting statistic E n,Vthat is based on the sample variances.
Each EWMA chart is designed using λ=0.1and ARL 0=400, so that the joint monitoring
scheme consisting of the mean chart and the variance chart has an ARL 0value of 200.SELF-STARTING AND ADAPTIVE EWMA CHARTS 211
Gan (1995) provided many numerical results about the performance of the above
joint monitoring EWMA scheme using En,MandEn,V, a corresponding joint moni-
toring CUSUM scheme (cf., Example 4.9 in Subsection 4.3.3), and several omnibus
EWMA schemes including the ones with the charting statistic deﬁned by (5.12) af-
ter(Xn−µ0)/σ0being replaced by (Xn−µ0)/(σ0/√m). Based on these results, we
can conclude that (i) the joint monitoring EWMA scheme and the joint monitor-
ing CUSUM scheme have similar performance in most cases, and (ii) they are often
more effective than the omnibus EWMA schemes for the joint monitoring of both
the process mean and process variance.
5.4 Self-Starting and Adaptive EWMA Charts
The EWMA charts discussed in the previous sections are based on the assumption
that the IC mean µ0and the IC variance σ2
0are known. In practice, they are often
unknown and need to be estimated from the observed data. Also, when designing an
EWMA chart, the weighting parameter λshould be chosen beforehand. From the
discussion in Section 5.2, we know that λshould be chosen large if the target shift
is large, and it should be chosen small if the target shift is small. However, for a real
production process, the size of a future shift is usually unknown. Therefore, it is still
unclear how to choose λproperly in real applications. Possible solutions to these
issues are discussed in this section.
5.4.1 Self-starting EWMA charts
When the IC mean µ0and the IC variance σ2
0are unknown, a natural idea is to
estimate them from an IC dataset. In Subsection 4.5.1, we have demonstrated that the
randomness in their estimators, denoted as /hatwideµ0and/hatwideσ2
0, respectively, would affect the
performance of a CUSUM chart in a substantial way in cases when the sample size
of the IC dataset is not large enough. Next, let us reconsider the scenarios discussed
in Example 4.11 to see whether it is also true for an EWMA chart.
Example 5.8 As in Example 4.11, let us assume that the true IC distribution of a pro-
duction process is N (0,1), which is unknown to us. Instead, it needs to be estimated
from an IC dataset of size 100. The IC mean µ0and the IC variance σ2
0are estimated
by the sample mean and sample variance of the IC dataset, denoted as /hatwideµ0and/hatwideσ2
0,
and their sampling distributions are /hatwideµ0∼N(0,0.01) and99/hatwideσ2
0∼χ2
99(cf., Section
2.7 and Example 4.11 for related discussions). Now, let us consider nine cases with
the values of/hatwideµ0and/hatwideσ0listed in the ﬁrst two columns of Table 5.5. In each case,
we treat the values of /hatwideµ0and/hatwideσ0as the true values of µ0andσ0, and then use the
conventional upward EWMA chart deﬁned by (5.8) and (5.9), except that the original
observation X nis replaced by its standardized value (Xn−/hatwideµ0)//hatwideσ0. In such cases, the
actual distribution of (Xn−/hatwideµ0)//hatwideσ0is N(−/hatwideµ0//hatwideσ0,/hatwideσ−2
0). In the control chart, λand
ARL 0are chosen to be 0.1 and 200. Then, by the function xewma.crit() in theR-
packagespc, the value of ρUis computed to be 2.365. In the nine cases considered,
the actual ARL 0values of this EWMA chart are listed in the third column of Table
5.5. We then consider an upward mean shift of size 0.2 occurring at the initial obser-
vation time point. The corresponding ARL 1values of the chart are listed in the fourth212 UNIV ARIA TE EWMA CHARTS
Table 5.5 The actual ARL 0values of the upward EWMA chart deﬁned by (5.8) and (5.9) and
the two-sided EWMA chart deﬁned by (5.1) and (5.7) in cases with several estimated values
of the IC mean µ0and IC standard deviation σ0, along with their actual ARL 1values for
detecting a mean shift of size 0.2. In the upward chart, (λ,ρU)are chosen to be (0.1,2.365)
so that its nominal ARL 0value is 200. In the two-sided EWMA chart, (λ,ρ)are chosen to be
(0.1,2.454), and its ARL 0value is also 200.
Upward EWMA Two-Sided EWMA
/hatwideµ0/hatwideσ0 ARL 0 ARL 1 ARL 0 ARL 1
−0.1 0.9 70.276 29.478 90.828 36.375
−0.1 1.0 106.295 39.018 147.327 48.895
−0.1 1.1 168.837 53.562 247.974 67.531
0 0.9 120.751 43.487 114.030 57.254
0 1.0 200.449 61.918 201.873 83.542
0 1.1 348.040 90.295 361.680 123.971
0.1 0.9 224.109 70.276 90.828 90.828
0.1 1.0 403.217 106.295 147.327 147.327
0.1 1.1 632.519 168.837 247.974 247.974
column of Table 5.5. From the table, it can be seen that the actual ARL 0values of the
chart could be very different from the assumed ARL 0value of 200 in various cases
when the IC parameters are estimated, and its OC performance is often affected quite
dramatically by the estimated values of the IC parameters as well.
In this example, we also consider the two-sided EWMA chart deﬁned by (5.1) and
(5.7), in which X nis replaced by (Xn−/hatwideµ0)//hatwideσ0, the λand ARL 0values are chosen to
be 0.1 and 200, respectively. By Table 5.1, the ρvalue should be chosen 2.454. In the
nine cases considered when the IC parameters are estimated by /hatwideµ0and/hatwideσ0, its actual
ARL 0and ARL 1values are presented in the ﬁfth and sixth columns of Table 5.5. It
can be seen that these results are similar to those of the upward EWMA chart.
Example 5.8 demonstrates that the IC and OC performance of the EWMA charts
is indeed affected substantially by the estimated IC parameter values in the case when
the IC sample size is 100. We can imagine that such an impact would be lessened
in cases when the IC sample size gets larger because the estimated values of the
IC parameters would get closer to their true values. Jones et al. (2001) studied the
performance of the EWMA charts with estimated IC parameters quite systematically,
and found that their performance was reliable only when the IC sample size was as
large as 2000. In practice, however, it is often difﬁcult to obtain a large IC dataset.
Therefore, we still need to ﬁnd a reliable and effective method to construct EWMA
charts when the IC parameters are unknown.
In Subsection 4.5.1, we described the self-starting CUSUM chart that was orig-
inally proposed by Hawkins (1987) to handle the case when the IC parameters are
unknown. The idea of self-starting CUSUM charts is actually quite general and it can
also be applied to other types of control charts, including the EWMA charts. Next,
we describe the construction of the self-starting version of the two-sided EWMA
chart deﬁned by (5.1) and (5.7). Let the phase II observations be {X1,X2,...}. If the
production process is IC at all times, then the observations are i.i.d. with the com-SELF-STARTING AND ADAPTIVE EWMA CHARTS 213
mon distrib ution N(µ0,σ2
0). In such cases, as pointed out in Subsection 4.5.1, the
transformed observations {Z1,Z2,...}are i.i.d. with the common distribution N(0,1),
where Zn, for n≥3, are deﬁned by (4.48). Because Znis obtained by a strictly in-
creasing transformation from the original observation Xn, detection of mean shifts in
the original data {X1,X2,...} is equivalent to detection of mean shifts in the trans-
formed data {Z1,Z2,...}. By these results, the self-starting two-sided EWMA chart
for detecting arbitrary mean shifts can be deﬁned by
En,SS=λZn+(1−λ)En−1,SS, (5.25)
where λ∈(0,1]is a weighting parameter, and the chart gives a signal when
|En,SS|>ρSS/radicalbigg
λ
2−λ[1−(1−λ)2n], (5.26)
where E0,SS=0 and ρSS>0 is a constant chosen to achieve a pre-speciﬁed ARL 0
value. In (5.26), we have used the facts that {Z1,Z2,...} are i.i.d. with the N(0,1)
distribution when the process is IC and that
σ2
En,SS=λ
2−λ/bracketleftbig
1−(1−λ)2n/bracketrightbig
.
If the asymptotic variance of En,SSis used instead, then the corresponding decision
rule of the chart is that it gives a signal when
|En,SS|>ρSS/radicalbigg
λ
2−λ. (5.27)
Note that, because the transformed data {Z1,Z2,...}are i.i.d. with the N(0,1)distri-
bution when the process is IC, the ρSSvalues for some commonly used ARL 0andλ
values can be found from Table 5.1.
Example 5.9 Assume that 10 independent observations are generated from the
N(0,1)distribution and another 30 independent observations are generated from the
N(0.5, 1)distribution. These observations are used for simulating a production pro-
cess whose IC distribution is N (0,1)and which has a mean shift of size 0.5 at the 11th
time point. The 40 observations are shown in Figure 5.13(a), and they are actually
the same as those considered in Example 4.12 in Subsection 4.5.1. The ﬁrst 10 obser-
vations{Xn,n=1,2,..., 10}, the computed sample means {Xn,n=1,2,..., 10}, the
sample standard deviations {sn,n=2,3,..., 10}, and the transformed observations
{Zn,n=3,4,..., 10}are presented in Table 4.7. Now, we apply the self-starting two-
sided EWMA chart deﬁned by (5.25) and (5.27) to this dataset, in which λand ARL 0
are chosen to be 0.05 and 200, respectively. Then, by Table 5.1, ρSSshould be chosen
to be 2.216. The charting statistic E n,SSis shown in Figure 5.13(b) by the solid curve,
and the control limits are shown in the same plot by two horizontal dashed lines. This
chart gives a ﬁrst signal at the 23rd time point. As a comparison, the conventional
two-sided EWMA chart deﬁned by (5.1) and (5.7) with the same values of λ, ARL 0,
and the two control limits is also shown in the plot by the dotted curve. This chart
assumes that the IC mean and variance are known. It gives a ﬁrst signal at the 23rd
time point as well.214 UNIV ARIA TE EWMA CHARTS
0 10 20 30 40−1 0 1 2 3
nXn
(a)0 10 20 30 40−0.4 −0.2 0.0 0.2 0.4
n
(b)
Figure 5.13 (a) The ﬁrst 10 observations are generated from the N (0,1)distribution and the
remaining 30 observations are generated from the N (0.5,1)distribution. All observations are
independent. (b) The self-starting two-sided EWMA chart deﬁned by (5.25) and (5.27) (solid
curve) and the conventional two-sided EWMA chart deﬁned by (5.1) and (5.7) (dotted curve).
In both charts, λis chosen to be 0.05 and ARL 0is chosen to be 200.
Figure 5.13(b) shows that the self-starting two-sided EWMA chart deﬁned by
(5.25) and (5.27) performs reasonably well, without assuming the IC mean and vari-
ance to be known. However, this plot also shows that the signal of mean shift from
this chart disappears quite fast. Therefore, if we do not react to its ﬁrst signal of mean
shift quickly, a persistent mean shift could be missed, as explained in Subsection
4.5.1 using the expression (4.50). As a comparison, the signal from the conventional
two-sided EWMA chart gets stronger and stronger over time.
The self-starting versions of other EWMA charts can be constructed in a simi-
lar way. For instance, to construct the self-starting version of the omnibus EWMA
schemes with the charting statistics deﬁned in (5.19), Yn= [(X n−µ0)/σ0]2can be
simply replaced by Z2
n, where{Zn,n≥3}are deﬁned by (4.48). With the EWMA
chart deﬁned by (5.20)–(5.23) for detecting process variance shifts, to construct its
self-starting version, we can replace σ2
0in (5.20) by a reasonable variance estimator
constructed from the previous n−1 samples, denoted as /hatwideσ2
0,n−1. Then, the statistic
s2
n//hatwideσ2
0,n−1would have an F-distribution after it is properly rescaled, and the con-
trol limits of the chart can be chosen accordingly. One possible variance estimator
constructed from the ﬁrst n−1 samples is/hatwideσ2
0,n−1= (s2
1+s2
2+···+s2
n−1)/(n−1),
although some other estimators are also possible.
5.4.2 Adaptive EWMA charts
In Subsection 5.2.1, we gave a general guideline for choosing the weighting parame-
terλin the conventional two-sided EWMA chart deﬁned by (5.1) and (5.7). By this
guideline, λshould be chosen relatively small if the target shift size is small, and
relatively large otherwise. In practice, however, the size of a potential shift is oftenSELF-STARTING AND ADAPTIVE EWMA CHARTS 215
unknown. In such cases, if we choose a relatively small value for λ, then the resulting
EWMA chart would perform poorly in cases when the real shift size is large. Simi-
larly, if λis chosen relatively large, then the resulting chart would be ineffective for
detecting small shifts. Can we propose a data-driven scheme for choosing λsuch that
the resulting EWMA chart performs reasonably well in a wide range of situations?
This is the focus of this subsection.
In Subsection 4.5.2, we discussed a similar problem about the selection of the
allowance constant kwhen implementing a CUSUM chart. In that scenario, theoret-
ical results say that kshould be chosen as half of a target shift size δin order for the
CUSUM chart to achieve its optimal performance in detecting that shift. Therefore,
as long as we can provide a reasonable estimate of δusing all available observations,
selection of kcan be solved accordingly. The adaptive CUSUM chart by Sparks
(2000) described in Subsection 4.5.2 is based on an EWMA estimate of δ. See the
expressions (4.51) and (4.52) for details. For the EWMA charts, however, there is no
corresponding theory about the functional relationship between the target shift size
δand the optimal value of λ, although certain researchers have explored such a rela-
tionship through numerical studies (e.g., Crowder, 1989; Lucas and Saccucci, 1990).
For this reason, the idea of the method by Sparks (2000) is difﬁcult to use here for
adaptively choosing λof an EWMA chart.
Capizzi and Masarotto (2003) provided a solution to the problem of choosing
λadaptively such that the resulting EWMA chart could perform reasonably well
in a variety of different situations. Next, we describe their adaptive exponentially
weighted moving average (AEWMA) control chart in detail. Assume that the IC pro-
cess distribution is N(µ0,σ2), and we are interested in detecting process mean shifts.
Then, the charting statistic of the AEWMA chart is deﬁned by
An=An−1+η(en), (5.28)
where A0=µ0,en=Xn−An−1, and η(·)is an increasing score function. The chart
gives a signal of process mean shift if
|An−µ0|>h (5.29)
where h>0 is the control limit chosen to achieve a given ARL 0value. In (5.28),
An−1can be regarded as a prediction of the process mean based on all previous n−1
observations, and enis the prediction error. The formula (5.28) updates Anaccording
to the prediction error. If the prediction error is small, then the update from An−1
toAnis also small, and the update is large otherwise, which should be intuitively
reasonable.
The expression (5.28) can be written in a more familiar form as follows:
An=w(e n)Xn+(1−w(e n))A n−1, (5.30)
where w(e n) =η(en)/en. In (5.30), Anis a weighted average of the current obser-
vation Xnand the charting statistic value at the previous time point An−1, as in a
conventional EWMA chart; but, the weights w(e n)change over time and they are216 UNIV ARIA TE EWMA CHARTS
determined by the prediction errors. In that sense, the EWMA chart (5.28)–(5.29) is
adaptive over time to all observed data.
To design the AEWMA chart, the score function η(·)should be chosen properly.
First, we notice that when η(en)=en(i.e., η(·)is an identity function), the AEWMA
chart becomes a Shewhart chart. On the other hand, when η(en) =λenwith λ∈
(0,1)a constant, the AEWMA chart is just a conventional EWMA chart. Because
Shewhart charts are good for detecting large shifts and conventional EWMA charts
with small values of λare good for detecting small shifts, Capizzi and Masarotto
suggested choosing η(en)between enandλen. More speciﬁcally, they suggested
choosing η(en)such that
(i)η(en)is strictly increasing in en,
(ii)η(−en)=−η(en),
(iii) η(en)is close to λenwhen|en|is small, and
(iv) η(en)is close to enwhen|en|is large.
Based on these considerations, they proposed several speciﬁc score functions, in-
cluding the following two:
η1(en)=

en+(1−λ)u, ifen<−u
λen, if|en|≤u
en−(1−λ)u, ifen>u
and
η2(en)=/braceleftbigg
en/bracketleftbig
1−(1−λ)(1−(en/u)2)2/bracketrightbig
,if|en|≤u
en, otherwise,
where λ∈(0,1]andu≥0 are two constants. When λ=0.1,u=2,4,6,anden∈
[−10,10],η1(en),w1(en)=η1(en)/en,η2(en), and w2(en)=η2(en)/enare presented
in plots (a)–(d) of Figure 5.14, respectively. From the ﬁgure, it can be seen that
(i) both w1(en)andw2(en)are between the values of λand 1 (i.e., the resulting
AEWMA chart would behave between the performance of the EWMA and Shewhart
charts), (ii) both w1(en)andw2(en)are closer to the value of λwhen uis larger (i.e.,
the AEWMA chart is more like an EWMA chart in such cases), and (iii) for a given
value of u,w2(en)is closer to 1, compared to w1(en)(i.e., the AEWMA chart with
w2(en)is more like a Shewhart chart, compared to the AEWMA chart with w1(en),
if the two charts use the same value of u).
In either η1(en)orη2(en), there are two parameters λandu. So, the AEWMA
chart using η1(en)orη2(en)has a total of three parameters h,λ, and uto choose.
To this end, Capizzi and Masarotto suggested a numerical algorithm with three steps
described below.
Step 1 Choose a desired IC ARL value, denoted as ARL 0, and two shift sizes δ1<δ2.
δ1is a small target shift size and δ2is a large target shift size. They are chosen
such that we hope the AEWMA chart can perform well in detecting shifts in the
range[δ1,δ2].SELF-STARTING AND ADAPTIVE EWMA CHARTS 217
−10 −5 0 5 10−10 −5 0 5 10
enη1□en□u=2
u=4
u=6
(a)−10 −5 0 5 100.0 0.2 0.4 0.6 0.8 1.0
enw1□en□u=2
u=4
u=6
(b)
−10 −5 0 5 10−10 −5 0 5 10
enη2□en□u=2
u=4
u=6
(c)−10 −5 0 5 100.0 0.2 0.4 0.6 0.8 1.0
enw2□en□u=2
u=4
u=6
(d)
Figure 5.14 In cases when λ=0.1, u=2,4,6,and e n∈[−10, 10], the four quantities η1(en),
w1(en)=η1(en)/en,η2(en), and w 2(en)=η2(en)/enare presented in plots (a)–(d), respec-
tively. In each plot, the dash-dotted and the long-dashed lines denote the corresponding quan-
tities of the Shewhart chart and the conventional EWMA chart, respectively.
Step 2 Solve the minimization problem
min
h,λ,uARL 1(δ2;h,λ,u)
subject to ARL 1(0;h,λ,u)= ARL 0,
where ARL 1(δ;h,λ,u)denotes the OC ARL value when the shift size is δand the
control chart has parameters h,λ, and u. The solution to the above problem may
not be unique. Let (h∗,λ∗,u∗)be one speciﬁc solution.218 UNIV ARIA TE EWMA CHARTS
Table 5.6 “Optimal” parameter values of the AEWMA chart determined by the algorithm
suggested by Capizzi and Masarotto (2003) in cases when ARL 0=100or 500, ν=0.05,
η(en)=η1(en)orη2(en), and σ=1. This table is reproduced from Tables 3 and 4 in Capizzi
and Masarotto (2003). In cases when σ/ne}ationslash=1, the values of h and u should be multiplied by σ.
ARL 0=100 ARL 0=500
η(en) µ1µ2 h λ u h λ u
0.25 4 0.1471 0.0162 2.7459 0.2017 0.0117 3.0326
0.50 4 0.3927 0.0614 2.6306 0.4306 0.0398 2.8990
1.00 4 0.7874 0.1813 2.5752 0.8238 0.1253 2.7765
0.25 5 0.1457 0.0192 3.3249 0.1835 0.0137 3.4473
η1(en)0.50 5 0.3767 0.0670 3.2654 0.3960 0.0437 3.3402
1.00 5 0.7688 0.1913 3.2907 0.7931 0.1354 3.2587
0.25 6 0.1515 0.0207 4.2537 0.2091 0.0175 4.2176
0.50 6 0.3671 0.0657 4.2638 0.4052 0.0474 4.1490
1.00 6 0.7310 0.1792 7.9825 0.7610 0.1305 4.1534
0.25 4 0.3542 0.0188 12.6145 0.4866 0.0082 12.5467
0.50 4 0.4858 0.0463 11.4741 0.5807 0.0256 11.9897
1.00 4 0.7697 0.1359 10.6114 0.8215 0.0830 11.1408
0.25 5 0.2065 0.0196 24.0162 0.3381 0.0094 17.2037
η2(en)0.50 5 0.3729 0.0520 19.9865 0.4763 0.0296 15.4062
1.00 5 0.6821 0.1473 20.1147 0.8551 0.1199 13.6702
0.25 6 0.1430 0.0168 48.7509 0.2283 0.0130 31.1230
0.50 6 0.3484 0.0577 40.6934 0.4133 0.0394 25.8760
1.00 6 0.7224 0.1736 47.4411 0.7659 0.1226 25.5065
Step 3 Letν>0 be a pre-speciﬁed small constant (e.g., ν=0.05). Solve the mini-
mization problem
min
h,λ,uARL 1(δ1;h,λ,u)
subject to ARL 1(0;h,λ,u)= ARL 0,
and ARL 1(δ2;h,λ,u)≤(1+ν)ARL 1(δ2;h∗,λ∗,u∗).
Then, the solution to this minimization problem is used by the AEWMA chart.
The AEWMA chart using the parameters determined by the above al-
gorithm would perform reasonably well for detecting both large and small
shifts. Source codes of the algorithm in care available on the web page
http://sirio.stat.unipd.it/caewma . When ARL 0=100 or 500, ν=0.05, η(en) =
η1(en)orη2(en), and σ=1, the parameters determined by the algorithm for some
pairs of(µ1,µ2)are given in Capizzi and Masarotto (2003), which are also presented
in Table 5.6. In cases when σ/ne}ationslash=1, the values of handushould be multiplied by σ.
Example 5.10 Let us consider two datasets. The ﬁrst one has 100 observations, the
ﬁrst 50 observations are generated from the N (0,1)distribution, the remaining 50
observations are generated from the N (0.5, 1)distribution, and all observations are
independent of each other. The second dataset is generated in the same way, exceptSOME DISCUSSIONS 219
that its last 50 observations are generated from the N (2,1)distribution. These two
datasets are used for simulating two production processes that have mean shifts at
the 51st time point with different shift sizes. The ﬁrst process has a relatively small
shift size of 0.5, while the second process has a relatively large shift size of 2.0. We
now apply three control charts to both datasets. The ﬁrst chart is the conventional
two-sided EWMA chart deﬁned by (5.1) and (5.7) with λ=0.01 andρ=1.973.
The second chart is also the conventional two-sided EWMA chart with λ=0.5and
ρ=3.071. The third chart is the AEWMA chart using η1(en)with λ=0.0398, u=
2.8990, and h =0.4306. By Tables 5.1 and 5.6, all these three charts have the same
ARL 0value of 500. The two datasets are shown by the two plots in the 1st row of
Figure 5.15. The charts are shown by the plots in the 2nd, 3rd, and 4th rows of
Figure 5.15. From the ﬁgure, it can be seen that, for the ﬁrst dataset, the ﬁrst EWMA
chart gives a ﬁrst signal around the 80th time point, the second EWMA cannot give
any signal, and the AEWMA chart gives a ﬁrst signal around the 75th time point. In
this case, the second EWMA chart does not perform well because it is designed for
detecting relatively large mean shifts while the true mean shift in this case is quite
small. The ﬁrst EWMA chart and the AEWMA chart perform reasonably well. For
the second dataset, all three charts can give signals because the mean shift in this
case is quite large. The ﬁrst EWMA chart gives a ﬁrst signal at the 57th time point,
the second EWMA chart gives a ﬁrst signal at the 52nd time point, and the AEWMA
chart gives a ﬁrst signal at the 54th time point. Therefore, the second EWMA chart
performs the best in this case and the ﬁrst EWMA chart performs the worst. As a
summary, this example demonstrates that the conventional two-sided EWMA chart
cannot be effective in detecting both small and large shifts, while the performance of
the AEWMA chart is quite robust to shift sizes.
5.5 Some Discussions
In the previous sections, we have described various EWMA charts for detecting pro-
cess mean and/or variance shifts in cases when the IC and OC process distributions
are assumed normal. These charts are good for detecting relatively small and per-
sistent shifts. Their performance is generally similar to the performance of the cor-
responding CUSUM charts, while they are easier to understand and implement. On
the other hand, CUSUM charts have certain theoretical optimality properties; the
corresponding theory for the EWMA charts is still lacking. For these reasons, both
CUSUM and EWMA charts are popularly used in practice.
In the literature, EWMA charts in cases when the distribution of the production
process in question follows several other parametric forms have also been proposed.
For instance, Pascual (2010) and Zhang and Chen (2004) constructed EWMA charts
for monitoring production processes with Weibull distributions. Some authors, in-
cluding Borror et al. (1998), Gan (1990a), and Weiß (2009), discussed process mon-
itoring using EWMA charts in cases when the process distributions were Poisson.
Gan (1990b), Perry and Pignatiello (2005), Sparks et al. (2011), and some others
discussed how to monitor processes with binomial or negative binomial distributions
using EWMA control charts.
All the EWMA charts discussed in this chapter are for detecting step shifts in the
process mean and/or variance. In some applications, when the process in question
becomes OC, its mean and/or variance would depart gradually from the IC level(s).220 UNIV ARIA TE EWMA CHARTS
0 20 40 60 80 100−3 −1 0 1 2 3 4
nXn
(a)
0 20 40 60 80 100−0.5 0.0 0.5 1.0
nEn
(b)
0 20 40 60 80 100−1 0 1 2 3
nEn
(c)
0 20 40 60 80 100−1.0 0.0 1.0 2.0
nAn
(d)0 20 40 60 80 100−3 −1 0 1 2 3 4
nXn
(e)
0 20 40 60 80 100−0.5 0.0 0.5 1.0
nEn
(f)
0 20 40 60 80 100−1 0 1 2 3
nEn
(g)
0 20 40 60 80 100−1.0 0.0 1.0 2.0
nAn
(h)
Figure 5.15 Plot (a) shows a dataset with 100 independent observations, the ﬁrst 50 of which
are generated from the N (0,1)distribution, and the remaining 50 of which are generated from
the N(0.5,1)distribution. Plots (b), (c), and (d) show the conventional two-sided EWMA chart
deﬁned by (5.1) and (5.7) with λ=0.01andρ=1.973, the conventional two-sided EWMA
chart with λ=0.5andρ=3.071, and the AEWMA chart using η1(en)with λ=0.0398, u=
2.8990, and h =0.4306, respectively. All three charts have the same ARL 0value of 500. Plots
(e)–(h) show the corresponding results for another dataset with 100 independent observations,
the ﬁrst 50 of which are generated from the N (0,1)distribution, and the remaining 50 of which
are generated from the N (2,1)distribution. Dashed horizontal lines in various plots denote
the control limits.EXERCISES 221
Such gradual departures are called drifts, as discussed in Section 4.7. In the literature,
some authors have modiﬁed the conventional EWMA charts for detecting various
mean/variance drifts. Interested readers are referred to papers including Gan (1991b),
Su et al. (2011), Tseng et al. (2007, 2010), and Zou et al. (2009a).
EWMA charts average the current and all previous observations using an ex-
ponentially weighted averaging scheme. In the statistical literature, because the
observed data are often assumed to have random noise involved, data smoothing
through data averaging is the major statistical tool for removing random noise. Many
different data averaging techniques have been proposed in the literature, which in-
clude kernel smoothing, smoothing splines, wavelet transformations, and so forth
(cf., Qiu, 2005, Chapter 2). Among all existing data smoothing techniques, the ones
in jump regression analysis (JRA) might be especially relevant to the SPC problem
for the reasons explained below. The major goal of JRA is to estimate regression
functions with jumps and other singularities (cf., Qiu, 2005). The SPC problem can
be regarded as a special JRA problem in the sense that the regression function equals
the IC process mean µ0when the production process in question is IC, and it jumps
to an OC process mean µ1at a speciﬁc time point τafter the process has a mean shift
atτ. There are two major differences between the phase II SPC problem and the JRA
problem though. One is that the regression function equals a constant before or after
the jump point τin the SPC problem, while the regression function could be any
continuous curves on the two sides of a jump point in the JRA problem. The second
difference is that the sample size of a JRA problem is often ﬁxed, while the sample
size in the phase II SPC problem keeps increasing (i.e., it is a sequential problem).
The second difference would disappear if we are concerned about the phase I SPC
problem, because the sample size in phase I SPC is often ﬁxed as well. Because of
these substantial differences between the SPC and JRA problems, the methods in the
JRA literature may not be efﬁcient if they are applied to the SPC problems directly.
However, ideas of certain existing JRA methods should be useful for us to construct
efﬁcient SPC procedures. For more information about JRA methods, read Gijbels
et al. (2007), Joo and Qiu (2009), Loader (1996), M ¨uller (1992, 2002), Qiu (1994,
1998, 2003, 2004), Qiu et al. (1991), Qiu and Yandell (1998), Wu and Chu (1993),
Wu and Zhao (2007), among many others.
5.6 Exercises
5.1 The EWMA charting statistic Endeﬁned in (5.1) is a weighted average of the
current and all previous observations {Xn,Xn−1,..., X1}. When n=20, list all
the weights received by these observations in the following cases:
(i)λ=1,
(ii)λ=0.5,
(iii) λ=0.2, and
(iv) λ=0.05.
Summarize your major ﬁndings from the weights listed. How would these dif-
ferent weighting schemes affect the properties of En?222 UNIV ARIA TE EWMA CHARTS
5.2 For the EWMA charting statistic Endeﬁned in (5.1), derive the results in (5.2)–
(5.5).
5.3 In Example 5.1, assume that we use the control limits deﬁned in (5.7) with λ=
0.1 and ρ=2.703 when implementing the two-sided EWMA chart. Plot the
control chart using the data in that example, and discuss how this change (i.e.,
the control limits are changed from those in (5.6) to those in (5.7)) would affect
the IC and OC performance of the control chart in general.
5.4 Assume that we obtain the following 30 observations from a production process
whose IC distribution is assumed to be known N(10,22):
13,12,10,10,9,7,11,12,7,10,11,10,11,10,9,
18,14,16,18,12,13,17,18,15,18,15,14,18,14,16.
Construct different two-sided EWMA charts deﬁned by (5.1) and (5.7) with the
following speciﬁcations:
(i)ARL 0=200, λ=0.1,
(ii)ARL 0=200, λ=0.5,
(iii) ARL 0=500, λ=0.1,
(iv) ARL 0=500, λ=0.5.
Discuss how the values of ARL 0andλwould affect the performance of the
control chart.
5.5 For the dataset in the previous exercise, consider using the upward EWMA chart
deﬁned by (5.8) and (5.9) with ARL 0=200 and λ=0.1. Its ρUvalue can be
computed using the function xewma.crit() in theR-package spcin which the
argument sided should be set as “one”. Compare the performance of this chart
with that of the two-sided chart in part (i) of the previous exercise.
5.6 For the two-sided EWMA charts deﬁned by (5.1) and (5.7), compute its ARL 0
values in the following cases, using the function xewma.arl() in theR-package
spc:
(i)λ=0.1,ρ=1,
(ii)λ=0.1,ρ=2,
(iii) λ=0.5,ρ=1,
(iv) λ=0.5,ρ=2.
Summarize your major ﬁndings about the relationship between ARL 0and(λ,ρ).
5.7 For the two-sided EWMA charts deﬁned by (5.1) and (5.7), compute its ρvalues
in the following cases, using the function xewma.crit() in theR-package spc:
(i)ARL 0=150, λ=0.1,
(ii)ARL 0=150, λ=0.5,
(iii) ARL 0=450, λ=0.1,
(iv) ARL 0=450, λ=0.5
Summarize your major ﬁndings about the relationship between ρand(ARL 0,λ).EXERCISES 223
5.8 Figure 5.4 demonstrates the effectiveness of the EWMA chart deﬁned by (5.1)
and (5.7) with different values of the weighting parameter λfor detecting pro-
cess mean shifts of different sizes. Produce a similar plot in cases when the IC
process distribution is N(0,1),ARL 0=200, λ=0.01, 0.3,or 0.75, and the shift
sizeδchanges from 0 to 3.0 with a step of 0.1. Summarize your results from the
plot.
5.9 Assume that observations from a production process can be adequately de-
scribed by the following AR(1) model:
Xn=10+0.2(X n−1−10)+ en, forn≥1,
where X0=10, and{en,n≥1}are i.i.d. with the common distribution N(0,1).
Design an EWMA chart with the adjusted control limits using the method dis-
cussed at the end of Subsection 5.2.2 with M=25,λ=0.1, and ρ=2.454.
Then, apply the designed EWMA chart to the observed data given below.
9,10,10,11,11,10,10,10,9,11,10,9,10,11,11,
16,16,15,17,17,17,16,18,18,17,16,16,15,15,16
5.10 Reproduce Figure 5.6 discussed in Subsection 5.2.3.
5.11 At the end of Subsection 5.2.3, it is explained that EWMA charts may not be
robust to the normality assumption. To further investigate this issue, consider a
simulation with the following several steps:
Step 1 Generate 50 random numbers from the χ2
kdistribution.
Step 2 Compute the value of the charting statistic Enof the conventional
EWMA chart deﬁned by (5.1) and (5.7) when n=50.
Step 3 Repeat Steps 1 and 2 100 times, and make a histogram of the 100 com-
puted values of E50.
Do the above simulation in the following cases:
(i)k=1,λ=0.5,
(ii)k=1,λ=0.1,
(iii) k=5,λ=0.5,
(iv) k=5,λ=0.1.
Summarize your simulation results about the distribution of E50in the different
cases considered.
5.12 For the EWMA charting statistic deﬁned in (5.12), verify the results in (5.13)–
(5.15).
5.13 Assume that the following 40 observations are obtained from a production pro-
cess with the IC distribution N(50,52):
33,55,51,57,57,56,49,45,55,50,
50,49,50,55,57,50,47,39,51,55,
52,54,36,37,43,57,52,49,51,47,
40,35,36,51,39,44,35,54,38,47.224 UNIV ARIA TE EWMA CHARTS
Apply the upward EWMA chart for detecting variance shifts, deﬁned by (5.12)
and (5.16) with ARL 0=200 and λ=0.1, to this dataset. Summarize your results.
5.14 For each of the two datasets discussed in Example 5.5, apply both the upward
and downward EWMA charts for detecting variance shifts deﬁned by (5.12),
(5.16), and (5.17). In each chart, use ARL 0=200 and λ=0.05. Summarize
your results.
5.15 For the four datasets considered in Example 5.6, apply the upward EWMA chart
deﬁned by (5.12) with the upper control limit Uin (5.18), λ=0.3, and ρU=
3.702. Generate a ﬁgure similar to Figure 5.10. Summarize your results and
compare these results with those in Example 5.6.
5.16 For the batch data discussed in Exercise 4.15, apply the EWMA chart deﬁned
by (5.20) and (5.22) with λ=0.1 and ρU=2.836 for detecting possible upward
variance shifts. The related production process is assumed to have the IC distri-
bution N(1,0.52). From Example 5.7, the EWMA chart described above has the
ARL 0value of 400. Summarize your results.
5.17 For the batch data discussed in Exercise 4.15, besides the EWMA chart con-
sidered in the previous exercise for detecting upward variance shifts, apply the
two-sided EWMA chart based on the sample means Xnfor detecting possible
process mean shifts as well. The formulas of its control limits can be found in
Example 5.7. In this chart, choose λ=0.1 and ρ=2.731 so that its ARL 0is also
400. Summarize your results from this joint monitoring scheme.
5.18 Reproduce the results presented in the ﬁrst and last rows of Table 5.5.
5.19 For the data considered in Exercise 4.21, apply the self-starting two-sided
EWMA chart deﬁned by (5.25) and (5.27) with λ=0.2 and ARL 0=200. Sum-
marize your results.
5.20 Assume that a production process has the IC distribution N(0,1), and the ﬁrst
30 observations obtained for phase II process mean monitoring are listed below.
0.0,−2.3, 0.6,−1.0,−0.2, 0.3, 0.5,−0.4, 0.3,−0.5,
−0.9,−0.5, 1.0,−0.9, 1.5, 1.4, 0.0, 2.2, 2.7, 0.7,
−0.4,−0.8,−0.1, 0.0, 0.3,−1.0, 2.5, 1.3, 0.3,−0.3.
Use the adaptive EWMA chart discussed in Subsection 5.4.2 with the following
speciﬁcations:
(i)ARL 0=100, η(en)=η1(en),(µ1,µ2)=(0.25, 4), and ν=0.05,
(ii)ARL 0=100, η(en)=η1(en),(µ1,µ2)=(1.0, 4), and ν=0.05,
(iii) ARL 0=100, η(en)=η1(en),(µ1,µ2)=(0.25, 6), and ν=0.05,
(iv) ARL 0=100, η(en)=η2(en),(µ1,µ2)=(0.25, 4), and ν=0.05,
(v)ARL 0=100, η(en)=η2(en),(µ1,µ2)=(1.0, 4), and ν=0.05,
(vi) ARL 0=100, η(en)=η2(en),(µ1,µ2)=(0.25, 6), and ν=0.05.
Summarize your results.Chapter 6
Univ ariate Control Charts by
Change-Point Detection
6.1 Introduction
From the description in the previous three chapters about the statistical process con-
trol (SPC) problem and various SPC control charts, we know that a major goal of SPC
is to monitor a production process to make sure that the process runs stably. When the
process runs stably, the distribution of its observations satisﬁes the requirements re-
lated to the quality of design and it remains unchanged. This distribution is called the
in-control (IC) process distribution in the SPC literature. In cases when the process
distribution changes from the IC distribution to another distribution (i.e., the out-of-
control (OC) distribution) at an unknown time point, the process becomes OC. An
SPC control chart should detect such a shift as soon as possible. From this descrip-
tion of the SPC problem, we can see that the process observations have a common
distribution (i.e., the IC distribution) before the shift, and they have another common
distribution (i.e., the OC distribution) after the shift. In SPC, our major goal is to
detect any distributional shift as quickly as possible, and to locate the shift position
accurately as well.
In the statistical literature, there is a research area called change-point detection
(CPD) that is closely related to the SPC problem described above. In CPD, we are
concerned about a sequence of random variables. The distribution of the ﬁrst part
of the random variables is assumed to be the same, the distribution of the remaining
part of the random variables is assumed to be the same as well, but the distribution of
the ﬁrst part of the random variables and the one of the remaining random variables
are assumed to be different. Then, the speciﬁc position in the sequence at which
the distribution of the random variables changes from one to the other is called a
change-point. In CPD, our major goal is to estimate the change-point position. See,
for instance, Gombay (2003), Hinkley (1970), Smith (1975), Worsley (1983, 1986),
and Yao (1987) for a more detailed description.
In CPD, the sample size is usually ﬁxed. When the two related distributions are
assumed to have some parametric forms, the change-point is often estimated by the
maximum likelihood estimation method (cf., Subsection 2.7.2). In phase I SPC, the
size of a set of observations obtained for SPC analysis is also ﬁxed. So, the CPD
methods can be applied to the phase I SPC problem directly. In phase II SPC, the
number of process observations increases sequentially over time. In such cases, con-
225226 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
ventional CPD methods cannot be applied to the phase II SPC problem directly.
Instead, they should be modiﬁed properly for handling cases with sequentially in-
creasing numbers of observations.
In recent years, CPD methodologies have been modiﬁed and applied to the SPC
problem (cf., Hawkins et al., 2003; Hawkins and Zamba, 2005a,b). Compared to
the three types of commonly used SPC control charts (i.e., the Shewhart charts, the
CUSUM charts, and the EWMA charts), control charts based on CPD, which are
called CPD charts in this book, have the advantage that they are efﬁcient for detecting
small and persistent shifts and can provide an estimator of the shift position as well
at the same time when they give a shift signal. The Shewhart charts, although they
can also tell us the shift position when they give a shift signal, are inefﬁcient for
detecting small and persistent shifts. On the other hand, the CUSUM and EWMA
charts, although they are efﬁcient for detecting small and persistent shifts, usually
cannot provide an efﬁcient estimator of the shift position when they give a shift
signal. With these control charts, to estimate the shift position, a separate change-
point detection procedure is often needed after a shift signal is delivered by them
(cf., Samuel and Pignatiello, 2001).
In this chapter, we ﬁrst describe some fundamental CPD methodologies, and then
discuss some recent CPD control charts for detecting mean and/or variance shifts of
univariate processes. Our discussion will mainly focus on the case when the IC and
OC process distributions are normal. Process monitoring by CPD charts in cases
when the processes are multivariate and their distributions are normal will be dis-
cussed in Chapter 7. Cases when the process distribution is nonparametric will be
discussed in Chapters 8 and 9. Furthermore, similar to the CUSUM and EWMA
charts, it would be more economical to use the CPD charts with individual observa-
tion data, although they can be easily applied to batch data.
6.2 Univariate Change-Point Detection
In this section, we describe some fundamental CPD methods in univariate cases.
These methods should be useful for phase I SPC. They can also be modiﬁed properly
for phase II SPC, which will be discussed in Section 6.3. Our description in this sec-
tion is divided into two parts. In Subsection 6.2.1, some CPD methods for detecting
a single change-point are described. Cases when multiple change-points are present
are discussed in Subsection 6.2.2.
6.2.1 Detection of a single change-point
Assume that {X1,X2,..., Xn}arenindependent random variables, {X1,X2,..., Xr}
have a common pdf (or pmf) f(x;θ0), and{Xr+1,Xr+2,..., Xn}have another com-
mon pdf (or pmf) f(x;θ1), where 1 ≤r≤n−1 is an unknown integer, f(x,θ)is a
parametric pdf (or pmf) with parameter θ, and θ0/ne}ationslash=θ1are two different values of θ.
Then, ris the change-point, and the major goal of CPD is to estimate the value of r
based on the observations {X1,X2,..., Xn}. In cases when the values of θ0andθ1are
unknown, they also need to be estimated. When θ0andθ1are the means of f(x;θ0)UNIV ARIATE CHANGE-POINT DETECTION 227
andf(x;θ1), respectively, the random variables {X1,X2,..., Xn}can be described by
the model
Xi=/braceleftbigg
θ0+εi,ifi=1,2,..., r,
θ1+εi,ifi=r+1,r+2,..., n,(6.1)
where{ε1,ε2,..., εn}is a sequence of i.i.d. random variables with a common pdf
(or pmf) f(x;0). Equation (6.1) describes the situation when {X1,X2,..., Xn}have a
mean shift from θ0toθ1at the unknown change-point r.
In this section, we assume that the parametric pdf (or pmf) f(x;θ)is given be-
forehand. In such cases, the likelihood function of the change-point problem is
L(r,θ0,θ1;X1,X2,..., Xn)=[Πr
i=1f(Xi;θ0)]×/bracketleftbig
Πn
i=r+1f(Xi;θ1)/bracketrightbig
.
The log-likelihood function is
log(L(r,θ0,θ1;X1,X2,..., Xn))=r
∑
i=1log(f(Xi;θ0))+n
∑
i=r+1log(f(Xi;θ1)).(6.2)
In the case when both θ0andθ1are known, the maximum likelihood estimator
(MLE) of the change-point ris deﬁned by
/hatwider=arg max
1≤r≤n−1log(L(r,θ0,θ1;X1,X2,..., Xn)). (6.3)
Hinkley (1970) studied the asymptotic distribution of the MLE /hatwider. Worsley (1986)
provided a conﬁdence interval for rand a hypothesis testing procedure for testing
the existence of the change-point in cases when the pdf (or pmf) f(x;θ)belonged to
the exponential family.
In cases when {X1,X2,..., Xr}have the normal distribution N(µ0,σ2)and
{Xr+1,Xr+2,..., Xn}have the normal distribution N(µ1,σ2), where µ0/ne}ationslash=µ1are two
different constants, the random variables {X1,X2,..., Xn}have a change-point in their
means at r, and their variances are unchanged. In such cases, it can be checked that
the log-likelihood function deﬁned in (6.2) becomes
log/parenleftbig
L(r,µ0,µ1,σ2;X1,X2,..., Xn)/parenrightbig
=−nlog/parenleftig√
2πσ/parenrightig
−1
2σ2/bracketleftigg
r
∑
i=1(Xi−µ0)2+n
∑
i=r+1(Xi−µ1)2/bracketrightigg
.
Thus, the negative log-likelihood function is proportional to
/tildewideS2
r=r
∑
i=1(Xi−µ0)2+n
∑
i=r+1(Xi−µ1)2
=r
∑
i=1/bracketleftbig
(Xi−µ0)2−(Xi−µ1)2/bracketrightbig
+n
∑
i=1(Xi−µ1)2. (6.4)
Therefore, the MLE of rdeﬁned in (6.3) becomes
/hatwider=arg min
1≤r≤n−1/tildewideS2
r=arg min
1≤r≤n−1r
∑
i=1/bracketleftbig
(Xi−µ0)2−(Xi−µ1)2/bracketrightbig
. (6.5)228 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
Ifµ0andµ1are both unknown, then conditional on r, their MLEs are respectively
Xr=1
rr
∑
i=1Xi, X′
r=1
n−rn
∑
i=r+1Xi.
In such cases, the MLE of rcan be computed by
/hatwider=arg min
1≤r≤n−1/hatwide/tildewideS2
r=arg max
1≤r≤n−1r(n−r)
n(Xr−X′
r)2, (6.6)
where
/hatwide/tildewideS2
r=r
∑
i=1(Xi−Xr)2+n
∑
i=r+1(Xi−X′
r)2
=n
∑
i=1(Xi−X)2−/bracketleftig
r(Xr−X)2+(n−r)(X′
r−X)2/bracketrightig
=n
∑
i=1(Xi−X)2−n
r(n−r)/bracketleftigg
r
∑
i=1(Xi−X)/bracketrightigg2
=n
∑
i=1(Xi−X)2−r(n−r)
n/parenleftig
Xr−X′
r/parenrightig2
. (6.7)
Example 6.1 Assume that there are 20 observations, the ﬁrst 10 of them are gener-
ated from the distribution N (0,1), and the remaining 10 observations are generated
from the distribution N (1,1). So, the sequence of the 20 observations has a mean
shift of size 1 at r +1=11. One realization of these observations is presented in the
second column of Table 6.1. First, we assume that µ0andµ1are known to be 0 and
1, respectively. Then, the MLE /hatwider can be computed by (6.5). To this end, the values
of{/tildewideS2
i,i=1,2,..., 19}are computed by (6.4) and presented in the third column of
Table 6.1, from which we can see that /hatwider=10. Now, let us assume that both µ0andµ1
are unknown. In such cases, the MLE /hatwider can be computed by (6.6). For that purpose,
the values of {/hatwide/tildewideS2
i,i=1,2,..., 19}are computed and presented in the fourth column
of Table 6.1, from which we also obtain /hatwider=10. In the latter case, we can compute
the MLEs of µ0andµ1to be
/hatwideµ0=X/hatwider=1
/hatwider/hatwider
∑
i=1Xi=−0.018,/hatwideµ1=X′
/hatwider=1
n−/hatwidern
∑
i=/hatwider+1Xi=1.234.
Hawkins (1977) discussed the hypothesis testing problem regarding a loca-
tion shift in a sequence of normally distributed independent random variables
{X1,X2,..., Xn}, which is discussed below. The null and alternative hypotheses of
the problem can be formulated as
H0:Xi∼N(µ0,σ2), fori=1,2,..., n,UNIV ARIATE CHANGE-POINT DETECTION 229
Table 6.1 Thesecond column presents a sequence of 20 observations, and the third and fourth
columns present the corresponding values of {/tildewideS2
i,i=1,2,..., 19}and{/hatwide/tildewideS2
i,i=1,2,..., 19},
respectively.
i Xi/tildewideS2
i/hatwide/tildewideS2
i
1 -0.502 18.398 16.03
2 0.132 17.661 15.929
3 -0.079 16.503 15.3
4 0.887 17.277 16.084
5 0.117 16.511 15.68
6 0.319 16.148 15.494
7 -0.582 13.984 13.873
8 0.715 14.413 14.227
9 -0.825 11.763 11.672
10 -0.36 10.043 9.494
11 1.09 11.223 10.586
12 1.096 12.415 11.502
13 0.798 13.012 11.616
14 1.74 15.492 13.583
15 1.123 16.739 14.153
16 0.971 17.68 14.349
17 0.611 17.902 13.598
18 1.511 19.924 14.685
19 0.086 19.096 9.639
20 3.31 - -
versus
H1:Xi∼/braceleftbigg
N(µ0,σ2),fori=1,2,..., r,
N(µ1,σ2),fori=r+1,r+2,..., n,
where 1≤r≤n−1 is an unknown change-point. In cases when σ2is known, it can
be checked that the well-known likelihood ratio test (LRT) statistic Λ(X 1,X2,..., Xn)
(cf., Subsection 2.7.3) has the expression
−2σ2log(Λ(X 1,X2,..., Xn))= S2
n−min
1≤r≤n−1/hatwide/tildewideS2
r=S2
n−/hatwide/tildewideS2
/hatwider,
where S2
n=∑n
i=1(Xi−X)2and/hatwide/tildewideS2
ris deﬁned by (6.7). By the relationship that
S2
n=/hatwide/tildewideS2
r+T2
r,
where
T2
r=r(n−r)
n/parenleftig
Xr−X′
r/parenrightig2
=n
r(n−r)/bracketleftigg
r
∑
i=1(Xi−X)/bracketrightigg2
,
we ha ve
−2σ2log(Λ(X 1,X2,..., Xn))= max
1≤r≤n−1T2
r.230 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
Therefore, the LRT test is equivalent to the test using the test statistic
U=max
1≤r≤n−1|Tr|, (6.8)
andH1can be rejected if the observed value of Uis too large. To make formal deci-
sions about the null and alternative hypotheses using Udeﬁned in (6.8), we still need
to derive its distribution under H0(i.e., its null distribution). To this end, Hawkins
(1977) derived formulas for the null distributions of both Uand/hatwider, which were un-
fortunately too complicated to use in practice. However, these null distributions can
always be approximated well using numerical simulations.
In cases when σ2is unknown, it can be checked that the LRT statistic
Λ(X 1,X2,..., Xn)is a strictly decreasing function of
W=max
1≤r≤n−1|Tr|//hatwide/tildewideSr. (6.9)
Therefore, Wcan be used as a test statistic, and H1can be rejected if the Wvalue is
too large. Because Win (6.9) is a strictly increasing function of
V=max
1≤r≤n−1|Tr|/Sn, (6.10)
Vcan also be used as a test statistic for testing the hypotheses H0andH1. Wors-
ley (1979) derived the null distribution of Vin (6.10). Again, the related formulas
are complicated. In practice, the null distribution of Vcan be approximated using
numerical simulations instead.
The point estimation and hypothesis testing methods discussed above are for han-
dling the case when the random variables (X1,X2,..., Xn)are independent of each
other. Kokoszka and Leipus (1998) showed that the MLE /hatwiderdeﬁned in (6.6) was also
statistically consistent in various cases when (X1,X2,..., Xn)are correlated. For re-
lated discussions, see Box and Tiao (1965), Gombay (2008), Henderson (1986), Kim
(1996), Ling (2007), and the references cited therein.
6.2.2 Detection of multiple change-points
In this subsection, we brieﬂy discuss the case when multiple change-points are pos-
sible in the sequence of nindependent random variables {X1,X2,..., Xn}. Assume
that the sequence consists of ksegments, random variables in the ﬁrst segment
{X1,X2,..., Xr1}have the same pdf (or pmf) f(x,θ1), those in the second segment
{Xr1+1,Xr1+2,..., Xr2}have the same pdf (or pmf) f(x,θ2),..., and those in the k-
th segment {Xrk−1+1,Xrk−1+2,..., Xn}have the same pdf (or pmf) f(x,θk), where
f(x,θ)is a pre-speciﬁed parametric pdf (or pmf), (θ1,θ2,..., θk)arekdifferent val-
ues of θ, and
1≤r1<r2<...< rk−1≤n−1
arek−1 change-points. If k=2, then there is only one change-point and the CPD
problem becomes the one discussed in the previous subsection. In this subsection,
we focus mainly on cases when at least two change-points are present (i.e., k>2).UNIV ARIATE CHANGE-POINT DETECTION 231
In cases when f(x,θ)is the pdf of a normal distribution and θis its mean µ, by
the CPD model described above, the random variables {X1,X2,..., Xn}have change-
points in their means and their variances are unchanged. In such cases, we can de-
scribe{X1,X2,..., Xn}by
Xi=

µ1+εi,ifi=1,2,..., r1
µ2+εi,ifi=r1+1,r1+2,..., r2
......
µk+εi,ifi=rk−1+1,rk−1+2,..., n,(6.11)
where{εi,i=1,2,..., n}are i.i.d. with the common distribution N(0,σ2), and
µ1,µ2,..., µkarekdifferent values of µ. To handle this CPD problem, a classic
method is the regression tree approach proposed by Breiman et al. (1984), which uses
a recursive binary splitting algorithm to estimate the change-points. This method is
computationally fast. But, as pointed out by Hawkins (2001), it requires the change-
points to have a hierarchic structure, and therefore it may not yield optimal estima-
tors. Next, we describe the dynamic programming (DP) algorithm that was proposed
by Hawkins (2001) for estimating multiple change-points.
For 0≤h<m≤n, let Q(h, m)be the−2 times the maximized log-likelihood
based on the sequence of random variables {Xh+1,Xh+2,..., Xm}. Then, we have
Q(0, n)
=−2max
r,µlog(L(r,µ;X1,X2,..., Xn))
=−2max
r/bracketleftbigg
max
µlog(L(r,µ;X1,X2,..., Xn))/bracketrightbigg
=min
rk
∑
j=1Q(r j−1,rj),
where r=(r 1,r2,..., rk−1)′,µ=(µ1,µ2,..., µk)′,r0=0, and rk=n. From the above
expression, we can notice the so-called “principle of optimality” (cf., Bellman and
Dreyfus, 1962), described as follows. To split the sequence of nrandom variables into
ksegments in an optimal way, the following recursive algorithm can be used. First,
the estimator of the last change-point rk−1, denoted as/hatwiderk−1, can be determined from
the original sequence {X1,X2,..., Xn}. Then, the estimators of the remaining k−
2 change-points can be obtained from the sequence {X1,X2,..., X/hatwiderk−1}by splitting
it into k−1 segments. To determine the estimators /hatwiderk−1,/hatwiderk−2,...,/hatwider1using such a
recursive algorithm, we can make use of the following results. Let X2(j,m)be the
−2 times the maximized log-likelihood by ﬁtting a j-segment model (i.e., k=jin
(6.11)) to the sequence {X1,X2,..., Xm}, where j≤mare two integers. Then, after
some constants are omitted, we have the following recursive relationship:
X2(j,m)= min
0<h<m/parenleftbig
X2(j−1,h)+ Q(h, m)/parenrightbig
, (6.12)
where X2(1,m) = Q(0, m). Based on the “principle of optimality” and (6.12),232 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
Hawkins (2001) proposed the DP algorithm to ﬁnd the estimators /hatwiderk−1,/hatwiderk−2,...,/hatwider1,
which is described in the box below.
Dynamic Programming Algorithm
Assume that the sequence of independent random variables {X1,X2,..., Xn}
satisﬁes the change-point model (6.11). Then, the change-points r1,r2,..., rk−1
can be estimated recursively as follows.
Step 1 Compute X2(j,m), for all j=1,2,..., k−1 and m=j,j+1,..., n−1.
Step 2 Forℓ=1,2,..., k−1, search the minimizer of
min
k−ℓ≤h</hatwiderk−ℓ+1/parenleftbig
X2(k−ℓ,h)+ Q(h,/hatwiderk−ℓ+1)/parenrightbig
,
where/hatwiderk=n. The searched minimizer is deﬁned as the estimator of rk−ℓ, denoted
as/hatwiderk−ℓ, and µk−ℓ+1can be estimated accordingly by the MLE /hatwideµk−ℓ+1obtained
from Q(/hatwiderk−ℓ,/hatwiderk−ℓ+1). After/hatwider1and/hatwideµ2are deﬁned,/hatwideµ1can be deﬁned from Q(0,/hatwider1)
by the MLE of µ1.
Hawkins (2001) proposed the above DP algorithm in cases when f(x,θ)belongs
to the exponential family (cf., (4.29) in Subsection 4.4.1). In cases when f(x,θ)is
the pdf of a normal distribution, then for any 0 ≤h<m≤n, we can replace Q(h, m)
by
W(h,m)=m
∑
i=h+1(Xi−Xh,m)2,
where Xh,mis the sample mean of {Xh+1,Xh+2,...,Xm}.
Example 6.2 Assume that there are n =30observations, the ﬁrst 10 of them are
generated from the distribution N (0,0.52), the second 10 observations are generated
from the distribution N (1,0.52), and the remaining 10 observations are generated
from the distribution N (0,0.52). These observations are shown in Figure 6.1(a) by
the dark dots. So, there are k =3segments, and k −1=2change-points at r 1=10
and r 2=20in this dataset. To detect the change-points using the DP algorithm, we
ﬁrst compute/braceleftbig
X2(2,h)+ Q(h, n),h=2,3,..., n−1/bracerightbig
.
This sequence is shown in Figure 6.1(b) by the solid curve. It can be seen that the
minimum of this sequence is reached at h =20. So, we have /hatwider2=20, and/hatwideµ3=
X20,30=−0.065. To estimate r 1, we compute the sequence
/braceleftbig
X2(1,h)+ Q(h,/hatwider2),h=1,2,...,/hatwider2−1/bracerightbig
,
which is shown in Figure 6.1(b) by the dashed curve. It can be seen that the minimum
of this sequence is reached at h =10. So, we have /hatwider1=10, and/hatwideµ2=X10,20=1.117.
Finally, we have /hatwideµ1=X0,10=−0.009.CONTROL CHARTS BY CHANGE-POINT DETECTION 233
0 5 10 15 20 25 30−1.0 0.0 1.0 2.0
iXi
(a)0 5 10 15 20 25 300 2 4 6 8 10 12
h
(b)
Figure 6.1 (a) The ﬁrst 10 observations are generated from the N (0,0.52)distribution, the
second 10 observations are generated from the N (1,0.52)distribution, and the remaining 10
observations are generated from the N (0,0.52)distribution. All observations are independent
of each other. (b) The sequence {X2(2,h)+ Q(h, 30), h=2,3,..., 29}is shown by the solid
curve, and the sequence {X2(1,h)+ Q(h, 20), h=1,2,..., 19}is shown by the dashed curve.
In the DP algorithm, the number of change-points k−1 is assumed known. In
the literature, there is much discussion about estimation of k−1. Theoretically, this
is a difﬁcult problem because it is found that most test statistics proposed in the
literature for testing hypotheses about k−1 do not have asymptotic distributions (cf.,
Bhattacharya, 1994; Hinkley, 1970; Hawkins, 1977; Yao, 1987). However, a number
of practical approaches for estimating the number and locations of the change-points
are available. Most of these approaches treat k−1 as a parameter and estimate it
by a model selection approach (e.g., Fearnhead, 2006; Lavielle, 2005; Lavielle and
Moulines, 2000; Yao and Au, 1989).
Detection of multiple change-points in time series and other correlated data has
also been discussed in the literature. See, for instance, Choi et al. (2008), Lavielle
and Ludena (2000), Shao and Zhang (2010), and the references cited therein.
6.3 Control Charts by Change-Point Detection
In this section, we describe some CPD control charts for phase II SPC in cases when
process observations are univariate and follow normal distributions. Our description
is divided into three parts. Monitoring of process mean is discussed in Subsection
6.3.1, monitoring of process variance is discussed in Subsection 6.3.2, and joint mon-
itoring of both process mean and variance is discussed in Subsection 6.3.3.234 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
6.3.1 Monitoring of the process mean
Assume that the univariate quality characteristic of a production process is X, its
observations Xifollow the IC distribution N(µ0,σ2)when the process is IC, they
follow the OC distribution N(µ1,σ2)after the process mean shifts from µ0toµ1
at an unknown time point r+1. The major goal of phase II SPC is to detect such
a distributional shift as soon as possible. From this description of the phase II SPC
problem for monitoring the process mean, it can be seen that it is related to the CPD
problem discussed in the previous section. But, the two problems have the following
substantial difference. In the CPD problem (6.1), the sample size nis ﬁxed; but, the
sample size in the phase II SPC problem keeps increasing until a signal of the mean
shift is given. Because of this difference, the CPD methods cannot be applied to the
phase II SPC problem directly. Instead, they need to be modiﬁed properly.
In cases when the parameters µ0,µ1, and σare all known, it has been demon-
strated in the literature that the CUSUM charts have some optimality properties. See
Subsection 4.2.4 for a related discussion. In practice, however, these parameters are
often unknown. Although the self-starting CUSUMs and the adaptive CUSUMs dis-
cussed in Section 4.5 can help solve the problem in such cases, these CUSUM charts
would not be optimal any more. Furthermore, most CUSUM charts do not provide a
good estimator of the shift time point τ=r+1 at the time when they give a signal of
the process distributional shift. In cases when estimation of τis desirable, then it is
often estimated by a separate CPD procedure, after a signal of process distributional
shift is given by a CUSUM chart (cf., Pignatiello and Samuel, 2001). In this section,
we introduce a CPD control chart that was ﬁrst proposed by Hawkins et al. (2003)
for monitoring the process mean. This chart can handle the case when all parameters
µ0,µ1, and σare unknown and it can give an estimator of τat the same time when it
gives a signal of process mean shift.
Assume that nis the current time point, and {X1,X2,..., Xn}are the observed
data up to the current time point. Then, from (6.8) and (6.9), the LRT statistic for
testing a possible mean shift at τis
Tmax,n=max
1≤j≤n−1/radicalbigg
j(n−j)
n/vextendsingle/vextendsingle/vextendsingleXj−X′
j/vextendsingle/vextendsingle/vextendsingle/slashig/hatwide/tildewideSj, (6.13)
where/hatwide/tildewideSjis deﬁned in (6.7). Clearly, Tmax,nis exactly the same as Wdeﬁned in (6.9).
We use a different notation here to distinguish the SPC problem discussed in this
section from the CPD problem discussed in the previous section. By using Tmax,n, a
mean shift can be signaled if
Tmax,n>hn, (6.14)
where hn>0 is a control limit that may depend on n. From the above description,
the charting statistic Tmax,nis mainly for detecting a change-point in the observations
{X1,X2,..., Xn}. In this book, such control charts are called CPD charts.
Example 6.3 For each 1≤j≤n−1, let
Tjn=/radicalbigg
j(n−j)
n/parenleftig
Xj−X′
j/parenrightig/slashig/hatwide/tildewideSj.CONTROL CHARTS BY CHANGE-POINT DETECTION 235
Then,
Tmax,n=max
1≤j≤n−1|Tjn|,
and it is easy to see that T jnis just the pooled sample t-test statistic deﬁned in (2.36)
in Subsection 2.7.3 for testing the equality of two population means (i.e., treating
{X1,X2,..., Xj}and{Xj+1,Xj+2,..., Xn}as two samples from two populations). Un-
der the assumption that the two population means are the same (i.e., there is no
mean shift in the current process), each T jnshould have the t n−2distribution, which
has a mean of 0. If there is a mean shift of size δat the(j0+1)-th time point,
then T j0nwould have a mean of g( δ)/ne}ationslash=0, where g(·) is a speciﬁc function. When
j moves away from j 0, the mean of the distribution of T jnwould move away from
g(δ)towards 0. Therefore, when the process is IC, the distributions of |Tjn|, for
1≤j≤n−1, are all the same, and consequently T max,nwould take the value of
any one of {|Tjn|,1≤j≤n−1}by chance. On the other hand, when the process has
a mean shift of size δat the(j0+1)-th time point, the mean of |Tj0n|would be larger
than the means of other variables in the sequence {|Tjn|,1≤j≤n−1}; thus, T max,n
would most probably take the value of |Tj0n|which is on average larger than the IC
means of {|Tjn|,1≤j≤n−1}. Therefore, T max,nis effective in detecting the mean
shift. To demonstrate these results, the plot (a) in Figure 6.2 shows 100 observa-
tions generated from the N (0,1)distribution, which can be regarded as the observed
data from an IC process with the IC distribution of N (0,1). The computed values of
{|Tjn|,1≤j≤99}are shown in plot (b), from which it can be seen that these values
are similar and there is no obvious pattern among them. The plot (c) shows the same
data as those in plot (a), except that the value of each of the last 50 observations was
increased by 1. These modiﬁed observations can be regarded as the observed data
from a process with a mean shift of size δ=1which occurred at the 51st time point.
The corresponding values of {|Tjn|,1≤j≤99}are shown in plot (d), from which
we can see that this sequence peaks around the true shift time point and it tends to 0
when j moves away from the true shift time point.
From the deﬁnition of Tmax,n, the CPD control chart (6.13)–(6.14) can be used
only when n≥3 because the quantities/hatwide/tildewideSj, for 1≤j≤n−1, are 0 or undeﬁned
otherwise. Therefore, to use a CPD control chart for phase II process monitoring, we
should collect a number of IC observations beforehand. This, however, is not a big
constraint of CPD control charts for the following reasons. Recall that conventional
Shewhart, CUSUM, and EWMA control charts usually assume that the IC process
mean and variance are known. In reality, these IC parameters are actually estimated
from IC data collected at the end of a phase I SPC analysis. See Section 3.1 for a
related discussion. If the size of the IC data is small, then the accuracy of these IC
parameter estimators is not guaranteed. In such cases, the related control charts are
unreliable (cf., Example 4.11 in Section 4.5.1). Therefore, in order to have a reliable
phase II process monitoring, these conventional control charts usually require a quite
large IC dataset. As a comparison, the CPD control chart (6.13)–(6.14) does not
assume that the IC process mean and variance are known. Hawkins et al. (2003) have
shown that its performance is quite reliable when n0−1 IC observations are collected
before phase II process monitoring, where n0could be as small as 10. In such cases,
if these n0−1 IC observations are treated as a part of phase II data, then the deﬁnition236 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
0 20 40 60 80 100−2 −1 0 1 2
nXn
(a)0 20 40 60 80 1000.0 0.1 0.2 0.3 0.4
n□Tjn□
(b)
0 20 40 60 80 100−2 −1 0 1 2 3
nXn
(c)0 20 40 60 80 1000.0 0.2 0.4 0.6 0.8
n□Tjn□
(d)
Figure 6.2 (a) A dataset consisting of 100 observations generated independently from the
distribution N (0,1). (b) The computed values of {|Tjn|,1≤j≤99}from the data shown in
plot (a). (c) The same dataset as that in plot (a), except that the value of each of the last 50
observations was increased by 1. (d) The computed values of {|Tjn|,1≤j≤99}from the data
shown in plot (c).
ofTmax,nshould be modiﬁed to
Tmax,n= max
n0−1≤j≤n−1/radicalbigg
j(n−j)
n/vextendsingle/vextendsingle/vextendsingleXj−X′
j/vextendsingle/vextendsingle/vextendsingle/slashig/hatwide/tildewideSj. (6.15)
After a signal is given by the control chart at the time point n, the change-point
rcan be estimated by the maximizer of the maximization problem (6.13) or (6.15),
denoted as/hatwider, and µ0,µ1, and σcan be estimated by X/hatwider,X′
/hatwider, and/hatwide/tildewideS/hatwider/√n−2, respec-
tively. Note that these estimators can be obtained immediately after the signal is
given, without any extra computation, which cannot be achieved by the conventional
control charts discussed in the previous three chapters.CONTROL CHARTS BY CHANGE-POINT DETECTION 237
Next, we discuss the determination of the control limit hn. In phase I SPC, the
sample size nis often ﬁxed. In such cases, for a given signiﬁcance level α>0, it is
reasonable to choose hnsuch that, when the process is IC, we have
P(Tmax,n>hn)≤α. (6.16)
Namely, the false signal rate is controlled at the level of α. Because the distribution
ofTmax,nis quite complicated, the exact value of hnsatisfying (6.16) is difﬁcult to
compute. See a related discussion in Subsection 6.2.1 about the statistics WandV
deﬁned in (6.9) and (6.10). In the literature, several approximations to hnhave been
proposed. One simple approximation is based on the following Bonferroni inequality
P(Tmax, n>hn)≤n−1
∑
j=1P/parenleftigg/radicalbigg
j(n−j)
n/vextendsingle/vextendsingle/vextendsingleXj−X′
j/vextendsingle/vextendsingle/vextendsingle/slashig/hatwide/tildewideSj>hn/parenrightigg
= (n−1)P(|tn−2|>hn),
where tn−2denotes a random variable that has the tdistribution with n−2 degrees
of freedom. By the above expression, hncan be chosen the (1−α/[2(n−1)])-th
quantile of the tn−2distribution. Other approximations to hnthat satisfy (6.16) are
available. See Irvine (1982), Worsley (1979), and Worsley (1982) for related discus-
sions.
In phase II SPC, the observation Xnis collected only in cases when there is no
signal of shift at the (n−1)-th time point. So, in such cases, a more reasonable way
is to choose hnsuch that
P(Tmax,n>hn|no signal before time n)≤α. (6.17)
The expression (6.17) implies that, conditional on the fact that there is no signal be-
fore the n-th time point, the chance to have a false signal at the nth time point is
not larger than α. In such cases, it is obvious that the ARL 0value of the correspond-
ing control chart is 1/ α. Because the conditional distribution of Tmax,ninvolved in
(6.17) is complicated to derive, determination of hnby (6.17) is difﬁcult analytically.
But, we can always use Monte Carlo simulations to calculate the value of hnthat
satisﬁes (6.17). For instance, when α=0.05, 0.02, 0.01, 0.005, 0.002, and 0.001,
the corresponding ARL 0values of the control chart are 20, 50, 100, 200, 500, and
1000, respectively. In such cases, when n0=10 and ntakes various values between
10 and 200, the computed hnvalues of the CPD control chart (6.14)–(6.15) by 16
million replicated simulations are shown in Table 6.2, which is copied from Table 3
in Hawkins et al. (2003). From the table, it can be seen that, for each αvalue, the
value of hndecreases and then stabilizes when nincreases. So, in practice, we can
simply set hn=h200when n>200, and compute the value of hnby interpolation
when n0≤n≤200 and nis not listed in the table. An alternative approach is to
build a numerical relationship between hnand(α,n)based on some simulation re-
sults such as those in Table 6.2. One such numerical relationship given by Hawkins
et al. (2003) when n0=10 is
hn≈h∗
α/parenleftbigg
0.677+0.019log( α)+1−0.115log( α)
n−6/parenrightbigg
, (6.18)238 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
Table 6.2 Contr ol limits h nwhen n 0=10, the sample size n takes various values between 10
and 200, and the conditional false signal rate αequals 0.05, 0.02, 0.01, 0.005, 0.002, and
0.001. This table is copied from Table 3 in Hawkins et al. (2003).
α
n 0.05 0.02 0.01 0.005 0.002 0.001
10 3.662 4.371 4.928 5.511 6.340 7.023
11 3.242 3.908 4.424 4.958 5.697 6.284
12 3.037 3.677 4.167 4.664 5.350 5.890
13 2.909 3.530 3.997 4.468 5.110 5.608
14 2.821 3.424 3.875 4.326 4.931 5.397
15 2.756 3.344 3.780 4.211 4.786 5.229
16 2.704 3.281 3.704 4.121 4.671 5.093
17 2.663 3.228 3.642 4.047 4.576 4.977
18 2.628 3.183 3.587 3.981 4.494 4.885
19 2.599 3.146 3.542 3.926 4.425 4.799
20 2.575 3.115 3.503 3.880 4.367 4.730
22 2.535 3.060 3.437 3.800 4.264 4.610
24 2.504 3.019 3.386 3.736 4.187 4.514
26 2.479 2.985 3.343 3.685 4.119 4.440
28 2.459 2.957 3.308 3.643 4.065 4.375
30 2.440 2.933 3.279 3.609 4.024 4.324
35 2.408 2.888 3.223 3.539 3.937 4.223
40 2.385 2.855 3.184 3.492 3.873 4.147
45 2.368 2.832 3.152 3.454 3.828 4.095
50 2.355 2.811 3.128 3.426 3.791 4.053
60 2.335 2.785 3.094 3.383 3.737 3.989
70 2.324 2.765 3.071 3.355 3.702 3.946
80 2.315 2.752 3.052 3.333 3.677 3.918
90 2.310 2.741 3.040 3.318 3.656 3.895
100 2.302 2.735 3.030 3.307 3.640 3.875
125 2.300 2.717 3.011 3.281 3.611 3.844
150 2.300 2.710 2.997 3.264 3.591 3.821
175 2.300 2.703 2.993 3.257 3.579 3.804
200 2.300 2.700 2.985 3.248 3.570 3.794
where h∗
αis a constant depending on αand it equals the computed hnvalues when
n=10. Namely, it equals 3.662, 4.371, 4.928, 5.511, 6.340, and 7.023, respectively,
when αequals 0.05, 0.02, 0.01, 0.005, 0.002, and 0.001.
From (6.15), each time a new observation is obtained, it seems that most quan-
tities on the right-hand side of that equation need to be re-computed. Therefore, the
CPD chart (6.14)–(6.15) involves a great amount of computation. However, the in-
volved computation can be greatly reduced if certain quantities can be computed
recursively, which is described next. At the current time point n, assume that
Wn=n
∑
i=1Xi, S2
n=n
∑
i=1/parenleftbig
Xi−Xn/parenrightbig2,CONTROL CHARTS BY CHANGE-POINT DETECTION 239
where Xnis the sample mean of the observed data {X1,X2,...,Xn}. Then, WnandS2
n
can be computed recursively by the formulas
Wn=Wn−1+Xn,
S2
n=S2
n−1+ [(n−1)X n−Wn−1]2/slashig
[n(n−1)], forn≥n0.(6.19)
It is obvious that the equation (6.15) can be written as
Tmax,n= max
n0−1≤j≤n−1|Tjn|,
and it can be checked that
T2
jn=(n−2)V2
jn
S2n−V2
jn, (6.20)
where
V2
jn=(nWj−jWn)2
n j(n−j).
From (6.19) and (6.20), the value of Tmax,ncan be computed easily from the values of
{Wj,n0−1≤j≤n}andS2
n, which can be computed recursively by (6.19). Therefore,
the computation involved in the CPD control chart (6.14)–(6.15) is manageable.
Example 6.4 Assume that we collected n 0−1=9IC observations before phase II
process mean monitoring. These IC observations and the ﬁrst 21 phase II observa-
tions are presented in the second column of Table 6.3. Among the total of 30 observa-
tions, the ﬁrst 20 observations are actually generated from the N (0,1)distribution,
and the remaining 10 observations are actually generated from the N (2,1)distri-
bution. Therefore, this data simulate a production process that has the IC process
distribution N (0,1), and it has a mean shift of size 2 at the 21st time point (note:
r=20in the change-point model (6.1) in this case). The observed data and the com-
puted quantities W n, S2
n, Tmax,n, and h nthat are used in the construction of the CPD
control chart (6.14)–(6.15) are presented in Table 6.3, where W nand S2
nare computed
recursively by (6.19), T max,nis computed from {T2
jn}that is deﬁned in (6.20), and h n
is computed by the numerical approximation formula (6.18) when αis ﬁxed at 0.005
(i.e., the ARL 0value of the chart is ﬁxed at 1/0.005=200). From the table, it can be
seen that the ﬁrst signal of mean shift is given at the 24th time point because this is
the ﬁrst time that T max,n>hn. The observed data and the CPD control chart are also
shown in the two plots of Figure 6.3. From plot (b), we can see that h nstabilizes when
n increases, and the charting statistic T max,nkeeps increasing after the true shift time
point.
Because the CPD control chart (6.14)–(6.15) does not require the IC mean µ0,
the OC mean µ1, and the process variance σ2to be known, and it estimates all
these parameters simultaneously when it detects the mean shift, the chart would
be more sensitive to a mean shift if the shift occurs later, due to the fact that
there would be more information in the observed data about the IC process dis-
tribution in such cases. This result has been conﬁrmed by Hawkins et al. (2003)
in the numerical example described below. Assume that αtakes one of the values240 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
Table 6.3 Thesecond column presents a sequence of 30 observations, and the third, fourth,
ﬁfth, and sixth columns present the corresponding values of {Wn,n=9,10,..., 30},{S2n,n=
9,10,..., 30},{Tmax,n,n=10,11,..., 30}, and{hn,n=10,11,..., 30}.
n Xn Wn S2
nTmax,n hn
1 0.550 - - - -
2−0.842 - - - -
3 0.033 - - - -
4 0.524 - - - -
5−1.728 - - - -
6−0.278 - - - -
7 0.361 - - - -
8−0.591 - - - -
9 0.976−0.995 12.706 - -
10−1.446−2.440 14.310 1.005 5.393
11 0.295−2.145 14.575 0.473 4.950
12 0.555−1.591 15.090 0.721 4.654
13−0.499−2.089 15.214 0.471 4.443
14 0.196−1.893 15.332 0.577 4.285
15−0.456−2.349 15.428 0.443 4.162
16−0.363−2.712 15.467 0.368 4.063
17−0.157−2.869 15.468 0.367 3.982
18−0.765−3.634 15.804 0.590 3.915
19−1.166−4.800 16.684 1.115 3.858
20−0.323−5.123 16.689 0.993 3.810
21 1.650−3.473 20.150 1.985 3.767
22 1.413−2.060 22.528 2.637 3.730
23 0.410−1.650 22.771 2.498 3.698
24 3.690 2.040 36.329 3.707 3.669
25 2.564 4.603 42.227 4.418 3.643
26 4.668 9.271 61.555 5.926 3.620
27 2.357 11.627 65.407 6.112 3.598
28 1.638 13.265 66.812 5.915 3.579
29 2.569 15.834 71.050 6.325 3.562
30 2.029 17.863 73.175 6.475 3.546
{0.02, 0.01,0.005, 0.002}. Then, the corresponding ARL 0value of the CPD control
chart (6.14)–(6.15) is one of the values {50, 100, 200, 500}. We consider a shift of
the size δ∈ {0, 0.25, 0.5,1.0,2.0} occurring at τ∈ {10, 25,50,100, 250}. Then, in
various cases considered, the computed ARL 1values of the CPD control chart using
the approximation formula (6.18) for computing the control limit hnare presented in
Table 6.4. From the table, it can be seen that (i) when δ=0 (i.e., the process is IC),
the actual ARL 0values are close to 1/ α, (ii) when δis larger, the ARL 1value tends
to be smaller, as expected, and (iii) when δ>0 and τis larger (i.e., the mean shift
occurs later), the ARL 1value tends to be smaller as well.
When the IC mean µ0and the IC variance σ2are unknown, the self-starting
CUSUM chart discussed in Subsection 4.5.1 can also be used. It should have a rea-CONTROL CHARTS BY CHANGE-POINT DETECTION 241
0 5 10 15 20 25 30−2 −1 0 1 2 3 4 5
nXn
(a)10 15 20 25 300 2 4 6 8
nTmax□□n
(b)
Figure 6.3 (a) The ﬁrst 20 observations are generated from the N (0,1)distribution, and the
remaining 10 observations are generated from the N (2,1)distribution. All observations are
independent of each other. (b) The CPD control chart (6.14)–(6.15) (solid line) with n 0−1=9
and the control limit h ncomputed by the numerical approximation formula (6.18) when α=
0.005(dashed line).
sonably good performance in cases when the shift size δis known and its allowance
constant kis chosen to be δ/2. Hawkins et al. (2003) made a numerical comparison
about the performance of such a self-starting CUSUM chart and the CPD control
chart (6.14)–(6.15). To make the two charts comparable, the two-sided version of the
self-starting CUSUM chart was considered, because the CPD control chart (6.14)–
(6.15) can detect arbitrary mean shifts. In the self-starting CUSUM chart, kwas
chosen to be 0.25, 0.5, or 1.0, and the ARL 0value was speciﬁed to be 100 or 500. In
the CPD control chart, αwas chosen accordingly to be 0.01 or 0.002. In both charts,
it was assumed that the ﬁrst 9 observations were IC (i.e., n0−1=9). The computed
ARL 1values of the two charts for detecting a mean shift of size δ∈[0,3]occurring
atτ=10 or 100 are shown in Figure 6.4. From the ﬁgure, it can be seen that the self-
starting CUSUM chart performs well only when its allowance constant kis carefully
chosen to match half of the shift size (i.e., δ/2) and when τis reasonably large. Its
performance may not be reliable when kandδ/2 are quite different or when the
mean shift occurs quite early. As a comparison, the CPD control chart is quite robust
to both the shift size and the shift time point.
6.3.2 Monitoring of the process variance
The CPD control chart discussed in the previous subsection is for detecting process
mean shifts only. As pointed out in previous chapters (e.g., Subsection 4.3.1), online
monitoring of the process variance is also important for ensuring product quality.242 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
Table 6.4 ARL 1values of the CPD control chart (6.14)–(6.15) when α∈ {0.02,0.01,0.005,
0.002} , and a shift of size δ∈{0,0.25,0.5,1.0,2.0}occurs at τ∈{10,25,50,100, 250} .
δ
α τ 0 0.25 0.5 1.0 2.0
0.02 10 54.5 51.8 43.3 21.3 4.1
25 54.2 46.7 30.8 9.4 2.4
50 53.8 42.8 23.3 7.0 2.1
100 54.7 41.4 19.4 6.0 1.9
250 58.7 33.4 16.6 6.3 1.8
0.01 10 99.3 95.9 82.4 39.1 5.3
25 99.4 86.9 55.2 13.4 2.8
50 99.2 76.3 38.2 8.8 2.3
100 99.7 69.3 28.5 7.6 2.2
250 96.9 55.4 23.9 7.0 2.1
0.005 10 195.9 186.2 168.3 84.9 7.0
25 196.6 174.7 113.9 20.4 3.3
50 196.3 154.9 68.7 11.2 2.7
100 196.9 131.3 42.2 9.4 2.5
250 194.8 99.0 29.7 8.2 2.3
0.002 10 535.8 531.1 492.7 280.9 10.8
25 538.7 504.3 357.5 43.7 4.3
50 539.5 457.8 195.4 15.7 3.4
100 542.8 373.1 77.3 12.3 3.0
250 546.2 222.9 43.3 10.8 2.8
Therefore, in the CPD framework, Hawkins and Zamba (2005a) proposed a control
chart for monitoring the process variance, which is described below.
Assume that the IC distribution of the quality characteristic XisN(µ0,σ2
0). After
an unknown time point τ, this distribution may shift to the OC distribution N(µ1,σ2
1),
where µ0/ne}ationslash=µ1are the IC and OC process means, σ2
0/ne}ationslash=σ2
1are the IC and OC pro-
cess variances, and all these parameters are unknown. Then, the major goal of phase
II SPC is to detect such a distributional shift as soon as it occurs. Note that the con-
trol charts for process variance monitoring discussed in Sections 3.2, 4.3, and 5.3 can
only be used in cases when the IC parameters µ0andσ2
0are known. Their perfor-
mance is good only in cases when their procedure parameters are properly chosen to
match the unknown OC parameters well, which is challenging to achieve. The self-
starting control charts and the adaptive control charts discussed in Sections 4.5 and
5.4 can help overcome these limitations. An alternative approach to overcome these
limitations is to adopt the CPD framework when handling the SPC problem, which
is discussed below.
The phase II SPC problem described above is closely related to the following
CPD problem. Assume that {X1,X2,..., Xn}is a sequence of independent process
observations up to the time point n. When the process is IC, these random variables
follow the distribution
Xi∼N(µ0,σ2
0), fori=1,2,..., n.CONTROL CHARTS BY CHANGE-POINT DETECTION 243
deltalog(ARL1)
0.0 0.5 1.0 1.5 2.0 2.5 3.00 1 2 3 4 5 6CPD
k=0.25
k=0.5
k=1.0
(a)deltalog(ARL1)
0.0 0.5 1.0 1.5 2.0 2.5 3.00 1 2 3 4 5 6CPD
k=0.25
k=0.5
k=1.0
(b)
deltalog(ARL1)
0.0 0.5 1.0 1.5 2.0 2.5 3.00 1 2 3 4 5 6CPD
k=0.25
k=0.5
k=1.0
(c)deltalog(ARL1)
0.0 0.5 1.0 1.5 2.0 2.5 3.00 1 2 3 4 5 6CPD
k=0.25
k=0.5
k=1.0
(d)
Figure 6.4 ARL 1values (in natural log scale) of the CPD control chart (6.14)–(6.15) (solid
curves) and the self-starting CUSUM chart (dotted, short-dashed, and long-dashed curves)
when the process mean shift size δchanges from 0 to 3. (a) α=0.01(or ARL 0=100) and
τ=10. (b) α=0.01(or ARL 0=100) and τ=100. (c) α=0.002(or ARL 0=500) and
τ=10. (d) α=0.002(or ARL 0=500) and τ=100.
When the process has a shift at a certain time point, they follow the distributions
Xi∼/braceleftbigg
N(µ0,σ2
0),fori=1,2,..., r
N(µ1,σ2
1),fori=r+1,r+2,..., n,
where ris the change-point, and τ=r+1 is the shift time point. If ris known, then244 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
it iseasy to check that the MLEs of µ0,µ1,σ2
0,and σ2
1are
/hatwideµ0=Xr,
/hatwideµ1=X′
r,
/hatwideσ2
0=1
r−1r
∑
i=1/parenleftbig
Xi−Xr/parenrightbig2,
/hatwideσ2
1=1
n−r−1n
∑
i=r+1/parenleftig
Xi−X′
r/parenrightig2
.
Under the assumption that σ2
0=σ2
1, the MLE of the common variance σ2is
/hatwideσ2=1
n−2/hatwide/tildewideS2
r,
where/hatwide/tildewideS2
ris deﬁned in (6.7). Then, Bartlett (1937, 1955) and Bartlett and Kendall
(1946) derived the following likelihood ratio statistic
Brn=/bracketleftbigg
(r−1)log/parenleftbigg/hatwideσ2
/hatwideσ2
0/parenrightbigg
+(n−r−1)log/parenleftbigg/hatwideσ2
/hatwideσ2
1/parenrightbigg/bracketrightbigg/slashbigg
Crn, (6.21)
for testing the hypotheses
H0:σ2
0=σ2
1 versus H1:σ2
0/ne}ationslash=σ2
1, (6.22)
where
Crn=1+/bracketleftbigg1
r−1+1
n−r−1−1
n−2/bracketrightbigg/slashbigg
3
is the so-called Bartlett correction factor. It has been shown that Brnin (6.21) has the
null distribution of χ2
1. Further, it can be written as
Brn=1
Crn[(r−1)log(r−1+(n−r−1)F rn) +
(n−r−1)log/parenleftbig
(r−1)F−1
rn+n−r−1/parenrightbig
−
(n−2)log(n−2)], (6.23)
where
Frn=/hatwideσ2
1
/hatwideσ2
0
is the F-test statistic for testing the equality of the two variances. From (6.23), it is
clear that the test statistic Brnis for testing the two-sided alternative hypothesis H1
in (6.22), and it is sensitive to both upward and downward variance shifts. In cases
when ris unknown, the MLE of ris deﬁned by
/hatwider=arg max
2≤r≤n−2Brn, (6.24)CONTROL CHARTS BY CHANGE-POINT DETECTION 245
and the test statistic for testing the hypothesis in (6.22) would be
Bmax,n=max
2≤r≤n−2Brn. (6.25)
In both (6.24) and (6.25), ris considered in the range from 2 to n−2 because Brnis
not well deﬁned when r=1 or when r=n−1.
From the discussion in the previous subsection, the statistic Bmax,ndeﬁned in
(6.25) can also be used for monitoring the process variance in phase II SPC. More
speciﬁcally, a variance shift is signaled at the n-th time point if
Bmax,n>hn, (6.26)
where hn>0 is a control limit. Similar to (6.17), the control limit hncan be chosen
such that
P(Bmax,n>hn|no signal before time n)≤α, (6.27)
where α∈[0,1]is a given conditional probability. If hnis chosen by (6.27), then the
IC ARL of the CPD control chart (6.25)–(6.26) is 1 /α. From the deﬁnition of the
charting statistic Bmax,n, this chart can be used for online process monitoring when
n≥4. But, similar to the CPD control chart (6.14)–(6.15), its performance would
be more reliable if n0−1 IC observations are collected before the online process
monitoring. In such cases, for both (6.24) and (6.25), the range of rconsidered on
the right-hand side of both expressions should be changed from 2 ≤r≤n−2 to
n0+1≤r≤n−2. When n0−1=9,αequals 0.05, 0.02, 0.01, 0.005, 0.002, and
0.001, and nchanges from 10 to 30, the computed hnby a Monte Carlo simulation
with 5 million replicated simulations are shown in Table 6.5, which is part of Table
1 in Hawkins and Zamba (2005a). From the table, it can be seen that, for a given
αvalue, hnﬁrst decreases and then increases and stabilizes when ngets larger. In
practice, Hawkins and Zamba (2005a) proposed the following approach to compute
hn:
•Forn=10,11,..., 15, use the hnvalues in Table 6.5.
•Forn>15, use the approximation formula
hn≈/braceleftigg
−1.38−2.241log(α)+1.61+0.691log(α)√n−9,ifα∈[0.001, 0.05)
5+0.066log(n −9), ifα=0.05.
For phase II process monitoring, the quantities Brnused in computing the charting
statistic Bmax,ncan be computed recursively as follows. For 2 ≤r≤n−2, let
Xr=1
rr
∑
i=1Xi, X′
r=1
n−rn
∑
i=r+1Xi,
/tildewideS2
r=r
∑
i=1/parenleftbig
Xi−Xr/parenrightbig2,/tildewideS2′
r=n
∑
i=r+1/parenleftig
Xi−X′
r/parenrightig2
.
Then, Wn=∑n
k=1XkandS2
n=∑n
k=1(Xi−Xn)2can be computed recursively by (6.19).246 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
Table 6.5 Contr ol limits h nwhen n 0=10, the sample size n takes various values between
10 and 30, and the conditional false signal rate αequals 0.05, 0.02, 0.01, 0.005, 0.002, and
0.001.
α
n 0.05 0.02 0.01 0.005 0.002 0.001
10 6.374 8.003 9.229 10.451 12.039 13.238
11 5.651 7.328 8.585 9.840 11.489 12.734
12 5.357 7.077 8.373 9.653 11.357 12.631
13 5.228 6.988 8.312 9.634 11.367 12.672
14 5.173 6.960 8.304 9.658 11.423 12.760
15 5.149 6.960 8.323 9.692 11.469 12.828
16 5.141 6.974 8.357 9.731 11.541 12.885
17 5.145 6.992 8.386 9.776 11.596 12.962
18 5.142 7.010 8.413 9.808 11.651 13.034
19 5.145 7.020 8.434 9.838 11.696 13.070
20 5.150 7.034 8.458 9.875 11.722 13.120
22 5.160 7.064 8.500 9.921 11.788 13.191
24 5.173 7.085 8.529 9.961 11.853 13.297
26 5.184 7.108 8.562 10.000 11.894 13.340
28 5.196 7.125 8.585 10.035 11.947 13.385
30 5.204 7.136 8.610 10.065 11.981 13.408
Furthermore, we have
X′
r= ( Wn−Wr)/(n−r)
/tildewideS2′
r=S2
n−/tildewideS2
r−r(n−r)
n(Xr−X′
r)2
/hatwideσ2
0=/tildewideS2
r/(r−1)
/hatwideσ2
1=/tildewideS2′
r/(n−r−1).
By (6.21) (or (6.23)), we can compute Brnfrom/hatwideσ2
0,/hatwideσ2
1,/tildewideS2
r, and/tildewideS2′
r. Therefore, to
compute the values of {Brn,n0+1≤r≤n−2}, we only need to maintain the two
sequences {Wn,n≥n0}and{S2
n,n≥n0}, which can be computed recursively.
Example 6.5 Assume that we collected n 0−1=9IC observations before phase II
process variance monitoring. These IC observations and the ﬁrst 21 phase II ob-
servations are presented in the second column of Table 6.6. Among the total of 30
observations, the ﬁrst 20 observations are actually generated from the N (0,1)distri-
bution, and the remaining 10 observations are actually generated from the N (0,22)
distribution. Therefore, these data simulate a production process that has the IC pro-
cess distribution N (0,1), and has a variance shift of size 4−1=3at the 21st time
point. The observed data and the computed quantities W n, S2
n, Bmax,n, and h nthat
are used in the construction of the CPD control chart (6.25)–(6.26) are presented in
Table 6.6, where W nand S2
nare computed recursively by (6.19), B max,nis computed
from{Brn}that is deﬁned in (6.21), and h nis computed by the numerical approxi-
mation formula given in the previous paragraph. From the table, it can be seen thatCONTROL CHARTS BY CHANGE-POINT DETECTION 247
Table 6.6 Thesecond column presents a sequence of 30 observations, and the third, fourth,
ﬁfth, and sixth columns present the corresponding values of {Wn,n=9,10,..., 30},{S2n,n=
9,10,..., 30},{Bmax,n,n=11,12,..., 30}, and{hn,n=10,11,..., 30}.
n Xn Wn S2
nBmax,n hn
1−0.502 - - - -
2 0.132 - - - -
3−0.079 - - - -
4 0.887 - - - -
5 0.117 - - - -
6 0.319 - - - -
7−0.582 - - - -
8 0.715 - - - -
9−0.825 0.180 2.935 - -
10−0.360−0.180 3.065 - 10.451
11 0.090−0.090 3.075 0.399 9.840
12 0.096 0.007 3.085 6.484 9.653
13−0.202−0.195 3.123 2.661 9.634
14 0.740 0.545 3.652 0.585 9.658
15 0.123 0.668 3.659 1.186 9.692
16−0.029 0.639 3.664 1.850 9.718
17−0.389 0.250 3.837 1.796 9.768
18 0.511 0.761 4.070 1.666 9.810
19−0.914−0.153 4.936 1.136 9.845
20 2.310 2.157 10.042 8.023 9.875
21−0.876 1.281 10.964 9.685 9.901
22 1.528 2.809 13.018 10.367 9.925
23 0.524 3.333 13.169 9.365 9.945
24 1.547 4.880 15.052 9.371 9.964
25−1.629 3.251 18.274 12.657 9.981
26−0.877 2.374 19.249 12.799 9.996
27−1.440 0.934 21.509 13.653 10.010
28 0.462 1.396 21.685 12.972 10.023
29−2.315−0.920 27.086 15.287 10.035
30 0.494−0.426 27.354 14.762 10.046
the ﬁrst signal of variance shift is given at the 22nd time point. The observed data
and the CPD control chart are also shown in the two plots of Figure 6.5. From plot
(b), we can see that h nstabilizes when n increases, and the charting statistic B max,n
is convincingly above the control limit curve after the 25th time point.
6.3.3 Monitoring of both the process mean and variance
Because both the process mean shift and the process variance shift would have an
impact on the product quality, we often need to monitor the process mean and vari-
ance simultaneously in practice. To this end, one possible approach is to jointly use
the two CPD control charts described in the previous two subsections. Alternatively,
we can develop a single CPD control chart from the corresponding CPD problem,248 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
0 5 10 15 20 25 30−2 −1 0 1 2 3 4
nXn
(a)10 15 20 25 300 5 10 15
nBmax□□n
(b)
Figure 6.5 (a) The ﬁrst 20 observations are generated from the N (0,1)distribution, and the
remaining 10 observations are generated from the N (0,22)distribution. All observations are
independent of each other. (b) The CPD control chart (6.25)–(6.26) (solid line) with n 0−1=9
and the control limit h ncomputed by the numerical approximation formula (dashed line).
as was done in Hawkins and Zamba (2005b). In this subsection, we brieﬂy describe
such a CPD control chart that is proposed by Hawkins and Zamba (2005b).
Assume that {X1,X2,..., Xn}is a sequence of independent process observations
collected up to the current time point n, and we are concerned about the hypotheses
H0:Xi∼N(µ0,σ2
0), fori=1,2,..., n
versus
H1:Xi∼/braceleftbigg
N(µ0,σ2
0),fori=1,2,..., r,
N(µ1,σ2
1),fori=r+1,r+2,..., n,
where either µ0/ne}ationslash=µ1orσ2
0/ne}ationslash=σ2
1or both, and 1 ≤r≤n−1 is the change-point. If r
is known, then the likelihood ratio test statistic for testing the above hypotheses with
the Bartlett correction factor (cf., Kendall and Stuart, 1961; Lawley, 1956) is
Jrn=/bracketleftigg
rlog/parenleftigg
/hatwideσ2
H0
/hatwideσ2
0/parenrightigg
+(n−r)log/parenleftigg
/hatwideσ2
H0
/hatwideσ2
1/parenrightigg/bracketrightigg/slashigg
C∗
rn, (6.28)
where/hatwideσ2
H0=S2
n/nis the MLE of σ2
0when H0is assumed to be true, /hatwideσ2
0and/hatwideσ2
1are
the same as those deﬁned in the previous subsection, and
C∗
rn=1+11
12/bracketleftbigg1
r+1
n−r−1
n/bracketrightbigg
+/bracketleftbigg1
r2+1
(n−r)2−1
n2/bracketrightbigg
.
By comparing Jrndeﬁned in (6.28) with Brndeﬁned in (6.21), it can be seen that
their major difference is in estimating the variance parameter. In (6.21), the estimatorCONTROL CHARTS BY CHANGE-POINT DETECTION 249
Table 6.7 Contr ol limits h nwhen n 0=10, the sample size n takes values between 10 and 14,
and the conditional false signal rate αequals 0.05, 0.02, 0.01, 0.005, 0.002, and 0.001.
α
n 0.05 0.02 0.01 0.005 0.002 0.001
10 10.128 12.237 13.795 15.330 17.352 18.840
11 9.213 11.389 12.996 14.556 16.609 18.173
12 8.854 11.083 12.719 14.313 16.397 17.965
13 8.690 10.961 12.631 14.265 16.353 17.950
14 8.616 10.917 12.610 14.249 16.361 17.978
/hatwideσ2=S2
r/(n−2)is used, which is robust to a potential mean shift at the change-
point r. As a comparison, in (6.28), the estimator /hatwideσ2
H0is used, which is affected by a
potential mean shift at the change-point r. Because of this difference, Jrnis sensitive
to both process mean shifts and process variance shifts, while Brnis sensitive to
process variance shifts only.
In phase II process monitoring, the change-point ris unknown. In such cases, if
n0−1 IC observations are collected beforehand, then we can use the charting statistic
Jmax,n= max
n0+1≤r≤n−2Jrn, (6.29)
where the range n0+1≤r≤n−2 is considered because Jrnmay not be well deﬁned
when r≤n0orr=n−1. Then, a signal of process mean/variance shift is given when
Jmax,n>hn, (6.30)
where hn>0 is a control limit that is properly chosen to achieve a given ARL 0value.
Similar to (6.17) and (6.27), for a given conditional probability α,hncan be chosen
such that
P(Jmax,n>hn|no signal before time n)≤α.
In cases when n0−1=9 IC observations are collected beforehand, Hawkins and
Zamba (2005b) proposed the following numerical approach for computing hn:
•Forn=10,11,..., 14, use the hnvalues in Table 6.7, which are computed using a
Monte Carlo simulation with 10 million replicated simulations.
•Forn>14, use the approximation formula
hn≈/braceleftigg
1.58−2.52log( α)+0.094+0.33log(α)√n−9,ifα∈[0.001, 0.05)
8.43+0.074log(n −9), ifα=0.05.
To compute the charting statistic Jmax,n, we only need to maintain the two sequences
{Wn,n≥n0}and{S2
n,n≥n0}, which can be computed recursively by (6.19), as in
computing the charting statistic Bmax,nin the previous subsection.
After a signal is given by the CPD control chart (6.29)–(6.30), the following three
root causes are possible: (i) the process mean has shifted, (ii) the process variance
has shifted, and (iii) both the process mean and the process variance have shifted. To250 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
distinguish these three scenarios, Hawkins and Zamba (2005b) suggested performing
the two post-signal tests described below.
•Let/hatwiderbe the change-point estimator deﬁned by the maximizer of (6.29). Consider
the two-sided F-test with the test statistic
F=/hatwideσ2
0
/hatwideσ2
1,
where/hatwideσ2
0=/tildewideS2
/hatwider/(/hatwider−1)and/hatwideσ2
1=/tildewideS2′
/hatwider/(n−/hatwider−1). Then, under the hypothesis that
the process variance does not shift on or before the n-th time point, the distribu-
tion of this statistic should be close to the F/hatwider−1,n−/hatwider−1distribution (cf., Subsection
2.3.4). Therefore, this F-test can be used to conclude whether the process variance
has shifted by the time point n.
•Consider the two-sample t-test with the test statistic
t=X/hatwider−X′
/hatwider/radicalig
/hatwideσ2
0//hatwider+/hatwideσ2
1/(n−/hatwider).
Then, under the hypothesis that the process mean does not shift on or before the n-
th time point, the distribution of this statistic should be close to the tkdistribution
(cf., Subsection 2.3.3), where
k=/bracketleftbig/hatwideσ2
0//hatwider+/hatwideσ2
1/(n−/hatwider)/bracketrightbig2
1
/hatwider−1/bracketleftbig/hatwideσ2
0//hatwider/bracketrightbig2+1
n−/hatwider−1/bracketleftbig/hatwideσ2
1/(n−/hatwider)/bracketrightbig2.
Therefore, this t-test can be used to conclude whether the process mean has shifted
by the time point n.
Regarding the above two tests, the speciﬁed null distributions of their test statistics
are valid only in cases when the true change-point ris known and/hatwiderin their test
statistics is replaced by r. With the extra randomness in /hatwider, the actual null distributions
of their test statistics could be quite different from the speciﬁed null distributions.
Furthermore, if the CPD control chart (6.29)–(6.30) performs well, the time lag from
the occurrence of the mean/variance shift to its ﬁrst signal (i.e., n−/hatwider) is usually
short. Consequently, the two test statistics might be quite variable. For these reasons,
the above two post-signal tests can only be used as a reference, and their results may
not be reliable.
Example 6.6 In this example, we consider three different datasets. Each dataset has
30 observations, the ﬁrst 9 of which are regarded as IC observations. In the ﬁrst
dataset, the ﬁrst 20 observations are generated from the N (0,1)distribution, and
the remaining 10 observations are generated from the N (2,1). So, a process mean
shift occurs at the 21st time point. The data are shown in Figure 6.6(a). Then, the
three CPD control charts described in this and the previous two subsections, with
n0−1=9,α=0.005, and h ncomputed by the related approximation formulas, are
applied to the dataset, and the three control charts are shown in Figure 6.6(b)–(d).CONTROL CHARTS BY CHANGE-POINT DETECTION 251
From the plots, it can be seen that the CPD control chart (6.14)–(6.15) gives the ﬁrst
signal of process mean shift at the 24th time point, the CPD control chart (6.25)–
(6.26) does not give any signal, and the CPD control chart (6.29)–(6.30) gives the
ﬁrst signal of process mean or process variance shift at the 26th time point. For the
CPD control chart (6.29)–(6.30), after the signal, we obtain
/hatwider=20, X/hatwider=−0.256, X′
/hatwider=2.399,
/hatwideσ2
0=0.508,/hatwideσ2
1=2.466.
Then, the computed value of the F-test statistic is 0.206, its null distribution is F 19,5,
and the corresponding two-sided p-value is about 0.01 (note: the two-sided p-value
is deﬁned as 2P(F 19,5<0.206)). On the other hand, the computed value of the t-
test statistic is −4.019, its null distribution is t 6, and the corresponding p-value for
a two-sided t-test is 0.007. Based on these two tests, it seems that both the process
mean and the process variance have shifted, which is different from the truth that
only the process mean shifts in the ﬁrst dataset.
In the second dataset, the ﬁrst 20 observations are generated from the N (0,1)
distribution, and the remaining 10 observations are generated from the N (0,32). So,
a process variance shift occurs at the 21st time point. The data are shown in Figure
6.6(e), and the three CPD control charts in the same setup as that in analyzing the
ﬁrst dataset are shown in Figure 6.6(f)–(h). From the plots, it can be seen that the
CPD control chart (6.14)–(6.15) gives signals of process mean shift, but the signals
are quite weak. As a comparison, the CPD control charts (6.25)–(6.26) and (6.29)–
(6.30) both give convincing signals. For the CPD control chart (6.29)–(6.30), after
the ﬁrst signal at the 24th time point, we obtain
/hatwider=18, X/hatwider=0.042, X′
/hatwider=0.913,
/hatwideσ2
0=0.226,/hatwideσ2
1=2.830.
Then, the computed value of the F-test statistic is 0.080, its null distribution is F 17,5,
and the corresponding p-value is 6.73×10−5. On the other hand, the computed
value of the t-test statistic is −1.252, its null distribution is t 5, and the corresponding
p-value for a two-sided test is 0.266. Based on these two tests, we conclude that the
process mean does not shift but the process variance shifts after the 18th time point,
which is close to the truth since the true variance shift happens after the 20th time
point.
In the third dataset, the ﬁrst 20 observations are generated from the N (0,1)dis-
tribution, and the remaining 10 observations are generated from the N (1,22). So,
both the process mean and the process variance shift at the 21st time point. The data
are shown in Figure 6.6(i), and the three CPD control charts in the same setup as
that in analyzing the ﬁrst two datasets are shown in Figure 6.6(j)–(l). From the plots,
it can be seen that all three CPD control charts give signals in this case. For the CPD
control chart (6.29)–(6.30), after the ﬁrst signal at the 26th time point, we obtain
/hatwider=23, X/hatwider=−0.312, X′
/hatwider=4.281,
/hatwideσ2
0=0.618,/hatwideσ2
1=4.435.
Then, the computed value of the F-test statistic is 0.139, its null distribution is F 22,2,
and the corresponding two-sided p-value is 0.008. On the other hand, the computed252 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
value of the t-test statistic is −3.744, its null distribution is t 2, and the corresponding
p-value for a two-sided test is 0.065. Based on these two tests, we conclude that
the process variance shifts and there is marginally signiﬁcant evidence of a process
mean shift in this case.
6.4 Some Discussions
We have described some recent CPD control charts in this chapter. For a long time,
the SPC literature focused mainly on the Shewhart, CUSUM, and EWMA charts.
While these control charts are effective for phase I analysis and phase II online pro-
cess monitoring, their performance depends largely on their design and a good design
requires certain information about the IC and OC process distributions. For instance,
a conventional CUSUM chart (cf., Chapter 4) assumes that the IC process distribu-
tion is completely known, and a distributional shift is in one or more parameters (e.g.,
the mean, or the variance, or both). In such cases, it has good performance when its
allowance constant k(cf., (4.7)) is chosen properly for detecting a target shift. In
practice, however, the IC process distribution may not be known, and the target shift
is often difﬁcult to specify. Furthermore, a CUSUM chart tuned properly for a given
target shift may not perform well when detecting other possible shifts. Although the
self-starting control charts and the adaptive control charts (e.g., Section 4.5) can al-
leviate the impact of these limitations on the practical use of the conventional control
charts, the limitations have not been completely eliminated. The CPD control charts
provide a new approach to the SPC problem. Two major features of this approach are
that (i) it does not require much information about the IC and OC process distribu-
tions, and (ii) it can provide reasonably good estimators of the shift time and the IC
and OC distribution parameters at the same time as when it gives a signal of process
distributional shift. These two properties make the CPD approach appropriate to use
in cases when we have little prior information about the IC and OC process distribu-
tions and when it is desirable to have the estimators of the shift time and the IC and
OC distribution parameters immediately after obtaining a signal of shift.
The CPD methods discussed in Section 6.2 are for analyzing data from retrospec-
tive studies in which the data sizes are ﬁxed. These methods can be used directly for
phase I process analysis, although besides change-points there are many other issues
to handle (i.e., outliers detection) in a typical phase I process analysis. The meth-
ods described in that section are traditional, and there are many other CPD methods
in the literature. For more recent developments in the CPD area, see Brodsky and
Darkhovsky (1993), Chen and Gupta (1997, 2000), Chib (1998), Gustafsson (2000),
Herberts and Jensen (2004), Lebarbier (2005), Spokoiny (2009), among many others.
The CPD control charts discussed in Section 6.3 are for phase II process mon-
itoring in which the sample size sequentially increases. Their charting statistics are
modiﬁed from the test statistics of the corresponding change-point hypothesis test-
ing problems. In their design and implementation, it is critically important to de-
velop proper numerical approximation formulas for choosing the control limits and
to formulate the recursive computation of the charting statistics. The control charts
discussed in that section are for general cases when all parameters, including the ICSOME DISCUSSIONS 253
0 5 10 20 30−2 0 1 2 3 4 5
nXn
(a)
10 15 20 25 300 2 4 6 8
nTmax□□n
(b)
10 15 20 25 300 2 4 6 8 10
nBmax□□n
(c)
10 15 20 25 300 5 10 15 20 25
nJmax□□n
(d)0 5 10 20 30−4 −2 0 2 4
nXn
(e)
10 15 20 25 300 1 2 3 4 5 6
nTmax□□n
(f)
10 15 20 25 300 5 10 15 20 25
nBmax□□n
(g)
10 15 20 25 300 5 10 15 20 25
nJmax□□n
(h)0 5 10 20 30−4 0 2 4 6
nXn
(i)
10 15 20 25 300 2 4 6 8
nTmax□□n
(j)
10 15 20 25 300 5 10 15 20
nBmax□□n
(k)
10 15 20 25 300 5 10 15 20 25
nJmax□□n
(l)
Figure 6.6 (a) The ﬁrst 20 observations are generated from the N (0,1)distribution, and the
remaining 10 observations are generated from the N (2,1)distribution. All observations are
independent of each other. (b)–(d) The CPD control charts (6.14)–(6.15), (6.25)–(6.26), and
(6.29)–(6.30) in cases with n 0−1=9,α=0.005, and h ncomputed by the related approx-
imation formulas. Plots (e)–(h) and (i)–(l) show the corresponding results when the process
distribution shifts at the 21st time point from N (0,1)to N(0,32)and from N (0,1)to N(1,22),
respectively.254 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
and OC means and variances and the shift time point, are unknown. Various cases
when some of these parameters are known are discussed extensively in the literature.
See, for instance, Lai (1995, 2001), and Mei (2006). CPD control charts for analyz-
ing correlated data are discussed by Choi et al. (2008), and Perry et al. (2011); CPD
control charts for cases when the process distribution is Poisson or other parametric
distributions are discussed by Perry and Pignatiello (2008), and Perry et al. (2007).
Although the CPD control charts have their advantages, compared to the conven-
tional control charts, as described above, their computation is still relatively com-
plicated, even though certain quantities involved in their charting statistics can be
computed in a recursive way. The main reason for this computational limitation is
that the change-point estimator /hatwider(cf., (6.24)) has to be re-computed each time when
a new observation Xnis obtained, which involves a search in a sequence of random
variables of length in the order of n. In certain applications, a quick computation is
desirable when monitoring a process. For such applications, a proper modiﬁcation of
the conventional CPD control charts is needed. One possible modiﬁcation is to search
within a number of recent observation times only, each time when the change-point
estimator is updated after a new observation is obtained. However, this approach has
the risk of missing a true shift, especially when only a small number of recent obser-
vation times are considered in the search algorithm. Therefore, much future research
is needed to balance the computational consideration and the risk of missing a true
shift. Also, as discussed in Chapters 4 and 5, self-starting and adaptive CUSUM and
EWMA charts can also handle situations in which the IC and OC distributional pa-
rameters are unknown. A systematic comparison between this approach and the CPD
approach is currently lacking, which requires much future research as well.
6.5 Exercises
6.1 Assume that the sequence of independent random variables {X1,X2,..., Xn}fol-
lows the change-point model below.
Xi∼/braceleftbigg
N(µ0,σ2),fori=1,2,..., r
N(µ1,σ2),fori=r+1,r+2,..., n,
where nis ﬁxed, µ0,µ1, and σ2are unknown parameters, and 1 ≤r≤n−1 is
an unknown change-point.
(i) Verify the expression (6.6).
(ii) Verify all equations in the expression (6.7).
6.2 Generate a dataset from the change-point model described in the previous exer-
cise with n=100, r=50,µ0=0,µ1=1, and σ=1. Compute the MLEs of µ0,
µ1,σ, and r.
6.3 In the change-point model described in Exercise 6.1, assume that n=100, µ0=
µ1=0, and σ=1. Namely, there is actually no change-point in the model. In
such cases, it has been demonstrated in the literature that the time points closer
to 1 or nwould have larger chances to be chosen as the estimated change-point.
To verify this result, perform a simulation study with the following steps.EXERCISES 255
Step 1 Generate a dataset from the change-point model, and compute the values
of
g(r)=r(n−r)
n(Xr−X′
r)2, for 1≤r≤n−1.
Step 2Repeat Step 1 for a total of 100 times, and average {g(r),1≤r≤n−1}
over the 100 replications.
Step 3 Make a histogram (cf., Subsection 2.6.3) of the averaged values of
{g(r),1≤r≤n−1}.
By (6.6), the MLE of ris deﬁned by
/hatwider=arg max
1≤r≤n−1g(r).
From the histogram, is it true that the time points closer to 1 or nhave larger
values of g(r)?
6.4 In the change-point model described in Exercise 6.1, in cases when σ2is un-
known, check that the LRT statistic Λ(X 1,X2,..., Xn)discussed in Subsection
6.2.1 is a strictly decreasing function of Wdeﬁned in (6.9). Also, check that it is
a strictly decreasing function of Vdeﬁned in (6.10).
6.5 Check that the recursive formula (6.12) is valid.
6.6 The following 30 observations are obtained from a production process:
8.308, 7.525, 12.549, 13.127, 6.874, 7.536, 10.430, 9.840, 9.261, 9.601,
7.981, 4.932, 5.968, 4.379, 8.861, 4.562, 7.132, 7.022, 9.164, 8.590, 17.642,
14.252, 14.583, 14.443, 12.573, 12.950, 15.315, 14.700, 14.475, 16.102.
Use the dynamic programming algorithm described in Subsection 6.2.2 to detect
possible change-points in the data and compute point estimates of all related
distribution parameters.
6.7 Assume that 9 IC observations have been collected for phase II monitoring of a
production process. These observations along with the ﬁrst 21 phase II observa-
tions are presented below.
11.528, 8.990, 9.590, 9.648, 16.807, 14.850,
10.708, 7.042, 5.427, 10.107, 0.029, 9.836,
6.807, 12.428, 18.920, 7.535, 11.330, 3.883,
8.874, 16.850, 9.627, 10.887, 21.789, 12.482,
12.741, 13.236, 18.913, 15.113, 16.006, 10.006
Use the CPD control chart (6.14)–(6.15) to monitor the process mean. In the
control chart, use n0−1=9,α=0.005, and the control limit hncomputed by
the approximation formula (6.18).
6.8 The approximation formula (6.18) is obtained empirically from simulation re-
sults such as those in Table 6.2. It is developed for the convenience of online256 UNIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION
process monitoring. Please use the results in Table 6.2 to verify that this ap-
proximation formula provides a reasonably good approximation to the computed
values of hnin the table.
6.9 Reproduce all the results in Example 6.4.
6.10 Verify the expressions (6.19) and (6.20).
6.11 Show that the expressions (6.21) and (6.23) are equivalent.
6.12 Assume that 9 IC observations have been collected for phase II monitoring of a
production process. These observations along with the ﬁrst 21 phase II observa-
tions are presented below.
5.139, 5.097, 5.329, 4.449, 4.890, 4.356, 5.065, 4.883, 4.580, 6.065,
5.525, 4.847, 4.630, 5.036, 5.273, 5.154, 5.226, 5.050, 4.548, 4.857,
1.682, 5.582, 6.180, 2.352, 4.557, 6.713, 6.225, 4.463, 7.486, 3.954
Use the CPD control chart (6.25)–(6.26) to monitor the process variance. In the
control chart, use n0−1=9,α=0.005, and the control limit hncomputed by
the approximation formula given in Subsection 6.3.2.
6.13 Reproduce all the results in Example 6.5.
6.14 The following 50 observations are collected from a production process, of which
the ﬁrst 9 observations are known to be IC observations.
4.806, 5.710, 4.329, 4.269, 5.307, 4.441, 5.917, 5.182, 4.899, 5.448,
4.874, 5.090, 4.606, 4.934, 5.688, 4.430, 4.509, 5.577, 5.620, 5.814,
4.426, 5.266, 4.776, 4.115, 5.502, 5.250, 4.871, 5.211, 4.104, 5.237,
7.188, 8.417, 7.354, 8.161, 5.617, 8.435, 3.447, 9.775, 3.864, 8.452,
6.863, 8.866, 9.478, 7.270, 7.462, 5.669, 6.177, 4.383, 7.971, 5.823
Use the CPD control chart (6.29)–(6.30) to monitor both the process mean and
the process variance. In the control chart, use n0−1=9,α=0.005, and the
control limit hncomputed by the approximation formula given in Subsection
6.3.3. If the control chart gives a signal, then perform the two post-signal tests
discussed in Subsection 6.3.3 to see whether the signal is due to a process mean
shift, or a process variance shift, or both.
6.15 Apply the CPD control chart (6.29)–(6.30) with n0−1=9 and α=0.005 to
the data in Exercise 6.7. Compare the results here to the results found in that
exercise.Chapter 7
Multiv ariate Statistical Process Control
7.1 Introduction
The control charts discussed in Chapters 3–6 are for handling cases when the qual-
ity characteristic in question is univariate. In most applications, however, the quality
of a product is affected by multiple characteristics of the product. For instance, the
quality of a bottle of soft drink may be affected by the weight, amounts of different
ingredients, quality of the paper or plastic label on the bottle, and so forth. Regard-
ing the quality of a product with a complicated structure (e.g., cars, airplanes, space
shuttles), we can easily list hundreds of quality characteristics that are important to
monitor during its production. As described in Chapter 1, quality is a multifaceted
concept. Garvin (1987) gave eight dimensions to the deﬁnition of quality, including
performance, features, reliability, conformance, durability, serviceability, aesthetics,
and perceived quality (cf., Section 1.1). Therefore, most statistical process control
(SPC) applications have multiple quality characteristics involved. Such SPC prob-
lems are often referred to as multivariate SPC (MSPC) problems, which are the main
focus of this chapter.
In cases when multiple quality characteristics need to be monitored, one natural
idea is to use a joint monitoring scheme consisting of a set of univariate SPC control
charts, each control chart is for monitoring a single quality characteristic, and the
joint monitoring scheme gives a signal of process distributional shift when at least
one individual control chart gives a signal. In practice, some people prefer this idea
because it only has univariate SPC control charts involved. Thus, it is easy to un-
derstand and implement. However, such a joint monitoring scheme has at least two
limitations, described brieﬂy below. First, a proper design of the joint monitoring
scheme is quite complicated. Each univariate SPC control chart has its own proce-
dure parameters; thus, the joint monitoring scheme would have many parameters to
determine before it can be used. For instance, if a univariate CUSUM chart is used for
monitoring a single quality characteristic, then the univariate CUSUM chart usually
has two parameters involved (i.e., the allowance constant kand the control limit h).
Thus, the joint monitoring scheme to monitor pquality characteristics would have 2 p
parameters to determine. Intuitively, different probability distributions of the quality
characteristics and the possible correlation among them should be taken into account
when we determine the parameters. These issues, along with a relatively large num-
ber of procedure parameters involved, make the proper design of the joint monitoring
scheme challenging. Second, in the statistical hypothesis testing literature, it has been
257258 MULTIV ARIATE STATISTICAL PROCESS CONTROL
demonstrated that, to test the possible difference between two p-dimensional popu-
lation means, where p>1 is a given integer, it would be more powerful to treat
the two population means as two vectors and compare them by a multivariate testing
procedure (e.g., the Hotelling’s T2test described in Section 7.2 below) than to utilize
the strategy to use punivariate testing procedures jointly and use the j-th univariate
testing procedure for testing the possible difference between the j-th components
of the two mean vectors, for 1 ≤j≤p(cf., Johnson and Wichern, 2007, Chapters
5 and 6). Similarly, in the SPC literature, it has been demonstrated that an MSPC
procedure that is constructed properly in the multivariate setup (i.e., treating all ob-
servations as p-dimensional vectors and using them for detecting possible shifts in
thep-dimensional distribution of the process) would be more effective than a joint
monitoring scheme consisting of a set of univariate SPC control charts (cf., Crosier,
1988). A main reason for this result is that a vector-based MSPC procedure could
accommodate the possible association among the components of a multivariate pro-
cess well, while with the joint monitoring scheme based on a set of univariate control
charts it is often difﬁcult to achieve that goal.
In this chapter, we mainly describe some basic MSPC control charts for detect-
ing shifts in the mean and/or covariance matrix of the distribution of a multivariate
production process in cases when the IC and OC process distributions are assumed to
be normal distributions. Cases when the process distributions are multivariate non-
normal will be discussed in Chapter 9. The remaining part of this chapter is organized
as follows. In Sections 7.2–7.5, some fundamental multivariate Shewhart charts, mul-
tivariate CUSUM charts, multivariate EWMA charts, and multivariate CPD charts
are discussed, respectively. In Section 7.6, some recent MSPC charts that integrate
the variable selection problem in regression with the MSPC problem are discussed.
Some concluding remarks are given in Section 7.7.
7.2 Multivariate Shewhart Charts
In this section, we describe some Shewhart charts for monitoring multivariate pro-
duction processes. Our description is divided into two parts. In Subsection 7.2.1,
multivariate normal distributions and their major properties are brieﬂy discussed.
Then, in Subsection 7.2.2, the Hotelling’s T2statistic and certain related multivariate
Shewhart charts are discussed.
7.2.1 Multivariate normal distributions and some basic properties
In this subsection, we brieﬂy introduce multivariate normal distributions and their
major properties. For a more detailed discussion on this topic, see textbooks such as
Anderson (2003), Eaton (2007), and Johnson and Wichern (2007).
Assume that X=(X 1,X2,..., Xp)′is ap-dimensional numerical random vector.
Its cumulative distribution function (cdf) and probability density function (pdf) are
deﬁned by (2.8) and (2.9) in Section 2.2. Its mean vector, denoted as µXor E(X), is
deﬁned by
µX=(µX1,µX2,..., µXp)′,MULTIV ARIATE SHEWHART CHARTS 259
and its covariance matrix, denoted as Cov(X), is deﬁned by
Cov(X)= E[(X−µX)(X−µX)′],
which is a p×pmatrix with the (i,j)-th element equal to E[(X i−µXi)(X j−µXj)], for
i,j=1,2,..., p. Then, Cov(X) is a symmetric nonnegative deﬁnite matrix. Its j-th
diagonal element is E(X j−µXj)2, which is just the variance of Xj, for j=1,2,..., p
(cf., (2.5) and (2.7)). Also, its (i,j)-th element is called the covariance of the two
random variables X iand X j, denoted as Cov(X i,Xj), which measures the linear asso-
ciation between XiandXj. Generally speaking, the linear association between Xiand
Xjis stronger if their covariance is larger. However, the value of Cov(X i,Xj)depends
on the variances of XiandXj. To get rid of this dependence, the quantity
Cov(Xi,Xj)
σXiσXj, fori,j=1,2,..., p
is deﬁned to be the correlation coefﬁcient of the random variables XiandXj, denoted
as Cor(X i,Xj). The p×pmatrix of all pairwise correlation coefﬁcients

Cov(X1,X1)
σ2
X1,Cov( X1,X2)
σX1σX2,···,Cov(X1,Xp)
σX1σXp
Cov(X2,X1)
σX2σX1,Cov( X2,X2)
σ2
X2,···,Cov(X2,Xp)
σX2σXp
............
Cov( Xp,X1)
σXpσX1,Cov( Xp,X2)
σXpσX2,···,Cov(Xp,Xp)
σ2
Xp

=
1, Cor(X 1,X2),···,Cor(X 1,Xp)
Cor(X 2,X1), 1, ···,Cor(X 2,Xp)
............
Cor(X p,X1),Cor(X p,X2),···, 1

is called the correlation matrix ofX, denoted as Cor(X). It can be checked that it is
always true that
−1≤Cor(X i,Xj)≤1, fori,j=1,2,..., p.
The linear association between XiandXjis weak when Cor (Xi,Xj)is close to 0, it
is positively strong when Cor(X i,Xj)is close to 1, and it is negatively strong when
Cor(X i,Xj)is close to −1. In cases when Cor (Xi,Xj) =0,XiandXjare said to be
uncorrelated.
In cases when the pdf of Xhas the parametric form
f(x)=1
(2π)p/2|Σ|1/2exp/bracketleftbigg
−1
2(x−µ)′Σ−1(x−µ)/bracketrightbigg
,forx=(x 1,x2,..., xp)′∈Rp,
(7.1)
where µis ap-dimensional parameter vector and Σis ap×pparameter matrix, the260 MULTIV ARIATE STATISTICAL PROCESS CONTROL
distribution ofXis called a p-dimensional normal distribution andXis called a p-
dimensional normal random vector. It can be checked that, if Xhas a p-dimensional
normal distribution with the pdf in (7.1), then its mean vector is just µand its covari-
ance matrix is just Σ. Namely,
µX=µ, Cov(X)= Σ.
Because the p-dimensional normal distribution is uniquely determined by its mean
vector and covariance matrix, in cases when Xhas the pdf (7.1), it is denoted as
X∼Np(µ,Σ). Also, it can be checked that, in cases when Xhas a multivariate nor-
mal distribution, for any pair (Xi,Xj)of its components with 1 ≤i/ne}ationslash=j≤p, they
are uncorrelated if and only if they are independent (cf., (2.10) for the deﬁnition of
independence).
In cases when p=2, the pdf in (7.1) can be written as
f(x1,x2) =1
2πσX1σX2/radicalbig
1−Cor(X 1,X2)2×
exp/braceleftigg
−1
2(1−Cor(X 1,X2)2)/bracketleftigg/parenleftbiggx1−µX1
σX1/parenrightbigg2
−
2Cor(X 1,X2)/parenleftbiggx1−µX1
σX1/parenrightbigg/parenleftbiggx2−µX2
σX2/parenrightbigg
+/parenleftbiggx2−µX2
σX2/parenrightbigg2/bracketrightigg/bracerightigg
.
When σX1=1,σX2=0.5, and Cor(X 1,X2)=0, the pdf function f(x1,x2)is shown in
Figure 7.1(a). Three contour curves {(x1,x2):f(x1,x2)=c}with c=0.05, 0.1, and
0.2 are shown in Figure 7.1(b). From both plots, it can be seen that, in cases when X1
andX2are uncorrelated, the surface of f(x1,x2)is bell shaped with elliptical contour
curves, and the major and minor axes of the contour curves are parallel to the xand
yaxes. In cases when σX1=1,σX2=0.5, and Cor(X 1,X2) =0.8 (i.e., X1andX2
are positively correlated), the pdf function f(x1,x2)is shown in Figure 7.1(c). Three
contour curves {(x1,x2)):f(x1,x2) =c}with c=0.05, 0.1, and 0.2 are shown in
Figure 7.1(d). It can be seen that the surface of f(x1,x2)is still bell shaped with
elliptical contour curves, but the major and minor axes of the contour curves are no
longer parallel to the xandyaxes. As a matter of fact, the major axes of the contour
curves have a positive slope in such a case, indicating a positive linear relationship
between X1andX2.
Now, if X∼Np(µ,Σ),Ais any m×pconstant matrix, and bis any m-dimensional
constant vector, then it can be checked that (cf., Johnson and Wichern, 2007, Chapter
4)
AX+b∼Nm(Aµ+b,AΣA′). (7.2)
From this property, we have the conclusion that, if X∼Np(µ,Σ)and/tildewideXis a vector of
any subset of the components of X, then/tildewideXmust have a multivariate normal distribu-
tion. Another property of the multivariate normal distribution is described in the box
below, which plays an important role in MSPC.MULTIV ARIATE SHEWHART CHARTS 261
0123456
x10123456
x2
0
0.1
0.2
0.3
0.4f(x1,x2)
(a)x1x2
0 1 2 3 4 5 60 1 2 3 4 5 60.050.10.2
(b)
0123456
x10123456
x2
0
0.1
0.2
0.3
0.4f(x1,x2)
(c)x1x2
0 1 2 3 4 5 60 1 2 3 4 5 60.050.1
0.2
(d)
Figure 7.1 (a) Surface of f (x1,x2)when(X1,X2)has a bivariate normal distribution, σX1=
1,σX2=0.5, and Cor (X1,X2) =0. (b) Three contour curves {(x1,x2)):f(x1,x2) =c}of
f(x1,x2)shown in plot (a) when c =0.05,0.1, and 0.2. (c) Surface of f (x1,x2)when(X1,X2)′
has a bivariate normal distribution, σX1=1,σX2=0.5, and Cor(X 1,X2) =0.8. (b) Three
contour curves {(x1,x2)):f(x1,x2) =c}of f(x1,x2)shown in plot (c) when c =0.05,0.1,
and0.2.
Distribution of a Quadratic Form of a Multivariate Normal Random V ector
Assume that X∼Np(µ,Σ)andΣis a non-singular covariance matrix. Then,
the distribution of (X−µ)′Σ−1(X−µ)isχ2
p.
The property in the above box is easy to verify. Let Z=Σ−1/2(X−µ). Then, it
can be checked by (7.2) that Z∼Np(0,Ip×p)and(X−µ)′Σ−1(X−µ)=Z′Z, where
Ip×pis the p×pidentity matrix. Let Z=(Z 1,Z2,..., Zp)′. Then,{Z1,Z2,..., Zp}is262 MULTIV ARIATE STATISTICAL PROCESS CONTROL
a sequence of i.i.d. random variables with the standard normal distribution. By the
deﬁnition of a chi-square distribution in Subsection 2.3.2, we have (X−µ)′Σ−1(X−
µ)=Z2
1+Z2
2+···+Z2
p∼χ2
p. Now, Σ−1/2(X−µ)can be interpreted as a weighted
difference between Xandµ, with the components of Xthat have larger variances
receiving smaller weights. Therefore,
d2
S(X,µ)=(X−µ)′Σ−1(X−µ)
is often referred to as the squared statistical distance from Xto its mean vector µ.
By the result in the above box, if X∼Np(µ,Σ), then Xhas a 1−αchance to be
contained in the following region:
C=/braceleftbig
x:x∈Rp,d2
S(x,µ)≤χ2
1−α,p/bracerightbig
,
where α∈[0,1]is a given signiﬁcance level, and χ2
1−α,pis the(1−α)-th quantile of
theχ2
pdistribution. If we ignore the possible association among the components of
Xand assume that all components are independent of each other, then we can use the
method described below to construct a similar region. First, for the j-th component
Xj, it has a 1 −αjchance to be in the region
Cj=/braceleftig
xj:µj−Z1−αj/2σXj≤xj≤µj+Z1−αj/2σXj/bracerightig
,
where αj∈[0,1]is a signiﬁcance level, and Z1−αj/2is the(1−αj/2)-th quantile of
theN(0,1)distribution. To guarantee that there is a 1 −αchance that Xj∈Cjfor all
j, we should choose αjsuch that
1−α
=P/parenleftiggp/intersectiondisplay
j=1(Xj∈Cj)/parenrightigg
= (1−α1)(1−α2)···(1−αp).
For simplicity, let us assume that α1=α2=···=αp=α′. Then, we have
α′=1−(1−α)1/p.
In the case shown in Figure 7.1(c) when p=2,µX1=3,µX2=3,σX1=1,σX2=0.5,
and Cor(X 1,X2)=0.8, if α=0.05, then α′=0.0253. In such a case, the region C
is shown in Figure 7.2 by the ellipse, and the intervals C1andC2are shown in the
same plot by the dotted and dashed lines, respectively. From the plot, we can see that,
although it is guaranteed that Xhas a 95% chance to be in the square surrounded by
the dotted and dashed lines, it is often too conservative (i.e., the actual probability
would be larger than 0.95), compared to the elliptical region.
Assume that there is a p-dimensional population with the population distribu-
tion Np(µ,Σ), and(X1,X2,..., Xn)is a simple random sample of size nfrom theMULTIV ARIATE SHEWHART CHARTS 263
x1x2
0 1 2 3 4 5 60 1 2 3 4 5 6
Figure 7.2 In the case when p =2,µX1=3,µX2=3,σX1=1,σX2=0.5, and Cor(X 1,X2)=
0.8, the elliptical region is constructed from the distribution of d2
S(X,µ)directly such that X
has a 95% chance to be in the region, and the square has the same property but it is constructed
from individual components of Xby assuming the components are independent.
population (cf., Section 2.5). Then, X1,X2,..., Xnis a sequence of i.i.d. random vec-
tors having the common distribution Np(µ,Σ). The likelihood function based on the
sample (cf., Subsection 2.7.2) is
L(µ,Σ;X1,X2,..., Xn)
=Πn
i=1/braceleftbigg1
(2π)p/2|Σ|1/2exp/bracketleftbigg
−1
2(Xi−µ)′Σ−1(Xi−µ)/bracketrightbigg/bracerightbigg
=1
(2π)np/2|Σ|n/2exp/bracketleftigg
−1
2n
∑
i=1(Xi−µ)′Σ−1(Xi−µ)/bracketrightigg
.
By some algebraic manipulations (cf., Johnson and Wichern, 2007, Section 4.3), we
have the results summarized in the box below.264 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Maximum Likelihood Estimators of µandΣ
Assume that (X1,X2,..., Xn)is a simple random sample from a p-
dimensional population with the population distribution Np(µ,Σ). Then, the max-
imum likelihood estimators (MLEs) of µandΣare
/hatwideµ=X,/hatwideΣ=n−1
nS2, (7.3)
where X=1
n∑n
i=1Xiis the sample mean and S2=1
n−1∑n
i=1(Xi−X)(X i−X)′is
the sample covariance matrix.
To describe the sampling distribution of S2(also the sampling distribution of
/hatwideΣin (7.3)), we need to deﬁne the so-called Wishart distribution as follows. Let
Z1,Z2,..., Zmbe a sequence of mi.i.d. random vectors having the common distri-
bution Np(0,Σ). Then, the distribution of the random matrix ∑m
i=1ZiZ′
iis called the
Wishart distribution with mdegrees of freedom (df) and with the covariance matrix
Σ, denoted as Wm,Σ. Then, results about the sampling distributions of XandS2are
summarized in the box below.
Sampling Distributions of X and S2
Assume that (X1,X2,..., Xn)is a simple random sample from a p-
dimensional population with the population distribution Np(µ,Σ). Then, the sam-
pling distributions of the sample mean Xand the sample covariance matrix S2
have the following properties:
(i)X∼Np(µ,Σ/n),
(ii)(n−1)S2∼Wn−1,Σ, and
(iii)XandS2are independent of each other.
In cases when the p-dimensional population distribution is non-normal or un-
known but the sample size nis large, the sampling distribution of Xwould be close
to normal, which is the central limit theorem (CLT) summarized in the box below.
Central Limit Theorem
Assume that (X1,X2,..., Xn)is a simple random sample from a p-
dimensional population, and Xis the sample mean. Then, the sampling distri-
bution of√n(X−µ)converges to Np(0,Σ), and the sampling distribution of
n(X−µ)′(S2)−1(X−µ)converges to χ2
p, when nincreases.
7.2.2 Some multivariate Shewhart charts
Assume that (X1,X2,..., Xn)is a simple random sample from a p-dimensional pop-
ulation with the distribution Np(µ,Σ), and XandS2are the sample mean vector andMULTIV ARIATE SHEWHART CHARTS 265
the sample covariance matrix. Then, the random variable
T2=n(X−µ)′/parenleftbig
S2/parenrightbig−1(X−µ) (7.4)
is the so-called Hotelling’s T2statistic in the literature, which plays an important
role in MSPC. The Hotelling’s T2statistic was ﬁrst proposed by Hotelling (1931) as
a generalization of the t-test statistic in univariate statistical inference. Recall from
Subsection 2.7.1 that, if (X1,X2,..., Xn)is a simple random sample from a univariate
population with the distribution N(µ,σ2), then the random variable
X−µ
s/√n
would ha ve the tn−1distribution (cf., (2.18)). Its square can be written as
/parenleftbiggX−µ
s/√n/parenrightbigg2
=n(X−µ)/parenleftbig
s2/parenrightbig−1(X−µ).
Obviously, the Hotelling’s T2statistic deﬁned in (7.4) is the multivariate version of
the above random variable. Hotelling (1947) was the ﬁrst to apply the T2statistic
to the MSPC problem. His MSPC chart and several variants are described below.
For related discussions about the Hotelling’s T2statistic, its properties, and some
control charts constructed from it, see Alt (1985), Fuchs and Kenett (1998), Lowry
and Montgomery (1995), Mason and Young (2002), and the references cited therein.
In this book, certain quadratic statistics similar to T2in (7.4), such as T2
0,iandT2
1,i
deﬁned in (7.5) and (7.7) below, are also called the Hotelling’s T2statistics for sim-
plicity of presentation. Hopefully, this will not cause any confusion.
Let us ﬁrst discuss the phase I MSPC problem. Assume that (X1,X2,..., XM)is
a phase I dataset obtained from a p-dimensional production process. In cases when
the process is IC, its distribution is assumed to be Np(µ0,Σ0), and we are interested
in detecting any mean shifts in the process. In cases when µ0andΣ0are known, at
thei-th time point, it is natural to consider the charting statistic
T2
0,i=(X i−µ0)′Σ−1
0(Xi−µ0). (7.5)
When the process is IC at the i-th time point, it is obvious that
T2
0,i∼χ2
p.
Therefore, the Shewhart chart using T2
0,ias its charting statistic would give a signal
of mean shift if
T2
0,i>χ2
1−α,p, (7.6)
where α∈[0,1]is a given signiﬁcance level, and χ2
1−α,pis the(1−α)-th quantile
of the χ2
pdistribution. Obviously, T2
0,iis the IC squared statistical distance between
Xiand the IC mean vector µ0, and the multivariate Shewhart chart (7.5)–(7.6) gives266 MULTIV ARIATE STATISTICAL PROCESS CONTROL
a signal of mean shift when this distance is larger than the critical value χ2
1−α,p. In
cases when all observations are independent and the process is IC, we have
ARL 0=1
α.
In practice, both µ0andΣ0are usually unknown. In such cases, they can be
estimated by the sample mean vector Xand the sample covariance matrix S2. Then,
theresulting charting statistic is
T2
1,i=(X i−X)′/parenleftbig
S2/parenrightbig−1(Xi−X). (7.7)
When the process is IC and the sample size Mis large, the IC distribution of T2
1,i
would be close to the χ2
pdistribution because XandS2are close toµ0andΣ0,
respectively. However, when Mis small, the distribution of T2
1,icould be substantially
different from χ2
p, because much randomness is added to T2
1,ibyXandS2. Tracy
etal. (1992) studied the IC distribution of T2
1,i, and found that the IC distribution of
M
(M−1)2T2
1,iwas actually abeta distribution with parameters p/2 and(M−p−1)/2,
denoted as Beta( p/2,(M−p−1)/2). The Beta(a, b)distribution is an absolutely
continuous distribution with the pdf
f(x)=1
B(a, b)xa−1(1−x)b−1, forx∈[0,1],
where B(a, b) =/integraltext1
0ua−1(1−u)b−1duis a constant. Then, the Shewhart chart with
the charting statistic T2
1,igives a signal of mean shift in cases when
T2
1,i>(M−1)2
MBeta1−α(p/2,(M−p−1)/2), (7.8)
where α∈[0,1]is a given signiﬁcance level, and Beta 1−α(p/2,(M−p−1)/2) is
the(1−α)-th quantile of the Beta( p/2,(M−p−1)/2) distribution.
Example 7.1 Table 7.1 contains 30 observations from a 3-dimensional production
process for phase I analysis. To apply the Shewhart chart (7.7)–(7.8), we ﬁrst com-
pute the sample mean vector and sample covariance matrix to be
X=(0.490, 0.464, 0.416)′
and
S2=/parenleftigg0.832 0.644 0.492
0.644 0.943 0.794
0.492 0.794 1.059/parenrightigg
.
If we choose α=0.005 (note: ARL 0=1/α=200), then the control limit in (7.8) is
determined to be
(30−1)2
30Beta0.995(1.5, 13)= 10.773.
The corresponding Shewhart chart (7.7)–(7.8) is shown in Figure 7.3 when it is ap-
plied to the data in Table 7.1, from which we can see that a signal is given at the 24th
time point. Therefore, the root cause of this signal should be investigated.MULTIV ARIATE SHEWHART CHARTS 267
Table 7.1: This table contains 30 observations from a 3-dimensional production process.
i X1 X2 X3 i X1 X2 X3
1−0.224−0.464−0.662 16 0.217−0.260−0.005
2−0.082−0.203 0.682 17−0.611−0.048−0.428
3−0.436 0.342 −0.174 18 0.473 0.066 0.890
4 0.455 0.715 1.229 19−1.130−1.214−0.064
5 0.437 0.237 −0.377 20 1.379 2.443 2.350
6 0.669−0.002 0.230 21 0.671 0.534 1.120
7−0.186−0.480−0.907 22 1.467 0.945 0.402
8 0.672 0.384 0.903 23 1.077 0.949 −0.085
9−0.121−0.812−1.279 24 2.126 3.964 3.775
10−0.683 0.093 −0.436 25 2.237 0.959 0.175
11 0.063 0.193 −0.028 26 0.362 0.344 0.375
12−1.029 0.503 0.728 27 2.119 1.569 1.031
13−0.080−0.238−0.218 28 1.147 1.003 1.417
14 0.943 0.272 0.831 29 0.667 0.525 1.676
15 0.147 0.655 −0.543 30 1.944 0.935 −0.130
Next, let us discuss the phase II MSPC problem. Assume that X1,X2,...are
phase II observations obtained from a p-dimensional production process with the IC
distribution Np(µ0,Σ0). In the case when the IC distribution is known (i.e., both µ0
andΣ0are known), we can use the Shewhart chart (7.5)–(7.6) for process monitoring.
In cases when both µ0andΣ0are unknown, they need to be estimated from an IC
dataset. Assume that an IC sample of size Mis available, and µ0andΣ0are estimated
by the sample mean and the sample covariance matrix, respectively, denoted as /hatwideµ0
and/hatwideΣ0. Then, the phase II observations X1,X2,...are independent of both /hatwideµ0and
/hatwideΣ0. At the n-th time point, we can use the charting statistic
T2
2,n=(X n−/hatwideµ0)′/parenleftig
/hatwideΣ0/parenrightig−1
(Xn−/hatwideµ0), (7.9)
which can be regarded as the estimated value of the squared statistical distance be-
tween the observation Xnand the IC mean vector µ0(i.e., d2
S(Xn,µ0)). Tracy et al.
(1992) have shown that when the process is IC, we have
(M−p)M
p(M−1)(M+1)T2
2,n∼Fp,M−p,
where Fp,M−pdenotes theFdistribution with the numerator degrees of freedom p
and the denominator degrees of freedom M−p(cf., Subsection 2.3.4). Therefore,
the Shewhart chart gives a signal of mean shift at the n-th time point if
T2
2,n>p(M−1)(M+1)
(M−p)MF1−α,p,M−p, (7.10)
where F1−α,p,M−pis the(1−α)-th quantile of the Fp,M−pdistribution.268 MULTIV ARIATE STATISTICAL PROCESS CONTROL
0 5 10 15 20 25 300 5 10 15
iT1□□i2
Figure 7.3 The She whart chart (7.7)–(7.8) when it is applied to the data in Table 7.1 and when
α=0.005. The dashed horizontal line denotes the control limit.
Example 7.1 (continued) For the data presented in Table 7.1, assume that the ﬁrst
20 observations are IC observations, the remaining 10 observations are phase II
observations, and we want to use the Shewhart chart (7.9)–(7.10) for phase II moni-
toring of the process. To this end, we ﬁrst compute /hatwideµ0and/hatwideΣ0from the phase I data
to be
/hatwideµ0=(0.044, 0.109, 0.136)′
and
/hatwideΣ0=/parenleftigg0.412 0.279 0.305
0.279 0.532 0.451
0.305 0.451 0.726/parenrightigg
.
Next, if we choose α=0.005, then the control limit is
3(20−1)(20+1)
(20−3)20F0.995,3,17=21.671.
The resulting Shewhart chart (7.9)–(7.10) is shown in Figure 7.4 when it is applied
to the 10 phase II observations, from which it can be seen that a signal of mean shift
is given at the 4th phase II observation time point.
In the above discussion, we assume that there is only one observation vector
at each time point (i.e., the cases with individual observation data). In some ap-
plications, we can collect multiple observation vectors at each time point (i.e., theMULTIV ARIATE SHEWHART CHARTS 269
2 4 6 8 100 5 10 15 20 25 30
nT2□□n2
Figure 7.4 The She whart chart (7.9)–(7.10) when it is applied to the last 10 observations
presented in Table 7.1. The dashed horizontal line denotes the control limit when α=0.005.
cases with batch data) for monitoring a production process. Assume that, in a phase
I MSPC analysis, the following mobservation vectors have been collected from a
p-dimensional production process at the i-th time point:
Xi1,Xi2,..., Xim, fori=1,2,..., M,
where each Xi jis ap-dimensional observation vector, for j=1,2,..., m, and mis
the batch size. Let
Xi=1
mm
∑
j=1Xi j, fori=1,2,..., M,
X=1
MM
∑
i=1Xi,
S2
i=1
m−1m
∑
j=1/parenleftbig
Xi j−Xi/parenrightbig/parenleftbig
Xi j−Xi/parenrightbig′fori=1,2,..., M,
S2=1
MM
∑
i=1S2
i.
Then, XiandS2
iare the sample mean and sample covariance matrix of the mobser-
vation vectors in the i-th batch, Xis the grand sample mean of all mM observation270 MULTIV ARIATE STATISTICAL PROCESS CONTROL
vectors, and S2is the average of {S2
i,i=1,2,..., M}. In the case when the IC process
distribution Np(µ0,Σ0)is known, we can still use the Shewhart chart (7.5)–(7.6) for
process monitoring, except that T2
0,ideﬁned in (7.5) needs to be replaced by
/tildewideT2
0,i=m/parenleftbig
Xi−µ0/parenrightbig′Σ−1
0/parenleftbig
Xi−µ0/parenrightbig
. (7.11)
In cases when both µ0andΣ0are unknown, they can be estimated by XandS2,
respectiv ely. In such cases, the charting statistic T2
1,iin (7.7) can be replaced by
/tildewideT2
1,i=m/parenleftig
Xi−X/parenrightig′/parenleftig
S2/parenrightig−1/parenleftig
Xi−X/parenrightig
. (7.12)
When the process is IC, according to Bersimis et al. (2007) and Mason et al. (2001),
we haveMm−M−p+1
p(M−1)(m−1)/tildewideT2
1,i∼Fp,Mm−M−p+1.
Therefore, the Shewhart chart gives a signal of mean shift at the i-th time point when
/tildewideT2
1,i>p(M−1)(m−1)
Mm−M−p+1F1−α,p,Mm−M−p+1, (7.13)
where α∈[0,1]is a given signiﬁcance level.
The Shewhart chart (7.12)–(7.13) is for phase I MSPC. For phase II MSPC, in
cases when batch data with the batch size of mare available and when the IC process
distribution Np(µ0,Σ0)is known, we can still use the Shewhart chart (7.5)–(7.6)
for process monitoring, except that T2
0,ideﬁned in (7.5) needs to be replaced by /tildewideT2
0,i
deﬁned in (7.11). In cases when both µ0andΣ0are unknown and they are estimated
by/hatwideµ0=Xand/hatwideΣ0=S2, respectively, constructed from an IC data of Mbatches with
thebatch size m, then we can use the charting statistic
/tildewideT2
2,n=m(Xn−/hatwideµ0)′/parenleftig
/hatwideΣ0/parenrightig−1
(Xn−/hatwideµ0), (7.14)
where Xnis the sample mean of the mobservations obtained at the n-th time point
for phase II process monitoring. In such cases, Mason et al. (2001) showed that the
IC distribution of /tildewideT2
2,nwas
Mm−M−p+1
p(Mm+1)(m−1)/tildewideT2
2,n∼Fp,Mm−M−p+1.
Therefore, the chart gives a signal of mean shift at the n-th time point when
/tildewideT2
2,n>p(Mm+1)(m−1)
Mm−M−p+1F1−α,p,Mm−M−p+1, (7.15)
where α∈[0,1]is a given signiﬁcance level.
In the literature, there are also some Shewhart charts proposed for monitoring the
process covariance matrix, or for joint monitoring of both the process mean vector
and the process covariance matrix. See, for instance, Alt (1985), Aparisi et al. (1999,
2001), Khoo and Quah (2003), Levinson et al. (2002), Tang and Barnett (1996a,b),
Yeh and Lin (2002), Yeh et al. (2006), and the references cited therein.MULTIV ARIATE CUSUM CHARTS 271
7.3 Multi variate CUSUM Charts
The multivariate Shewhart charts described in the previous section use the observed
data at the current time point alone for making decisions about the process perfor-
mance at the current time point. As pointed out in Section 4.1 about univariate cases,
such control charts are effective for detecting relatively large and transient shifts in
the process distribution, and are commonly used in phase I SPC analysis. To detect
relatively small and persistent shifts in the process distribution, alternative control
charts, such as the CUSUM, EWMA, and CPD charts, would be more effective.
In this section, we describe some fundamental multivariate CUSUM (MCUSUM)
charts in two parts. Those for monitoring process mean vector are described in Sub-
section 7.3.1, and those for monitoring process covariance matrix are described in
Subsection 7.3.2. As in univariate cases, our discussion about these alternative con-
trol charts will mainly focus on the phase II MSPC, although they can also be used
for the phase I analysis. Also, these alternative control charts are often applied to
individual observation data, instead of batch data. See Section 4.1 for a related dis-
cussion.
7.3.1 MCUSUM charts for monitoring the process mean
Assume that X1,X2,... is a sequence of phase II observations obtained from a
p-dimensional production process with the IC distribution Np(µ0,Σ0), where µ0
and Σ0are known. To monitor the p-dimensional process, Woodall and Ncube
(1985) suggested monitoring the pindividual components of the process by a
joint monitoring scheme, described below. Without loss of generality, assume that
µ0=0(in cases when µ0/ne}ationslash=0, we can monitor the process using the centered data
X1−µ0,X2−µ0,...). For the j-th component with 1 ≤j≤p, let us consider a
two-sided version of the CUSUM chart whose charting statistics are
C+
n,j=max/parenleftig
0,C+
n−1,j+Xn j−kj/parenrightig
, forn≥1
C−
n,j=min/parenleftig
0,C−
n−1,j+Xn j+kj/parenrightig
, (7.16)
where Xn= (X n1,Xn2,..., Xnp)′is the n-th observation vector, C+
0,j=C−
0,j=0, and
kj>0 is an allowance constant. Then, the two-sided CUSUM chart gives a signal of
process mean shift in the j-th component at the n-th time point if
C+
n,j>hj or C−
n,j<−hj,
where hj>0 is a control limit. The joint monitoring scheme suggested by Woodall
and Ncube (1985) gives a signal of process mean shift in the p-dimensional process
if at least one individual two-sided CUSUM chart gives a signal. Namely, it gives a
signal at the n-th time point if
p/uniondisplay
j=1/parenleftig
C+
n,j>hjorC−
n,j<−hj/parenrightig
, (7.17)272 MULTIV ARIATE STATISTICAL PROCESS CONTROL
where/uniontextp
j=1Ajmeans that at least one of the events A1,A2,..., Aphappens.
In cases when the pcomponents of the p-dimensional process are independent,
the average run length (ARL) of the joint monitoring scheme (7.16)–(7.17) can be
approximated by/parenleftbigg
1−1
ARL/parenrightbigg
≈Πp
j=1/parenleftbigg
1−1
ARL j/parenrightbigg
where ARL jdenotes the ARL value of the j-th individual CUSUM chart. From the
above expression, in cases when the ARL andARL jvalues are all quite large, the
ARL value can be approximated by
1
ARL≈p
∑
j=11
ARL j. (7.18)
Forinstance, in the case when the IC ARL values of the pindividual CUSUM charts,
denoted as {ARL 0,j,j=1,2,..., p}, are all chosen to be large, the IC ARL value of
the joint monitoring scheme, denoted as ARL 0, can be computed by
1
ARL 0≈p
∑
j=11
ARL 0,j.
In aspecial case when ARL 0,1=ARL 0,2=···=ARL 0,p, we have ARL 0≈ARL 0,1/p.
Example 7.2 Table 7.2 presents 20 phase II observations obtained from a 3-
dimensional production process for online monitoring of the process mean vector.
The IC process distribution is assumed to be known N 3(µ0,Σ0)where µ0=(0, 0,0)′
andΣ0=I3×3. Therefore, the three components of the quality characteristic vector
X= (X 1,X2,X3)′are independent of each other when the process is IC. The multi-
variate Shewhart charting statistic
T2
0,n=(X n−µ0)′Σ−1
0(Xn−µ0)
is computed at each observation time point, and the calculated values of T2
0,nare also
presented in Table 7.2. When α=0.02 (i.e., the ARL 0value of the Shewhart chart is
1/0.02=50), the control limit of the Shewhart chart is χ2
1−0.02,3=9.837 (cf., (7.6)).
From the table, we can see that the ﬁrst signal by the Shewhart chart is given at the
20th observation time point. The 20 observations in Table 7.2 are actually generated
from N 3(µ1,Σ0)where µ1=c(1,0,0)′. Therefore, the multivariate Shewhart chart
(7.5)–(7.6) is not quite effective in this example.
Next, we apply the joint monitoring scheme (7.16)–(7.17) to the same dataset.
When deﬁning the charting statistics in (7.16), we use k 1=k2=k3=0.5. In the
decision rule (7.17), we use h 1=h2=h3=3.892. So, by Table 4.1 in Subsection
4.2.2, each individual two-sided CUSUM chart in the joint monitoring scheme has an
IC ARL value of 150. Consequently, by (7.18), the ARL 0value of the joint monitoring
scheme (7.16)–(7.17) is approximately 150/3=50, which matches the ARL 0value of
the multivariate Shewhart chart (7.5)–(7.6) described above. The observed data and
the three individual two-sided CUSUM charts are shown in Figure 7.5, from which
we can see that the joint monitoring scheme gives the ﬁrst signal of process mean
shift at the fourth time point, which is much sooner than the ﬁrst signal given by the
multivariate Shewhart chart (7.5)–(7.6).MULTIV ARIATE CUSUM CHARTS 273
0 5 10 15 20−3 −2 −1 0 1 2 3 4
nXn1
(a)0 5 10 15 20−5 0 5 10 15
n
(b)
0 5 10 15 20−3 −2 −1 0 1 2 3 4
nXn2
(c)0 5 10 15 20−5 0 5 10 15
n
(d)
0 5 10 15 20−3 −2 −1 0 1 2 3 4
nXn3
(e)0 5 10 15 20−5 0 5 10 15
n
(f)
Figure 7.5 Observed data (plots (a), (c), (e)) and the corresponding individual two-sided
CUSUM charts (plots (b), (d), (f)). In each individual CUSUM chart, the upward CUSUM
is shown by the dark dots connected by the solid lines, the downward CUSUM is shown by the
small circles connected by the dotted lines, and the control limits are shown by the horizontal
dashed lines.274 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Table 7.2 This table presents 20 phase II observations from a 3-dimensional production pro-
cess and the calculated values of the multivariate Shewhart charting statistic T2
0,n.
i X1 X2 X3 T2
0,n i X1 X2 X3 T2
0,n
10.498−0.438−0.102 0.45 11 1.090−0.091−0.447 1.396
21.132 0.764 1.403 3.833 12 1.096 1.757 −1.739 7.313
30.921 0.262 −1.777 4.074 13 0.798−0.138 0.179 0.688
41.887 0.773 0.623 4.546 14 1.740−0.111 1.897 6.640
51.117−0.814−0.522 2.184 15 1.123−0.690−2.272 6.900
61.319−0.438 1.322 3.679 16 0.971−0.222 0.980 1.953
70.418−0.720−0.363 0.826 17 0.611 0.183 −1.399 2.364
81.715 0.231 1.319 4.733 18 1.511 0.417 1.825 5.787
90.175−1.158 0.044 1.373 19 0.086 1.065 1.381 3.050
10 0.640 0.247 −1.879 4.000 20 3.31 0.970 −0.839 12.603
Example 7.2 shows that the joint monitoring scheme (7.16)–(7.17) is much more
effective in detecting persistent process mean shifts than the multivariate Shewhart
chart (7.5)–(7.6) in that example. Woodall and Ncube (1985) demonstrated that this
conclusion was true in general. Also, after the multivariate Shewhart chart (7.5)–
(7.6) gives a signal of process mean shift, it is still unknown which components of
the mean vector of Xhave shifted. With the joint monitoring scheme (7.16)–(7.17),
this information is often clear to us. For instance, in the example of Figure 7.5, the
upward CUSUM of the ﬁrst individual CUSUM chart gives the ﬁrst signal at the
fourth time point, and the remaining two individual CUSUM charts do not give any
signals before that time point. Based on these individual CUSUM charts, we can
conclude that the ﬁrst component of Xhas an upward mean shift on or before the
fourth time point, and the remaining two components of Xdo not seem shifted by
that time point.
In cases when the components of Xare dependent (i.e., Σ0is not a diagonal
matrix), the result in (7.18) would not be true any more. In such cases, the design
of the joint monitoring scheme (7.16)–(7.17) is quite complicated because it has p
allowance constants and pcontrol limits to determine. One way to overcome this
difﬁculty is to use the principal components approach, ﬁrst discussed in the MSPC
literature for constructing multivariate Shewhart charts by Jackson (1959), Jackson
and Mudholkar (1979), and Jackson (1980). Let Σ0have the following matrix de-
composition
Σ0=Q′ΛQ,
where Qis ap×porthogonal matrix (i.e., Qhas the properties that QQ′=Q′Q=
Ip×p), and Λ=diag( λ1,λ2,..., λp)is a diagonal matrix. Without loss of generality,
let us assume that λj>0, for all j. Otherwise, some components of Xare redundant
(i.e., they can be expressed as linear combinations of the remaining components),
and they can be removed from the process monitoring. Then, X∗=Λ−1/2QXwould
have the identity covariance matrix, and thus its pcomponents are independent of
each other. In the literature, the components of QXare called the principal compo-MULTIV ARIATE CUSUM CHARTS 275
nents of the original random vector X(cf., Johnson and Wichern, 2007, Chapter 8),
andλjis just the IC variance of the j-th principal component, for j=1,2,..., p.
Intuitively, X∗is obtained by ﬁrst rotating the coordinate system of the data, so that
thepcomponents of the rotated data (i.e., QX) are independent, and then rescal-
ing the rotated data to have the same unit variability on all paxes. Then, instead of
monitoring the original data, we can monitor the transformed data
X∗
n=Λ−1/2QX n, forn≥1.
It is obvious that the transformed data have a mean shift at a speciﬁc time point if
and only if the original data have a mean shift at the same time point.
The joint monitoring scheme described above is easy to understand. But, it may
not be convenient to use in practice, especially when the dimensionality pis large.
In cases when the components of the original quality characteristic vector Xare
correlated and its transformed version X∗is used, its advantage of easy interpretation
of the shift signal would disappear. Can we use a single control chart for monitoring
a multivariate process? In the literature, there have been many discussions in that
direction. Some representative approaches are described below.
Healy (1987) suggested a multivariate CUSUM chart using the general formula
(4.20) of the decision interval form of the CUSUM chart (cf., Subsection 4.2.4).
Assume that the IC distribution of a p-dimensional production process is Np(µ0,Σ0),
and it changes to the OC distribution Np(µ1,Σ0)with µ1/ne}ationslash=µ0after an unknown time
point. Then, by (4.20), the charting statistic of the CUSUM chart is
Cn=max[0,Cn−1+log(f1(Xn)/f0(Xn))], forn≥1,
where C0=0, and f0andf1are the pdfs of the IC and OC process distributions. By
some routine algebraic manipulations, this statistic is
Cn=max[0,Cn−1+a′(Xn−µ0)−0.5D], (7.19)
where
a′=(µ1−µ0)′Σ−1
0
D, D=/radicalig
(µ1−µ0)′Σ−1
0(µ1−µ0).
The chart gives a signal of process mean shift when
Cn>h (7.20)
where h>0 is a control limit. To interpret the meaning of aandD, let us consider
the special case when Σ0=Ip×p. In such cases, it is clear that Dis the Euclidean
length of δ=µ1−µ0,δis the vector of shift sizes in different process components,
andais the shift direction. To use the CUSUM chart (7.19)–(7.20), ashould be
known. Therefore, this CUSUM chart is actually a univariate control chart, and it
aims to detect shifts in the mean of a′Xnwhich is univariate. For this reason, most
discussions in Chapter 4 about univariate CUSUM charts can apply to this control
chart.276 MULTIV ARIATE STATISTICAL PROCESS CONTROL
A closely related control chart was proposed by Hawkins (1991), described be-
low. Hawkins (1991) noticed that, in practice, mean shift of a multivariate production
process often occurred in a small number of components, although the indices of the
shifted components were often unknown. For this reason, instead of monitoring a
speciﬁc linear combination of X, as done by the CUSUM chart (7.19)–(7.20) de-
scribed above, we can monitor all individual components of X. Further, when mon-
itoring the individual components of X, their possible association should be taken
into account. To this end, Hawkins (1991) considered the following regression rela-
tionship between the j-th component of Xand its remaining components:
Xj−µ0j=∑
ℓ/negationslash=jβℓj(Xℓ−µ0ℓ)+εj,
where X=(X 1,X2,..., Xp)′,µ0=(µ01,µ02,..., µ0p)′,{βℓj}were regression coefﬁ-
cients, and εjwas the random error with the distribution N(0,τj j). By the properties
of multivariate normal distributions, if X∼Np(µ0,Σ0), then the above regression
model is always true, and there are the following relationships:
τj j=/parenleftig
σj j
0/parenrightig−1
, βℓj=−σℓj
0τj j,forℓ/ne}ationslash=j,
and
τj j=σ0,j j−∑
ℓ/negationslash=jβℓjσ0,ℓj,
where σ0,ℓjandσℓj
0are the(ℓ,j)-th elements of Σ0andΣ−1
0, respectively. Then, to
monitor the j-th component of X, we can use the statistic
Zj=/bracketleftigg
(Xj−µ0j)−∑
ℓ/negationslash=jβℓj(Xℓ−µ0ℓ)/bracketrightigg/slashigg
τ1/2
j j. (7.21)
When the process is IC, then Zjhas the distribution of N(0,1). The statistic Zj
can be regarded as the standardized residual of the regression of Xj−µ0jon
{Xℓ−µ0ℓ, ℓ/ne}ationslash=j}. It has adjusted the variability in Xj−µ0jdue to the possible as-
sociation between Xj−µ0jand{Xℓ−µ0ℓ, ℓ/ne}ationslash=j}, and therefore it is expected to be
more sensitive to shifts in the mean of Xj, compared to the original variable Xj. Let
Z=(Z 1,Z2,..., Zp)′. Then, Zcan be computed by
Z=/bracketleftig
diag(Σ−1
0)/bracketrightig−1/2
Σ−1
0(X−µ0), (7.22)
where diag(Σ−1
0)=diag( σ11
0,σ22
0,···,σpp
0)is ap×pdiagonal matrix.
It can be checked that Zjin (7.21) is exactly the same as a′Xconsidered in
Healy’s CUSUM chart (7.19)–(7.20) in cases when δ=µ1−µ0has a non-zero
value at the j-th position and 0 elsewhere (i.e., the mean shift is in the jcomponent
only). Therefore, CUSUM charts based on Zjwould be optimal for detecting meanMULTIV ARIATE CUSUM CHARTS 277
shifts in Xj.To monitor the p-dimensional production process, we can use a set of
univariate CUSUM charts based on {Zj,j=1,2,..., p}. To this end, let
C+
n,j=max/parenleftig
0,C+
n−1,j+Zn j−k/parenrightig
, forn≥1
C−
n,j=min/parenleftig
0,C−
n−1,j+Zn j+k/parenrightig
, (7.23)
where Zn=(Z n1,Zn2,..., Znp)′is the vector of Zdetermined by (7.22) from the n-th
observation vector Xn, and k>0 is an allowance constant. Then, the j-th individual
CUSUM chart gives a signal of process mean shift in the j-th component of Xif
/parenleftig
C+
n,j>h or C−
n,j<−h/parenrightig
, (7.24)
and the joint monitoring scheme gives a signal of process mean shift in Xat the n-th
time point if
p/uniondisplay
j=1/parenleftig
C+
n,j>horC−
n,j<−h/parenrightig
,
where h>0 is a control limit. Obviously, the above expression is equivalent to
Cn=pmax
j=1/bracketleftig
max/parenleftig
C+
n,j,−C−
n,j/parenrightig/bracketrightig
>h. (7.25)
Because Zn jhas the IC distribution of N(0,1), for each j,kandhcan be determined
to achieve a given ARL 0value for the individual control charts in the same way as
discussed in Chapter 4 about univariate CUSUM charts. For instance, when (k,h)are
chosen to be (0.5, 4.171), each individual CUSUM chart (7.24) would have an ARL 0
value of 200 (cf., Table 4.1 in Subsection 4.2.2), and they are good for detecting mean
shifts of sizes around ±1.0 in each component. However, the ARL 0value of the joint
monitoring scheme (7.25) is difﬁcult to determine analytically from the ARL 0values
of the individual CUSUM charts because {Zn j,j=1,2,..., p}might be associated.
One way to determine the ARL 0value of the joint monitoring scheme is to use a
Monte Carlo simulation, as discussed in Subsection 4.2.2.
An alternative approach to construct a multivariate CUSUM chart based on Znis
to use the charting statistic
/tildewideCn=p
∑
j=1/parenleftig
C+
n,j+C−
n,j/parenrightig2
, (7.26)
and the chart gives a signal of process mean shift if
/tildewideCn>/tildewideh (7.27)
where/tildewideh>0 is a control limit chosen to achieve a given ARL 0value. Again, the
value of/tildewidehcan be determined by a Monte Carlo simulation. Between the multivariate
CUSUM chart (7.26)–(7.27) and the joint monitoring scheme (7.25), Hawkins (1991)
showed by a numerical study that the former was slightly more effective than the
latter for detecting mean shifts in X.278 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Example 7.3 Consider a 3-dimensional production process with the IC distribution
N3(µ0,Σ0), where
µ0=(0, 0,0)′
and
Σ0=/parenleftigg1.0 0.8 0.5
0.8 1.0 0.8
0.5 0.8 1.0/parenrightigg
.
The ﬁrst 30 phase II observations are presented in columns 2–4 of Table 7.3. The
three components of Xnare also shown in Figure 7.6(a)–(c). To monitor the process,
we ﬁrst compute the standardized residuals Znby (7.22), and the three components
ofZnare shown in Figure 7.6(d)–(f). Then, we use both control charts (7.25) and
(7.26)–(7.27) for process monitoring. In both charts, k and ARL 0are chosen to be
0.5 and 200, respectively, and the control limits h and /tildewideh are computed by the R
codes written by the author to be 5.014 and 42.031. With these parameters, the three
individual CUSUM charts deﬁned by (7.23)–(7.24) are shown in Figure 7.6(g)–(i).
From the plots, we can see that the ﬁrst individual CUSUM chart gives the ﬁrst signal
at the 14th time point, and the second and third CUSUM charts both give signals at
later times. Therefore, the joint monitoring scheme (7.25) shown in Figure 7.6(j)
gives the ﬁrst signal at the 14th time point as well. The multivariate CUSUM chart
(7.26)–(7.27) is shown in Figure 7.6(k), which gives the ﬁrst signal at the 14th time
point too. The production process actually has a mean shift starting from the 11th
time point from µ0toµ1= (1, 0,0)′. From the plots in Figure 7.6, it seems that (i)
the mean shift in X 1is more obviously revealed in plot (d), compared to plot (a), and
(ii) the mean shift in X 1affects both Z 1and the remaining components of Z, although
its impact on Z 1is much larger than its impact on the remaining components of Z
(cf., plots (g)–(i)). As a matter of fact, the expression (7.22) conﬁrms the second
conclusion that the mean shift in X 1would affect all components of Zwhen the
components of Xare correlated (i.e., when Σ0is not a diagonal matrix).
Besides the above multivariate CUSUM charts, another multivariate CUSUM
chart that receives much attention in the literature was proposed by Crosier (1988).
Its charting statistic Cn, for n≥1, is deﬁned as follows. Let
Un=/braceleftbigg
0, ifYn≤k
(Un−1+Xn−µ0)(1−k/Yn),otherwise,(7.28)
where U0=0,k>0 is an allowance constant, and
Yn=/bracketleftig
(Un−1+Xn−µ0)′Σ−1
0(Un−1+Xn−µ0)/bracketrightig1/2
.
Then, the chart gives a signal of process mean shift at the n-th time point when
Cn=/parenleftig
U′
nΣ−1
0Un/parenrightig1/2
>h, (7.29)
where h>0 is a control limit chosen to reach a pre-speciﬁed ARL 0value. The statistic
Unis deﬁned using the restarting mechanism of CUSUM charts (cf., a related discus-
sion in Subsection 4.2.1). When Ynis less than or equal to k,Unis set to be 0, becauseMULTIV ARIATE CUSUM CHARTS 279
0 5 10 20 30−2 0 1 2 3
nXn1
(a)0 5 10 20 30−2 0 1 2 3
nXn2
(b)0 5 10 20 30−2 0 1 2 3
nXn3
(c)
0 5 10 20 30−3 −1 1 2 3 4
nZn1
(d)0 5 10 20 30−3 −1 1 2 3 4
nZn2
(e)0 5 10 20 30−3 −1 1 2 3 4
nZn3
(f)
0 5 10 20 30−10 0 10 20
nCn□□1
(g)0 5 10 20 30−10 0 10 20
nCn□□2
(h)0 5 10 20 30−10 0 10 20
nCn□□3
(i)
0 5 10 20 300 5 10 15 20 25
nCn
(j)0 5 10 20 300 200 400 600 800
nCn
(k)
Figure 7.6 Plots (a)–(c) show the three components of the original observed data Xn, plots
(d)–(f) show the three components of the standardized residuals Zn, plots (g)–(i) show the three
individual CUSUM charts deﬁned by (7.23)–(7.24), and plots (j) and (k) show the multivariate
CUSUM charts (7.25) and (7.26)–(7.27). In plots (g)–(k), the horizontal dashed lines denote
the control limits. In control charts (7.25) and (7.26)–(7.27), k and ARL 0are chosen to be 0.5
and 200.280 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Table 7.3 This table presents the ﬁrst 30 phase II observations of a 3-dimensional production
process and the calculated values of the charting statistics C nand/tildewideCndeﬁned in (7.25) and
(7.26), respectively.
n X1 X2 X3 Cn/tildewideCn
1−0.533−0.385−0.443 0.003 0.000
2 0.167−0.052 0.263 0.235 0.103
3 0.068−0.138−0.133 0.006 0.000
4 0.492 0.680 1.232 0.709 0.521
5−0.071 0.306 0.053 0.323 0.151
6 0.229 0.413 0.199 0.305 0.093
7−0.400−0.396−0.789 0.427 0.352
8 0.387 0.640 0.898 0.110 0.012
9−0.404−0.529−1.318 1.105 1.496
10−1.430−0.408 0.880 0.907 1.373
11 1.206−0.194−0.241 1.902 6.901
12 3.231 1.959 0.492 3.655 14.281
13 0.637 0.140 −0.184 3.897 15.654
14 0.177−0.497 1.074 5.470 46.898
15 1.270−0.185−2.002 6.230 46.872
16 0.322−0.219 0.302 6.963 58.578
17 1.710 0.434 −0.688 8.201 76.067
18 0.481 0.342 1.306 8.802 95.855
19 1.356 0.798 1.737 10.374 152.797
20 1.972 1.432 0.133 10.657 131.571
21 1.164−0.310−0.098 12.817 209.360
22 2.228 1.375 1.160 14.399 262.789
23−0.511−1.410−1.890 14.480 255.437
24−0.016 1.060 1.565 12.920 185.391
25 0.583−0.675−0.287 14.629 272.393
26 2.467 1.322 0.754 16.464 337.168
27 0.399−0.404 0.037 17.524 396.194
28 2.137 1.089 1.339 19.643 512.923
29 1.304−0.364 0.234 22.398 705.441
30−0.575−1.801−1.668 23.305 772.824
there is little evidence of process mean shift in such cases. Otherwise, Unis set to be
(Un−1+Xn−µ0)(1−k/Yn), which shrinks the cumulative sum Un−1+Xn−µ0by
1−k/Yntimes.
Crosier (1988) studied another multivariate CUSUM chart with the charting
statistic
/tildewideCn=max/parenleftig
0,/tildewideCn−1+Tn−k/parenrightig
, (7.30)
where/tildewideC0≥0 is a pre-speciﬁed initial value, k>0 is an allowance constant, and
Tn=/bracketleftig
(Xn−µ0)′Σ−1
0(Xn−µ0)/bracketrightig1/2
.
Clearly, Tnis the square-root of the Hotelling’s T2statistic, and/tildewideCnis the conventionalMULTIV ARIATE CUSUM CHARTS 281
CUSUM charting statistic based on Tn. For this reason, the resulting CUSUM chart
is called the CUSUM of Tn, or simply the COT chart. This chart gives a signal when
/tildewideCn>/tildewideh, (7.31)
where/tildewideh>0 is a control limit chosen to achieve a given ARL 0value. Based on a
numerical study, Crosier (1988) demonstrated that the multivariate CUSUM chart
(7.28)–(7.29) was often more effective than the COT chart (7.30)–(7.31).
7.3.2 MCUSUM charts for monitoring the process covariance matrix
All the multivariate CUSUM charts described in the previous subsection can be mod-
iﬁed properly for monitoring the process covariance matrix. For instance, in the mul-
tivariate CUSUM chart (7.16)–(7.17) by Woodall and Ncube (1985), if its charting
statistics C+
n,jandC−
n,jare replaced by the charting statistics for detecting variance
shifts in the j-th component of X(e.g., C+
nandC−
ndeﬁned in (4.21) and (4.23)), then
the resulting CUSUM chart should be effective for detecting shifts in the process
covariance matrix. For a related discussion about variance monitoring by CUSUM
charts in univariate cases, see Section 4.3.
Healy (1987) considered a case when the process mean vector would not shift but
the process covariance matrix could shift from Σ0toΣ1=cΣ0at an unknown time
point, where c>0 was a constant. In such cases, if the p-dimensional process be-
comes OC, then the variances of the pcomponents of Xchange by a same proportion
and the correlation between any two individual components does not change. By the
general formula (4.20) of the CUSUM charting statistic, Healy (1987) derived the
following charting statistic for monitoring the process covariance matrix:
Cn=max/bracketleftbig
0,Cn−1+T2
n−k/bracketrightbig
, forn≥1, (7.32)
where C0≥0 is a pre-speciﬁed initial value, T2
n= (X n−µ0)′Σ−1
0(Xn−µ0)is the
Hotelling’s T2statistic, and
k=pclog(c)
c−1.
This chart gives a signal at the n-th time if
Cn>h, (7.33)
where h>0 is a control limit chosen to achieve a given ARL 0value. By the opti-
mality of the CUSUM chart (cf., Subsection 4.2.4), the chart (7.32)–(7.33) should be
optimal for detecting the process covariance matrix shift from Σ0toΣ1=cΣ0.
By comparing the CUSUM chart (7.32)–(7.33) with the COT chart (7.30)–(7.31),
we can see that their only difference is that the Hotelling’s T2statistic T2
nis used in
the construction of the former chart while its square-root is used in the construction
of the latter chart. Remember that the COT chart is proposed mainly for detecting
process mean shifts, while the CUSUM chart (7.32)–(7.33) is derived for detecting
process covariance matrix shifts. Therefore, both of them are actually effective for
detecting both process mean shifts and process covariance matrix shifts, which is
demonstrated in the example below.282 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Example 7.4 Assume that a 3-dimensional production process has the IC distribu-
tion N 3(µ0,Σ0), where
µ0=(0, 0,0)′
and
Σ0=/parenleftigg1.0 0.8 0.5
0.8 1.0 0.8
0.5 0.8 1.0/parenrightigg
.
Let us consider the following three scenarios:
(i)The process has a mean shift only at the 11th time point from µ0toµ1=(1, 0,0)′;
(ii)The process has a covariance matrix shift only at the 11th time point from Σ0to
Σ1=1.1Σ 0; and
(iii) The process has a mean shift from µ0toµ1=(1, 0,0)′and a covariance matrix
shift from Σ0toΣ1=1.1Σ 0at the 11th time point.
In each scenario, 30 observations of the process are generated from the related dis-
tribution. In scenario (i), the values of the multivariate Shewhart charting statistic
T2
0,n=(X n−µ0)′Σ−1
0(Xn−µ0), for n=1,2,..., 30
are shown in Figure 7.7(a), together with the control limit χ2
0.995,3=12.838. This
chart has the ARL 0value of 1/(1−0.995) = 200. Then, we apply the multivariate
CUSUM chart (7.32)–(7.33) and the COT chart (7.30)–(7.31) to the same dataset. In
the chart (7.32)–(7.33), k and ARL 0are chosen to be 4 and 200, respectively, and C 0
is chosen to be 0. By a simulation using an Rcode written by the author, the control
limit h is computed to be 13.062. In the COT chart, k and ARL 0are chosen to be 1
and 200, respectively, /tildewideC0is chosen to be 0, and the control limit /tildewideh is computed to
be 2.713. These two charts are shown in Figure 7.7(b)–(c). From the plots, we can
see that the Shewhart chart could not detect the mean shift in this case, the chart
(7.32)–(7.33) gives the ﬁrst signal at the 14th time point, and the COT chart gives
the ﬁrst signal at the 11th time point. The corresponding results for scenarios (ii)
and (iii) are shown in the plots in the 2nd and 3rd rows of Figure 7.7. In scenario
(ii), the Shewhart chart could not detect the covariance matrix shift, the chart (7.32)–
(7.33) gives the ﬁrst and the only signal at the 24th time point, and the COT chart
gives the ﬁrst signal at the 12th time point. In scenario (iii), the Shewhart chart gives
a marginally signiﬁcant signal at the 12th time point, the chart (7.32)–(7.33) gives
the ﬁrst signal at the 14th time point, and the COT chart gives the ﬁrst signal at
the 11th time point. From this example, it can be seen that the Shewhart chart is
not sensitive to either the process mean shift or the process covariance matrix shift
in cases when such shifts are small, the multivariate CUSUM chart (7.32)–(7.33)
and the COT chart (7.30)–(7.31) are sensitive to both the process mean shift and
the process covariance matrix shift, and it seems that the COT chart (7.30)–(7.31)
is more effective than the chart (7.32)–(7.33) for detecting either the process mean
shift or the process covariance matrix shift or both.
Hawkins (1991) mentioned that the regression-adjusted standardized residuals Z
deﬁned in (7.22) could also be used for monitoring process variance shifts. More
speciﬁcally, to monitor the variance shift in the j-th component of X, for 1≤j≤p,
we can consider
Wn j=/parenleftig
|Zn j|1/2−0.822/parenrightig/slashig
0.349, forn≥1, (7.34)MULTIV ARIATE CUSUM CHARTS 283
0 5 10 20 300 5 10 15
nT0□□n2
(a)0 5 10 20 300 10 20 30 40 50 60
nCn
(b)0 5 10 20 300 5 10 15 20 25 30
nCn
(c)
0 5 10 20 300 5 10 15
nT0□□n2
(d)0 5 10 20 300 5 10 15
nCn
(e)0 5 10 20 300 5 10 15 20
nCn
(f)
0 5 10 20 300 5 10 15
nT0□□n2
(g)0 5 10 20 300 10 20 30 40 50 60
nCn
(h)0 5 10 20 300 5 10 15 20 25 30
nCn
(i)
Figure 7.7 Plots (a)–(c) show the Shewhart chart, the multivariate CUSUM chart (7.32)–
(7.33) with k =4, and the COT chart (7.30)–(7.31) with k =1, respectively, when they are
applied to a dataset of the ﬁrst 30 observations of a 3-dimensional production process in
scenario (i). In each chart, the ARL 0value is chosen to be 200, and the corresponding control
limit is denoted by the horizontal dashed line in the related plot. Results in scenarios (ii) and
(iii) are shown in the corresponding plots in the 2nd and 3rd rows, respectively.284 MULTIV ARIATE STATISTICAL PROCESS CONTROL
where Zn=(Zn1,Zn2,..., Znp)′is the n-th regression-adjusted standardized residual
vector. It can be checked that the IC distribution of Wn jis approximately N(0,1),
and its mean would shift upward (downward) when the variance of Xjshifts upward
(downward). Deﬁne
C+
n,j=max/parenleftig
0,C+
n−1,j+Wn j−k/parenrightig
, forn≥1
C−
n,j=min/parenleftig
0,C−
n−1,j+Wn j+k/parenrightig
, (7.35)
where C+
0,j=C−
0,j=0, and k>0 is an allowance constant. Then, C+
n,jcan be used for
detecting an upward variance shift in the j-th component of X, and C−
n,jfor detecting
a downward variance shift in the j-th component. To detect an arbitrary variance shift
in any components of X, a joint monitoring scheme can be used, and it gives a signal
at the n-th time point if
Cn=pmax
j=1/bracketleftig
max/parenleftig
C+
n,j,−C−
n,j/parenrightig/bracketrightig
>h, (7.36)
where h>0 is a control limit chosen to achieve a pre-speciﬁed ARL 0value. An
alternative charting statistic for joint monitoring is
/tildewideCn=p
∑
j=1/parenleftig
C+
n,j+C−
n,j/parenrightig2
, (7.37)
and the chart gives a signal of process variance shift if
/tildewideCn>/tildewideh, (7.38)
where/tildewideh>0 is a control limit chosen to achieve a pre-speciﬁed ARL 0value.
7.4 Multivariate EWMA Charts
In this section, we describe some multivariate EWMA (MEWMA) charts for moni-
toring a p-dimensional quality characteristic vector Xof a production process, where
p≥2 is a given integer. Although MEWMA charts can also be used for phase I SPC
analysis, they are mainly used for phase II process monitoring, and the latter is the
focus of this section. Our description is divided into two subsections. Those for mon-
itoring the process mean are discussed in Subsection 7.4.1, and those for monitoring
the process covariance matrix are discussed in Subsection 7.4.2.
7.4.1 MEWMA charts for monitoring the process mean
The univariate EWMA chart was ﬁrst generalized to multivariate cases by Lowry
et al. (1992) for detecting process mean shifts. Let X1,X2,...be a sequence of phase
II observation vectors obtained from a p-dimensional production process with the
IC distribution Np(µ0,Σ0), where µ0andΣ0are assumed known. Then, a natural
generalization of the univariate EWMA charting statistic deﬁned in (5.1) is
En=Λ(Xn−µ0)+(I p×p−Λ)En−1, (7.39)MULTIV ARIATE EWMA CHARTS 285
where E0=0,Λ=diag(λ1,λ2,..., λp), and λj∈(0,1]is a weighting parameter for
thej-th component of X, for j=1,2,..., p. The corresponding MEWMA chart with
the charting statistic Enin (7.39) gives a signal of process mean shift at the n-th time
point if
V2
n=E′
nΣ−1
EnEn>h, (7.40)
where h>0 is a control limit chosen to reach a pre-speciﬁed ARL 0value, and ΣEnis
the covariance matrix of En.
In practice, if there is no a priori reason to weight different components differ-
ently, then we can simply choose λ1=λ2=···=λp=λ. In such cases,
En=λ(Xn−µ0)+(1−λ)En−1,
and by some routine algebraic manipulations, it can be checked from the above ex-
pression that
En=λn
∑
i=1(1−λ)n−i(Xi−µ0).
Therefore, when the process is IC up to the time point n, we have
ΣEn=n
∑
i=1λ2(1−λ)2(n−i)Σ0
=λ
2−λ/bracketleftbig
1−(1−λ)2n/bracketrightbig
Σ0, (7.41)
and
En∼Np(0,ΣEn).
It is obvious that, when nincreases, ΣEnin (7.41) converges to
/tildewideΣ0,λ=λ
2−λΣ0. (7.42)
Also, the IC distribution of V2
nin (7.40) is χ2
p. However, because the variables in
the sequence {V2
n,n=1,2,...} are correlated, the control limit hin (7.40) cannot
simply be chosen to be the (1−α)-th quantile χ2
1−α,pof the χ2
pdistribution, as we
did in (7.6) for the Shewhart charts. Instead, it can be determined by a Monte Carlo
simulation (cf., the pseudo code given in Subsection 4.2.2). In cases when the process
mean shifts at the time point τ≤nfrom µ0toµ1, we have
En∼Np/parenleftigg
λn
∑
i=τ(1−λ)n−i(µ1−µ0),ΣEn/parenrightigg
.
In such cases, the distribution of V2
nisχ2
p(cn)with the noncentrality parameter
cn=λ(2−λ)/bracketleftbig
∑n
i=τ(1−λ)n−i/bracketrightbig2
1−(1−λ)2n(µ1−µ0)′Σ−1
0(µ1−µ0).286 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Table 7.4 ARL 1values of the chart (7.39)–(7.40) for detecting several mean shifts of various
sizes when p =3, ARL 0=200, and λ=0.1,0.2,0.3,0.4, and 0.5.
δ’/radicalig
δ′Σ−1
0δλ=0.1 λ=0.2 λ=0.3 λ=0.4 λ=0.5
(0,0,0) 0200.047 199.967 199.939 199.981 199.914
(0.1614,0,0) 0.292 72.326 90.606 108.387 121.276 134.209
(0.25,0.25,0.25) 0.292 72.408 90.889 108.491 121.850 134.791
(0.25,0.25,0) 0.420 42.199 54.444 68.738 81.786 94.375
(0.25,0,0) 0.452 37.581 48.439 61.813 75.128 87.174
(0.5,0.5,0.5) 0.584 24.768 30.422 39.434 48.901 59.062
(0.5,0.5,0) 0.839 14.418 15.604 19.058 23.430 28.804
(1,1,1) 1.168 9.176 8.807 9.603 11.099 13.227
(1.5,1.5,1.5) 1.752 5.599 4.862 4.758 4.906 5.288
(2,2,2) 2.336 4.102 3.416 3.160 3.070 3.093
(2,2,0) 3.358 2.872 2.324 2.099 1.942 1.827
Therefore, the OC run length distribution of the MEWMA chart (7.39)–(7.40) is
affected by the shift size δ=µ1−µ0through[δ′Σ−1
0δ]1/2which can be interpreted
as the statistical distance from δto0(cf., Subsection 7.2.1), or the statistical length
ofδ.
From the above discussion, the IC behavior of the MEWMA chart (7.39)–(7.40)
depends only on the parameters p,λ, and ARL 0, and its OC behavior depends on
these parameters together with the statistical length of the shift size vector δ. In
cases when p=3,ARL 0=200, and λ=0.1,0.2,0.3,0.4, and 0.5, the searched h
values of the chart by an R-code written by the author are, respectively,
10.820, 11.879, 12.320, 12.559, 12.696.
In such cases, the ARL 1values of the chart for detecting several mean shifts of var-
ious different sizes of a 3-dimensional production process with the IC distribution
N3(µ0,Σ0)are presented in Table 7.4, where µ0=(0, 0,0)′and
Σ0=
1.0 0.8 0.5
0.8 1.0 0.8
0.5 0.8 1.0
.
From the table, we can see that (i) the ARL 1value indeed depends on δthrough
[δ′Σ−1
0δ]1/2(cf., lines 2 and 3 of the table in which the values of [δ′Σ−1
0δ]1/2are
about the same and the two sets of ARL 1values are also about the same), (ii) for a
given λvalue, the ARL 1value decreases when [δ′Σ−1
0δ]1/2increases, and (iii) the
chart with a large λvalue is good for detecting relatively large shifts and it is good
for detecting relatively small shifts when λis chosen to be small.
Example 7.5 For the phase II data considered in Example 7.3, let us consider using
the MEWMA chart (7.39)–(7.40) for monitoring the process mean. In the chart, we
choose λ=0.2and h=11.879 so that its ARL 0value is 200. The chart is shown inMULTIV ARIATE EWMA CHARTS 287
0 5 10 15 20 25 300 10 20 30 40
nVn2
Figure 7.8 The MEWMA chart (7.39)–(7.40) when it is applied to the data considered in
Example 7.3 and when λ=0.2and ARL 0=200. The dashed horizontal line denotes the
control limit.
Figure 7.8, from which we can see that the ﬁrst signal of process mean shift is given
at the 17th time point.
Hawkins et al. (2007) discussed the cases when the weighting matrix Λin (7.39)
contained non-zero off-diagonal elements. More speciﬁcally, they discussed in detail
the case when all diagonal elements of Λwere the same to be λonand all off-diagonal
elements of Λwere the same to be λoff. Further, they assumed that λoff=cλonwith
|c|<1, and that the summation of the elements in each column of Λwas the same
to be r. The former assumption implies that the j-th component of Xnhas the largest
impact on the j-th component of En, for each j, and the latter assumption implies
that the total weights assigned to each component of Xnare the same to be r. In such
cases, it is easy to check that
λon=r
1+(p−1)c, λoff=cr
1+(p−1)c.
Therefore, the weighting matrix Λis uniquely determined by the two parameters c
andr. Based on the preliminary study in Hawkins et al. (2007), the following two
conclusions can be made:288 MULTIV ARIATE STATISTICAL PROCESS CONTROL
(i)The performance of the MEWMA chart (7.39)–(7.40) can be improved by using
the more general weighting matrix Λdescribed above, compared to its perfor-
mance when a single weighting parameter λis used, and
(ii)The ARL performance of the MEWMA chart (7.39)–(7.40) using the more gen-
eral weighting matrix Λdescribed above depends on the direction of a mean shift
and on the correlation structure of different components of Xnas well. As a com-
parison, its ARL performance does not depend on the shift direction, when a sin-
gle weighting parameter λis used.
However, the design of the MEWMA chart using the weighting matrix Λwould be
much more complicated. For instance, it is still unknown how to choose the param-
eters candrproperly for detecting a speciﬁc process mean shift, partly because the
shift direction and the correlation structure among the process components should
be taken into account in the design, and the relationship between the ARL and these
two factors is unclear yet. Therefore, much future research is required on this topic.
The MEWMA chart (7.39)–(7.40) is based on the assumption that the IC pro-
cess distribution Np(µ0,Σ0)is known. In reality, both the IC process mean vector
µ0and the IC process covariance matrix Σ0are often unknown. In such cases, cer-
tain self-starting multivariate control charts have been proposed in the literature. See,
for instance, Hawkins and Maboudou-Tchao (2007), Quesenberry (1997), and Sul-
livan and Jones (2002). Next, we brieﬂy describe the self-starting MEWMA chart
proposed by Sullivan and Jones (2002).
LetX1,X2,...be a sequence of phase II observation vectors obtained from a
p-dimensional production process, and XnandS2
nbe the sample mean vector and
sample covariance matrix of the ﬁrst nobservation vectors. Then, XnandS2
ncan be
computed by the recursive formulas below.
Xn=1
n/bracketleftbig
(n−1)Xn−1+Xn/bracketrightbig
,forn≥1,
S2
n=n−2
n−1S2
n−1+1
n/parenleftbig
Xn−Xn−1/parenrightbig/parenleftbig
Xn−Xn−1/parenrightbig′,forn≥2, (7.43)
where X0=0andS2
1=0p×p. Further ,
un=/radicalbigg
n−1
n/parenleftbig
Xn−Xn−1/parenrightbig
∼Np(0,Σ0). (7.44)
Based on these results, we can consider the following self-starting MEWMA charting
statistic
En,SS=λun+(1−λ)En−1,SS, (7.45)
where E0,SS=0, and λ∈(0,1]is a weighting parameter. The chart gives a signal at
then-th time point if
V2
n,SS=E′
n,SS/hatwideΣ−1
En,SSEn,SS>hSS, (7.46)
where
/hatwideΣEn,SS=λ
2−λ/bracketleftbig
1−(1−λ)2n/bracketrightbig
S2
n−1MULTIV ARIATE EWMA CHARTS 289
is an estimator of ΣEn,SS, and hSS>0 is a control limit chosen to achieve a pre-
speciﬁed ARL 0value. Note that, in (7.46), we need to compute the inverse of /hatwideΣEn,SS.
When nis small, such an inverse may not exist, or it exists but the matrix /hatwideΣEn,SSis
close to a singular matrix. To overcome this numerical difﬁculty, we suggest starting
the process monitoring at n=p+2, and letting V2
n,SS=0 when n<p+2. Namely,
to use the self-starting MEWMA chart (7.45)–(7.46), at least p+1 IC observation
vectors need to be collected beforehand.
To design the self-starting MEWMA chart (7.45)–(7.46), we can determine the
value of hSSby a numerical simulation, pretending the IC process distribution is
Np(0,Ip×p). Although the control limit computed in this way is only approximately
valid, due to the fact that un∼Np(0,Σ0)andΣ0is approximated by the sample
covariance matrix S2
nin the chart, it is quite reliable based on our numerical studies
(cf., Example 7.6 below), especially when ARL 0is chosen relatively large. Sullivan
and Jones (2002) pointed out that the control limit hSSdepended on the value of p,
besides the values of λandARL 0. To get rid of its dependence on p, they suggested
the following alternative charting statistic:
/tildewideV2
n,SS=/radicaligg
G−1/braceleftbigg
Fp,n−p−1/bracketleftbiggn−p−1
p(n−2)V2
n,SS/bracketrightbigg/bracerightbigg
,
where Gis the cdf of the χ2
1distribution, and Fp,n−p−1is the cdf of the Fp,n−p−1
distribution. The IC distribution of /tildewideV2
n,SSis the same as the distribution of the square-
root of a χ2
1distributed random variable, which does not depend on p. Thus, the
control limit of /tildewideV2
n,SSdoes not depend on peither.
Example 7.6 The ﬁrst 30 observation vectors of a 3-dimensional production process
are presented in columns 2–4 of Table 7.5. The three components of undeﬁned by
(7.44) are presented in columns 5–7 of the table. Then, the self-starting MEWMA
chart (7.45)–(7.46) is applied to this data for online process mean monitoring. In the
chart, λand ARL 0are chosen to be 0.2 and 200, respectively. By an R-code written
by the author, the control limit h SSis computed to be 14.167 and 14.168, respectively,
in cases when the IC process distribution is assumed to be N p(0,Ip×p)and when the
true IC distribution N p(0,Σ0)is used, where Σ0is the same as the one in Example
7.4. The values of the charting statistic V2
n,SSare presented in the last column of Table
7.5. The self-starting MEWMA chart (7.45)–(7.46) is also shown in Figure 7.9. From
the ﬁgure, it can be seen that the ﬁrst signal of process mean shift is given at the
25th time point; but, the signal does not last very long. Therefore, we should react to
the signal from the chart quickly. Otherwise, the shift could be missed. For a related
discussion on this feature of the self-starting control charts, see Subsections 4.5.1
and 5.4.1.
7.4.2 MEWMA charts for monitoring the process covariance matrix
In this subsection, we discuss some MEWMA charts for monitoring the process
covariance matrix. From the discussion in Chapters 4 and 5, it can be seen that290 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Table 7.5 This table presents the ﬁrst 30 phase II observations of a 3-dimensional production
process, the three components of uncomputed by (7.44), and the values of the charting statistic
V2
n,SSof the self-starting MEWMA chart (7.45)–(7.46).
n X1 X2 X3 u1 u2 u3 V2
n,SS
1−0.224−0.464−0.662 0 0 0 0
2−0.082−0.203 0.682 0 0 0 0
3−0.436 0.342 −0.174−0.231 0.551 −0.150 0
4 0.455 0.715 1.229 0.609 0.713 1.109 0
5 0.437 0.237 −0.377 0.455 0.125 −0.577 4.649
6 0.669−0.002 0.230 0.583−0.116 0.083 3.486
7−0.186−0.480−0.907−0.299−0.541−0.982 2.752
8 0.672 0.384 0.903 0.544 0.339 0.842 2.563
9−0.121−0.812−1.279−0.268−0.828−1.315 4.645
10−0.683 0.093 −0.436−0.773 0.118 −0.376 1.224
11 0.063 0.193 −0.028 0.012 0.202 0.048 1.019
12−1.029 0.503 0.728 −1.034 0.482 0.769 4.220
13−0.080−0.238−0.218−0.039−0.269−0.202 1.455
14 0.943 0.272 0.831 0.949 0.242 0.824 0.214
15 0.147 0.655 −0.543 0.114 0.596 −0.561 3.733
16 0.217−0.260−0.005 0.175−0.328−0.003 0.514
17−0.611−0.048−0.428−0.639−0.104−0.414 0.538
18 0.473 0.066 0.890 0.451 0.014 0.891 0.204
19−1.130−1.214−0.064−1.133−1.233−0.086 8.145
20 1.379 2.443 2.350 1.370 2.394 2.271 5.608
21 0.671−0.466 0.120 0.613−0.561−0.015 2.811
22 1.467−0.055−0.598 1.361−0.134−0.716 5.203
23 1.077−0.051−1.085 0.919−0.124−1.161 7.389
24 2.126 2.964 2.775 1.908 2.833 2.667 13.398
25 2.237−0.041−0.825 1.938−0.227−0.969 17.783
26 0.362−0.656−0.625 0.024−0.821−0.735 9.438
27 2.119 0.569 0.031 1.746 0.412 −0.063 14.527
28 1.147 0.003 0.417 0.728−0.158 0.318 11.751
29 0.667−0.475 0.676 0.232−0.623 0.561 11.525
30 1.944−0.065−1.130 1.479−0.199−1.234 14.106
most CUSUM charts can be changed into EWMA charts after proper modiﬁca-
tions. By this connection between the two types of charts, the MCUSUM charts
discussed in Subsection 7.3.2 for monitoring the process covariance matrix can also
be changed into MEWMA charts. For instance, the MCUSUM chart (7.32)–(7.33)
can be modiﬁed as follows. Let X1,X2,...be a sequence of phase II observation
vectors obtained from a p-dimensional production process with the IC distribution
Np(µ0,Σ0), where µ0andΣ0are assumed known. Then, the Hotelling’s T2statis-
ticT2
n=(X n−µ0)′Σ−1
0(Xn−µ0)would have a χ2
pdistribution when the process is
IC. Instead of using the MCUSUM charting statistic in (7.32), we can consider theMULTIV ARIATE EWMA CHARTS 291
0 5 10 15 20 25 300 5 10 15 20
nVn□□SS2
Figure 7.9 The self-starting MEWMA chart (7.45)–(7.46) when it is applied to the data pre-
sented in Table 7.5 and when λ=0.2and ARL 0=200. The dashed horizontal line denotes
the control limit h SS=14.167.
following MEWMA charting statistic:
En=λ(T2
n−p)+(1−λ)En−1, forn≥1, (7.47)
where E0=0,λ∈(0,1]is a weighting parameter, and the dimensionality pis also the
IC mean of T2
n(cf., Subsection 2.3.2). The resulting MEWMA chart gives a signal
of process covariance matrix shift at the n-th time point if
En>h (7.48)
where h>0 is a control limit chosen to achieve a pre-speciﬁed ARL 0value, and
it can be determined by a Monte Carlo simulation. Similar to the construction of
the MEWMA chart (7.47)–(7.48), the COT chart (7.30)–(7.31) and the regression-
adjusted MCUSUM chart (7.34)–(7.38) can both be modiﬁed properly into the cor-
responding MEWMA charts.
Hawkins and Maboudou-Tchao (2008) proposed a MEWMA chart speciﬁcally
for monitoring the process covariance matrix, described as follows. For the IC pro-
cess covariance matrix Σ0, assume that its Cholesky decomposition is
Σ0=UU′(7.49)292 MULTIV ARIATE STATISTICAL PROCESS CONTROL
where Uis ap×plower triangular matrix. Let L=U−1. Then LΣ0L′=Ip×p, and
Lis ap×plower triangular matrix. For the n-th observation vector Xnwith n≥1,
deﬁne its transformation
Yn=L(Xn−µ0). (7.50)
Then, it is easy to check that the IC distribution of YnisNp(0,Ip×p). Thus, its pcom-
ponents are independent of each other, and each of them has the N(0,1)distribution
when the process is IC. As a matter of fact, its j-th component Yn jcan be interpreted
as the residual of the regression of Xn jon(Xn1,Xn2,..., Xn,j−1), rescaled to have a
unit variance (cf., Hawkins, 1993b). Then, we deﬁne
En=λYnY′
n+(1−λ)En−1, (7.51)
where E0=Ip×p, and λ∈(0,1]is a weighting parameter. The MEWMA chart gives
a signal of process covariance matrix shift at the n-th time point if
Cn=Tr(E n)−log|En|−p>h (7.52)
where Tr(A)denotes the trace of a square matrix A(i.e., the summation of all diag-
onal elements of A), and h>0 is a control limit chosen to achieve a pre-speciﬁed
ARL 0value. The charting statistic Cnin (7.52) is derived using the log-likelihood
ratio statistic for testing H0:Σ=Ip×pversus H1:Σ/ne}ationslash=Ip×pbased on En, where Σ
denotes the true covariance matrix of Yn.
By Monte Carlo simulations, Hawkins and Maboudou-Tchao (2008) searched
for the hvalues for some commonly used λandARL 0values, part of which are
presented in Table 7.6. From the table, it is apparent that the control limit hincreases
when either one of p,λ, and ARL 0increases.
Example 7.7 Consider a 3-dimensional production process with the IC distribution
N3(µ0,Σ0), where
µ0=(0, 0,0)′
and
Σ0=/parenleftigg1.0 0.8 0.5
0.8 1.0 0.8
0.5 0.8 1.0/parenrightigg
.
The ﬁrst 30 phase II observations are presented in columns 2–4 of Table 7.7. Then,
by using the function chol() in theR-package Matrix, the Cholesky decomposition of
Σ0(cf., (7.49)) is found to be
Σ0=/parenleftigg1.0 0 0
0.8 0.6 0
0.5 0.667 0.553/parenrightigg
×/parenleftigg1.0 0.8 0.5
0 0.6 0.667
0 0 0.553/parenrightigg
.
Therefore, the regression-adjusted standardized residuals Yncan be computed by
(7.50), where
L=/parenleftigg1.0 0 0
−1.333 1.667 0
0.704−2.010 1.809/parenrightigg
.MULTIV ARIATE EWMA CHARTS 293
Table 7.6This table presents the values of the control limit h of the MEWMA chart (7.51)–
(7.52) for some commonly used λand ARL 0values in cases when p =2,3,4,5. This table is
part of Table 1 in Hawkins and Maboudou-Tchao (2008).
ARL 0
p λ 100 200 250 500 1000
2 0.05 0.182 0.232 0.247 0.295 0.342
0.10 0.446 0.542 0.573 0.669 0.765
0.15 0.738 0.883 0.930 1.077 1.228
0.20 1.051 1.247 1.311 1.515 1.724
0.25 1.383 1.632 1.714 1.977 2.247
0.30 1.732 2.037 2.138 2.461 2.794
3 0.05 0.301 0.364 0.383 0.441 0.496
0.10 0.712 0.831 0.868 0.981 1.093
0.15 1.163 1.340 1.396 1.569 1.741
0.20 1.646 1.884 1.960 2.195 2.430
0.25 2.159 2.459 2.556 2.856 3.157
0.30 2.701 3.066 3.184 3.550 3.919
4 0.05 0.444 0.521 0.544 0.611 0.673
0.10 1.028 1.169 1.212 1.342 1.467
0.15 1.665 1.872 1.937 2.132 2.322
0.20 2.347 2.623 2.709 2.972 3.231
0.25 3.072 3.417 3.526 3.860 4.188
0.30 3.839 4.256 4.388 4.793 5.194
5 0.05 0.612 0.702 0.729 0.805 0.876
0.10 1.396 1.559 1.608 1.754 1.891
0.15 2.250 2.486 2.559 2.775 2.984
0.20 3.163 3.474 3.570 3.861 4.143
0.25 4.135 4.523 4.643 5.008 5.364
0.30 5.166 5.631 5.776 6.219 6.652
The computed values of Ynarepresented in columns 5–7 of Table 7.7. The MEWMA
chart (7.51)–(7.52) is then applied to this dataset, in which the λand ARL 0values
are chosen to be 0.2 and 200, respectively, and thus the control limit h is 1.884
according to Table 7.6. The calculated values of the charting statistic C ndeﬁned
in (7.52) are presented in the last column of Table 7.7, and the MEWMA chart is
shown in Figure 7.10 as well. From the plot, the chart gives its ﬁrst signal of process
covariance matrix shift at the 14th time point.
In the literature, there is much other discussion about the monitoring of the pro-
cess covariance matrix. For instance, Huwang et al. (2007), Yeh and Lin (2002),
and Yeh et al. (2003, 2004a, 2005) proposed several MEWMA charts for monitoring
the process covariance matrix, some of which are based on similar ideas to that of
the chart (7.51)–(7.52). Reynolds and Stoumbos (2008) compared a number of joint
monitoring schemes for monitoring both the process mean vector and the process
covariance matrix. In some of these joint monitoring schemes, both the MEWMA
charts and the multivariate Shewhart charts are used.294 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Table 7.7 This table presents the ﬁrst 30 phase II observations of a 3-dimensional produc-
tion process (columns 2–4), the three components of Yn=(Yn1,Yn2,Yn3)′computed by (7.50)
(columns 5–7), and the values of the charting statistic C nof the MEWMA chart (7.51)–(7.52)
(last column) in which λand ARL 0are chosen to be 0.2 and 200, respectively.
n Xn1 Xn2 Xn3 Yn1 Yn2 Yn3 Cn
1−0.533−0.385−0.443−0.533 0.070 −0.404 0.053
2 0.167−0.052 0.263 0.167−0.309 0.698 0.181
3 0.068−0.138−0.133 0.068−0.322 0.085 0.410
4 0.492 0.680 1.232 0.492 0.476 1.209 0.524
5−0.071 0.306 0.053 −0.071 0.603 −0.568 0.692
6 0.229 0.413 0.199 0.229 0.383 −0.309 0.959
7−0.400−0.396−0.789−0.400−0.127−0.912 1.215
8 0.387 0.640 0.898 0.387 0.551 0.610 1.454
9−0.404−0.529−1.318−0.404−0.343−1.605 1.698
10−1.430−0.408 0.880 −1.430 1.227 1.407 1.060
11 0.363−0.305−0.230 0.363−0.993 0.454 0.772
12 2.157 2.151 −0.149 2.157 0.710 −3.077 1.722
13−0.574 0.444 −0.337−0.574 1.505 −1.905 1.583
14−0.845−0.914 1.673 −0.845−0.397 4.269 3.976
15 0.364 0.375 −2.650 0.364 0.140 −5.293 7.629
16−0.814−0.212 0.487 −0.814 0.732 0.734 5.938
17 0.737 0.704 −1.118 0.737 0.191 −2.920 6.213
18−0.814 0.254 1.607 −0.814 1.508 1.825 5.240
19 0.192 0.491 2.024 0.192 0.562 2.810 5.061
20 0.661 1.919 −0.451 0.661 2.316 −4.209 7.267
21 0.368−0.535 0.020 0.368−1.383 1.372 5.994
22 1.089 1.324 0.997 1.089 0.756 −0.092 4.162
23−1.495−0.984−1.998−1.495 0.353 −2.688 3.950
24−1.826 1.527 1.599 −1.826 4.980 −1.461 6.858
25−0.266−0.833−0.093−0.266−1.034 1.318 5.333
26 1.422 1.302 0.476 1.422 0.274 −0.755 3.781
27−0.632−0.443 0.214 −0.632 0.104 0.834 2.686
28 1.108 0.820 1.375 1.108−0.111 1.620 2.048
29 0.601−0.809 0.508 0.601−2.150 2.969 3.496
30−1.387−1.689−1.509−1.387−0.966−0.311 2.379
7.5 Multivariate Control Charts by Change-Point Detection
As discussed in Section 6.4, the CUSUM and EWMA charts both require a substan-
tial amount of prior information about the IC and OC process distributions in their
design and construction. As a comparison, the CPD control charts have the advan-
tages that they do not need much prior information about the IC and OC process
distributions for process monitoring and that they can provide an estimator of the
shift time at the same time as they give a signal of process mean or variance shift.
Some of the univariate CPD charts discussed in Chapter 6 have been generalized to
multivariate cases, which are described in this section.MULTIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION 295
0 5 10 15 20 25 300 2 4 6 8
nCn
Figure 7.10 The MEWMA chart (7.51)–(7.52) when it is applied to the data presented in Table
7.7 and when λ=0.2and ARL 0=200. The dashed horizontal line denotes the control limit.
Zamba and Hawkins (2006) generalized the univariate CPD chart (6.13)–(6.14)
to multivariate cases for online monitoring of the process mean vector. First, let us
assume that {X1,X2,..., Xn}is a sequence of observation vectors obtained from a
p-dimensional production process, and the sequence follows the change-point model
Xi∼/braceleftbigg
Np(µ0,Σ0), ifi≤r
Np(µ1,Σ0), ifi>r,
where µ0andΣ0are the IC process mean vector and the IC process covariance
matrix, µ1is the OC process mean vector that is assumed different from µ0, and
1≤r≤n−1 is the change-point. In this change-point model, the process mean vector
has a shift at the time point τ=r+1, but the process covariance matrix is assumed
unchanged. In such cases, the Hotelling’s T2statistic for testing the hypotheses H0:
µ0=µ1versus H1:µ0/ne}ationslash=µ1is
T2
r=r(n−r)
n/parenleftbig
X0,r−Xr,n/parenrightbig′/parenleftig
/tildewideS2
r/parenrightig−1/parenleftbig
X0,r−Xr,n/parenrightbig
(7.53)296 MULTIV ARIATE STATISTICAL PROCESS CONTROL
where
Xj1,j2=1
j2−j1j2
∑
i=j1+1Xi,for an y 0≤j1<j2≤n
/tildewideS2
r=1
n−2/bracketleftigg
r
∑
i=1/parenleftbig
Xi−X0,r/parenrightbig/parenleftbig
Xi−X0,r/parenrightbig′+
n
∑
i=r+1/parenleftbig
Xi−Xr,n/parenrightbig/parenleftbig
Xi−Xr,n/parenrightbig′/bracketrightigg
.
Now, let us discuss phase II process monitoring, and assume that X1,X2,...are
phase II observation vectors obtained from a p-dimensional production process. To
detect a process mean shift at the current time point n, it is natural to consider the
charting statistic
T2
max,n=max
1≤r≤n−1T2
r, (7.54)
where T2
ris deﬁned in (7.53). The corresponding CPD chart gives a signal of process
mean shift if
T2
max,n>hn (7.55)
where hn>0 is a control limit chosen to achieve a pre-speciﬁed ARL 0value and it
may depend on n. After a signal is given, the shift time τcan be estimated by /hatwider+1,
where/hatwideris the maximizer found in (7.54).
To use the CPD chart (7.54)–(7.55), the control limit hnshould be chosen prop-
erly. As discussed in Subsection 6.3.1, one reasonable way is to choose hnsuch that,
when the process is IC,
P/parenleftbig
T2
max,n>hn/vextendsingle/vextendsingleno signal before n/parenrightbig
≤α,
where α∈[0,1]is a pre-speciﬁed conditional false alarm rate. If hnis chosen in this
way, then the ARL 0value of the CPD chart (7.54)–(7.55) would be 1/ α. Based on
numerical studies, Zamba and Hawkins (2006) provided the following approximation
formulas for computing hnin cases when α=0.001, 0.002, and 0.005 and n>25:
log(h n)=

3.043+0.221 p−p+4
50log(n−25), ifα=0.001
2.897+0.226 p−2p+7
100log(n−25), ifα=0.002
2.706+0.230 p−p+3
50log(n−25), ifα=0.005.(7.56)
To simplify the computation involved in the CPD chart (7.54)–(7.55), a recursive
algorithm for computing its charting statistic T2
max,nwas developed by Zamba and
Hawkins (2006), described below. First, for a given nand a given 1 ≤r≤n−1, we
can re-write T2
rdeﬁned in (7.53) as
T2
r=(n−2)crd′
rW−1
ndr
1−crd′rW−1ndr, (7.57)MULTIV ARIATE CONTROL CHARTS BY CHANGE-POINT DETECTION 297
where cr=rn/(n−r),dr=X0,r−X0,n, and
Wn=n
∑
i=1/parenleftbig
Xi−X0,n/parenrightbig/parenleftbig
Xi−X0,n/parenrightbig′.
Second, the sample mean X0,ncan be computed recursively by
X0,n=X0,n−1+1
n/parenleftbig
Xn−X0,n−1/parenrightbig
. (7.58)
Finally, Wncanbe computed recursively by
Wn=Wn−1+n−1
n/parenleftbig
Xn−X0,n−1/parenrightbig/parenleftbig
Xn−X0,n−1/parenrightbig′.
From this formula, we have
W−1
n=W−1
n−1−(n−1)W−1
n−1/parenleftbig
Xn−X0,n−1/parenrightbig/parenleftbig
Xn−X0,n−1/parenrightbig′W−1
n−1
n/bracketleftig
1+n−1
n/parenleftbig
Xn−X0,n−1/parenrightbig′W−1
n−1/parenleftbig
Xn−X0,n−1/parenrightbig/bracketrightig. (7.59)
Therefore, T2
rcan be computed recursively by formulas (7.57)–(7.59).
Example 7.8 The ﬁrst 50 observations obtained from a 3-dimensional production
process are shown in Figure 7.11(a)–(c). It is assumed that the ﬁrst 25 of them are IC
observations, and that the IC process distribution is N 3(µ0,Σ0). But, the IC process
mean µ0and the IC process covariance matrix Σ0are both unknown. We then apply
the CPD control chart (7.54)–(7.55) to this data, and start to monitor the process
mean vector at the 26th time point. In the chart, αis chosen to be 0.005 (i.e., ARL 0
is chosen 1/0.005=200), h nis approximated by the third formula in (7.56), and
the formulas (7.57)–(7.59) are used for recursively computing the charting statistic
T2
max,n. The CPD control chart is shown in Figure 7.11(d), from which it can be seen
that the ﬁrst signal of process mean shift is given at the 36th time point. Then, the
MLE of the change-point r is obtained from (7.54) to be /hatwider=30. Therefore, the shift
time is estimated to be 31. The IC and OC process mean vectors can then be esti-
mated by the sample mean vectors of the ﬁrst 30 observations and the following 6
observations, respectively, to be
/hatwideµ0=(− 0.027, 0.038, 0.065)′,/hatwideµ1=(1.273, 0.090,−0.030)′.
The IC process covariance matrix Σ0can be estimated by the pooled sample variance
/tildewideS2
/hatwiderof the ﬁrst 36 observations, which is computed to be
/tildewideS2
/hatwider=/parenleftigg0.774 0.595 0.201
0.595 0.856 0.586
0.201 0.586 0.852/parenrightigg
.
Zamba and Hawkins (2009) proposed a CPD control chart for monitoring both
the process mean vector and the process covariance matrix. Assume that X1,X2,...298 MULTIV ARIATE STATISTICAL PROCESS CONTROL
0 10 20 30 40 50−2 −1 0 1 2 3
nXn1
(a)0 10 20 30 40 50−2 −1 0 1 2 3
nXn2
(b)
0 10 20 30 40 50−2 −1 0 1 2 3
nXn3
(c)30 35 40 45 500 10 20 30 40 50
nTmax□□n2
Figure 7.11 The thr ee components of the ﬁrst 50 observations obtained from a 3-dimensional
production process (plots (a)–(c)) and the CPD control chart (7.54)–(7.55) (plot (d)). In plot
(d), the dashed curve denotes the control limit h n, approximated by the third formula of (7.56)
when αis chosen to be 0.005.
are observation vectors obtained from a p-dimensional production process, and they
follow the change-point model
Xi∼/braceleftbigg
Np(µ0,Σ0), ifi≤r
Np(µ1,Σ1), ifi>r,
where µ0andΣ0are the IC process mean vector and the IC process covariance
matrix, µ1andΣ1are the OC process mean vector and the OC process covariance
matrix, and 1 ≤r≤n−1 is the change-point. In this change-point model, both the
process mean vector and the process covariance matrix may have shifts at the timeMULTIV ARIATE CONTROL CHARTS BY LASSO 299
point τ=r+1. To use the ﬁrst nobservations to test the hypotheses
H0:µ1=µ0,Σ1=Σ0 versus H1:H0is not true,
under the assumptions that ris given and r<n, the LRT statistic is proportional to
Λr,n=|S2
0,r|(r−1)/2|S2
r,n|(n−r−1)/2
|S2
0,n|(n−1)/2,
where S2
j1,j2denotes the sample covariance matrix constructed from the observations
Xj1+1,Xj1+2,..., Xj2, for any j1<j2. Based on this result, Zamba and Hawkins
(2009) showed that the IC distribution of the statistic
G2
r,n=−2log(Λr,n)[p(p+3)]/Cr,n
was approximately a chi-square distribution, where
Cr,n
=p[log(2)+(n −1)log(n−1)−(n−r−1)log(n−r−1)−(r−1)log(r−1)]
+p
∑
j=1[(n−1)ψ((n−j)/2)−(r−1)ψ((r−j)/2)−(n−r−1)ψ((n−r−j)/2)]
was the Bartlett correction factor. So, Zamba and Hawkins (2009) considered the
charting statistic
G2
max,n=max
1≤r≤n−1G2
r,n. (7.60)
The chart gives a signal at the n-th time point if
G2
max,n>hn, (7.61)
where hn>0 is a control limit, and it can be computed by a Monte Carlo simulation.
7.6 Multivariate Control Charts by LASSO
In MSPC, a multivariate production process is monitored for possible shifts in its
mean vector and/or its covariance matrix. In practice, many shifts only involve a
small number of unknown process components. If there is a data-driven procedure
for ﬁguring out the shifted components, then we can make use of this information in
process monitoring, and the resulting MSPC charts could be more efﬁcient. In recent
years, certain variable selection procedures, such as the least absolute shrinkage and
selection operator (LASSO) (cf., Tibshirani, 1996), have been demonstrated to be
useful for MSPC. In this section, we brieﬂy discuss how to construct multivariate
control charts using LASSO. Our discussion is divided into two parts. In Subsection
7.6.1, the LASSO procedure is brieﬂy described in the context of regression variable
selection. Then, a MEWMA chart based on LASSO variable selection is described
in Subsection 7.6.2.300 MULTIV ARIATE STATISTICAL PROCESS CONTROL
7.6.1 LASSO for regression variable selection
Consider the following multiple linear regression model:
yi=Z′
iβ+εi, fori=1,2,..., n,
where y,Z, and βare the response variable, vector of predictors, and vector of re-
gression coefﬁcients, respectively, (Z′
i,yi)is the i-th observation of (Z′,y), and{εi}
are i.i.d. random errors with the distribution N(0,σ2). In practice, some predictors do
not provide much useful information about the response variable, given the remain-
ing predictors; thus, they can be deleted from the model. To ﬁnd which variables
should be deleted, the stepwise and all subset variable selection procedures along
with a model selection criterion (e.g., AIC or BIC) are often used (cf., Devore, 2011,
Chapter 13). Such model selection procedures are practically useful; but they have
several limitations, including the lack of stability (cf., Breiman, 1996), the lack of
theoretical properties (cf., Fan and Li, 2001), and the extensive computation (cf.,
Tibshirani, 1996). To overcome these limitations, some authors suggest using the
following penalized least squares method (or equivalently, the penalized likelihood
method in the normal error distribution case):
n
∑
i=1(yi−Z′
iβ)2+np
∑
j=1gγj(|βj|),
where βjdenotes the j-th component of β,{γj}are the penalty parameters (also
called the regularization parameters), and {gγj}are the penalty functions. When
gγj(|βj|)= γ|βj|where γis a constant parameter, the corresponding penalized least
squares method is called LASSO (cf., Tibshirani, 1996). Besides LASSO, another
major penalized least squares method is the so-called smoothly clipped absolute de-
viation (SCAD) method (cf., Fan and Li, 2001). Among other good properties, Fan
and Li (2001) have shown that, with the proper choice of the penalty functions and
regularization parameters, the penalized likelihood estimators of βwould perform
asymptotically as well as the estimator obtained in cases when the correct submodel
was known, which is referred to as the oracle property in the literature. When the
penalty functions are chosen to be continuous, the coefﬁcient estimates that corre-
spond to those insigniﬁcant predictors would shrink towards 0 as γincreases, and
these coefﬁcient estimates could be exactly 0 if γis chosen sufﬁciently large. In ad-
dition, the penalized likelihood method, especially when LASSO-type penalty func-
tions are used, enjoys efﬁcient computation using the LARS algorithm by Efron
(2004). See Zou and Li (2008) for a detailed discussion about the computational
issues of LASSO and SCAD.
7.6.2 A LASSO-based MEWMA chart
In this subsection, we describe a MEWMA chart using the LASSO variable selection
procedure described in the previous subsection for monitoring the mean vector of a
p-dimensional production process, where p≥2 is a given integer. This MEWMAMULTIV ARIATE CONTROL CHARTS BY LASSO 301
chart w as proposed by Zou and Qiu (2009); thus, a more detailed description can be
found in that paper.
From the description about the MSPC control charts in the previous several sec-
tions, it can be seen that the fundamental tasks of MSPC control charts for monitoring
the process mean vector include (i) determining whether the process mean vector µ
has changed from the IC process mean µ0up to the current time point n, (ii) detect-
ing the speciﬁc time point at which a detected mean shift occurs, and (iii) identifying
the shifted components of µ. Let X1,X2,..., Xnbe the ﬁrst nobservation vectors
obtained from a p-dimensional production process with the known IC distribution
Np(µ0,Σ0). Then, different methods for accomplishing these tasks usually adopt the
following change-point model:
Xi∼/braceleftbigg
Np(µ0,Σ0), fori=1,2,..., r,
Np(µ1,Σ0), fori=r+1,r+2,..., n,
where the IC process covariance matrix Σ0is assumed unchanged over time, the
process mean vector is assumed changed from µ0toµ1atτ=r+1, and ris the
change-point. Throughout this subsection, we further assume that µ0=0, without
loss of generality. Otherwise, we can simply replace XibyXi−µ0in all related
descriptions below. Then, a basic strategy for detecting a mean shift is to test hy-
potheses
H0:µ=0 versus H1:µ/ne}ationslash=0
using the likelihood ratio test (LRT) statistic nX′Σ−1
0X, where µdenotes the true
process mean vector, and X=1
n∑n
i=1Xiis the sample mean vector. In cases when
the shift direction dwith unit length is known, the above alternative hypothesis can
be replaced by H′
1:µ=δd, where δis an unknown constant denoting the shift
magnitude in the direction of d. In such cases, Healy (1987) has shown that the LRT
statistic and its null distribution are
n/parenleftig
d′Σ−1
0X/parenrightig2
d′Σ−1
0dH0∼χ2
1. (7.62)
The test based on (7.62) should be more efﬁcient than the test based on nX′Σ−1
0Xin
cases when the shift direction dis known.
In practice, the shift direction dis usually unknown. Therefore, the procedure
by Healy (1987) cannot be used directly in many applications. However, it can be
estimated using the idea of the LASSO variable selection as follows. After a constant
term is ignored, the penalized likelihood (PL) function of the observed data can be
written as
PL(µ)=n/parenleftbig
X−µ/parenrightbig′Σ−1
0/parenleftbig
X−µ/parenrightbig
+np
∑
j=1gγj(|µj|),
where µ=(µ1,µ2,..., µp)′. If the adaptive LASSO (ALASSO) penalty function by
Zou (2006) is used, then it becomes
PL(µ)=n/parenleftbig
X−µ/parenrightbig′Σ−1
0/parenleftbig
X−µ/parenrightbig
+nγp
∑
j=11
|Xj||µj|, (7.63)302 MULTIV ARIATE STATISTICAL PROCESS CONTROL
where X= (X1,X2,..., Xp)′. The ALASSO penalty function used in (7.63) is
slightly dif ferent from the traditional one by Tibshirani (1996) in that the latter uses
the same amount of shrinkage for each µjwhile the former determines the amount
of shrinkage for µjadaptively by the value of |Xj|. Because of this difference, the
coefﬁcient estimator by the traditional LASSO cannot be as efﬁcient as the oracle
estimator (cf., Fan and Li, 2001) and its model selection results could be inconsis-
tent in certain cases; but, the ALASSO estimator is asymptotically unbiased and it
has certain oracle properties. See Fan and Li (2001), Zhao and Yu (2006), and Zou
(2006) for a related discussion. The ALASSO estimator of µis then deﬁned by
/hatwideµγ=argmin
µPL(µ).
Because of its property that some of its components are exactly zero when γis prop-
erly chosen, the ALASSO estimator /hatwideµγis an ideal estimator of the shift direction in
the MSPC problem. Then, a LASSO-based test statistic can be deﬁned by
/tildewideTγ=n/parenleftig
/hatwideµ′
γΣ−1
0X/parenrightig2
/hatwideµ′
γΣ−1
0/hatwideµγ.
Theoretically,/hatwideµγ/ne}ationslash=0almost surely. For completeness, /tildewideTγcan be deﬁned to be any
negative number when /hatwideµγ=0. Obviously,/tildewideTγcan be regarded as a data-driven ver-
sion of the test statistic deﬁned in (7.62) by Healy (1987), with the shift direction d
replaced by its estimator /hatwideµγ.
To use the above LASSO-based test statistic /tildewideTγ, the regularization parameter γ
should be chosen properly, since it plays an important role in balancing robustness
and sensitivity of /tildewideTγto various shifts. From some theoretical results, it is found that
selection of γshould depend on the shift size. For detecting a large shift, γshould be
chosen to be large, and it should be chosen to be small for detecting a small shift. Fur-
ther, numerical results show that conventional procedures for choosing regulariza-
tion parameters, such as the cross-validation (CV), the generalized cross-validation
(GCV), AIC, BIC, etc. (cf., Subsection 2.8.5), do not work properly in the current
problem, because these parameter selection procedures are mainly for model estima-
tion and they usually do not produce a powerful testing procedure (cf., Bickel and
Li, 2006; Hart, 1997). To overcome this difﬁculty, Zou and Qiu (2009) suggested
using the approach proposed by Horowitz and Spokoiny (2001) in the nonparametric
testing setup, by combining several values of γto make the resulting test nearly op-
timal in various different cases. Let Γq={γk,k=1,..., q}be a set of values of the
regularization parameter γ, where qis a pre-speciﬁed constant. Then, the modiﬁed
penalized test statistic is deﬁned by
/tildewideT=max
k=1,...,q/tildewideTγk−E/parenleftig
/tildewideTγk/parenrightig
/radicalbigg
Var/parenleftig
/tildewideTγk/parenrightig,
where E(/tildewideTγk)and Var(/tildewideTγk)are respectively the mean and variance of /tildewideTγkunder H0.MULTIV ARIATE CONTROL CHARTS BY LASSO 303
The pointset Γqcanbe determined as follows. Let us ﬁrst rewrite the ALASSO-
type penalized likelihood function (7.63) as
PL(α)=n/parenleftbig
X−Dα/parenrightbig′Σ−1
0/parenleftbig
X−Dα/parenrightbig
+nγp
∑
j=1|αj|, (7.64)
where α= (α1,α2,..., αp)′,αj=µj/|Xj|, for j=1,2,..., p, and D=
diag(| X1|,|X2|,...,|Xp|). This is exactly a LASSO-type penalized likelihood func-
tion. According to Zou et al. (2007c), for a given Xin (7.64), there is a ﬁnite sequence
/tildewideγ0>/tildewideγ1>...>/tildewideγK=0 (7.65)
such that (i) for all γ>/tildewideγ0,/hatwideαγ=0, where/hatwideαγdenotes the minimizer of (7.64), and (ii)
when γis in the interval (/tildewideγk+1,/tildewideγk), the active set B(γ)={j: sgn[/hatwideαγ,j]/ne}ationslash=0}and the
sign vector S(γ) ={sgn[/hatwideαγ,1],..., sgn[/hatwideαγ,p]}are unchanged, where /hatwideαγ,jis the j-th
component of/hatwideαγ, and sgn is a sign function taking the values of −1, 0, and 1 when
its argument is negative, 0, and positive, respectively. These /tildewideγm’s are called transition
points because the active set changes at each /tildewideγmonly. The transition points can be
determined easily using the LARS algorithm by Efron (2004). Further, according to
Efron (2004), the random integer Kcan be larger than p. Thus, the quantities /tildewideγmlast
k,
fork=1,..., q, can be used for constructing Γq, where mlast
kis the index of the last
/tildewideγin the sequence {/tildewideγ0,/tildewideγ1,...,/tildewideγK}deﬁned in (7.65) that the corresponding active set
contains exactly kelements. According to Zou et al. (2007c), /tildewideT/tildewideγmlast
kare well deﬁned,
because the “one at a time” condition (cf., Efron, 2004) holds almost everywhere,
where “one at a time” means that the two active sets of two consecutive /tildewideγs differ on
at most a single index. After Γqis determined in this way, the resulting test statistic
becomes
/tildewideTL=max
k=1,...,q/tildewideT/tildewideγmlast
k−E/parenleftbigg
/tildewideT/tildewideγmlast
k/parenrightbigg
/radicaligg
Var/parenleftbigg
/tildewideT/tildewideγmlast
k/parenrightbigg. (7.66)
Note that/tildewideT/tildewideγmlastpis equivalent to the Hotelling’s T2test statistic. Therefore, the test
using the test statistic in (7.66) should share certain properties of the Hotelling’s T2
test, which does not take into account any structure of the potential shift, and certain
properties of the likelihood ratio tests constructed using some speciﬁc structures of
the potential shift.
Next, we construct a phase II MEWMA chart using the LASSO-based test statis-
tic/tildewideTLdeﬁned in (7.66), and it should be pointed out that other types of MSPC charts
(e.g., multivariate CUSUM and Shewhart charts) can also be developed in a similar
way. Let X1,X2,...be phase II observation vectors obtained from a p-dimensional
production process. Then, a sequence of MEWMA statistics using a single weighting
parameter λ∈(0,1](cf., (7.39)) is deﬁned by
En=λXn+(1−λ)En−1, forn≥1, (7.67)304 MULTIV ARIATE STATISTICAL PROCESS CONTROL
where E0=0.For each En, we can compute the qLASSO estimators /hatwideµn,/tildewideγmlast
k,for
k=1,2,..., q, from the penalized likelihood function
(En−µ)′Σ−1
0(En−µ)+γp
∑
j=11
|En,j||µj|, (7.68)
where En=(E n,1,En,2,..., En,p)′. Then, the LASSO-based MEWMA chart, denoted
as LEWMA, gives a signal of process mean shift at the n-th time point if
Qn=max
k=1,...,qWn,/tildewideγmlast
k−E/parenleftbigg
Wn,/tildewideγmlast
k/parenrightbigg
/radicaligg
Var/parenleftbigg
Wn,/tildewideγmlast
k/parenrightbigg>h, (7.69)
where
Wn,γ=2−λ
λ[1−(1−λ)2n]/parenleftig
E′
nΣ−1
0/hatwideµγ/parenrightig2
/hatwideµ′
γΣ−1
0/hatwideµγ,
andh>0 is a control limit chosen to achieve a given ARL 0value. In practice,
(2−λ)/{λ[1−(1−λ)2n]}can be replaced by its asymptotic form (2−λ)/λ, as
discussed in (7.41)–(7.42).
In the LEWMA chart (7.67)–(7.69), selection of λmainly depends on a target
shift, as in conventional EWMA charts (cf., Subsection 5.2.1). It should be chosen
large if the target shift is large and small otherwise. Regarding the value of q, if
prior information indicating potential shifts in at most rcomponents, with 1 ≤r≤p,
then the numerical studies show that using q=r+1 or q=r+2 often provides
a satisfactory performance in practice. When such prior information is unavailable,
numerical results show that the LEWMA chart with q=pwould perform reasonably
well. Further, theoretical results show that the quantities E( Wn,/tildewideγmlast
k)and Var( Wn,˜γmlast
k)
used in (7.69) do not depend on λandnwhen the process is IC. Therefore, they can
be approximated by the empirical mean and variance of Wn,˜γmlast
k, computed from the
simulated IC observation vectors, since Enis the same as Xnwhen λ=1. The control
limit hin (7.69) can also be determined by a Monte Carlo simulation.
Example 7.9 Assume that the IC distribution of a 5-dimensional production pro-
cess is N 5(0,Σ0), where Σ0= (σi j)is speciﬁed as σii=1andσi j=0.75|i−j|, for
i,j=1,2,..., 5. In the LEWMA chart (7.67)–(7.69), q, λ, and ARL 0are chosen to be
5, 0.2, and 500, respectively. Then, by a simulation with 20,000 replicated runs, its
control limit h is computed to be 5.262. Besides this chart, the MEWMA chart (7.39)–
(7.40) by Lowry et al. (1992), denoted as MEWMA, and the same chart applied to the
regression-adjusted observations {Zn,n=1,2,...} (cf., (7.21) and (7.22)), denoted
as REWMA, are also considered. In each of the MEWMA and REWMA charts, a sin-
gle weighting parameter is used and its value is chosen to be 0.2, as in the LEWMA
chart. The control limits of the MEWMA and REWMA charts are computed by sim-
ulation to be 18.130 and 3.425, respectively, to reach the ARL 0value of 500. Then,MULTIV ARIATE CONTROL CHARTS BY LASSO 305
20 dif ferent shifts are considered, and a true shift is assumed to occur at τ=26. The
computed OC ARL values of the three charts by a simulation with 20,000 replications
are presented in Table 7.8. From the table, we can see that the LEWMA chart may
not be the best in a given case, but it is always close to the best. As a comparison, the
MEWMA chart does not perform well for detecting the ﬁrst several shifts in the table
while the REWMA chart does not perform well for detecting the last several shifts.
Table 7.8 OC ARL values of the control charts LEWMA, MEWMA, and REWMA in the case
when p=5,λ=0.2, and ARL 0=500. Numbers in parentheses are standard errors. They are
shown as “.00” when they are smaller than 0.005.
Shifts
X1 X2 X3 X4 X5 MEWMA REWMA LEWMA
0.91 0.00 0.00 0.00 0.00 17.3 (.09) 14.4 (.07) 14.9 (.07)
0.00 0.36 0.00 0.00 0.00 17.0 (.08) 13.3 (.06) 14.3 (.07)
0.00 0.00 0.48 0.00 0.00 17.3 (.09) 13.8 (.07) 15.0 (.07)
0.00 0.00 0.00 0.34 0.00 17.2 (.09) 13.4 (.06) 14.6 (.07)
0.00 0.00 0.00 0.00 0.46 17.9 (.09) 14.1 (.07) 15.2 (.07)
0.36 0.36 0.00 0.00 0.00 15.0 (.07) 13.5 (.06) 13.7 (.06)
0.54 0.00 0.54 0.00 0.00 12.8 (.06) 12.9 (.06) 12.4 (.05)
0.32 0.00 0.00 0.32 0.00 15.2 (.07) 13.1 (.06) 13.6 (.06)
0.49 0.00 0.00 0.00 0.49 13.2 (.06) 12.6 (.06) 12.5 (.06)
0.00 0.54 0.54 0.00 0.00 8.79 (.03) 12.3 (.06) 8.88 (.03)
0.00 1.60 0.00 1.60 0.00 3.48 (.00) 9.03 (.03) 3.57 (.00)
0.00 0.28 0.00 0.00 0.28 13.0 (.06) 10.5 (.05) 11.3 (.05)
0.00 0.00 0.28 0.28 0.00 13.0 (.06) 10.5 (.05) 11.4 (.05)
0.00 0.00 1.26 0.00 1.26 4.28 (.01) 8.70 (.03) 4.34 (.01)
0.00 0.00 0.00 0.56 0.56 8.60 (.03) 12.2 (.06) 8.70 (.03)
0.01−0.15 0.07 0.17 −0.09 15.0 (.07) 11.5 (.05) 12.5 (.06)
0.07−0.13−0.40 0.19 0.35 10.1 (.04) 12.4 (.06) 10.1 (.04)
0.40 0.63 −0.57 0.47 −0.68 4.74 (.01) 9.28 (.04) 4.94 (.01)
−1.11 0.26 −0.17 0.34 −0.04 11.8 (.05) 14.6 (.07) 12.2 (.05)
2.51 7.11 7.05 7.11 7.08 1.19 (.00) 7.52 (.02) 1.30 (.00)
Assume that the LEWMA chart (7.67)–(7.69) gives a mean shift signal at then-
th observation. Then, estimation of the shift location and identiﬁcation of the shifted
mean components can proceed as follows, which will help engineers to eliminate the
root causes of the shift in a timely fashion. With respect to the shift location, it can be
determined by a change-point detection approach (e.g., Zamba and Hawkins, 2006).
After an estimator of the shift location is obtained, which is denoted as /hatwideτ, we have
n−/hatwideτ+1 OC observations, of which a few mean components have shifted. Among
these n−/hatwideτ+1 observations, a number of them might actually be IC observations,
because/hatwideτis only an estimator of the true shift location τ. After/hatwideτis obtained, the
LASSO methodology can be used for specifying the shifted mean components as
follows. Let
γ∗=argmin
γ(n−/hatwideτ+1)/parenleftig
X/hatwideτ−1,n−/hatwideµγ/parenrightig′
Σ−1
0/parenleftig
X/hatwideτ−1,n−/hatwideµγ/parenrightig
+η·/hatwidedf(/hatwideµγ),(7.70)306 MULTIV ARIATE STATISTICAL PROCESS CONTROL
where X/hatwideτ−1,n=∑n
i=/hatwideτXi/(n−/hatwideτ+1),/hatwideµγis the ALASSO estimator of µfrom X/hatwideτ−1,n,
ηis a parameter, and /hatwidedf(/hatwideµγ)is the number of nonzero coefﬁcients in /hatwideµγ. Obviously,
(7.70) is a model selection criterion (cf., Yang, 2005). If the AIC model selection
procedure is used, then η=2. It equals ln(n −/hatwideτ+1)if the BIC procedure is used.
Based on some numerical studies, we found that the diagnostic procedure (7.70)
would perform well if the risk inﬂation criterion (RIC) proposed by George and
Foster (1994) was adopted, in which η=2log( p). Zou et al. (2007c) has shown that
/hatwideµγ∗is one of {/hatwideµ/tildewideγ1,...,/hatwideµ˜γK}. Since some components of /hatwideµγ∗are exactly zero, we
can simply take its nonzero components as the shifted mean components.
In the literature, there is some related discussion on MSPC using regression vari-
able selection and LASSO. For instance, Wang and Jiang (2009) suggested if a for-
ward search algorithm is used to determine the shifted mean components, the dimen-
sionality of the MSPC problem can then be reduced, and consequently the resulting
control charts could be more effective in detecting process mean shifts. Capizzi and
Masarotto (2011) suggested a MEWMA chart by integrating the MSPC problem with
the variable selection technique using the LARS algorithm. One major difference be-
tween this chart and the chart by Zou and Qiu (2009) is that the change-point model
in the former approach includes both the “unstructured” scenarios, such as the ones
considered by Wang and Jiang (2009) and Zou and Qiu (2009), and the “structured”
scenarios, such as shifts occurring at some speciﬁc stages of a multistage process or
shifts involving parameters of a parametric proﬁle. Besides process mean shifts, the
approach by Capizzi and Masarotto (2011) can also detect an increase in the total
variability of the process. The LASSO-based MEWMA chart by Li et al. (2013a)
is speciﬁcally for detecting shifts in the process covariance matrix. Regarding the
post-signal diagnostics, Zou et al. (2011) proposed a LASSO-based approach using
the BIC variable selection criterion. This approach does not assume the IC process
distribution to be known.
7.7 Some Discussions
In the previous sections, we have described some MSPC control charts in cases when
multiple quality characteristics of a production process, denoted as a vector X, are
concerned, and when the IC and OC distributions of Xare both normal. In most of
these control charts, the Hotelling’s T2statistic plays an important role. The multi-
variate Shewhart charts described in Section 7.2 are based directly on different ver-
sions of the Hotelling’s T2statistic. Many other types of control charts are usually
constructed in two steps. First, a statistic carrying useful information in the observed
data about a potential shift in concern is constructed. Such a statistic usually has the
same dimension as X. Then, in the second step, this multi-dimensional statistic is
transformed to a scalar charting statistic by a quadratic transformation in a similar
form to the Hotelling’s T2statistic. Section 7.2 has provided an explanation about the
reason why the Hotelling’s T2statistic is so important in cases when the distribution
ofXis normal. One major reason is that the Hotelling’s T2statistic provides a good
measure of the distance between the observed data and the assumed IC model of the
production process.SOME DISCUSSIONS 307
In this chapter, observation vectors at different time points are assumed indepen-
dent, which may be invalid in certain applications. The MSPC problem when the
observation vectors at different time points are correlated has been discussed by sev-
eral authors. See, for instance, Jiang (2004), Kramer and Schmid (1997), Pan and
Jarrett (2004, 2007), and Vanbrackle and Reynolds (1997). But, this problem has
not been completely solved because most of the existing methodologies use some
speciﬁc time series models to account for the autocorrelation among different obser-
vation vectors. However, such time series models may be invalid in certain applica-
tions. Many MSPC control charts discussed in this chapter assume that the IC process
distribution is known, which is rarely true in practice. As discussed in Section 7.4,
a number of self-starting MEWMA charts have been developed to handle the case
when the IC process distribution is unknown. But, some questions are still open. For
instance, a self-starting MEWMA chart usually requires a number of IC observations
to be available before the online process monitoring. If the number of such IC ob-
servations is larger, then the self-starting process monitoring would be more reliable,
especially in the early stage of the monitoring. But, it might be challenging to col-
lect such IC observations in certain applications. Also, this issue is closely related
to the dimensionality pofX. A dozen IC observations might be good enough in 2-
dimensional cases; but they would not be enough in 10 or higher dimensional cases.
Therefore, much future research is required to address all such issues.
In univariate cases, it has been shown that the CUSUM chart for monitoring pro-
cess mean shifts has the optimality property when its allowance constant is chosen to
be half of a target shift (cf., Subsection 4.2.2). In multivariate cases, similar results
about the design of a MSPC chart are still lacking. For instance, in the regression-
adjusted multivariate CUSUM chart (7.25), it has been shown that the allowance
constant kshould be chosen relatively large if the shift size δ=µ1−µ0is large
in the sense that its statistical length/radicalig
δ′Σ−1
0δis large. However, the speciﬁc rela-
tionship between the optimal value of kand the quantity/radicalig
δ′Σ−1
0δis still unknown.
For the MEWMA charts, as discussed in Subsection 7.4.1, it is still unclear in which
cases we should use a general weighting matrix with non-zero off-diagonal elements,
and in which other cases we should use a single weighting parameter. Also, the re-
lationship among the optimal weighting parameters, the shift size δ, and the dimen-
sionality prequires much future research to explore. In the multivariate CPD control
charts, the control limits usually depend on the observation times in the early stage of
process monitoring, and they stabilize over time. In some cases, numerical formulas
are available for approximating the control limits. These formulas often have room
for further improvement in their approximation accuracy. The LASSO-based MSPC
charts are relatively new. They usually combine a variable selection procedure (e.g.,
ALASSO, LAR) with a SPC charting technique (e.g., EWMA, CUSUM). Therefore,
all design issues related to the multivariate CUSUM, EWMA, and other types of
control charts are also relevant to them.
All control charts discussed in this chapter are based on the assumption that the
process distribution is multivariate normal, which is rarely valid in practice. There-
fore, it is important to investigate their robustness to the normality assumption. If308 MULTIV ARIATE STATISTICAL PROCESS CONTROL
some of them are not robust, then how can they be modiﬁed properly so that the
modiﬁed charts are more robust? One solution to this question is to use the nonpara-
metric control charts discussed in the next two chapters. Another possible solution
is to adopt the transformation approach, by which the observed data are ﬁrst trans-
formed properly so that the transformed data are approximately normally distributed
and then the MSPC control charts are applied to the transformed data. So far, we
have not found much existing research on this topic. Also, little existing research can
be found in handling cases when the distribution of Xbelongs to a parametric family
other than the multivariate normal distribution family (e.g., multivariate t, multivari-
ateΓ), or when only part of the components of Xfollows a normal distribution.
7.8 Exercises
7.1 Assume that the distribution of the 3-dimensional random vector X=
(X1,X2,X3)′isN3(µ,Σ), where
µ=(1, 2,−1)′
and
Σ=
1.0 0.7 0.2
0.7 1.0 0.7
0.2 0.7 1.0
.
Find the distributions of the following random variables or random vectors:
(i)X2,
(ii)(X1,X2)′,
(iii) AX, where A=/parenleftbigg
2 7 −9
5−5 0/parenrightbigg
.
7.2 Assume that the distribution of the 3-dimensional random vector X=
(X1,X2,X3)′isN3(µ,Σ), where
µ=(1, 2,−1)′
and
Σ=
1.0 0.7 0
0.7 1.0 0
0 0 1.0
.
For each pair of the random variables below, determine whether they are inde-
pendent of each other, and provide an explanation.
(i)X1andX2,
(ii)X1andX3,
(iii)(X1+X2)/2 and X3,
(iv) X1and(X2+X3)/2.
7.3 Make a plot similar to the one in Figure 7.2 in cases when p=2,µX1=3,µX2=
3,σX1=1,σX2=1, and Cor(X 1,X2)=0.9. Summarize your ﬁndings from this
plot.EXERCISES 309
7.4 Assume that(X1,X2,..., Xn)is a simple random sample from a p-dimensional
population with the distribution Np(µ,Σ).
(i) Find the distribution of X.
(ii) Find the probability P(d2
S(X,µ)>10)when p=5, where
d2
S(X,µ)=n(X−µ)′Σ−1(X−µ)
is the squared statistical distance from the sample mean vector Xto the pop-
ulation mean vector µ.
(iii) The region
{µ:d2
S(X,µ)≤χ2
1−α,p}
has a 100(1 −α)% chance to cover the true population mean vector µ, where
α∈[0,1]is a given signiﬁcance level. This region is often called a 100(1 −
α)%conﬁdence region forµ. Compute a 95% conﬁdence region for µin the
case when p=2,X= (5, 5)′,andΣ=/parenleftbigg
1 0.5
0.5 1/parenrightbigg
.Make a plot of this
conﬁdence region.
7.5 Assume that (X1,X2,..., Xn)is a simple random sample from a p-dimensional
population whose distribution is unknown. Let XandS2be the sample mean
vector and the sample covariance matrix. In cases when p=4 and n=100,
compute the following probabilities:
(i)P(d2
S(X,µ)≤9), where d2
S(X,µ)is deﬁned in the previous exercise,
(ii)P(n( X−µ)′(S2)−1(X−µ)>6).
7.6 The ﬁrst 20 observation vectors in Table 7.1 were actually generated from the
distribution N3(0,Σ0), where
Σ0=
1.0 0.8 0.5
0.8 1.0 0.8
0.5 0.8 1.0
.
Assume that this is the IC process distribution and it is known. Use the multi-
variate Shewhart chart (7.5)–(7.6) with α=0.005 to monitor the process mean
vector by applying it to the 30 observation vectors in Table 7.1. Compare your
results with the results in Example 7.1 where the IC process distribution is as-
sumed unknown.
7.7 The data shown in Table 7.9 include the ﬁrst 50 observation vectors obtained
from a sheet metal assembly process. The six quality characteristic variables
x1–x6denote the sensor recorded deviation from the nominal thickness (mil-
limeters) at six locations on a car. This dataset was obtained from Table 5.14 in
Johnson and Wichern (2007). Assume that the ﬁrst 30 observation vectors are
IC. Use the multivariate Shewhart chart (7.9)–(7.10) with α=0.005 to monitor
the remaining 20 observation vectors for detecting a potential shift in the process
mean vector. Summarize your results.310 MULTIV ARIATE STATISTICAL PROCESS CONTROL
Table 7.9 This table presents the ﬁrst 50 observation vectors obtained from a sheet metal
assembly process.
i X1 X2 X3 X4 X5 X6
1−0.12 0.36 0.40 0.25 1.37 −0.13
2−0.60−0.35 0.04 −0.28−0.25−0.15
3−0.13 0.05 0.84 0.61 1.45 0.25
4−0.46−0.37 0.30 0.00 −0.12−0.25
5−0.46−0.24 0.37 0.13 0.78 −0.15
6−0.46−0.16 0.07 0.10 1.15 −0.18
7−0.46−0.24 0.13 0.02 0.26 −0.20
8−0.13 0.05 −0.01 0.09 −0.15−0.18
9−0.31−0.16−0.20 0.23 0.65 0.15
10−0.37−0.24 0.37 0.21 1.15 0.05
11−1.08−0.83−0.81 0.05 0.21 0.00
12−0.42−0.30 0.37 −0.58 0.00 −0.45
13−0.31 0.10 −0.24 0.24 0.65 0.35
14−0.14 0.06 0.18 −0.50 1.25 0.05
15−0.61−0.35−0.24 0.75 0.15 −0.20
16−0.61−0.30−0.20−0.21−0.50−0.25
17−0.84−0.35−0.14−0.22 1.65 −0.05
18−0.96−0.85 0.19 −0.18 1.00 −0.08
19−0.90−0.34−0.78−0.15 0.25 0.25
20−0.46 0.36 0.24 −0.58 0.15 0.25
21−0.90−0.59 0.13 0.13 0.60 −0.08
22−0.61−0.50−0.34−0.58 0.95 −0.08
23−0.61−0.20−0.58−0.20 1.10 0.00
24−0.46−0.30−0.10−0.10 0.75 −0.10
25−0.60−0.35−0.45 0.37 1.18 −0.30
26−0.60−0.36−0.34−0.11 1.68 −0.32
27−0.31 0.35 −0.45−0.10 1.00 −0.25
28−0.60−0.25−0.42 0.28 0.75 0.10
29−0.31 0.25 −0.34−0.24 0.65 0.10
30−0.36−0.16 0.15 −0.38 1.18 −0.10
31−0.40−0.12−0.48−0.34 0.30 −0.20
32−0.60−0.40−0.20 0.32 0.50 0.10
33−0.47−0.16−0.34−0.31 0.85 0.60
34−0.46−0.18 0.16 0.01 0.60 0.35
35−0.44−0.12−0.20−0.48 1.40 0.10
36−0.90−0.40 0.75 −0.31 0.60 −0.10
37−0.50−0.35 0.84 −0.52 0.35 −0.75
38−0.38 0.08 0.55 −0.15 0.80 −0.10
39−0.60−0.35−0.35−0.34 0.60 0.85
40 0.11 0.24 0.15 0.40 0.00 −0.10
41 0.05 0.12 0.85 0.55 1.65 −0.10
42−0.85−0.65 0.50 0.35 0.80 −0.21
43−0.37−0.10−0.10−0.58 1.85 −0.11
44−0.11 0.24 0.75 −0.10 0.65 −0.10
45−0.60−0.24 0.13 0.84 0.85 0.15
46−0.84−0.59 0.05 0.61 1.00 0.20
47−0.46−0.16 0.37 −0.15 0.68 0.25
48−0.56−0.35−0.10 0.75 0.45 0.20
49−0.56−0.16 0.37 −0.25 1.05 0.15
50−0.25−0.12−0.05−0.20 1.21 0.10EXERCISES 311
7.8 Assume that the data shown in Table 7.9 are batch data with the batch size of
m=2. The ﬁrst batch includes the ﬁrst two observation vectors in the table,
the second batch includes the next two observation vectors in the table, and so
forth. So, there are a total of 25 batches of data in the table. Use the multivariate
Shewhart chart (7.14)–(7.15) with α=0.005 to monitor the last 10 batches of
observation vectors for detecting potential process mean shift, by assuming the
ﬁrst 15 batches of observation vectors are IC. Compare your results with those
obtained in the previous exercise.
7.9 Assume that the 30 observation vectors presented in Table 7.1 are obtained from
a 3-dimensional production process with the IC distribution N3(0,Σ0), where
Σ0=
1.0 0.8 0.5
0.8 1.0 0.8
0.5 0.8 1.0
.
(i) Apply the joint monitoring scheme (7.16)–(7.17) to this data for monitoring
the process mean vector. In the joint monitoring scheme, use k1=k2=k3=
0.5, and h1=h2=h3=4.171. So, by Table 4.1 in Subsection 4.2.2, each
individual two-sided CUSUM chart in the joint monitoring scheme would
have the ARL 0value of 200. Summarize your results.
(ii) Decompose the IC covariance matrix Σ0into
Σ0=Q′ΛQ,
where Qis ap×porthogonal matrix, and Λ=diag( λ1,λ2,..., λp)is a diago-
nal matrix. Then, X∗=Λ−1/2QXwould have the identity covariance matrix,
and thus its pcomponents are independent of each other, as discussed in
Subsection 7.3.1 immediately after Example 7.2. Apply the joint monitoring
scheme (7.16)–(7.17) to the transformed data
X∗
n=Λ−1/2QX n, for 1≤n≤30.
Use the same setup as that in part (i) for the joint monitoring scheme. Sum-
marize your results, and compare the results with those in part (i). (Note: The
decomposition of Σ0can be accomplished by using the Rfunctioneigen().)
7.10 For the data described in the previous exercise, assume that a potential shift is
µ1= (1, 1,1)′. Apply the CUSUM chart (7.19)–(7.20) to the data. Design the
chart speciﬁcally for detecting µ1with ARL 0=200. Summarize your results.
7.11 For the data described in Exercise 7.9, compute the regression-adjusted data by
(7.22). Plot the original data and the regression-adjusted data, and discuss their
major differences.
7.12 Reproduce the results in Example 7.3.
7.13 For the data shown in Table 7.9, assume that the ﬁrst 30 observation vectors
are IC, and their sample mean and sample covariance matrix can be regarded
as the IC process mean and the IC process covariance matrix, respectively. Use312 MULTIV ARIATE STATISTICAL PROCESS CONTROL
the control chart (7.25) to monitor the remaining 20 observation vectors in the
table. In the chart, choose k=0.25 and h=8,585, so that the ARL 0value of
each individual two-sided CUSUM chart deﬁned by (7.23)–(7.24) is about 500
(cf., Table 4.1 in Subsection 4.2.2). Summarize your results.
7.14 Apply the CUSUM chart (7.28)–(7.29) to the data described in Example 7.3. In
the chart, choose k=0.5 and h=6.5. Summarize your results.
7.15 For the data described in Exercise 7.9, use the multivariate CUSUM chart
(7.32)–(7.33) and the COT chart (7.30)–(7.31) to detect possible process co-
variance matrix shifts. In the chart (7.32)–(7.33), choose k,ARL 0, and C0to be
4, 200, and 0, respectively. By the results in Example 7.4, its control limit his
13.062. In the COT chart, choose k,ARL 0, and/tildewideC0to be 1, 200, and 0, respec-
tively, and the corresponding control limit /tildewidehis 2.713. Summarize your results,
and discuss your major ﬁndings.
7.16 For the data shown in Table 7.9, assume that the ﬁrst 30 observation vectors
are known to be IC, and we are asked to monitor the remaining 20 observation
vectors for possible process mean and process covariance matrix shifts. Use the
methods discussed in Section 7.3 to achieve that goal. Describe your monitoring
schemes, and summarize your major ﬁndings.
7.17 Verify the results in (7.41) and (7.42).
7.18 Reproduce part of the results in Table 7.4 in cases when the shift size δ=
(0.25, 0.25, 0.25)′,(0.25, 0.25, 0)′, and(0.25, 0,0)′. The sizes of these three
shifts seem to decrease from (0.25, 0.25, 0.25)′to(0.25, 0,0)′. Explain why the
ARL 1values of the chart (7.39)–(7.40) also decrease over these three shifts.
7.19 Apply the MEWMA chart (7.39)–(7.40) to the data discussed in Example 7.3.
In the chart, use a single weighting parameter λ, and choose the values of λand
ARL 0to be 0.2 and 200, respectively. Summarize your results.
7.20 Verify the equations in (7.43)
7.21 Apply the self-starting MEWMA chart (7.45)–(7.46) to the data in Table 7.9. In
the chart, choose λandARL 0to be 0.2 and 200, respectively. By Example 7.6,
the control limit hSSis 14.167 in such cases, if the the IC process distribution is
assumed to be Np(0,Ip×p). Explain that this control limit value is still approx-
imately valid in the current problem. Summarize your major ﬁndings from the
control chart.
7.22 Consider a 3-dimensional production process with the IC distribution N3(0,Σ0)
where
Σ0=
1.0 0.7 0.3
0.7 1.0 0.7
0.3 0.7 1.0
.
The ﬁrst 30 phase II observations are presented in Table 7.10. Apply the
MEWMA chart (7.51)–(7.52) to this dataset. In the chart, choose λandARL 0to
be 0.2 and 250, respectively. Summarize your results.
7.23 Reproduce the results in Example 7.8.EXERCISES 313
Table 7.10 This table presents the ﬁrst 30 phase II observations of a 3-dimensional production
process.
n Xn1 Xn2 Xn3 n Xn1 Xn2 Xn3
1 0.526−0.352−0.420 16−0.921−0.264 0.500
2 0.182−0.098 0.296 17 0.953 0.604 −1.074
3 0.104−0.152−0.135 18−0.861 0.392 1.783
4 0.397 0.622 1.273 19 0.245 0.887 2.247
5−0.126 0.350 0.020 20 0.090 1.879 −0.125
6 0.190 0.433 0.155 21 0.287−0.440−0.092
7−0.356−0.346−0.816 22 1.390 1.661 1.291
8 0.301 0.616 0.905 23−1.730−1.599−2.279
9−0.314−0.451−1.395 24−1.691 1.421 2.050
10−1.606−0.416 1.128 25−0.443−0.866−0.254
11 0.334−0.267−0.314 26 1.756 1.605 0.722
12 2.720 2.439 0.201 27−0.765−0.503 0.159
13−0.516 0.255 −0.256 28 1.302 1.252 1.595
14−1.123−0.721 1.627 29 0.469−0.567 0.368
15 0.533−0.070−2.760 30−1.765−2.163−1.899
7.24 Apply the CPD control chart (7.54)–(7.55) to the data presented in Table 7.9 for
monitoring the process mean vector. In the data, the ﬁrst 25 observation vectors
are assumed to be IC, and the process monitoring starts at the 26th time point.
In the chart, αis chosen to be 0.002, hncan be approximated by the second
formula in (7.56), and the formulas (7.57)–(7.59) can be used for computing the
charting statistic T2
max,nrecursively. Construct the control chart, and present it in
a plot. Do the post-signal analysis (e.g., compute the estimates of the shift time,
IC and OC process mean vectors, IC process covariance matrix, etc.), if a signal
of process mean shift is given by the chart. Summarize your results.
7.25 For the CPD control chart (7.60)–(7.61), what is the minimum value of nat
which the chart can be used? If the chart is used at the n-th time point and nis
too small, what are the possible consequences?
7.26 Verify that (7.64) is equivalent to (7.63).Chapter 8
Univ ariate Nonparametric Process
Control
8.1 Introduction
The SPC control charts discussed in the previous several chapters, for monitoring
univariate or multivariate continuous numerical quality characteristics, are all based
on the assumption that the related quality characteristics follow normal distributions
when the production process in question is IC and after it becomes OC. As pointed
out in Subsection 2.3.1, normal distributions play an important role in statistics, be-
cause many continuous numerical variables in practice roughly follow normal dis-
tributions and much statistical theory is developed for normally distributed random
variables. An intuitive explanation about the reason many continuous numerical vari-
ables in our daily life roughly follow normal distributions can be given using the
central limit theorem (CLT) discussed in Subsection 2.7.1. For instance, a quality
characteristic in question (e.g., the lifetime of a machine) is often affected by many
different factors, including the quality of the raw material, labor, manufacturing fa-
cilities, proper operation in the manufacturing process, and so forth (cf., Figure 1.1
in Section 1.2). So, by the CLT, its distribution would be roughly normal.
In practice, however, there are also many variables whose distributions are sub-
stantially different from normal distributions. For instance, economic indices and
other nonnegative indices are often skewed to the right. The lifetimes of products
can often be described properly by Weibull distributions, which could be substan-
tially different from normal distributions (cf., Subsection 2.3.5). In many cases, it is
difﬁcult to ﬁnd a parametric distribution to describe the distribution of a variable in
question. In such cases, various nonparametric methods are available for estimating
the variable distribution (cf., Jones et al., 1996; Scott, 1992; Wand and Jones, 1995).
In cases when the normality assumption is invalid, several authors have pointed
out that the conventional control charts would be unreliable for process monitoring
(cf., Amin et al., 1995; Hackl and Ledolter, 1992; Lucas and Crosier, 1982b; Rocke,
1989). For instance, Qiu and Li (2011a) provided a demonstration example described
below. Figure 8.1 shows the actual IC ARL values of the conventional CUSUM chart
(4.7)–(4.8) based on the assumption that the IC process distribution is N(0,1), in
cases when the allowance constant kof the chart is chosen to be 0.5, the assumed
IC ARL value is 500, and the true process distribution is the standardized version
(with mean 0 and variance 1) of the chi-square (plot (a)) or t(plot (b)) distribution.
315316 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
From the plots, it can be seen that the actual IC ARL values of the conventional
CUSUM chart are much smaller than the assumed IC ARL value in both cases when
the df is small, implying that the related process would be stopped too often by the
control chart when it remains IC and consequently a considerable amount of time
and resources would be wasted in such cases.
0 10 20 30 40 50 600 100 200 300 400 500
degrees of freedomActual IC ARL
(a)0 10 20 30 40 50 600 100 200 300 400 500
degrees of freedomActual IC ARL
(b)
Figure 8.1 Actual IC ARL values of the conventional CUSUM chart (4.7)–(4.8) in cases when
the assumed IC ARL value is 500, and the true process distribution is the standardized version
(with mean 0 and variance 1) of the chi-square (plot (a)) or t (plot (b)) distribution with
degrees of freedom changing from 1 to 60 in plot (a) and from 3 to 60 in plot (b).
It has been pointed out that the conventional EWMA charts discussed in Chapter
5 were quite robust to the normality assumption when the weighting parameter λwas
chosen to be small (cf., Borror et al., 1999; Testik et al., 2003). As discussed at the
end of Subsection 5.2.1, we think that the robustness property of the EWMA charts
should be used with care for two main reasons. First, from various numerical results
presented in Example 5.2 and in several other sources, it seems that it depends on the
magnitude of the difference between the actual IC process distribution and a normal
distribution to decide how small the λvalue should be chosen in order to have the
robustness property, and this magnitude is difﬁcult to measure in practice. Second,
ifλis chosen to be small, then the resulting chart would be ineffective in detecting
relatively large shifts, as discussed in Subsection 5.2.1 This viewpoint is conﬁrmed
recently by an extensive numerical study in Human et al. (2011). Therefore, in cases
when the actual IC process distribution is non-normal, we suggest using the nonpara-
metric (or distribution-free) control charts that will be discussed in this and the next
chapters, unless we know beforehand that the IC process distribution is quite close to
a normal distribution or to another parametric distribution that can be handled more
effectively by a parametric control chart.
To handle cases when the normality assumption is invalid, a number of
distribution-free or nonparametric control charts have been developed in the litera-RANK-BASED NONPARAMETRIC CONTROL CHARTS 317
ture. See, for instance, Albers and Kallenberg (2004, 2009), Albers et al. (2006), Al-
loway and Raghavachari (1991), Amin et al. (1995), Amin and Searcy (1991), Amin
and Widmaier (1999), Bakir (2004, 2006), Bakir and Reynolds (1979), Chakraborti
and Eryilmaz (2007), Chakraborti et al. (2009, 2004), Chakraborti and van der Laan
(2000), Chatterjee and Qiu (2009), Hackl and Ledolter (1991), Hawkins and Deng
(2010), McDonald (1990), Park and Reynolds (1987), Qiu and Li (2011a,b), Wille-
main and Runger (1996), Yashchin (1992), and Zou and Tsung (2010) for some re-
lated discussions on univariate nonparametric SPC. Chakraborti et al. (2001) gave a
quite thorough overview on this topic. In this chapter, we describe some fundamen-
tal univariate nonparametric SPC charts. Some important multivariate nonparamet-
ric SPC charts will be described in the next chapter. It should be pointed out that,
in the literature, people do not always make a clear distinction between the termi-
nologies of “nonparametric control charts” and “distribution-free control charts.” In
many papers, both terminologies are used to refer to the control charts that can be
applied to cases when the process distribution does not have a parametric form. Some
“distribution-free control charts” may not be really distribution-free, in the sense that
their design may still depend on the process distribution, although they do not require
a parametric form of the process distribution.
8.2 Rank-Based Nonparametric Control Charts
As discussed in Section 2.8, in cases when a parametric model is unavailable to
describe the process distribution (or, the process distribution is nonparametric), non-
parametric statistical methods based on the ranking or ordering information of the
observed data can be considered for making inferences about the underlying process
distribution. In this section, we describe some fundamental control charts constructed
using certain rank-based nonparametric statistical methods for process monitoring in
cases when the process distribution is nonparametric. Our description will mainly
focus on the monitoring of process mean, although some methods described can also
be used for the monitoring of process variance. This section is organized in four
parts. Shewhart-type nonparametric control charts are discussed in Subsection 8.2.1,
and some nonparametric CUSUM, EWMA, and CPD charts are described in Sub-
sections 8.2.2–8.2.4, respectively.
8.2.1 Nonparametric Shewhart charts
In the literature, a number of nonparametric Shewhart charts have been proposed for
both phase I and phase II process monitoring. Some relatively early discussions on
this topic can be found in papers, such as Alloway and Raghavachari (1991), Amin
et al. (1995), Pappanastos and Adams (1996), Park and Reynolds (1987), Willemain
and Runger (1996), and the references cited therein. In this subsection, we ﬁrst de-
scribe the nonparametric Shewhart chart proposed by Bakir (2004), which is based
on the Wilcoxon signed-rank test discussed in Subsection 2.8.3.
The nonparametric Shewhart chart by Bakir (2004) works with batch data. As-
sume that Xi1,Xi2,..., Ximaremobservations obtained at the i-th time point, where318 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
m>1 is the batch size. The mobservations obtained at the same time point are
assumed to be i.i.d.. It is further assumed that the process distribution is symmetric
about its median /tildewideµ. Then,/tildewideµis obviously the mean of the process distribution as well.
When the process is IC, /tildewideµ=/tildewideµ0. Here, we assume that /tildewideµ0is known; but, it should be
estimated from an IC dataset in practice. Deﬁne the charting statistic to be
ψi=m
∑
j=1sign(Xi j−/tildewideµ0)R+
i j, (8.1)
where sign(u)= −1,0,1, respectively, when u<0,=0,> 0,
R+
i j=1+m
∑
ℓ=1I(|Xiℓ−/tildewideµ0|<|Xi j−/tildewideµ0|),
andI(u)equals 1 and 0, respectively, when uis “true” and “false”. In the above
expressions, the value of R+
i jis actually the rank of |Xi j−/tildewideµ0|in the sequence
|Xi1−/tildewideµ0|,|Xi2−/tildewideµ0|,...,|Xim−/tildewideµ0|, sign(Xi j−/tildewideµ0)R+
i jis the conventional Wilcoxon
signed-rank of Xi j−/tildewideµ0within the i-th batch of observations, and ψiis the sum of
all Wilcoxon signed-ranks within the i-th batch (cf., Subsection 2.8.3). Obviously,
in cases when the process is IC, positive and negative Wilcoxon signed-ranks are
mostly canceled out in ψi. Consequently, the absolute value of ψishould be small
in such cases and ψishould be centered at 0. When the process has a positive mean
(or median) shift at the i-th time point, however, the positive Wilcoxon signed-ranks
would be larger than the negative Wilcoxon signed-ranks in magnitudes within the
i-th batch, resulting in a relatively large value of ψi. Thus, the upward chart gives a
signal of an upward process mean shift if
ψi≥U, (8.2)
where U>0 is an upper control limit. Similarly, the downward chart gives a signal of
a downward process mean shift when ψi≤L, and the two-sided chart gives a signal
of an arbitrary process mean shift when ψi≤Lorψi≥U, where L<0 is a lower
control limit. Since the distribution of ψiis symmetric about 0 when the process is IC,
it is natural to choose L=−U. This control chart will be called the nonparametric
signed-rank (NSR) chart hereafter.
From the deﬁnition of ψi, it can be checked that
ψi=2S+−m(m+1)/2,
where S+is the Wilcoxon signed-rank test statistic described in Subsection 2.8.3. By
this connection, the IC distribution of ψican be obtained from the IC distribution
ofS+, which has been tabulated in Table 2.7. Then, the false alarm rate α+of the
upward NSR chart can be computed by
α+=P(ψi≥U),RANK-BASED NONPARAMETRIC CONTROL CHARTS 319
where the probability is computed using the IC distribution of ψi, and the IC ARL
value of the upward NSR chart, denoted as ARL+
0, can be computed by
ARL+
0=1/α+.
When m=5,6,8, and 10, and Utakes various integer values, the values of α+and
ARL+
0have been computed in Bakir (2004), and they are presented in Table 8.1.
From the table, it can be seen that, for a given batch size m, the upward NSR chart
(8.1)–(8.2) can only reach a limited number of ARL 0values. This phenomenon is
common in cases when the charting statistic can only take a ﬁnite number of values,
as discussed in Subsection 3.3.1 about the pchart (3.19). For the downward NSR
chart, the results in Table 8.1 can also be used after the Uvalues in the table are
replaced by the L=−Uvalues. For the two-sided NSR chart, its false alarm rates,
denoted as α, are 2 times the values of α+presented in the table, and consequently
itsARL 0values are halves of the ARL+
0values in the table.
Note that the NSR chart described above can be used for both phase I and phase
II SPC. In phase I SPC, the value of /tildewideµ0is usually unknown. In such cases, it can
be replaced by the average of the sample medians (or sample means) of different
batches of data obtained for phase I analysis. In phase II SPC, the value of /tildewideµ0needs
to be estimated beforehand from IC data collected at the end of the phase I analysis.
In both cases, the symmetry of the process distribution should be veriﬁed properly.
Example 8.1 The data shown in Figure 8.2(a) consist of 30 batches of observations
with the batch size of m =10. The ﬁrst 20 batches of observations are generated
from the t 3distribution, and the remaining 10 batches of observations are generated
from the t 3+1distribution. So, these data can be regarded as observations from
a production process with IC process distribution of t 3, which is symmetric about
/tildewideµ0=0, and the process has a mean (or median) shift of size 1 at the 21st time point.
From the plot of Figure 8.2(a), it seems that the process distribution is symmetric.
Now, let us assume that /tildewideµ0is known to be 0, and we are interested in the online
monitoring of the process mean. To this end, we would like to apply the upward NSR
chart (8.1)–(8.2) to the observed data, and the values of the charting statistic ψiare
then computed by the formula (8.1). The upward NSR chart (8.1)–(8.2) is shown in
Figure 8.2(b) with the upper control limit of U =49. By Table 8.1, this chart has
the ARL 0value of 204.0816. From the plot, it can be seen that the ﬁrst signal of the
chart is given at the 21st time point. So, the production process should be stopped
at that time point for investigating the possible root causes of the detected upward
mean shift.
The NSR chart described above can be modiﬁed for various different consider-
ations. For instance, if we are uncertain about the symmetry of the process distri-
bution, then we can consider replacing the Wilcoxon signed-rank test statistic used
in the chart by the sign test statistic discussed in Subsection 2.8.3 (cf., Amin et al.,
1995). Of course, the resulting control chart will lose certain efﬁciency in cases when
the process distribution is symmetric or close to symmetric. Chakraborti and Eryil-
maz (2007) generalized the decision rule (8.2) based on various different runs (cf.,
their deﬁnitions given in Subsection 3.2.1) of the charting statistic ψi, and showed320 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
Table 8.1 This table presents the values of α+and ARL+
0of the upward NSR chart (8.1)–(8.2)
in various cases when m =5,6,8, and 10.
m=5 m=6
U α+ARL+
0U α+ARL+
0
10 0.1563 6.3980 10 0.2188 4.5704
11 0.0938 10.6610 11 0.1563 6.3980
12 0.0938 10.6610 12 0.1563 6.3980
13 0.0625 16.0000 13 0.1094 9.1408
14 0.0625 16.0000 14 0.1094 9.1408
15 0.0313 32.0000 15 0.0781 12.8041
16 0.0000 ∞ 16 0.0781 12.8041
17 0.0469 21.3220
18 0.0469 21.3220
19 0.0313 31.9489
20 0.0313 31.9489
21 0.0156 64.1026
22 0.0000 ∞
m=8 m=10
U α+ARL+
0U α+ARL+
0
18 0.1250 8.0000 25 0.1162 8.6059
20 0.0977 10.2354 27 0.0967 10.3413
22 0.0742 13.4771 29 0.0801 12.4844
24 0.0547 18.2815 31 0.0654 15.2905
26 0.0391 25.5755 33 0.0527 18.9753
28 0.0273 36.6300 35 0.0420 23.8095
30 0.0195 51.2821 37 0.0322 31.0559
32 0.0117 85.4701 39 0.0244 40.9836
34 0.0078 128.2051 41 0.0186 53.7634
36 0.0039 256.4103 43 0.0137 72.9927
>36 0.0000 ∞ 45 0.0098 102.0408
47 0.0068 147.0588
49 0.0049 204.0816
51 0.0029 344.8276
53 0.0020 512.0328
55 0.0010 1024.5900
>55 0.0000 ∞
that the control charts with the generalized decision rules would be more efﬁcient in
various cases.
Next, we discuss the so-called distribution-free precedence (DFP) control chart
proposed by Chakraborti et al. (2004) for phase II SPC. Assume that a reference sam-
ple of size M, denoted as (Y1,Y2,..., YM), is available beforehand and it is obtained
from a production process when it is IC, the IC process distribution is continuous but
unknown, and we are interested in the online monitoring of the process mean µ. Let
Xi(1)≤Xi(2)≤···≤ Xi(m), i=1,2,...RANK-BASED NONPARAMETRIC CONTROL CHARTS 321
0 5 10 15 20 25 30−10 −5 0 5
iXij
(a)0 5 10 15 20 25 30−40 0 20 40
iψi
(b)
Figure 8.2 (a) Observed data from a production process with the IC process distribution of
t3, and the process has a median shift at the 21st time point. The data consist of 30 batches
of observations with the batch size of m =10. (b) The upward NSR chart (8.1)–(8.2) with the
upper control limit of U =49(dashed horizontal line).
bemordered observations obtained at the i-th time point during the online monitor-
ing. Then, this is a case with batch data and the batch size is m. For the j-th ordered
observation Xi(j)with 1≤j≤m, we deﬁne Wjto be the number of Y-observations in
the reference sample that are smaller than or equal to (or, “precede”) Xi(j). The statis-
ticWjis called a precedence statistic and a test based on Wjis called a precedence
test in the literature (cf., Chakraborti and van der Laan, 1996, 1997; Nelson, 1963,
1993). By some routine combinatorial arguments, the IC distribution of Wjcan be
derived to be
P(Wj=w)=/parenleftbigg
j+w−1
w/parenrightbigg/parenleftbigg
M+m−j−w
M−w/parenrightbigg
/parenleftbigg
M+m
M/parenrightbigg , w=0,1,2,...,M.(8.3)
From (8.3), it can be seen that the IC distribution of Wjdepends only on M,m,and
j, and it does not depend on the IC process distribution. Therefore, it is distribution-
free, and consequently any tests or control charts based on Wjwould be distribution-
free as well.
For simplicity of presentation, let us assume that the batch size m=2s+1 is
an odd integer number, and we are interested in using the sample median Xi(s+1)
for process monitoring. In such cases, the IC distribution of Wjin (8.3) is obviously
symmetric about its center, and therefore it is natural to consider the decision rule
that a signal of process mean shift is given when
Xi(s+1)<L=Y(a) or Xi(s+1)>U=Y(M−a+1), (8.4)322 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
where 1≤a<M/2 is an integer number, and Y(a)andY(M−a+1)are the a-th and the
(M−a+1)-th order statistics of the reference sample. Clearly, (8.4) is equivalent to
Ws+1<a or Ws+1>M−a. (8.5)
So, for a given false alarm rate p0, we can choose the largest asuch that
P(Ws+1<a)+ P(Ws+1>M−a)
=1−P(a≤Ws+1≤M−a)
=M−a
∑
w=a/parenleftbigg
s+w
w/parenrightbigg/parenleftbigg
M+s−w
M−w/parenrightbigg
/parenleftbigg
M+2s+1
M/parenrightbigg
<p0. (8.6)
Forseveral commonly used p0,M, and mvalues, the computed values of the largest
asuch that (8.6) holds, the actual p0values, and the actual ARL 0value of the DFP
chart (8.4)–(8.6) are presented in Table 8.2, which is reorganized from Table 1 in
Chakraborti et al. (2004). From the table, it can be seen that the actual p0values are
generally smaller than the assumed p0values, due to the discreteness of the charting
statistic Ws+1, as mentioned above about the NSR chart (8.1)–(8.2).
For the DFP chart (8.4)–(8.6), its ARL 0value would be different from the value
of 1/ p0, because the signaling events deﬁned by (8.4) are generally associated at
different time points, due to the fact that the same random variables Y(a)andY(M−a+1)
are used in deﬁning all these events. When the reference sample size Mis large,
Y(a)andY(M−a+1)would be quite close to the (p0/2)-th and (1−p0/2)-th quantiles
of the IC process distribution, respectively. In such cases, the actual ARL 0value of
the chart should be close to 1/ p0. However, Mmust be really large to make this
approximation reliable, especially in cases when p0is small, which is conﬁrmed by
Table 8.2. From the table, it can be seen that the actual ARL 0values are quite close to
1/p0when M=1000 and p0=0.01; but, such ARL 0values are quite different from
1/p0when M=1000 and p0=0.0027. In some applications, it is difﬁcult to obtain a
reference sample of a large size. To overcome this difﬁculty, Chakraborti et al. (2004)
derived formulas for the run length distribution and the IC and OC ARL values of
the DFP chart (8.4)–(8.6). Based on these formulas, we can compute the value of a
such that the ARL 0value of the chart equals a given value. For several commonly
used ARL 0,M, and mvalues, such avalues, along with the actual p0values and the
actual ARL 0values, are presented in Table 8.3, which is reorganized from Table 2 in
Chakraborti et al. (2004). From the table, it can be seen that the actual and assumed
ARL 0values are generally different, and they are close to each other when Mis large,
which is similar to the results found in Table 8.2. Between the two approaches for
choosing aby specifying either the false alarm rate p0or the ARL 0value, the ARL 0
approach should be preferred, because the p0approach is difﬁcult to interpret due
to the possible association among signaling events at different time points, while the
ARL 0approach can be interpreted as usual.RANK-BASED NONPARAMETRIC CONTROL CHARTS 323
Table 8.2 This table presents the computed values of the largest a such that (8.6) holds (1st
line in each entry), the actual p 0values (2nd line in each entry), and the actual ARL 0values
(3rd line in each entry) of the DFP chart (8.4)–(8.6) for several commonly used p 0, M, and m
values.
p0m s M=50 M=100 M=500 M=1000
0.0100 5 2 3 7 40 82
0.0072 0.0086 0.0095 0.0099
635.7 214.9 114.5 104.6
11 5 7 15 83 167
0.0093 0.0085 0.0098 0.0097
642.2 245.0 113.3 108.4
25 12 10 23 127 258
0.0061 0.0080 0.0095 0.0099
10990.0 510.8 128.3 109.8
0.0050 5 2 2 5 31 64
0.0030 0.0035 0.0047 0.0049
5671.0 678.4 242.3 215.1
11 5 5 13 72 146
0.0025 0.0045 0.0048 0.0049
9503.0 574.5 240.9 219.8
25 12 9 21 118 239
0.0031 0.0040 0.0049 0.0049
44750.0 1488.0 261.0 227.5
0.0027 5 2 1 4 25 51
0.0008 0.0020 0.0025 0.0026
∞ 1550.0 460.2 419.5
11 5 5 11 64 130
0.0025 0.0021 0.0026 0.0026
9503.0 1630.0 456.1 409.8
25 12 8 19 110 224
0.0015 0.0018 0.0025 0.0027
173700.0 5183.0 526.2 430.2
Tables 8.2 and 8.3 are both for the two-sided decision rule (8.4). If an upward or
downward decision rule is preferred in a given application, then the value of acan be
computed similarly from the IC distribution formula (8.3) of Wjand from the ARL
formulas given in Chakraborti et al. (2004).
Example 8.2 To online monitor the mean of a production process, a reference sam-
ple of size M =1000 has been obtained from the production process when it is IC.
Figure 8.3(a) shows 30 batches of phase II observations with batch size of m =5. We
would like to apply the DFP chart (8.4)–(8.6) to this dataset for the process mean
monitoring. In the chart, we choose the assumed ARL 0value to be 370. Then, by
Table 8.3, the value of a should be chosen to be 53. From the reference sample, the
lower and upper control limits of the chart (8.4)–(8.6) are found to be
L=Y(a)=−1.0847, U=Y(M−a+1)=1.8308.324 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
Table 8.3 This table presents the computed values of a (1st line in each entry), the actual p 0
values (2nd line in each entry), and the actual ARL 0values (3rd line in each entry) of the DFP
chart (8.4)–(8.6) for several commonly used ARL 0, M, and m values.
ARL 0m s M=50 M=100 M=500 M=1000
370 5 2 6 11 27 53
0.0055 0.0038 0.0033 0.0029
359.6 385.5 365.5 374.4
11 5 14 27 67 132
0.0063 0.0041 0.0033 0.0029
367.8 372.4 355.3 377.3
25 12 24 46 114 227
0.0111 0.0053 0.0035 0.0030
316.5 375.7 367.3 377.0
500 5 2 6 10 24 48
0.0055 0.0029 0.0023 0.0022
359.6 520.1 520.3 501.9
11 5 13 26 63 125
0.0045 0.0034 0.0024 0.0023
574.5 460.5 497.2 506.9
25 12 23 45 111 219
0.0080 0.0044 0.0028 0.0023
510.8 472.5 480.1 492.2
1000 5 2 5 8 19 38
0.0035 0.0016 0.0011 0.0011
678.4 1067.5 1055.8 1005.9
11 5 11 23 56 110
0.0021 0.0019 0.0013 0.0011
940.6 927.8 953.2 1021.7
25 12 22 42 103 206
0.0057 0.0024 0.0014 0.0012
854.6 986.2 1033.6 1004.4
Then, the chart is shown in Figure 8.3(b), from which it can be seen that the ﬁrst
signal of process mean shift is given at the 23rd observation time point. From Figure
8.3(a), it seems that there is an outlier at the 16th time point, which does not have any
impact on the charting statistic X i(3)shown in Figure 8.3(b). Therefore, besides its
distribution-free property, the DFP chart (8.4)–(8.6) is also robust to a small number
of outliers in each batch of the phase II observations.
The decision rule (8.4) has been generalized by Chakraborti et al. (2009) using
various different runs. Chakraborti et al. (2009) showed that the runs-type decision
rules can enhance the performance of the DFP chart (8.4)–(8.6) in various cases.
8.2.2 Nonparametric CUSUM charts
Since Page (1954) proposed the conventional CUSUM chart under the assumption
that the distribution of a production process in question is normal (cf., Section 4.2 forRANK-BASED NONPARAMETRIC CONTROL CHARTS 325
0 5 10 15 20 25 300 2 4 6 8 10
iXij
(a)0 5 10 15 20 25 30−1 0 1 2 3
iXi□3□
(b)
Figure 8.3 (a) Phase II batch data with the batch size of m =5obtained from a production
process. (b) The DFP chart (8.4)–(8.6) with the assumed ARL 0value of 370. In the chart, the
dashed horizontal lines denote the lower and upper control limits obtained from a reference
sample of size M =1000.
a description), there have been many discussions about its unreliable performance in
various cases when the normality assumption is invalid, and a number of nonparamet-
ric CUSUM charts have been proposed in the literature. See, for instance, McDonald
(1990), Park and Reynolds (1987), Reynolds (1975) for some relatively early discus-
sions. Next, we describe the nonparametric CUSUM chart suggested by Bakir and
Reynolds (1979).
Let
Xn1,Xn2,..., Xnm, forn=1,2,...,
bemphase II observations obtained at the n-th time point. It is further assumed that
the IC process distribution is symmetric about its mean (or median), and the IC mean
(or median) is 0. Let
ψn=m
∑
j=1sign(Xn j)R+
n j (8.7)
be the sum of the Wilcoxon signed-ranks within the n-th batch of observations. Then,
ψnin (8.7) is actually the same as the one deﬁned in (8.1), except that /tildewideµ0=0 in
the current setup. As pointed out in the paragraph containing (8.1) in the previous
subsection, ψnis centered at 0 when the process is IC at the n-th time point, and its
value is lifted upward if there is an upward process mean (or median) shift at that
time point. Based on this intuition, Bakir and Reynolds (1979) suggested using the
CUSUM charting statistic
C+
n=max/parenleftbig
0,C+
n−1+ψn−k/parenrightbig
, (8.8)
where C+
0=0 and k>0 was an allowance constant, and the chart gave a signal of326 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
upward mean shift if
C+
n>h, (8.9)
where h>0 was a control limit chosen to achieve a pre-speciﬁed ARL 0value. The
downward and two-sided versions of this CUSUM chart can be deﬁned similarly. See
a related discussion in Subsection 4.2.1. This chart will be called the NSR CUSUM
chart hereafter.
The upward NSR CUSUM chart (8.8)–(8.9) has two parameters kandhto choose
before the chart can actually be used. Because ψntakes integer values, Bakir and
Reynolds (1979) suggested choosing kandhto be integer values as well to simplify
the theoretical study of the CUSUM chart. By some theoretical studies of the charting
statistic C+
n, Bakir and Reynolds (1979) provided approximate optimal values of k
in cases when the process distribution is symmetric, m=4,6,and 10, and the size
of the process mean shift equals δ=0.2σ,0.6σ,σ,2σ,and 3 σ, where σis the IC
process standard deviation. These approximate optimal values of kare presented in
Table 8.4. After kis chosen, the control limit hcan be chosen such that a given
ARL 0level is reached. But, because the charting statistic C+
ncan only take discrete
values, not all ARL 0values can be reached by the chart, as mentioned in the previous
subsection. Bakir and Reynolds (1979) demonstrated how to use the Markov chain
approach (cf., Subsection 4.6.1) for computing the ARL values of the upward NSR
CUSUM chart (8.8)–(8.9). By the Markov chain approach, the ARL 0values of the
chart when the process distribution is assumed symmetric about the IC process mean
and when (k,h)take various different values have been computed and tabulated. For
instance, in cases when m=6, some computed ARL 0values are presented in Table
8.5, which is part of Table 2a in Bakir and Reynolds (1979).
Table 8.4 Approximate optimal values of the allowance constant k of the upward NSR CUSUM
chart (8.8)–(8.9) in cases when the process distribution is symmetric, m =4,6,and 10, and
the size of the process mean shift equals δ=0.2σ,0.6σ,σ,2σ,and3σ, where σis the IC
process standard deviation.
δ
m0.2σ0.6σ σ 2σ3σ
4 1 3 4 5 5
6 2 6 8 10 10
10 6 16 22 27 27
Example 8.3 Figure 8.4(a) shows 30 batches of phase II observations with the batch
size of m =6obtained from a production process. It is known that the IC process
distribution is symmetric about 0, and we are interested in monitoring the process
mean by the upward NSR CUSUM chart (8.8)–(8.9). To this end, we choose k =8
and h=10in the chart. By Table 8.4, this chart is tuned for detecting a mean shift
of size 1σ. From Table 8.5, the ARL 0value of the chart is between 97.04 and 155.36.
The chart is shown in Figure 8.4(b), which gives its ﬁrst signal at the 21st time point.
From Figure 8.4(a), it seems that the process mean shifts upward at the 21st time
point; but, there are a number of quite large observations before that time point. The
chart (8.8)–(8.9) seems quite robust to these scattered large observations.RANK-BASED NONPARAMETRIC CONTROL CHARTS 327
Table 8.5 Computed ARL 0values of the upward NSR CUSUM chart (8.8)–(8.9) in cases when
the process distribution is symmetric, m =6, and(k,h)take various different values.
k h=2 h=4 h=6 h=8h=10 h=12 h=14 h=16
1 14.22 17.15 20.32 24.49 30.17 36.52 54.41 67.28
3 17.45 21.04 26.00 33.28 42.02 51.80 65.92 80.57
5 20.14 26.94 35.71 46.93 60.11 81.29 104.33 140.63
7 27.43 37.46 51.01 67.54 97.04 130.76 192.07
9 38.40 53.76 72.98 110.87 155.36 249.32
11 54.86 75.79 120.17 173.05 301.01
13 76.80 125.39 183.14 334.79
15 127.98 190.49 366.46
17 192.00 378.00
19 384.00
0 5 10 15 20 25 30−3 −2 −1 0 1 2 3
nXnj
(a)0 5 10 15 20 25 300 20 40 60 80 120
nCn+
(b)
Figure 8.4 (a) Phase II batch data with the batch size m =6obtained from a production
process. (b) The upward NSR CUSUM chart (8.8)–(8.9) with k =8and h=10(denoted by
the dashed horizontal line).
In cases when a reference sample (Y1,Y2,..., YM)is available beforehand, ob-
tained from a production process when it is IC, Li et al. (2010) proposed a nonpara-
metric CUSUM chart based on the Wilcoxon rank-sum test discussed in Subsection
2.8.3 for phase II process mean monitoring. Let (Xn1,Xn2,..., Xnm)be a batch of
mobservations obtained at the n-th time point of phase II process monitoring, for
n=1,2,..., and Wnbe the sum of the ranks of (Xn1,Xn2,..., Xnm)in the combined
sample
(Y1,Y2,..., YM,Xn1,Xn2,..., Xnm).
Then, Wnis the conventional Wilcoxon rank-sum test statistic for comparing
the means of the two populations that the two samples (Y1,Y2,..., YM)and
(Xn1,Xn2,..., Xnm)represent. In cases when the process is IC at the n-th time point,328 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
the upper -tail probabilities of the IC distribution of Wnare presented in Table 2.9 in
various cases. In such cases, the IC mean and variance of Wnare
µWn=m(m+M+1)/2, σ2
Wn=mM(m+M+1)/12.
The value of Wntends to be larger if the process mean shifts upward at the n-th time
point, and smaller if the process mean shifts downward. Therefore, Wncan be used
for detecting process mean shifts. Deﬁne the charting statistic of the upward CUSUM
chart to be
C+
n=max/bracketleftbig
0,C+
n−1+(Wn−m(m+M+1)/2)−k/bracketrightbig
, (8.10)
where C+
0=0 and k>0 is an allowance constant. The chart gives a signal of upward
mean shift if
C+
n>h, (8.11)
where h>0 is a control limit chosen to achieve a pre-speciﬁed ARL 0value. Similarly,
to detect downward process mean shifts, the charting statistic is deﬁned to be
C−
n=min/bracketleftbig
0,C−
n−1+(Wn−m(m+M+1)/2)+ k/bracketrightbig
, (8.12)
where C−
0=0, and the chart gives a signal of downward mean shift if
C−
n<−h. (8.13)
To detect an arbitrary process mean shift, a two-sided CUSUM chart should be used,
which gives a signal when either (8.11) or (8.13) or both hold. This chart will be
called the nonparametric rank-sum (NRS) CUSUM chart hereafter.
In the NRS CUSUM chart (8.10)–(8.13), if the allowance constant khas been de-
termined, then the control limit hcan be chosen to reach a pre-speciﬁed ARL 0value,
although not all ARL 0values can be reached with a certain accuracy, because of the
discreteness of the charting statistics C+
nandC−
n. The search of such an hvalue can
be accomplished by a numerical algorithm, such as the one described by the pseudo
code discussed in Subsection 4.2.2. For this chart, the relationship between the opti-
malkand the target shift size δin the process mean is unclear yet. Intuitively, this
relationship depends on the IC process distribution because the relationship between
δand the mean of Wnwould depend on the IC process distribution. However, the
general guidelines for selecting k, i.e., small kvalues are good for detecting small
shifts and large kvalues are good for detecting large shifts, should still be valid here.
See Subsection 4.2.2 for a related discussion. In all the numerical examples in Li
et al. (2010), kis chosen to be 0.5 σWn=0.5/radicalbig
mM(m+M+1)/12. In such cases,
when M=100, m=5, and ARL 0=500, the value of hwas computed by Li et al.
(2010) to be 353 for the two-sided NRS CUSUM chart.
Example 8.4 To online monitor the mean of a production process, M =100IC ob-
servations have been obtained beforehand and they are shown in Figure 8.5(a) by
the dark diamonds before the vertical dotted line at n =0. Then, 30 batches of phase
II observations with the batch size of m =5are collected from the same productionRANK-BASED NONPARAMETRIC CONTROL CHARTS 329
process, and they are shown in the same plot by the dark dots after the vertical dot-
ted line at n =0. The two-sided NRS CUSUM chart (8.10)–(8.13) is then applied
to this dataset for monitoring the process mean, in which k and h are chosen to be
0.5σWn=0.5/radicalbig
mM(m+M+1)/12 and 353, respectively. In such cases, the two-
sided chart has the ARL 0value of 500. The charting statistics C+
nand C−
nare shown
in Figure 8.5(b) by the dark dots and dark diamonds, respectively, and the upper and
lower control limits h and −h are shown by the dashed horizontal lines in the plot.
From the plot, the ﬁrst signal of process mean shift is given at the 23rd time point,
and it seems that the mean shift is upward because the signal is from the statistic C+
n.
From Figure 8.5(a), a mean shift can be noticed at n =21.
−20 −10 0 10 20 30−1 0 1 2 3 4 5
nXnj
(a)0 5 10 15 20 25 300 500 1000
n
(b)
Figure 8.5 (a) An IC dataset of size M =100(dark diamonds before the vertical dotted line)
and a phase II batch dataset with the batch size m =5obtained from a production process.
(b) The two-sided NRS CUSUM chart (8.10)–(8.13) with k =0.5/radicalbig
mM(m+M+1)/12 and
h=353. In plot (b), the dark dots and dark diamonds denote the values of C+nand C−n,
respectively, and the upper and lower control limits are shown by the dashed horizontal lines.
The NSR and NRS nonparametric CUSUM charts described above both use the
ranks of process observations for monitoring the mean of a production process. Chat-
terjee and Qiu (2009) proposed an alternative approach for constructing nonparamet-
ric CUSUM charts, brieﬂy described below. The approach by Chatterjee and Qiu
is mainly for phase II process mean monitoring, and it is designed for cases with
individual observation data, although it can be adapted easily to cases with batch
data and to cases for monitoring process variance and other parameters. Assume that
{Xn,n≥1}are phase II observations obtained from a production process with the
IC cdf F0that has the mean of 0. Instead of assuming F0to be known, we assume
that there is an IC dataset available, from which some procedure parameters can
be estimated. To monitor the process median, we use the charting statistics of the
conventional CUSUM charts described in Section 4.2. Without loss of generality,
assume that we are interested in detecting upward mean shifts. In such cases, the330 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
charting statistic is deﬁned by (4.7). For readers’ convenience, it is written below as
well.
C+
n=max/parenleftbig
0,C+
n−1+(X n−µ0)−k/parenrightbig
, n≥1, (8.14)
where C+
0=0 and kis an allowance constant. Instead of using a single control limit
to make a decision regarding the process performance at the current time point n, we
consider using a sequence of control limits {hj,j≥1}, depending on the value of
the so-called sprint length deﬁned by
Tn=/braceleftbigg0, ifC+
n=0
j,ifC+
n/ne}ationslash=0,C+
n−1/ne}ationslash=0,..., C+
n−j+1/ne}ationslash=0,C+
n−j=0,forj=1,2,..., n.
(8.15)
The sprint length Tnis the time elapsed since the last time the CUSUM statistic C+
n
was zero, and it can be easily computed based on the computed values of the charting
statistic. At the current time point n, in cases when Tn=j, for an integer 1 ≤j≤n,
a signal of process mean shift is given if
C+
n>hj. (8.16)
In practice, we can use a ﬁxed number of control limits {hj,1≤j≤jmax}in the
control chart (8.14)–(8.16), where jmaxis a ﬁxed integer. In such cases, if the ob-
served value of Tnis larger than jmax, then hjmaxis always used in (8.16). Chatter-
jee and Qiu (2009) proposed a bootstrap algorithm for computing the control limits
{hj,1≤j≤jmax}, and it was shown that the control chart was effective in most cases
considered if jmaxwas chosen in the range 20–50.
From the above description about the control chart (8.14)–(8.16), it can be seen
that the chart is nonparametric because it does not require speciﬁcation of a paramet-
ric form for the IC process distribution F0. Also, it makes decisions based on both Tn
andC+
n, which is intuitively appealing. However, there are still many open questions
about this method. For instance, the relationship between the joint distribution of
(Tn,C+
n)and the parameters kand jmaxis unclear yet. Consequently, more practical
guidelines are needed regarding the selection of these two parameters.
8.2.3 Nonparametric EWMA charts
The nonparametric CUSUM charts discussed in the previous subsection can all be
modiﬁed properly to become nonparametric EWMA charts. For instance, Graham
et al. (2011) changed the NSR CUSUM chart (8.8)–(8.9) to a nonparametric EWMA
chart, described as follows. Assume that the IC process distribution is symmetric
about the IC mean, which is assumed to be 0. Let (Xn1,Xn2,..., Xnm)bemobser-
vations obtained at the n-th time point when online monitoring the process mean of
a production process, for n=1,2,..., and ψnbe the sum of the Wilcoxon signed-
ranks within these observations, as deﬁned in (8.7). Then, the charting statistic of the
nonparametric EWMA chart can be deﬁned by
En=λψn+(1−λ)En−1, forn≥1, (8.17)RANK-BASED NONPARAMETRIC CONTROL CHARTS 331
where E0=0 and λ∈(0,1]is a weighting parameter. From the relation between ψn
andS+that
ψn=2S+−m(m+1)/2,
where S+is the Wilcoxon signed-rank test statistic described in Subsection 2.8.3
(note: the sample size nin Subsection 2.8.3 is actually mhere), and from the expres-
sions of the IC mean and variance of S+given in Subsection 2.8.3, it can be checked
that
µψn=0, σ2
ψn=m(m+1)(2m+1)/6.
Therefore, it is easy to check that the IC mean of Enis 0, and the IC variance of Enis
σ2
En=/bracketleftbiggm(m+1)(2m+1)
6/bracketrightbigg/bracketleftbiggλ
2−λ/bracketrightbigg/bracketleftbig
1−(1−λ)2n/bracketrightbig
.
The center line C, the upper control limit U, and the lower control limit L of the
nonparametric EWMA chart can then be deﬁned by
U=ρ/radicaligg/bracketleftbiggm(m+1)(2m+1)
6/bracketrightbigg/bracketleftbiggλ
2−λ/bracketrightbigg
[1−(1−λ)2n]
C=0 (8.18)
L=−U,
where ρ>0 is a parameter chosen to reach a given ARL 0value. When nincreases,
the IC distribution of Enconverges to its “steady-state” distribution with the variance
of[m(m+1)(2m+1)/6][ λ/(2−λ)]. The “steady-state” control limits can be deﬁned
to be
U=ρ/radicaligg/bracketleftbiggm(m+1)(2m+1)
6/bracketrightbigg/bracketleftbiggλ
2−λ/bracketrightbigg
C=0 (8.19)
L=−U.
As mentioned in Subsection 5.2.1, the control chart with the control limits in (8.19)
would be easier to use, the one with the control limits in (8.18) would be slightly
more reliable, and the two versions should have similar performance, especially in
cases when the potential mean shift does not occur early in the production process.
The chart (8.17)–(8.18) (or (8.17) and (8.19)) will be called the NSR EWMA chart
hereafter. The NSR EWMA chart described above is for detecting arbitrary process
mean shifts. If only the upward or the downward mean shifts are our concern in a
given application, then a one-sided EWMA chart can be deﬁned in a similar way to
those in (5.8)–(5.11) given in Subsection 5.2.1.
For the NSR EWMA chart deﬁned by (8.17) and (8.19), Graham et al. (2011)
computed the values of ρfor some commonly used values of m,λ, and ARL 0. These
values of ρare presented in Table 8.6. From the table, it can be seen that ρshould
be chosen larger when λis larger or ARL 0is larger; but, it is quite robust to the value332 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
ofmin cases when ARL 0is chosen to be quite large. By the way, the actual ARL 0
values of the chart with the ρvalues in the table are all within 10% of the assumed
ARL 0values.
Table 8.6 Computed values of ρused by the NSR EWMA chart deﬁned by (8.17) and (8.19),
for some commonly used values of m, λ, and ARL 0.
m ARL 0λ=0.01 λ=0.025 λ=0.05 λ=0.10 λ=0.20
5 370 1.822 2.230 2.481 2.668 2.764
500 1.975 2.368 2.602 2.775 2.852
10 370 1.821 2.230 2.486 2.684 2.810
500 1.975 2.367 2.610 2.794 2.905
Example 8.5 Figure 8.6(a) shows 30 batches of phase II observations with batch
size m=10obtained from a production process. It is known that the IC process
distribution is symmetric about 0, and we are interested in monitoring the process
mean by the NSR EWMA chart deﬁned by (8.17) and (8.19). To this end, we choose
λ=0.1and ARL 0=370. By Table 8.6, the value of ρused in (8.19) should be chosen
as 2.684. The control chart is shown in Figure 8.6(b), which gives its ﬁrst signal at
the 23rd time point
0 5 10 15 20 25 30−2 0 1 2 3 4
nXnj
(a)0 5 10 15 20 25 30−10 0 10 20 30
nEn
(b)
Figure 8.6 (a) Phase II batch data with the batch size of m =10obtained fr om a production
process. (b) The NSR EWMA chart deﬁned by (8.17) and (8.19) with λ=0.1and ARL 0=370.
The dashed horizontal lines in plot (b) denote the upper and lower control limits of the control
chart.
For the NRS CUSUM chart (8.10)–(8.13), Li et al. (2010) proposed a compan-
ion NRS EWMA chart described as follows. Let Wnbe the Wilcoxon rank-sum test
statistic deﬁned in the previous subsection for comparing the n-th batch of phaseRANK-BASED NONPARAMETRIC CONTROL CHARTS 333
II observ ations(Xn1,Xn2,..., Xnm)with the reference sample (Y1,Y2,..., YM). Deﬁne
the EWMA charting statistic to be
En=λWn+(1−λ)En−1, forn≥1, (8.20)
where E0=µWn=m(m+M+1)/2, and λ∈(0,1]is a weighting parameter. Then,
the center line C, the upper control limit U, and the lower control limit L of the chart
can be deﬁned by
U=m(m+M+1)
2+ρ/radicaligg/bracketleftbiggmM(m+M+1)
6/bracketrightbigg/bracketleftbiggλ
2−λ/bracketrightbigg
C=m(m+M+1)
2(8.21)
L=m(m+M+1)
2−ρ/radicaligg/bracketleftbiggmM(m+M+1)
6/bracketrightbigg/bracketleftbiggλ
2−λ/bracketrightbigg
,
where ρ>0 is a parameter chosen to reach a given ARL 0value. The chart gives a
signal of process mean shift when the charting statistic Enfalls outside the interval
[L,U]. For a given value of λ, Li et al. (2010) suggested determining the value of ρ
by simulation. In cases when λ=0.1,M=100, m=5, and ARL 0=500, Li et al.
(2010) computed the value of ρto be 2.1102. In such cases, the control limits are
L=219.5, C=265, U=310.5.
For the phase II SPC problem considered in Example 8.4, the NRS EWMA chart
(8.20)–(8.21) with λ=0.1 and ARL 0=500 is shown in Figure 8.7.
Next, we discuss the nonparametric EWMA chart proposed by Zou and Tsung
(2010) based on a nonparametric goodness-of-ﬁt test described below. Assume that
we have a simple random sample (X1,X2,..., Xn)obtained from a population with
the cdf F(x). To test the hypotheses
H0:F(x)=F0(x),for all x∈R versus H1:F(x)/ne}ationslash=F0(x),for some x∈R,
where F0(x)is a given cdf, Zhang (2002) proposed the following likelihood-ratio-
based test statistic:
n
∑
i=1/braceleftbigg1
1−Fn(Xi)log/parenleftbiggFn(Xi)
F0(Xi)/parenrightbigg
+1
Fn(Xi)log/parenleftbigg1−Fn(Xi)
1−F0(Xi)/parenrightbigg/bracerightbigg
, (8.22)
where Fn(x)=1
n∑n
i=1I(Xi≤x)is the empirical cumulative distribution function dis-
cussed in Subsection 2.8.1. When H0is true, Fn(x)should be close to F0(x). Conse-
quently, the test statistic in (8.22) should be close to 0. On the other hand, if H0is
false, the above test statistic should be relatively large. Now, in phase II SPC, assume
that{Xn,n≥1}are observations obtained from a production process for process
mean monitoring. Deﬁne
Fn,λ(x)=a−1
n,λn
∑
i=1(1−λ)n−iI(Xi≤x),334 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
0 5 10 15 20 25 30200 250 300 350 400
nEn
Figure 8.7 The N RS EWMA chart (8.20)–(8.21) with λ=0.1and ARL 0=500when it is
applied to the phase II SPC problem considered in Example 8.4.
where λ∈(0,1]is a weighting parameter, and
an,λ=n
∑
i=1(1−λ)n−i.
Then, Fn,λ(x)is also an empirical estimator of F0(x), although observations ob-
tained at time points closer to nwould receive more weight in Fn,λ(x), as in an
EWMA charting statistic. After replacing Fn(x)byFn,λ(x)and after including the
weight λ(1−λ)n−ifor the i-th term in (8.22), we obtain the following nonparamet-
ric EWMA charting statistic
En=n
∑
i=1λ(1−λ)n−i/braceleftbigg1
1−Fn,λ(Xi)log/parenleftbiggFn,λ(Xi)
F0(Xi)/parenrightbigg
+1
Fn,λ(Xi)log/parenleftbigg1−Fn,λ(Xi)
1−F0(Xi)/parenrightbigg/bracerightbigg
=λGn+(1−λ)En−1,forn≥1,
where E0=0, and
Gn=1
1−Fn,λ(Xn)log/parenleftbiggFn,λ(Xn)
F0(Xn)/parenrightbigg
+1
Fn,λ(Xn)log/parenleftbigg1−Fn,λ(Xn)
1−F0(Xn)/parenrightbigg
.
Obviously , the charting statistic Encombines the idea of EWMA process monitoringRANK-BASED NONPARAMETRIC CONTROL CHARTS 335
with the nonparametric goodness-of-ﬁt testing procedure by Zhang (2002). It should
be sensitive to any distributional shift from F0(x). However, to use this statistic, we
need to specify F0(x)completely, which is often difﬁcult to achieve in practice. To
overcome this limitation, we assume that F0(x)is unknown, but, there is an IC dataset
of size M, denoted as (X0,X−1,..., X−M+1). Then, F0(Xn)used in Gncan be replaced
by its estimator
/hatwideF0(Xn)=1
M+n−1n−1
∑
i=−M+1I(Xi≤Xn).
The resulting charting statistic is
En,SS=λ/tildewideGn+(1−λ)En−1,SS,forn≥1, (8.23)
where E0,SS=0, and
/tildewideGn=1
1−Fn,λ(Xn)log/parenleftbiggFn,λ(Xn)
/hatwideF0(Xn)/parenrightbigg
+1
Fn,λ(Xn)log/parenleftbigg1−Fn,λ(Xn)
1−/hatwideF0(Xn)/parenrightbigg
.
The chart gives a signal of process mean shift at the n-th time point if
En,SS>hn, (8.24)
where hn>0 is a control limit chosen to achieve a given ARL 0value. This chart will
be called the nonparametric likelihood ratio (NLR) EWMA chart hereafter.
When computing the charting statistic En,SSin (8.23), there might be numerical
difﬁculties, due to the facts that Fn,λ(Xn)could equal 1, /hatwideF0(Xn)could be 0 or 1,
and consequently /tildewideGnused by En,SSis not deﬁned in such cases. To overcome such
numerical difﬁculties, the following continuity corrections can be considered:
F∗
n,λ(Xn) =/bracketleftbig
∑n
i=1(1−λ)n−iI(Xi≤Xn)/bracketrightbig
−0.5
an,λ
/hatwideF∗
0(Xn) =max/braceleftig
0.5,/bracketleftig
∑n−1
i=−M+1I(Xi≤Xn)/bracketrightig
−0.5/bracerightig
M+n−1. (8.25)
Then, Fn,λ(Xn)and/hatwideF0(Xn)can be replaced by their modiﬁed versions F∗
n,λ(Xn)and
/hatwideF∗
0(Xn), respectively, when computing /tildewideGn.
The NLR EWMA chart (8.23)–(8.25) can be regarded as a self-starting version
of the chart that uses Enas its charting statistic. In (8.23), the true IC cdf F0(x)is
estimated by/hatwideF0(x), and the estimator is updated every time a new process observation
is obtained. It is obvious that both Fn,λ(Xn)and/hatwideF0(x)used in/tildewideGndepend only on
the ordering information of the observations (X−M+1,X−M+2,..., X0,X1,X2,..., Xn),
which are i.i.d. when the process is IC. Therefore, the IC performance of the chart
(8.23)–(8.25) does not depend on the IC cdf F0(x), and the chart is distribution-free
in that sense. Also, from the construction of the charting statistic En,SS, we can see
that it aims to detect any distributional shift from the IC distribution F0(x). Therefore,336 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
the chart (8.23)–(8.25) should be able to detect shifts in the location, scale, or other
distributional characteristics, which has been conﬁrmed by Zou and Tsung (2010).
By numerical simulations, Zou and Tsung (2010) computed the values of the
control limit hnfor some commonly used values of M,λ, and ARL 0. For instance,
the computed hnvalues in cases when M=100, λ=0.05 or 0.1, and ARL 0=370 or
500 are presented in Table 8.7. This table is modiﬁed from a part of Table 2 in Zou
and Tsung (2010), after correcting a mistake pointed out by Zou that the values in
Table 2 of Zou and Tsung (2010) should be multiplied by λto be valid control limit
values. In the table, only a limited number of nvalues between 1 and 500 are listed.
For a given nvalue between 1 and 500 that is not listed in the table, the corresponding
hnvalue can be obtained by linear interpolation, or it can be replaced by the hnvalue
in the same column of the table whose nvalue is the ﬁrst one before the given n.
When n>500, we can simply choose hn=h500.
Example 8.6 The dark diamond points shown before the vertical dotted line in Fig-
ure 8.8(a) denote 100 IC observations obtained from a production process for phase
II process monitoring. The dark dot points shown in the same plot denote 100 phase
II observations collected sequentially from the same production process. To apply the
NLR EWMA chart (8.23)–(8.25), we choose λ=0.05 and ARL 0=370. The modi-
ﬁcations described in (8.25) are used when computing the values of the charting
statistic E n,SS. The chart is shown in Figure 8.8(b), from which it can be seen that the
ﬁrst signal is given at the 62nd time point.
−100 −50 0 50 100−2 −1 0 1 2 3
nXn
(a)0 20 40 60 80 1000.0 0.2 0.4 0.6 0.8
nEn□□SS
(b)
Figure 8.8 (a) An IC dataset of size M =100(dark diamond points before the vertical dotted
line) and a phase II dataset (dark dot points after the vertical dotted line). (b) The NLR EWMA
chart (8.23)–(8.25) with λ=0.05and ARL 0=370. In plot (b), the dashed line denotes the
control limits h n.RANK-BASED NONPARAMETRIC CONTROL CHARTS 337
Table 8.7 Computed hnvalues of the NLR EWMA chart (8.23)–(8.25) in cases when M =100,
λ=0.05or 0.1, and ARL 0=370or 500.
λ=0.05 λ=0.1
nARL 0=370 ARL 0=500 ARL 0=370 ARL 0=500
1 0.753 0.803 1.372 1.442
2 0.754 0.799 1.318 1.429
3 0.740 0.793 1.240 1.350
4 0.726 0.788 1.183 1.284
5 0.711 0.772 1.110 1.219
6 0.686 0.744 1.038 1.141
7 0.667 0.726 0.983 1.072
8 0.642 0.701 0.924 1.005
9 0.622 0.681 0.873 0.944
10 0.601 0.657 0.826 0.887
11 0.578 0.633 0.783 0.843
12 0.556 0.610 0.745 0.798
13 0.538 0.586 0.709 0.759
14 0.520 0.568 0.677 0.719
15 0.503 0.548 0.647 0.690
16 0.485 0.528 0.626 0.664
17 0.470 0.510 0.600 0.634
18 0.455 0.493 0.578 0.612
19 0.439 0.478 0.561 0.591
20 0.426 0.462 0.544 0.575
22 0.400 0.432 0.513 0.548
24 0.376 0.408 0.494 0.522
26 0.356 0.384 0.478 0.505
28 0.337 0.362 0.460 0.489
30 0.320 0.344 0.448 0.479
35 0.284 0.303 0.430 0.454
40 0.256 0.274 0.419 0.444
50 0.220 0.235 0.408 0.432
60 0.199 0.212 0.410 0.433
70 0.187 0.198 0.411 0.435
80 0.180 0.193 0.417 0.439
90 0.176 0.188 0.419 0.443
115 0.176 0.188 0.427 0.453
140 0.178 0.191 0.434 0.459
165 0.184 0.194 0.441 0.466
200 0.187 0.199 0.446 0.476
250 0.193 0.207 0.459 0.488
370 0.205 0.219 0.468 0.505
500 0.209 0.227 0.472 0.512338 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
8.2.4 Nonpar ametric CPD charts
In the literature, some nonparametric control charts have been proposed based on the
change-point detection (CPD) framework. As discussed in Chapter 6, CPD control
charts have two major advantages, compared to the CUSUM and EWMA control
charts. One is that they do not require the speciﬁcation of certain parameters of the
IC process distribution, and the second advantage is that they can provide an estima-
tor of the shift time at the same time as they give a signal of the shift in the process
distribution. We describe some fundamental nonparametric CPD charts in this sub-
section.
First, the CPD chart (6.13)–(6.14) discussed in Subsection 6.3.1 that is based on
the normality assumption has been modiﬁed to be a nonparametric CPD chart by
Hawkins and Deng (2010). Assume that X1,X2,..., Xnare independent observations
obtained from a production process up to the current time point n, and they follow
the change-point model
Xi∼/braceleftbigg
F0(x), ifi=1,2,..., r,
F0(x−δ), ifi=r+1,r+2,..., n,(8.26)
where F0is the cdf of the IC process distribution, δis a location shift size, and
1≤r≤n−1 is a change-point. To test whether the process has a location shift at or
before n, the related hypotheses can be formulated as
H0:δ=0 versus H1:δ/ne}ationslash=0
for some 1 ≤r≤n−1, or equivalently, H0: 1≤r≤n−1 versus H1:r≥nfor
some δ/ne}ationslash=0 in (8.26). To test these hypotheses, Pettitt (1979) proposed the following
statistic based on the Mann-Whitney two-sample test (cf., Subsection 2.8.3):
Ujn=j
∑
i=1n
∑
i′=j+1sign(X i−Xi′), for 1≤j≤n−1, (8.27)
where sign(u) is the sign function deﬁned in (8.1). It is obvious that Ujnin (8.27) is
2 times the Mann-Whitney test statistic Udeﬁned in Subsection 2.8.3, that is con-
structed from the two samples (X1,X2,..., Xj)and(Xj+1,Xj+2,..., Xn). By the re-
lationship between the Mann-Whitney test statistic and the Wilcoxon rank-sum test
statistic described at the end of Subsection 2.8.3, we have
µUjn=0, σ2
Ujn=j(n−j)(n+1)
3.
Then, the test statistic for testing the above hypotheses is deﬁned by
Tmax,n=max
1≤j≤n−1|Tjn|, (8.28)
where
Tjn=Ujn/radicalbig
j(n−j)(n+1)/3.RANK-BASED NONPARAMETRIC CONTROL CHARTS 339
The null hypothesis is rejected and we conclude that there is a location shift at or
before nif
Tmax,n>hn, (8.29)
where hn>0 is a properly chosen control limit that may depend on n. In cases when
the null hypothesis is rejected, the change-point estimator can be deﬁned by
/hatwider=arg max
1≤j≤n−1|Tjn|. (8.30)
From (8.28) and (8.30), it can be seen that Tmax,n=|T/hatwidern|in such cases.
To use the nonparametric CPD (NCPD) control chart (8.28)–(8.29) for phase II
SPC, we need to choose the control limit hnsuch that a pre-speciﬁed ARL 0value is
reached. Because of the discrete nature of the charting statistic Tmax,n, it is required
thatn0IC observations should be collected before the online process monitoring.
Otherwise, a quite large ARL 0value (or, a quite small false alarm rate) is difﬁcult
to achieve within a reasonable accuracy. A related discussion can be found in the
paragraph containing (6.15) in Subsection 6.3.1. Hawkins and Deng (2010) found
that results of the chart (8.28)–(8.29) were quite reliable when n0is chosen to be 14
or larger. When n0=14, process monitoring starts at n=15. For some commonly
used ARL 0values, Hawkins and Deng computed the corresponding control limits hn
by simulation for 15 ≤n≤1000. Some of them are presented in Table 8.8, which
is the same as Table 1 in Hawkins and Deng (2010). In the table, not all values of
nbetween 15 and 1000 are listed. For those not in the table, the corresponding hn
values can be obtained by interpolation or by carrying entries forward. For instance,
by the approach of carrying entries forward, values of h50in the table can be used as
allhnvalues for 50 ≤n<60. The last control limit value in each column of the table
(denoted as hn∗) can be used as all hnvalues for n>n∗.
When computing the test statistic Tmax,n, the following recursive formula for com-
puting Ujnshould be helpful: for any 1 ≤j≤n−1, we have
Ujn=j
∑
i=1n
∑
i′=j+1sign(X i−Xi′)
=j
∑
i=1/bracketleftigg
n−1
∑
i′=j+1sign(X i−Xi′)+sign(Xi−Xn)/bracketrightigg
=Uj,n−1+j
∑
i=1sign(X i−Xn), (8.31)
where Un−1,n−1=0. From (8.31), it can be seen that, after a new observation Xnis
obtained, we only need to compare the new observation with all the old observations
(i.e., compute sign(X i−Xn), for 1≤j≤n−1) and then compute {Ujn,1≤j≤n−1}
from{Uj,n−1,1≤j≤n−2}by the recursive formula (8.31).
Example 8.7 Figure 8.9(a) shows the ﬁrst 100 observations obtained from a pro-
duction process for phase II process mean monitoring. It is known that the ﬁrst 14340 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
Table 8.8 Computed hnvalues of the NCPD control chart (8.28)–(8.29) in cases when n 0=14,
and ARL 0=50, 100, 200, 500, 1000, and 2000.
ARL 0
n 50 100 200 500 1000 2000
15 2.700 2.848 2.947 3.069 3.181 3.229
16 2.615 2.767 2.910 3.047 3.142 3.244
17 2.535 2.718 2.862 3.043 3.163 3.247
18 2.535 2.694 2.860 3.034 3.183 3.277
19 2.500 2.695 2.869 3.054 3.186 3.296
20 2.488 2.699 2.851 3.059 3.203 3.311
22 2.468 2.692 2.862 3.082 3.228 3.355
24 2.469 2.676 2.870 3.096 3.249 3.389
26 2.452 2.686 2.875 3.108 3.269 3.415
28 2.455 2.686 2.883 3.121 3.283 3.437
30 2.453 2.684 2.879 3.130 3.297 3.453
35 2.452 2.687 2.894 3.149 3.324 3.487
40 2.447 2.689 2.900 3.162 3.342 3.511
45 2.453 2.690 2.906 3.171 3.356 3.529
50 2.451 2.691 2.908 3.178 3.365 3.542
60 2.452 2.694 2.914 3.188 3.379 3.560
70 2.452 2.694 2.917 3.194 3.388 3.570
80 2.453 2.696 2.918 3.199 3.394 3.579
90 2.452 2.696 2.920 3.200 3.399 3.584
100 2.453 2.697 2.922 3.203 3.402 3.591
125 2.698 2.923 3.206 3.409 3.599
150 2.697 2.924 3.209 3.411 3.603
200 2.699 2.926 3.210 3.415 3.610
250 2.700 2.927 3.212 3.416 3.610
300 2.704 2.926 3.215 3.420 3.616
500 2.927 3.213 3.417 3.612
1000 2.927 3.214 3.418 3.612
observations are IC. So, we would like to use the NCPD control chart (8.28)–(8.29)
tomonitor the process mean, starting from n =15. In the chart, ARL 0is chosen to
be 200. Its control statistic T max,nis computed by (8.28) and (8.31), and is shown in
Figure 8.9(b). From the plot, the ﬁrst signal of process mean shift is given at n =55.
From the ﬁgure, it seems that there are a number of outliers in the observed data;
but, they do not have a substantial impact on the control chart.
Hawkins and Deng (2010) compared the NCPD control chart (8.28)–(8.29) with
the conventional CPD control chart (6.13)–(6.14) in cases when the normality as-
sumption of the process distribution is valid. They found an interesting phenomenon
that the former chart outperformed the latter chart in detecting relatively small pro-
cess mean shifts, and the latter chart was better than the former chart in detecting
relatively large process mean shifts only. The second part of this result is intuitively
reasonable; but, the ﬁrst part seems contradictory to our intuition. An explanation
given by Hawkins and Deng is that the estimated change-point by the conventionalNONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 341
0 20 40 60 80 100−4 −2 0 2 4
nXn
(a)0 20 40 60 80 1000 1 2 3 4 5 6 7
nTmax□□n
(b)
Figure 8.9 (a) The ﬁrst 100 observations obtained from a production process, among which
the ﬁr st 14 of them are IC. (b) The NCPD control chart (8.28)–(8.29) starting at n =15with
ARL 0=200. The dashed line in plot (b) denotes the control limits h n.
CPD chart tends to be close to the two ends of the observation time sequence when
the process is IC, this tendency is less obvious with the NCPD chart, and conse-
quently the NCPD chart would have a smaller control limit and react faster to rela-
tively small shifts, compared to the conventional CPD chart.
In the literature, there are some other NCPD charts proposed. For instance, Zhou
et al. (2009) proposed a NCPD control chart that was closely related to the chart
(8.28)–(8.29). Their charting statistic is deﬁned by the maximum of various exponen-
tially weighted moving averages of {Tjn,1≤j≤n−1}. Ross et al. (2011) proposed
two NCPD control charts for monitoring the process standard deviation and for mon-
itoring both the process mean and the process standard deviation, respectively. Ross
and Adams (2012) proposed two NCPD control charts for detecting arbitrary shifts
in the process distribution. One is based on the Kolmogorov-Smirnov test, and the
other is based on the Cramer-von-Mises test (cf., Gibbons and Chakraborti, 2003).
8.3 Nonparametric SPC by Categorical Data Analysis
All the nonparametric control charts described in the previous section are based on
the ranking or ordering information of the process observations. In this section, we
describe an alternative framework for constructing nonparametric control charts that
is based on categorization of numerical process observations. This method has been
shown competitive in various cases when process observations are continuous nu-
merical and they do not follow normal distributions. It can also handle cases when
process observations are discrete numerical or categorical. Our description here is di-
vided into two parts. The alternative framework is introduced in detail in Subsection
8.3.1, and it is compared to some alternative control charts in Subsection 8.3.2.342 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
8.3.1 Pr ocess monitoring by categorizing process observations
When the process distribution is not normal, people traditionally use the ranking
or ordering information of process observations for process monitoring. Some non-
parametric control charts require multiple observations at each time point (i.e., cases
with batch data). Qiu and Li (2011a) proposed an alternative method for handling
the univariate SPC problem with an unknown response distribution. By this method,
observed data are ﬁrst categorized, and then certain statistical procedures for categor-
ical data analysis are used for constructing nonparametric SPC charts. Major consid-
erations behind this method are as follows. First, statistical tools for describing and
analyzing non-normal numerical data are limited; but, there are many existing sta-
tistical tools for handling categorical data (cf., Agresti, 2002). Second, while both
data ranking and data categorization could result in a loss of information contained
in the observed data, the amount of lost information due to data categorization can
be controlled by the number of categories used. The bigger the number of categories
used, the less information would be lost. In comparison, the lost information due to
ranking is difﬁcult to control. Furthermore, the method by Qiu and Li (2011a) does
not require multiple observations at a single time point. It does not require observa-
tions to be numerical either. Methods based on ranking are generally difﬁcult to use
with non-numerical data. Like some existing nonparametric control charts (cf., Sec-
tion 8.2), the charts proposed by Qiu and Li (2011a) do not require the assumption
that the IC process distribution is known. Instead, we assume that an IC dataset has
been collected at the end of a phase I SPC analysis, and the IC dataset can be used
for estimating certain IC parameters.
LetXn= (X n1,Xn2,..., Xnm)′bemobservations obtained at the n-th time point
during phase II process monitoring. In cases when m>1, the observed data are batch
data with the batch size of m. In this section, the batch size mcould be 1. In such
cases, the observed data are actually individual observation data. The ﬁrst step to
construct nonparametric control charts based on data categorization is to categorize
the observed data as follows. Let
A1=(−∞, q1],A2=(q 1,q2], ..., Ap=(q p−1,∞)
be a partition of the real number line R, where −∞<q1<q2<···<qp−1<∞are
p−1 boundary points of the partitioning intervals. Deﬁne
Yn jl=I(Xn j∈Al), forj=1,2,..., m,l=1,2,..., p, (8.32)
andYn j= (Yn j1,Yn j2,..., Yn jp)′, where I(u)is the indicator function that equals 1
when uis “True” and 0 otherwise. Then, Yn jhas one and only one component being
1, the index of the component being 1 is the index of the partitioning interval that
contains Xn j, and this index has a discrete distribution with probabilities
fl=P(X n j∈Al), forl=1,2,..., p.
So,Yn jcan be regarded as the categorized data, and it records the index of the par-
titioning interval that contains Xn j. For simplicity, f=(f1,f2,..., fp)′is also called
the distribution of Yn jin this section.NONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 343
Let f(0)= (f(0)
1,f(0)
2,...,f(0)
p)′be the IC distribution of Yn j, and f(1)=
(f(1)
1,f(1)
2,..., f(1)
p)′be its OC distribution. For the distribution of Yn j, it can be
checked that, if the support of the IC cdf F0of the process distribution contains at
least one of the boundary points {q1,q2,..., qp−1}andp≥2, then any mean shift
inXnwould result in changes in the distribution f. It should be pointed out that the
conditions used in this result are weak. For instance, the supports of most commonly
used continuous numerical distributions (e.g., normal, t,χ2, uniform, exponential
distributions) are connected intervals on the number line. For these distributions, any
reasonable set of boundary points {q1,q2,..., qp−1}should have at least one point
contained in their supports. Otherwise, there must exist one partitioning interval that
contains all observations, which is contradictory to the purpose of categorization.
By the above result, under some mild regularity conditions, f(1)would be different
from f(0)if there is a mean shift in Xn. Therefore, detection of a mean shift in Xnis
equivalent to detection of a change in the distribution of Yn jin such cases.
To deﬁne Yn jby (8.32), we should choose {q1,q2,..., qp−1}beforehand. For that
purpose, existing research in categorical data analysis demonstrates that it would help
detect shifts from f(0)if they are chosen such that the expected counts of observa-
tions under F0in the partitioning intervals are roughly the same (cf., Agresti, 2002,
Section 1.5). Therefore, we suggest choosing qlto be the(l/p)-th quantile of F0, for
l=1,2,..., p−1. In such cases, f(0)= (1/ p,1/p,..., 1/p)′. In practice, qlcan be
estimated by the (l/p)-th sample quantile of the IC dataset.
To test whether the distribution of Yn jequals its IC distribution f(0), the Pearson’s
chi-square test (cf., Subsection 2.8.2) is a natural choice. Let
gnl=m
∑
j=1Yn jl, forl=1,2,..., p,n=1,2,..., (8.33)
andgn=(g n1,gn2,..., gnp)′. Then, gnlin (8.33), for l=1,2,..., p, denotes the num-
ber of original process observations obtained at the n-th time point that fall into the
l-th partitioning interval Al. The Pearson’s chi-square test statistic at the n-th time
point (cf., (2.43)) is then deﬁned by
/tildewideX2
n=p
∑
l=1/bracketleftig
gnl−m f(0)
l/bracketrightig2
m f(0)
l,
which measures the discrepancy between the observed counts gnand the expected
counts mf(0)in the ppartitioning intervals at the n-th time point. However, this statis-
tic uses observations at a single time point; it may not be effective to detect persistent
but relatively small changes in the distribution of Yn j(cf., a related discussion in Sec-
tion 4.1). To overcome this limitation, Qiu and Li (2011a) suggested the following
CUSUM chart, which adopted the structure of the multivariate CUSUM chart (7.28)–
(7.29), although the two charts were for two different purposes. Let Uobs
0=Uexp
0=0344 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
be tw op×1 column vectors, and


Uobs
n=0, ifBn≤kP
Uexp
n=0, ifBn≤kP
Uobs
n=/parenleftbig
Uobs
n−1+gn/parenrightbig
(1−kP/Bn), ifBn>kP
Uexp
n=/parenleftig
Uexp
n−1+mf(0)/parenrightig
(1−kP/Bn),ifBn>kP,
where
Bn=/braceleftig/parenleftig
Uobs
n−1−Uexp
n−1/parenrightig
+/parenleftig
gn−mf(0)/parenrightig/bracerightig′/parenleftig
diag(Uexp
n−1+mf(0))/parenrightig−1
/braceleftig/parenleftig
Uobs
n−1−Uexp
n−1/parenrightig
+/parenleftig
gn−mf(0)/parenrightig/bracerightig
,
kP≥0 is the allowance parameter, diag(a) denotes a diagonal matrix with its diago-
nal elements equal to the corresponding elements of the vector a, and the superscripts
“obs” and “exp” denote observed and expected counts, respectively. Deﬁne
Cn,P=/parenleftig
Uobs
n−Uexp
n/parenrightig′
(diag(Uexp
n))−1/parenleftig
Uobs
n−Uexp
n/parenrightig
. (8.34)
Then, a mean shift in Xnis signaled if
Cn,P>hP, (8.35)
where hP>0 is a control limit chosen to achieve a given IC ARL level. Chart (8.34)–
(8.35) is called the nonparametric P-CUSUM chart hereafter, to reﬂect the fact that
it is from the Pearson’s chi-square test.
When kP=0, it is not difﬁcult to check that Uobs
nis a frequency vector with
itsl-th element denoting the cumulative observed count of observations in the l-th
interval Alas of the time point n, for l=1,2,..., p, and Uexp
nequals nmf(0), which
is the vector of the corresponding cumulative expected counts. Therefore, in such
cases, Cn,Pis the conventional Pearson’s chi-square test statistic that measures the
difference between the cumulative observed and expected counts as of the time point
n. Further, it can be checked (cf., Qiu and Hawkins, 2001, Appendix C) that
Cn,P=max(0,Bn−kP).
Therefore, the charting statistic Cn,Pis deﬁned in the way that the CUSUM chart can
be repeatedly restarted when there is little evidence of distributional shift in Yn j.
For the nonparametric P-CUSUM chart (8.34)–(8.35), the control limit hPcan
be determined easily by a numerical algorithm as follows. First, choose an ini-
tial value for hP. Then, compute the IC ARL value of the P-CUSUM chart based
on a large number (e.g., 10000) of replicated simulation runs in which the IC
multinomial observations Yn jare sequentially generated from the IC distribution
f(0)=(1/ p,1/p,..., 1/p)′. If the computed IC ARL value is smaller than the nom-
inal IC ARL value, then increase the value of hP. Otherwise, choose a smaller hP
value. The above process is repeated until the nominal IC ARL value is reachedNONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 345
within a desired precision. See the pseudo code described in Subsection 4.2.2 for a
related discussion, in which the bisection search algorithm is used. From the above
description, it can be seen that determination of hPdoes not require any information
about the IC process distribution F0. Instead, it only depends on the nominal IC ARL
value, the allowance constant kP, the batch size m, and the number of categories p.
In this sense, the nonparametric P-CUSUM chart is distribution-free.
As a remark, due to the fact that the charting statistic Cn,Ptakes discrete values
on the positive number line, certain pre-speciﬁed nominal IC ARL values cannot
be reached within a desired precision. This phenomenon is common when handling
discrete data, as discussed in the previous section (cf., Table 8.5). To overcome this
limitation, when implementing the nonparametric P-CUSUM chart, we can simply
use an IC ARL value that the chart can reach. However, in practice, it is often de-
sirable to use a common IC ARL value (e.g., 200, 370, etc.). In such cases, Qiu and
Li (2011a) proposed the following simple but efﬁcient modiﬁcation of the charting
statistic Cn,P. Let bj(n)be a sequence of i.i.d. random vectors generated from the dis-
tribution Np(0,ν2Ip×p), where ν2is a small positive number and Ip×pis the p×p
identity matrix. Then, when computing Cn,P, we can replace Yn jbyYn j+bj(n).
Namely, we add a small random number from the distribution N(0,ν2)to each com-
ponent of Yn jto alleviate the discreteness of the charting statistic Cn,P. Based on our
numerical experience, as long as νis chosen to be small (e.g., ν=0.01), the OC be-
havior of the nonparametric P-CUSUM chart is hardly affected by this modiﬁcation.
However, most nominal IC ARL values can be reached within a desired precision
after the modiﬁcation. When ARL 0=200, 300, 500, or 1000, p=2, 3, 5, 10, 15,
or 20, kP=0.001, 0.005, 0.01, or 0.05, m=1, or 5, and M=500, the computed hP
values based on 10,000 replicated simulations, as described in this and the previous
paragraphs, are presented in Table 8.9. From the table, it can be seen that hPincreases
with ARL 0,kP, and p, and decreases with m.
To use the nonparametric P-CUSUM chart (8.34)–(8.35), besides hP, we also
need to choose kPandp, and the chart requires an IC data of size M. Based on an
extensive simulation study, Qiu and Li (2011a) provided some practical guidelines
on choosing kP,p, and M, which are described below. First, kPshould be chosen as
small as 0.05 or 0.01. Second, the chart would perform better when Mis larger, and
its results do not change much when M≥200. Third, regarding the selection of p, we
have the following practical guidelines. (i) pcan be chosen smaller when mis larger.
(ii) In cases when we do not have any prior information about the process distribu-
tion, then we can choose p=10. In such cases, the P-CUSUM chart should perform
reasonably well. (iii) If we know that the process distribution is quite symmetric, or
that it is skewed but the potential shift is in the direction of the longer tail, then pcan
be chosen as small as 5.
From the construction of the nonparametric P-CUSUM chart (8.34)–(8.35), we
can see that it should be able to detect any distributional shift of the original obser-
vations Xnthat results in a shift in the distribution of the corresponding categorized
data Yn j. Therefore, the P-CUSUM chart should have certain ability to detect shifts
in variance, or in both mean and variance, of the distribution of the original observa-
tions Xn. To demonstrate this, let us consider cases when the IC process distribution346 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
Table 8.9 Computed hPvalues of the nonparametric P-CUSUM chart (8.34)–(8.35) based on
10,000 replications when ARL 0=200, 300, 500, or 1000, p =2, 3, 5, 10, 15, or 20, k P=
0.001, 0.005, 0.01, or 0.05, m =1, or 5, and M =500.
m=1
kP ARL 0p=2 3 5 10 15 20
200 4.144 4.429 5.654 10.783 15.777 20.883
0.001 300 4.898 4.614 5.887 11.015 16.230 21.422
500 5.445 4.833 6.265 11.305 16.570 21.827
1000 6.402 5.552 6.843 11.960 16.979 22.155
200 5.089 5.148 6.215 11.180 16.142 21.297
0.005 300 5.848 5.481 6.650 11.531 16.407 21.589
500 6.497 6.099 7.251 12.006 16.992 22.106
1000 7.735 7.146 8.056 12.758 17.655 22.677
200 5.529 5.555 6.665 11.377 16.400 21.448
0.01 300 6.123 6.061 7.209 11.842 16.739 21.856
500 6.954 6.899 7.929 12.343 17.307 22.312
1000 8.078 7.979 8.600 13.205 18.056 22.993
200 5.918 6.860 7.957 12.171 16.981 21.931
0.05 300 6.656 7.685 8.438 12.841 17.550 22.397
500 7.595 8.492 9.269 13.616 18.181 22.958
1000 8.559 9.773 10.614 14.461 19.149 23.986
m=5
kP ARL 0p=2 3 5 10 15 20
200 0.899 0.983 1.318 2.430 3.588 4.753
0.001 300 1.080 1.065 1.379 2.496 3.647 4.814
500 1.265 1.183 1.485 2.598 3.734 4.916
1000 1.469 1.384 1.636 2.718 3.879 5.054
200 1.214 1.245 1.512 2.575 3.732 4.912
0.005 300 1.326 1.375 1.618 2.678 3.824 4.987
500 1.522 1.556 1.759 2.799 3.948 5.115
1000 1.778 1.815 1.966 2.981 4.119 5.254
200 1.276 1.389 1.635 2.686 3.826 5.024
0.01 300 1.412 1.530 1.750 2.777 3.909 5.084
500 1.600 1.725 1.911 2.911 4.032 5.214
1000 1.889 2.007 2.152 3.100 4.228 5.396
200 1.348 1.704 1.994 2.927 4.071 5.255
0.05 300 1.488 1.898 2.149 3.047 4.187 5.365
500 1.718 2.040 2.362 3.220 4.355 5.528
1000 1.924 2.272 2.628 3.459 4.577 5.745
is the standardized version with mean 0 and standard deviation 1 ofχ2
1orχ2
4, and the
OC distribution has a (mean, variance) shift from (0,1)to(µ1,σ2
1), where(µ1,σ2
1)
take the values of (0,1.5),(0,2.0),(0.5, 1.5), or(0.5, 2.0). The computed optimal
OC ARL values of the P-CUSUM chart (i.e., the minimum OC ARL values when kP
changes) when M=500, m=5,ARL 0=500, and p=5 are presented in Table 8.10.
The small ARL values indicate that the P-CUSUM chart can detect variance shifts,
and its computed optimal OC ARL values are much smaller in cases when both theNONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 347
mean and variance shift, compared to cases when only the variance shifts, which is
reasonable because the resulting shifts in the distribution of the categorized data Yn j
are bigger in the former cases. For a similar reason, the P-CUSUM chart is more sen-
sitive to variance shifts when the IC process distribution is more skewed. However,
based on the P-CUSUM chart alone, we cannot distinguish mean shifts from vari-
ance shifts, after a signal of shift is given. It requires much future research to design
diagnostic procedures for the P-CUSUM chart to make a distinction between the two
types of shifts after a signal is given.
Table 8.10 Computed optimal OC ARL values of the nonparametric P-CUSUM chart (8.34)–
(8.35) when M =500, m=5, ARL 0=500, p=5, the IC observation distribution is the stan-
dardized version with mean 0 and standard deviation 1 of χ2
1orχ2
4, and the OC distribution
has a (mean, variance) shift from (0,1)to(µ1,σ2
1).
IC Distribution (µ1,σ2
1)=(0,1.5) (0,2.0) (0.5,1.5) (0.5,2.0)
χ2
1 51.90 17.30 8.13 15.87
χ2
4 279.24 117.69 86.96 79.94
Example 8.8 To online monitor a production process, 500 IC observations are ob-
tained beforehand. Then, the ﬁrst 100 phase II process observations are collected for
online process monitoring, and they are shown in Figure 8.10(a). To apply the non-
parametric P-CUSUM chart (8.34)–(8.35) to the phase II observations, we choose
p=10and k P=0.01 in the chart, by the empirical guidelines discussed above. The
boundary points q lfor phase II observation categorization can be estimated by the
l/p-th sample quantiles, for l =1,2,..., p−1, of the IC dataset, and the estimates
are
/hatwideq1=−0.946,/hatwideq2=−0.585,/hatwideq3=−0.350,
/hatwideq4=−0.161,/hatwideq5=0.005,/hatwideq6=0.199,
/hatwideq7=0.340,/hatwideq8=0.530,/hatwideq9=0.941.
In such cases, the IC distribution of the categorized data Yn jcan be regarded as
f(0)=(1/ p,1/p,..., 1/p)′. In the chart, we further choose ARL 0=200. By Table 8.9,
the corresponding control limit is h P=11.377. The control chart is then constructed
and shown in Figure 8.10(b), where the horizontal dashed line denotes the control
limit. From the plot, we can see that the ﬁrst signal of distributional shift is given at
n=63.
The above discussion focuses on cases when process observations are continu-
ous numerical. Situations when observations are discrete numerical or categorical
can be handled similarly. For instance, when process observations are categorical,
the categorization step (cf., equation (8.32)) can be skipped when constructing the
nonparametric P-CUSUM chart (8.34)–(8.35). When process observations are dis-
crete numerical and the number of different observation values is quite small, we can
use each possible observation value as a single category, and construct the chart as
usual. In cases when process observations are discrete numerical but the number of348 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
0 20 40 60 80 100−3 −1 0 1 2 3
nXn
(a)0 20 40 60 80 1000 10 30 50 70
nCn□□P
(b)
Figure 8.10 (a) The ﬁrst 100 phase II observations obtained from a production process for
online monitoring. (b) The nonparametric P-CUSUM chart (8.34)–(8.35) with p =10, k P=
0.01, and ARL 0=200. In the chart, the boundary points q lare estimated by the l /p-th sample
quantiles, for l =1,2,..., p−1, of an IC data of size M =500. The dashed horizontal line in
plot (b) denotes the control limit h P.
different observation values is quite large, proper combination of certain observation
values might be necessary when deﬁning the categories.
8.3.2 Alternative control charts and some comparisons
In this subsection, we ﬁrst describe some alternative nonparametric control charts
based on observation categorization, and then discuss some numerical results given
by Qiu and Li (2011a) about the comparison among the nonparametric P-CUSUM
chart (8.34)–(8.35), these alternative nonparametric control charts, and some other
competitive control charts. Such numerical results should be helpful for users to
choose a proper control chart from many existing charts.
We ﬁrst introduce the competitive control charts considered in the numerical
comparison in Qiu and Li (2011a), including some alternative nonparametric control
charts based on observation categorization. To detect changes in the distribution of
the categorized data Yn j, besides the Pearson’s chi-square test (cf., /tildewideX2
ndeﬁned in the
previous subsection), another popular test is the likelihood ratio test (cf., Subsection
2.8.2) with the test statistic
/tildewideG2
n=2p
∑
l=1gnllog/parenleftigg
gnl
m f(0)
l/parenrightigg
.
Then, a CUSUM chart can be constructed similarly to (8.34)–(8.35) as follows. Let
/tildewideUobs
nand/tildewideUexp
nbe quantities deﬁned in the same way as Uobs
nandUexp
nused in (8.34),
except that the allowance constant kPis replaced by another constant kL, and BnisNONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 349
replaced by
/tildewideBn=2/parenleftig
/tildewideUobs
n−1+gn/parenrightig′
log/parenleftigg/tildewideUobs
n−1+gn
/tildewideUexp
n−1+mf(0)/parenrightigg
,
where a/b denotes a vector obtained by componentwise division of the vector a
by the vector b, and similarly log(a/b) denotes a vector obtained by applying the
logarithm transformation to all components of a/b. Deﬁne
Cn,L=2/parenleftig
/tildewideUobs
n/parenrightig′
log/parenleftigg/tildewideUobs
n
mf(0)/parenrightigg
. (8.36)
Then, a shift in the distribution of Xnis signaled if
Cn,L>hL, (8.37)
where the control limit hL>0 is chosen to achieve a given IC ARL level. Control
chart (8.36)–(8.37), which is based on the likelihood ratio test, will be called the
nonparametric L-CUSUM chart hereafter.
In the categorical data analysis, there is much discussion about the relationship
between the two tests based on /tildewideX2
nand/tildewideG2
n(cf., Agresti, 2002, Section 1.5.5). The
two tests are asymptotically equivalent, and the distribution of /tildewideX2
nconverges to a chi-
square distribution faster than that of /tildewideG2
n, when the observed counts in gnincrease.
In SPC, however, asymptotic properties are usually irrelevant because the related
control chart should be stopped immediately after a signal of distributional shift is
obtained. Therefore, the relationship between the nonparametric P-CUSUM and L-
CUSUM charts still needs to be studied.
From the construction of the nonparametric P-CUSUM and L-CUSUM charts,
we notice that the partitioning intervals {A1,A2,..., Ap}are ordered on the number
line; but, both the charting statistics Cn,PandCn,Lignore such ordering information
completely. In the nonparametric statistics literature, a popular test that takes into
account the ordering information among observations when testing for a potential
change in the observation distribution is the Kolmogorov-Smirnov goodness-of-ﬁt
test (cf., Chakravarti et al., 1967). To apply this test here for detecting potential shifts
from the IC process distribution F0, the test statistic can be written as
Dn=max
1≤j≤m/parenleftbigg
/hatwideF0/parenleftbig
Xn(j)/parenrightbig
−j−1
m,j
m−/hatwideF0/parenleftbig
Xn(j)/parenrightbig/parenrightbigg
,
where{Xn(j),j=1,2,..., m}are the order statistics of {Xn j,j=1,2,..., m}, and/hatwideF0
is the IC empirical cumulative distribution function (cf., (2.43)) constructed from the
IC data. Based on Dn, a CUSUM chart can be constructed as follows. Let C0,K=0,
and for n≥1,
Cn,K=max/bracketleftig
0,Cn−1,K+/parenleftig
Dn−µ(0)
D/parenrightig
−kK/bracketrightig
, (8.38)
where µ(0)
Ddenotes the IC mean of Dn, which can be estimated from the IC data, and
kKis an allowance constant. Then, a mean shift in Xnis signaled if
Cn,K>hK, (8.39)350 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
where hK>0 is a control limit. Chart (8.38)–(8.39) is called the nonparametric
K-CUSUM chart hereafter. It should be pointed out that the K-CUSUM chart is
constructed from the original observations Xn, instead of from their categorized
version{Yn j,j=1,2,..., m}. Although this chart can also be constructed from
{Yn j,j=1,2,..., m}, this approach is not recommended due to the reasons that
(i) the chart (8.38)–(8.39) based on Xnis already nonparametric, and (ii) it would
unnecessarily lose a certain efﬁciency in detecting potential mean shifts in Xnif the
categorized data {Yn j,j=1,2,..., m}were used.
Besides the nonparametric P-CUSUM, L-CUSUM, and K-CUSUM charts de-
scribed above, some other competitive control charts are also included in the nu-
merical comparison in Qiu and Li (2011a), which are brieﬂy described below. The
traditional CUSUM chart described in Section 4.2 is a standard tool for monitoring
univariate process mean in practice. Its charting statistics of the two-sided version in
cases when the IC process mean is known to be 0 are deﬁned by
C+
n,N=max/parenleftig
0,C+
n−1,N+Xn−kN/parenrightig
, forn≥1
C−
n,N=min/parenleftig
0,C−
n−1,N+Xn+kN/parenrightig
, (8.40)
where C+
0,N=C−
0,N=0,kNis an allowance constant, Xn=1
m∑m
j=1Xn j, and the sub-
script “N ” denotes the fact that this method is based on the normal-distribution as-
sumption. Then, a mean shift in Xnis signaled if
C+
n,N>h+
N or C−
n,N<−h−
N (8.41)
where the control limits h+
N,h−
N>0 are chosen to achieve a given IC ARL level.
When the true IC process distribution is symmetric (e.g., normal or t), then we can
seth+
N=h−
N. For skewed IC process distributions, different h+
Nandh−
Ncan be chosen
as follows. As demonstrated in Section 3.3 of Hawkins and Olwell (1998), when nis
large enough (e.g., n≥50), the distributions of the charting statistics C+
n,NandC−
n,N
become stable (i.e., the steady-state phenomenon discussed in Section 4.2). When
the IC process distribution is known, we can determine the steady-state distributions
ofC+
n,NandC−
n,Nby simulation and choose h+
Nandh−
Nsuch that P(u+
n,N>h+
N) =
P(u−
n,N<−h−
N)and the pre-speciﬁed IC ARL value is achieved. When the IC process
distribution is unknown but an IC dataset is available, the steady-state distributions
ofC+
n,NandC−
n,Ncan be estimated using bootstrap samples drawn from the IC data, as
in Chatterjee and Qiu (2009), and then h+
Nandh−
Ncan be determined in a similar way
to that in cases when the IC process distribution is known. The chart (8.40)–(8.41)
in such cases when the IC process distribution is unknown is called the N-CUSUM
chart hereafter.
As mentioned at the end of Subsection 5.2.1, when the process distribution is
not normal, Borror et al. (1999) showed that a properly designed EWMA chart was
robust to departures from normality. More speciﬁcally, the EWMA charting statistic
in cases when the IC process mean is known to be 0 is deﬁned by
En=λXn+(1−λ)En−1,NONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 351
where E0=0, and λ∈(0,1]is a weighting parameter. Then, a mean shift in Xnis
signaled if
|En|≥hR,
where hR>0 is a control limit chosen to achieve a pre-speciﬁed IC ARL level under
the normality assumption. Borror et al. (1999) showed that, when λ=0.05, this
chart performed reasonably well in various cases when the IC process distribution
was actually non-normal. This EWMA chart with λ=0.05 is called the R-EWMA
chart hereafter, where R stands for “robust.”
The upward NSR CUSUM chart (8.8)–(8.9) discussed in Subsection 8.2.2 is for
detecting upward process mean shifts. Its two-sided version is also considered in the
numerical comparison below. For convenience, the two-sided version is called the
S-CUSUM chart hereafter.
Phase II monitoring of categorized (or grouped) data was also discussed in
Steiner et al. (1996) and Steiner (1998). In their papers, Steiner and co-authors con-
sidered the case when the IC distribution had a known parametric form (e.g., nor-
mal), individual observations might not be completely known, and it was known that
they belonged to certain given intervals. In such cases, a CUSUM chart based on the
likelihood ratio formulation and a corresponding EWMA chart were proposed. Obvi-
ously, these charts are different from the nonparametric P-CUSUM, L-CUSUM, and
K-CUSUM charts discussed above, in that the former requires a parametric form of
the IC process distribution to be given beforehand while the latter does not have this
requirement. Next, we brieﬂy describe the CUSUM chart by Steiner et al. (1996).
To use this chart, we need to assume that the process distribution has a parametric
cdfF(x,θ), where θis a parameter. When the process is IC, θ=θ0. After the pro-
cess becomes OC, θshifts to θ1. Assume that the data are grouped into sintervals:
(−∞, t1],(t1,t2],...,(ts−1,∞). For j=1,2,..., s, let
π+
j(θ) = F(tj,θ)−F(tj−1,θ),
l+
j=log/parenleftig
π+
j(θ1)/π+
j(θ0)/parenrightig
,
w+
j=round/parenleftig
Q+l+
j/parenrightig
,
where t0=−∞, ts=∞, round(a) is a function that rounds ato its nearest integer,
andQ+=50/[max(l+
1,..., l+
s)−min(l+
1,..., l+
s)]. Then, to detect the shift in θfrom
θ0toθ1, the charting statistic is deﬁned to be
T+
n=max/parenleftigg
0,T+
n−1+s
∑
j=1m+
j(n)l+
j/parenrightigg
, forn≥1,
where T+
0=0, and m+
j(n)denotes the number of observations that belong to the
interval(tj−1,tj]at the n-th time point, for j=1,2,..., s. The chart gives a signal of
shift when
T+
n>hSt,
where hSt>0 is a control limit chosen to achieve a given IC ARL value. In the352 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
numerical study presented below, we choose Fto be the cdf of N(θ,1),θ0=0, and
s=5. As suggested by Steiner et al. (1996), {tj,j=1,2,..., s}are chosen to be
the optimal CUSUM gauge points listed in Table 2 of their paper that are scaled by
θ1. The control chart using T+
nis one-sided; but, all other control charts considered
in the numerical comparison are two-sided. To make the chart comparable with its
peers, we modify it to a two-sided control chart as follows. For j=1,2,..., s, let
π−
j(θ) = F(−tj−1,θ)−F(−tj,θ),
l−
j=log/parenleftig
π−
j(−θ1)/π−
j(θ0)/parenrightig
,
w−
j=round/parenleftig
Q−l−
j/parenrightig
,
and
T−
n=min/parenleftigg
0,T−
n−1−s
∑
j=1m−
j(n)l−
j/parenrightigg
, forn≥1,
where T−
0=0,Q−=50/[max(l−
1,..., l−
s)−min(l−
1,..., l−
s)], and m−
j(n)denotes
the number of observations that belong to the interval (−tj,−tj−1]at the n-th time
point, for j=1,2,..., s. Then, the two-sided control chart gives a signal of shift if
T+
n>hStorT−
n<−hSt,
where hStis chosen to achieve a given IC ARL value. This chart is called the St-
CUSUM chart hereafter.
Next, we present some numerical comparison results about the control charts
P-CUSUM, L-CUSUM, K-CUSUM, N-CUSUM, R-EWMA, S-CUSUM, and St-
CUSUM. In the comparison, the IC distribution is chosen to be the standardized
version with mean 0 and standard deviation 1 of one of the following four distribu-
tions: N(0,1),t4,χ2
1, and χ2
4. The t4distribution represents symmetric distributions
with heavy tails, and the χ2
1andχ2
4distributions represent skewed distributions with
different skewness. It is also assumed that the pre-speciﬁed IC ARL value is 500, and
the batch size of phase II observations at each time point is m=5. We ﬁx p=5 in
the P-CUSUM and L-CUSUM charts.
First, we compute the actual IC ARL values of the seven control charts, based
on 10,000 replicated simulations, for each of the four actual IC process distributions
described above. For the charts P-CUSUM, L-CUSUM, K-CUSUM, N-CUSUM,
and S-CUSUM, their control limits are determined based on 500 IC observations
when their allowance constants are chosen to be 0.1. The control limit of the chart
R-EWMA is chosen when λ=0.05 and the IC distribution is assumed normal. For
the chart St-CUSUM, it is assumed that the IC process distribution is normal in all
cases, and the OC mean θ1=0.6. The actual IC ARL values are shown in Table 8.11.
From the table, it can be seen that the actual IC ARL values of the charts P-CUSUM,
L-CUSUM, and K-CUSUM are close to 500 in all cases, as expected. The actual
IC ARL values of the charts N-CUSUM and R-EWMA are quite different from 500
when the actual IC process distribution is not normal. For the chart S-CUSUM, itsNONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 353
actual IC ARL values are moderately different from 500 due to the discreteness of its
charting statistic, as described in the previous section. Because the chart St-CUSUM
is constructed using a likelihood based on the normal distribution assumption, its
actual IC ARL value is close to 500 when the actual IC process distribution is N(0,1);
but, its actual IC ARL values are far from 500 in the other three cases.
Table 8.11 The actual IC ARL values and their standard errors (in parentheses) of the seven
control charts when the nominal IC ARL values are ﬁxed at 500 and the actual IC process
distribution is the standardized version of N (0,1), t 4,χ2
1, and χ2
4.
N(0,1) t4 χ2
1 χ2
4
P-CUSUM 501.9 (5.51) 503.3 (5.55) 504.8 (5.46) 501.1 (5.45)
L-CUSUM 498.1 (4.96) 495.3 (5.02) 504.2 (5.13) 497.4 (5.06)
K-CUSUM 499.0 (4.48) 499.7 (4.47) 504.4 (4.61) 496.4 (4.46)
N-CUSUM 498.9 (4.35) 156.0 (1.13) 321.4 (2.63) 371.5 (3.27)
R-EWMA 502.2 (6.24) 578.2 (20.87) 605.5 (8.65) 533.7 (6.57)
S-CUSUM 497.3 (5.22) 532.2 (5.57) 544.5 (5.88) 518.3 (5.63)
St-CUSUM 499.5 (4.87) 3037.7 (27.33) 9316.6 (20.46) 1862.2 (18.08)
Next, we compare the OC performance of the related control charts in cases when
the IC sample size M=500. In order to make the comparison more meaningful,
we intentionally adjust the parameters of the charts N-CUSUM, R-EWMA, and St-
CUSUM so that their actual IC ARL values equal 500 in all cases considered. For
the chart S-CUSUM, we use the same modiﬁcation procedure as the one described in
the previous subsection for the P-CUSUM chart to overcome the difﬁculty caused by
the discreteness of its charting statistic, and the actual IC ARL value of its modiﬁed
version can reach 500 in all cases considered. In this study, 10 mean shifts ranging
from−1.0 to 1.0 with a step of 0.2 are considered, representing small, medium, and
large shifts. Due to the fact that different control charts have different parameters
(e.g., kPin the chart P-CUSUM, kNin the chart N-CUSUM, and λin the chart R-
EWMA), and that the performance of different charts may not be comparable if their
parameters are pre-speciﬁed, we compare the optimal performance of all the charts
when detecting each shift, by selecting their parameters to minimize the OC ARL
values for detecting each individual shift, while their IC ARL values are all ﬁxed at
500. Based on 10,000 replications, the optimal OC ARL values of the related control
charts are shown in Figures 8.11 and 8.12. The results are shown in two ﬁgures to
better demonstrate the difference among different control charts. The optimal OC
ARL values of the P-CUSUM chart are plotted in both ﬁgures for the convenience
of comparison. When reading the plots in these ﬁgures, readers are reminded that the
scale on the y-axis is in natural logarithm, to better demonstrate the difference among
different control charts in detecting relatively large shifts.
From Figures 8.11(a) and 8.12(a), we can see that when the normality assump-
tion is valid, the N-CUSUM chart is the best, as expected. The St-CUSUM and P-
CUSUM charts lose a certain power in detecting mean shifts because of data group-
ing in the St-CUSUM chart and the data categorization in the P-CUSUM chart.
The R-EWMA and S-CUSUM charts perform well for detecting small shifts only.354 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
L−CUSUM   
K−CUSUM   
St−CUSUM   
(a)−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
L−CUSUM   
K−CUSUM   
St−CUSUM   
(b)
−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
L−CUSUM   
K−CUSUM   
St−CUSUM   
(c)−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
L−CUSUM   
K−CUSUM   
St−CUSUM   
(d)
Figure 8.11 Optimal OC ARL values of four control charts when the IC ARL is 500, M =500,
m=5, and the actual IC process distribution is the standardized version of N (0,1)(plot (a)),
t4(plot (b)), χ2
1(plot (c)), and χ2
4(plot (d)). Scale on the y-axis is in natural logarithm.
It seems that the K-CUSUM and L-CUSUM charts are not appropriate to use in this
scenario. In the scenario of Figures 8.11(b) and 8.12(b), the IC process distribution
ist4, which is symmetric with heavy tails. In such cases, results are quite similar
to those in the N(0,1)case, with two exceptions: (i) the P-CUSUM chart performs
the best or close to the best among all control charts in most cases of this scenario,NONPARAMETRIC SPC BY CATEGORICAL DATA ANALYSIS 355
−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
N−CUSUM   
R−EWMA   
S−CUSUM   
(a)−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
N−CUSUM   
R−EWMA   
S−CUSUM   
(b)
−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
N−CUSUM   
R−EWMA   
S−CUSUM   
(c)−1.0 −0.5 0.0 0.5 1.01 2 5 10 20 50 100 200 500
shiftARLP−CUSUM   
N−CUSUM   
R−EWMA   
S−CUSUM   
(d)
Figure 8.12 Optimal OC ARL values of four control charts when the IC ARL is 500, M =500,
m=5, and the actual IC process distribution is the standardized version of N (0,1)(plot (a)),
t4(plot (b)), χ2
1(plot (c)), and χ2
4(plot (d)). Scale on the y-axis is in natural logarithm.
and (ii) the N-CUSUM chart is not among the best any more when the shift is large,
although it still performs well when the shift is small. When the actual IC distribu-
tion is skewed (cf., Figures 8.11(c)–(d) and 8.12(c)–(d)), the charts P-CUSUM and
L-CUSUM perform well. The chart St-CUSUM performs well only when detecting356 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
downw ard shifts. The K-CUSUM chart performs well only when the skewness is
large. The other two charts do not perform well in such cases.
In Qiu and Li (2011a) and its supplementary ﬁle, there are corresponding numer-
ical results in cases when M=200 and in cases when procedure parameters of the
control charts are chosen to be the ones that minimize the OC ARL values for detect-
ing the shift of size 0.6 and these parameters are used in all other cases. These extra
results suggest the same relative performance of the seven control charts as observed
in Figures 8.11 and 8.12.
From the numerical results described above, we can make the following conclu-
sions. (i) The control charts constructed based on the normality assumption (e.g.,
the N-CUSUM, R-CUSUM, and St-CUSUM charts) would not be reliable to use in
cases when the normality assumption is invalid, because their actual IC ARL values
could be substantially different from the nominal IC ARL value. Even when they are
adjusted such that their actual IC ARL values equal the nominal IC ARL value, their
OC performance could be poor, especially when the process distribution is quite dif-
ferent from a normal distribution. (ii) The nonparametric control charts based on the
ranking information of process observations (e.g., the K-CUSUM and S-CUSUM
charts) are reliable to use, but they are not quite effective in various different cases.
(iii) The control charts based on observation categorization (e.g., the P-CUSUM and
L-CUSUM charts) are reliable to use, and they are quite effective as well in different
cases considered above. Between the P-CUSUM and L-CUSUM charts, it seems that
the P-CUSUM chart is generally more effective.
8.4 Some Discussions
In this chapter, we have discussed some nonparametric control charts for monitor-
ing univariate production processes in cases when the process distribution cannot be
described properly by a parametric form or when no parametric form of the process
distribution is available. From Figure 8.12(a), it can be seen that, in cases when the
assumed parametric form of the process distribution is valid, the parametric control
charts that makes use of the assumed parametric form would be more effective than
the nonparametric control charts. However, in practice, the assumed parametric form
of the process distribution (e.g., a normal distribution) is often invalid, or no para-
metric form is available. See, for instance, the aluminum smelter example discussed
in Qiu and Hawkins (2001) and the exchange rate example discussed in Qiu and Li
(2011a). In cases when the assumed parametric form is invalid, SPC results from
the related parametric control charts may not be reliable, and the results could even
be misleading because the actual false alarm rates of the parametric charts could be
substantially larger or smaller than the assumed false alarm rate (cf., Table 8.11).
As mentioned in Section 8.1, in cases when the actual false alarm rate of a con-
trol chart is larger than the assumed false alarm rate (or, the actual IC ARL value
is smaller than the assumed IC ARL value), much labor and other resources would
be wasted because the production process would be stopped too often unnecessarily.
On the other hand, if the actual false alarm rate of a control chart is smaller than
the assumed false alarm rate (or, the actual IC ARL value is larger than the assumedSOME DISCUSSIONS 357
IC ARL value), then the chart cannot give signals of process distributional shift in
a timely manner. A direct consequence could be that many defective products are
manufactured by the production process without notice. Therefore, in cases when no
parametric form of the process distribution is available or when no parametric form
is validated properly beforehand, nonparametric control charts should be considered.
In Sections 8.2 and 8.3, two different types of nonparametric control charts have
been described. One is based on the ranking or ordering information in the observed
data, and the other is based on observation categorization. Obviously, both types
of methods would lose information in the observed data. But the methods based
on observation categorization seem to be more efﬁcient in process monitoring (cf.,
Figures 8.11 and 8.12) because they have used certain information in the observation
magnitudes. The larger the number of partitioning intervals p, the more magnitude
information they use. Of course, the boundary points of the partitioning intervals
need to be estimated from the observed data in practice. When pis chosen to be
large, the estimation error could affect the control chart performance. So there is a
trade-off between these two considerations. In Subsection 8.3.1, we have described
some practical guidelines on choosing pand some other procedure parameters, from
which pcan be chosen to be 10 or smaller, depending on the batch size and the shape
of the process distribution. But much future research is needed to further explore the
relationship between the control chart performance and the values of p,M, the shape
of the process distribution, and so forth.
Most nonparametric control charts described in this chapter are for phase II pro-
cess monitoring. In the literature, there is only a limited discussion on phase I process
analysis in cases when the process distribution does not have any parametric form (cf.
Graham et al., 2010; Jones-Farmer et al., 2009). Also, many existing nonparametric
control charts assume that certain parameters (e.g., the median) of the IC process
distribution are known, or that there is an IC dataset available for phase II SPC. In
practice, some extra research effort is needed to estimate these parameters or collect
the IC dataset properly before phase II online process monitoring. Furthermore, ex-
isting research on nonparametric SPC focuses mainly on detection of location shifts
in the process distribution, although a few nonparametric control charts can also de-
tect scale shifts or arbitrary shifts in the process distribution (e.g., the NLR EWMA
chart in Subsection 8.2.3 and the two NCPD charts by Ross et al. (2011) that are men-
tioned in Subsection 8.2.4). Much future research is needed to study the monitoring
of process variance and the joint monitoring of process mean and variance.
The major limitation of the nonparametric control charts discussed in Section 8.2
is that they only use the ranking or ordering information in the process observations
for process monitoring and much useful information in the original process observa-
tions has been ignored. This limitation is partially overcome by the nonparametric
control charts discussed in Section 8.3 that are based on observation categorization.
However, the useful information in the process observations has not been used suf-
ﬁciently yet by the latter type of nonparametric control charts. For instance, the par-
titioning intervals {A1,A2,..., Ap}used in the P-CUSUM and L-CUSUM charts are
ordered on the number line. This kind of ordering information is ignored completely
in the construction of the two control charts. The charts do not use any quantita-358 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
tive measures of the intervals (e.g., their center locations and their lengths) either.
Therefore, these charts still have much room for improvement.
8.5 Exercises
8.1 The following 11 numbers constitute the i-th batch of observations obtained
from a production line for process monitoring, where iis given.
3.718, 0.695, 1.094, 1.175, 2.888,−0.234,−0.231, 0.581, 0.307,−0.193, 2.343
Assume that the IC process distribution is symmetric and the IC process median
is/tildewideµ0=1.
(i) Compute the value of ψideﬁned in (8.1).
(ii) Compute the value of the Wilcoxon signed-rank test statistic S+described in
Subsection 2.8.3.
(iii) Verify the equation ψi=2S+−m(m+1)/2, where m=11 is the batch size.
8.2 Perform a Monte Carlo simulation study to verify the following results about the
upward NSR chart (8.1)–(8.2) given in Table 8.1:
(i) When m=10 and U=47,ARL+
0is about 147.
(ii) When m=10 and U=49,ARL+
0is about 204.
Then, in cases when mis ﬁxed at 10, compute the ARL+
0values of the chart when
Uchanges from 47 to 49. Summarize your ﬁndings about the computed ARL+
0
values.
8.3 In the simulation study described in the previous exercise, you can assume that
the IC process distribution is N(0,1), and generate all IC process observations
from this distribution. You can also assume that the IC process distribution is t5.
Verify by a simulation study that the IC performance of the upward NSR chart
(8.1)–(8.2) is about the same in these two scenarios (i.e., the computed ARL+
0
values are about the same in the two scenarios). Therefore, the chart is indeed
distribution-free.
8.4 The upward NSR chart (8.1)–(8.2) requires the assumption that the IC pro-
cess distribution is symmetric about its median /tildewideµ0. Discuss the possible con-
sequences if the chart is used in cases when this assumption is invalid.
8.5 The data shown in Table 8.12 are the ﬁrst 30 batches of phase II observations
with the batch size m=10, obtained from a production process for process mean
monitoring. Assume that the IC process distribution is symmetric about the IC
median of/tildewideµ0=0. Monitor the process mean using the upward NSR chart (8.1)–
(8.2) with U=51 (the ARL 0value of the chart is about 345 according to Table
8.1). Summarize your results.
8.6 The following 50 observations constitute a reference sample of size M=50
obtained from a production process when it is IC:
−0.79,−0.95,−0.34, 2.87, −1.91,−0.84, 0.32, −0.35,−1.08, 0.25,
−0.11,−0.65, 0.43, −0.30,−1.29,−2.45,−0.09, 0.15, −1.89,−0.07,
0.57,−0.29, 0.07, −0.22,−0.66,−0.8, 0.12, −0.15, 0.85, 0.15,EXERCISES 359
Table 8.12 The ﬁrst 30 batches of phase II observations with the batch size m =10obtained
from a production process for process monitoring.
i Xi1 Xi2 Xi3 Xi4 Xi5 Xi6 Xi7 Xi8 Xi9 Xi10
1−0.33−0.37 0.72 0.16 −0.60−0.18 0.25 0.46 −0.31 0.71
2−0.04−0.61−0.10 0.83 0.02 −0.19 0.60 0.83 1.82 1.85
30.07 0.01 −0.33 0.18 0.02 0.61 −0.63 0.52 0.14 −0.45
4−0.30 0.27 0.20 −0.17−0.17−0.01−1.51−1.10−0.31−0.11
5−0.71 0.04 −1.21−0.09 0.55 0.18 1.42 0.22 0.64 −0.08
60.29−0.49−0.20 0.01 0.28 −0.24−0.56 1.26 −1.59−1.02
7−0.42−0.06−0.29 0.08 0.01 −0.67−0.41−0.53−1.60−0.17
8−0.24 3.34 0.41 0.46 −0.01 1.47 0.17 −0.19 0.03 0.32
90.74 0.41 0.30 0.15 −0.22 0.66 0.35 0.94 −0.03−0.22
10 0.53−0.05−1.74 0.91 −0.41 0.62 −0.15−0.19 0.11 2.24
11 0.48−0.58−0.13−1.31 1.13 0.42 −0.59 1.73 0.69 0.04
12 0.92 0.19 −0.29 0.43 0.30 0.48 −1.39 0.57 0.43 2.24
13−0.85−0.02−0.51−0.68 0.51 −0.97 0.84 0.28 0.41 0.05
14−0.73 0.85 3.00 0.12 −0.57−0.59 3.65 0.07 0.59 0.75
15−0.03−0.10 0.34 1.14 −0.19 0.56 1.26 −0.16 0.27 1.60
16−0.10 0.40 0.83 −0.44 0.43 −0.38 0.23 0.11 −0.41 0.21
17 0.46−0.17−0.17−0.50−0.22 1.40 −6.32−0.01 0.64 −0.45
18 0.19−0.49 1.02 −0.58−5.86−2.67−2.94 0.10 0.20 0.02
19 0.72−2.02 0.06 0.11 −0.53 0.91 0.20 −0.13 1.02 −1.99
20 1.36 0.83 1.18 −0.36−1.13−1.01 0.27 −0.43−0.35−0.72
21 0.47 2.33 0.72 1.07 0.99 2.17 2.65 2.02 0.08 0.86
22 1.22 1.73 1.09 1.18 1.68 1.18 −0.44 1.15 1.71 0.77
23 0.59 0.47 0.62 0.09 0.16 1.99 0.14 3.38 1.03 2.99
24 1.10 0.92 1.51 0.85 1.57 0.97 1.65 1.15 1.53 0.28
25 1.16 1.05 0.67 −1.11 1.53 0.89 1.92 2.23 0.88 1.49
26 0.82 0.95 −0.11 1.45 −0.04 1.07 1.35 0.54 1.49 2.08
27−0.29 2.56 −0.80 1.25 1.28 1.36 1.67 1.76 −0.96 0.95
28 1.63−1.31 0.99 1.69 1.30 −0.70 0.48 −0.26 1.35 1.58
29 1.12 1.22 −1.01 0.94 1.20 0.14 1.49 1.29 0.90 1.64
30 1.42 1.50 0.65 1.45 3.28 1.69 4.00 1.54 0.62 0.99
0.21, 1.30, −0.06, 0.62, 0.73, 0.62, −0.06, 0.08, 0.26, −0.23,
0.62,−0.50,−0.64, 0.48, 0.67, 0.39, −0.01,−0.24,−0.64, 0.13
Compute the values of the precedence statistic W3(cf., its deﬁnition in the para-
graph containing the expression (8.3)) for the following batches of phase II ob-
servations with the batch size m=5 obtained from the same production process:
(i)(1.23,−0.47, 0.01,−0.10, 1.25),
(ii)(−0.71,−0.27,−0.18, 0.14, 0.88),
(iii)(−0.05,−0.42,−1.42, 0.05, 1.39).
8.7 Assume that each row in Table 8.12 contains two batches of phase II ob-
servations from a production process. So, the ﬁrst batch of observations is
(−0.33,−0.37, 0.72, 0.16,−0.60), the second batch is (−0.18, 0.25, 0.46,360 UNIV ARIATE NONPARAMETRIC PROCESS CONTROL
−0.31, 0.71), and so forth. Use the DFP chart (8.4)–(8.6) and the reference
sample given in Exercise 8.6 to monitor the 60 batches of phase II observations
presented in Table 8.12 for possible process mean shift. In the chart, choose
ARL 0=370. Summarize your results.
8.8 Assume that {(X i1,Xi2,Xi3,Xi4,Xi5,Xi6),i=1,2,..., 30}shown in Table 8.12 are
the ﬁrst 30 batches of observations with the batch size of m=6 obtained from
a production process for phase II process monitoring. Use the upward NSR
CUSUM chart (8.8)–(8.9) with k=9 and h=12 to detect potential upward
process mean shift. Summarize your results.
8.9 For the Wilcoxon rank-sum test statistic Wndiscussed in the paragraph below
Figure 8.4, verify the following results:
µWn=m(m+M+1)/2, σ2
Wn=mM(m+M+1)/12.
8.10 The following M=100 observations constitute a reference sample obtained
from a production process when it is IC. The ﬁrst 60 batches of phase II obser-
vations with the batch size of m=5 from the same production process are those
described in Exercise 8.7. Use the two-sided NRS CUSUM chart (8.10)–(8.13)
with k=0.5σWn=0.5/radicalbig
mM(m+M+1)/12 and h=353to online monitor the
process mean. Summarize your results.
−0.13, 0.77, −1.01, 0.29, 2.49, 0.64, −0.08, 0.32, 2.1, −0.91,
−0.22, 0.54, −1.16,−0.24,−0.21, 0.95, 0.71, 0.68, −1.22, 0.68,
−2.61, 0.24, −1.88,−1.37,−1.32,−0.33,−2.58, 0.28, −1.31, 0.00,
−0.6,−0.8, 0.7, −0.06, 0.48, −0.33, 0.42, 0.34, −0.54,−0.02,
1.04,−0.08,−0.47, 0.04, 1.04, −0.12, 0.39, 0.00, −0.52, 3.81,
−0.53,−0.89,−0.06, 0.23, −0.03,−0.51, 0.26, −0.26, 0.21, 1.52,
0.05, 0.39, 0.21, 0.8, −0.03, 0.11, −1.00, 0.91, 0.07, 0.00,
0.71,−0.72,−0.13,−1.10,−0.11,−1.38, 1.40, −2.50,−0.37,−1.53,
−0.36,−0.93,−2.92,−0.40,−0.18, 2.09, 0.44, 3.27, 0.13, 0.85,
−0.05,−0.01, 0.44, 0.39, 0.24, −0.04, 0.76, 2.68, 0.11, −0.31
8.11 For the 100 observations shown in the previous exercise, compute the values of
the charting statistic C+
ndeﬁned in (8.14) and the values of the sprint length Tn
deﬁned in (8.15). In (8.14), use µ0=0 and k=0.5.
8.12 Apply the NSR EWMA chart deﬁned by (8.17) and (8.19) with λ=0.1 and
ARL 0=500 to the phase II observations described in Exercise 8.7. Summarize
your results.
8.13 Apply the NRS EWMA chart deﬁned by (8.20) and (8.21) with λ=0.1 and
ARL 0=500 to the observed data described in Exercise 8.10. Summarize your
results.
8.14 Apply the NLR EWMA chart (8.23)–(8.25) with λ=0.1 and ARL 0=500 to the
observed data described in Exercise 8.10. Summarize your results, and compare
the results here with those obtained in the previous exercise.EXERCISES 361
8.15 The ﬁrst 100 phase II observations obtained from a production process are given
below, among which the ﬁrst 14 observations are known to be IC. Use the NCPD
control chart (8.28)–(8.29) with ARL 0=500 to monitor the process mean, start-
ing from n=15. If a signal of process mean shift is given, then give an estimate
of the shift position as well. Summarize your results.
−0.39,−0.05, 0.08, −0.37,−0.79, 0.36, −0.52,−0.30, 0.92, 0.50,
0.56, 0.95, −0.91,−0.86,−0.04,−0.12, 0.51, 0.24, 0.83, 1.60,
−0.44,−0.70, 0.02, −0.20,−0.91,−0.72, 0.00, 1.94, 0.48, −1.35,
0.62, 0.93, −0.11, 0.44, −0.22,−0.58,−1.85, 1.01, 0.85, −0.13,
−0.39, 0.36, 0.80, 2.49, 0.39, 0.82, −0.16, 0.07, 0.13, 0.20,
1.96, 1.20, 0.81, 0.89, 1.01, 1.09, 1.55, 1.17, 2.11, −0.29,
1.55, 0.18, 1.13, 2.34, 0.55, 0.44, 0.32, 1.13, 0.59, 0.28,
1.03, 1.03, 0.80, 1.69, 1.34, 1.01, 1.00, −0.23, 0.42, 0.46,
1.23, 0.57, 2.02, 1.33, 1.57, 0.37, 0.76, 1.51, 0.72, −2.86,
0.41,−0.25, 0.78, 0.78 , 1.67, 0.98, 1.77, 2.12, 0.40, 1.22
8.16 The (l/p)-th sample quantiles, for p=10 and l=1,2,..., 9, of an IC dataset of
the size M=500 obtained from a production process are listed below.
−1.172,−0.708,−0.454,−0.201,−0.040, 0.193, 0.397, 0.617, 1.088
Use this IC dataset and the nonparametric P-CUSUM chart (8.34)–(8.35) with
p=10,kP=0.01, and ARL 0=200 to monitor the ﬁrst 100 phase II observations
presented in the previous exercise for possible process mean shifts. Summarize
your results.
8.17 In Table 8.11, the IC performance of seven control charts is compared by their
actual IC ARL values. Please comment on the possible consequences if they
are used in the three cases considered in the table when the actual IC process
distribution is not normal.Chapter 9
Multiv ariate Nonparametric Process
Control
9.1 Introduction
The nonparametric control charts discussed in the previous chapter are for cases
when the quality characteristic in question is univariate. In practice, however, the
quality of a product is usually described by multiple quality characteristic variables,
as discussed at the beginning of Chapter 7. That is, most applications require multi-
variate, instead of univariate, SPC methods. In multivariate cases, the assumption that
the multiple quality characteristic variables in question follow a normal distribution
is difﬁcult to satisfy, because this assumption implies that all individual quality char-
acteristic variables follow normal distributions and all subsets of them follow joint
normal distributions (cf., (7.2) and the related discussion in Subsection 7.2.1), which
are difﬁcult to satisfy in applications. Therefore, it is important to develop multi-
variate SPC control charts that are appropriate to use in cases when the normality
assumption is invalid.
The multivariate SPC control charts discussed in Chapter 7 are appropriate to use
only in cases when the normality assumption is valid. Their results are unreliable or
even misleading in cases when the normality assumption is violated, as demonstrated
by the following example originally discussed in Qiu and Hawkins (2001). Assume
that there are four quality characteristic variables involved in an SPC application,
and they are assumed to follow the normal distribution N(0,I4)when the related pro-
duction process is IC. However, the four quality characteristic variables are actually
independent of each other and each follows the standardized version with mean 0
and variance 1 of the Poisson(/tildewideλ)distribution (cf., Subsection 2.4.5). Let us consider
using the multivariate CUSUM chart (7.28)–(7.29) for phase II process monitoring,
in which the allowance constant kand the control limit hare chosen to be 1.0 and
4.503, respectively, so that its nominal IC ARL value equals 200 under the normal-
ity assumption. In cases when/tildewideλ=0.01, 0.1,0.5,1.0,1.5,2.0, and 5.0, its actual IC
ARL values are presented in Figure 9.1(a) by the small diamonds. It can be seen that
these actual IC ARL values differ substantially from the nominal IC ARL value, es-
pecially in cases when/tildewideλis small. When/tildewideλgets larger, the standardized version of the
Poisson(/tildewideλ)distribution becomes closer to the standard normal distribution N(0,1).
Consequently, the actual IC ARL values of the control chart get closer to its nominal
363364 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
IC ARL value, as seen in the plot. One idea to overcome this limitation of the multi-
variate CUSUM chart, caused mainly by the invalidity of the normality assumption,
is to transform the true IC process distribution to a normal distribution. A commonly
used transformation for the Poisson distribution is the square root transformation.
The corresponding actual IC ARL values of the chart, after the observations are ﬁrst
square-root transformed and then standardized to have mean 0 and variance 1, are
presented in Figure 9.1(b). Again, the actual IC ARL values are far away from the
nominal IC ARL value in most situations considered in this plot.
0 1 2 3 4 50 50 150 250 350
λ~IC ARL
(a)0 1 2 3 4 50 50 150 250 350
λ~IC ARL
(b)
Figure 9.1 (a) The small diamonds denote the actual IC ARL values of the multivariate
CUSUM chart (7.28)–(7.29) in cases when there are four quality characteristic variables
involved in an SPC application, the variables are independent of each other, and each has
the standardized version with mean 0 and variance 1 of the Poisson(/tildewideλ)distribution where
/tildewideλ=0.01,0.1,0.5,1.0,1.5,2.0, and 5.0. (b) The small diamonds denote the actual IC ARL
values of the chart after the original observations are square-root transformed and standard-
ized to have mean 0 and variance 1. In the chart (7.28)–(7.29), the control limit h and the
allowance constant k are chosen to be 4.503 and 1.0, respectively, such that its nominal IC
ARL equals 200 under the normality assumption. The dashed line in each plot denotes the
nominal IC ARL value of 200.
Stoumbos and Sullivan (2002) studied the robustness of the conventional multi-
variate EWMA charts (cf., Section 7.4) to the normality assumption, and they found
that such charts were quite robust as long as the smoothing parameters used in the
charts were chosen to be small. However, their numerical results showed that it de-
pended on the true process distribution to decide how small the smoothing param-
eters should be chosen. This conclusion is also conﬁrmed by the results shown in
Figure 9.2, which were originally given in Qiu (2008). In the plot, we consider cases
when three quality characteristic variables are involved, their joint IC distribution is
assumed to be N(0,I3), and they are actually independent of each other and each of
them has the standardized version with mean 0 and variance 1 of the χ2
rdistributionINTRODUCTION 365
where r=1,5,10,20, and 50. Both the multivariate CUSUM chart (7.28)–(7.29) and
the multivariate EWMA chart (7.39)–(7.40) are considered here. In the multivariate
CUSUM chart, kandhare chosen to be 1.0 and 3.786, respectively. In the multivari-
ate EWMA chart, a single weighting parameter λis used, and (λ,h)are chosen to be
(0.05, 9.603) or(0.2, 11.956). In such cases, all three charts have nominal IC ARL
values of 200. The plot shows their actual IC ARL values in various cases considered.
It can be seen that the actual IC ARL values of the multivariate CUSUM chart are
quite far away from their nominal IC ARL value, which is consistent with the results
shown in Figure 9.1(a). For the multivariate EWMA chart, when λ=0.2, its actual
IC ARL values are quite close to the nominal IC ARL value only in cases when r
is large. When λ=0.05, its actual IC ARL values are quite close to the nominal
IC ARL value in cases when r≥5. When r=1, it seems that λshould be chosen
smaller than 0.05. In practice, the difference between the true IC process distribution
and a normal distribution is often difﬁcult to measure. Also, when the smoothing
parameter in the multivariate EWMA chart is chosen to be small, the chart would be
ineffective in detecting relatively large shifts, as demonstrated in Table 7.4. There-
fore, the robustness property of multivariate EWMA charts should be used with care
in practice, as discussed in univariate cases in Section 8.1.
0 10 20 30 40 500 50 100 150 200
rIC ARL
MCUSUM
MEWMA,lambda=0.05
MEWMA,lambda=0.2
Figure 9.2 Actual IC ARL values of the multivariate CUSUM chart (7.28)–(7.29), denoted as
MCUSUM, and the multivariate EWMA chart (7.39)–(7.40), denoted as MEWMA, in cases
when there are three quality characteristic variables involved in an SPC application, the vari-
ables are independent of each other, and each has the standardized version with mean 0 and
variance 1 of the χ2rdistribution where r =1,5,10,20, and 50. In the multivariate CUSUM
chart,(k,h)are chosen to be (1.0,3.786) (solid curve). In the multivariate EWMA chart, (λ,h)
are chosen to be (0.05,9.603) (dotted curve) or (0.2,11.956) (dot-dashed curve). All charts
have nominal IC ARL values of 200 (dashed horizontal line) under the normality assumption.366 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
In cases when the multiple quality characteristic variables are not normally dis-
tributed, one natural idea is to transform them properly so that the tranformed vari-
ables would be roughly normally distributed. The results shown in Figure 9.1(b) were
obtained by this idea. In the statistical literature, in cases when a multivariate dataset
is not normally distributed, existing tools for describing such a dataset, or transform-
ing it to a normally distributed dataset, are limited (cf., Eaton, 1983; Fang et al.,
1990; Johnson and Wichern, 2007). Therefore, this idea is challenging to accomplish
in practice.
To handle multivariate SPC in cases when the normality assumption is invalid,
there have been some nonparametric or distribution-free control charts proposed
in the literature. See, for instance, Boone and Chakraborti (2012), Liu (1995), Liu
et al. (2004), Qiu (2008), Qiu and Hawkins (2001, 2003), Sun and Tsung (2003),
Zou and Tsung (2011), Zou et al. (2012), and the references cited therein. In this
chapter, we discuss some of them. As in univariate cases, we do not always make a
clear distinction between the words “nonparametric multivariate control charts” and
“distribution-free multivariate control charts” in this chapter. See Section 8.1 for a
related discussion.
9.2 Rank-Based Multivariate Nonparametric Control Charts
In this section, we describe some multivariate nonparametric control charts based on
the ranking or ordering information of the observed data. Unlike univariate cases in
which the ranking information refers to the order among observations at different
time points, in multivariate cases, the order could be among observations at differ-
ent time points, which is called longitudinal ranking or longitudinal ordering in this
chapter. It can also refer to the order among different components of an observa-
tion vector at a given time point, which is called cross-component ranking or cross-
component ordering in this chapter. When computing the longitudinal ranking, there
are several different ways to consider as well. Some fundamental multivariate non-
parametric control charts based on different types of ranking or ordering information
of the observed data will be discussed in two parts of this section. Those based on
different types of longitudinal ranking are described in Subsection 9.2.1, and those
based on cross-component ranking are described in Subsection 9.2.2.
9.2.1 Control charts based on longitudinal ranking
Let us ﬁrst describe two recent multivariate nonparametric Shewhart charts proposed
by Boone and Chakraborti (2012) that are based on componentwise signs and com-
ponentwise signed-ranks. These two Shewhart charts are mainly for phase II SPC, al-
though they can also be modiﬁed properly for phase I process analysis. Assume that
there are pquality characteristic variables involved in a production process, which
are denoted as a p-dimensional vector X, and at the n-th time point of phase II SPC,
we have collected a sample of mi.i.d. p-dimensional observations
Xn1,Xn2,..., Xnm, forn=1,2,...,RANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 367
where Xn j=(Xn j1,Xn j2,..., Xn jp)′, for j=1,2,..., m. Then, for the l-th component,
with l=1,2,..., p, we can deﬁne the componentwise sign statistic
ξnl=m
∑
j=1sign/parenleftbig
Xn jl−/tildewideµ0l/parenrightbig
, (9.1)
where sign(·) is the sign function deﬁned in (8.1), and /tildewideµ0= (/tildewideµ01,/tildewideµ02,...,/tildewideµ0p)′is
thep-dimensional vector of the IC process distribution that is assumed known. In-
tuitively, in cases when the process is IC, ξnlis about 0, because the numbers of
positive and negative values among {Xn jl−/tildewideµ0l,j=1,2,..., m}are about the same.
In cases when one or more components of Xhave location shifts at n, the correspond-
ing components of ξn=(ξn1,ξn2,..., ξnp)′would move away from 0. Therefore, the
sign statistic vector ξncan be used for detecting process location shifts.
The covariance matrix of ξncan be estimated by /hatwideV= (/hatwidevl1l2)where l1,l2=
1,2,..., p,
/hatwidevl1l2=/braceleftbiggm, when l1=l2
∑m
j=1sign/parenleftbig
Xn jl1−/tildewideµ0l1/parenrightbig
sign/parenleftbig
Xn jl2−/tildewideµ0l2/parenrightbig
,when l1/ne}ationslash=l2.
Then, the Shewhart charting statistic can be deﬁned by
T2
S=ξ′
n/hatwideV−1ξn. (9.2)
The chart gives a signal of process location shift when
T2
S>hS, (9.3)
where hS>0 is a control limit chosen to achieve a given ARL 0value. The chart
(9.2)–(9.3) will be called the multivariate nonparametric sign (MNS) chart hereafter.
In cases when the process is IC, it can be shown that T2
Sconverges in distribution
toχ2
pasmincreases (cf., Hettmansperger, 2006). Therefore, when mis large, for a
given false alarm rate α(or equivalently, a given ARL 0=1/α), the control limit hS
can be chosen to be
hS=χ2
1−α,p, (9.4)
where χ2
1−α,pis the(1−α)-th quantile of the χ2
pdistribution. Boone and Chakraborti
(2012) have shown that formula (9.4) provides a reliable control limit only in cases
when the batch size mis reasonably large (e.g., m≥50). In cases when mis small,
this formula often provides a conservative control limit. Namely, the control limit
computed by (9.4) is often larger than the control limit that achieves a given ARL 0
value, or the actual false alarm rate (actual ARL 0value) using the control limit by
(9.4) is often smaller (larger) than the nominal false alarm rate (nominal ARL 0value).
In such cases, a more reliable control limit can be computed by a bootstrap algorithm
from a reasonably large IC dataset, as discussed in Chatterjee and Qiu (2009).
The second multivariate nonparametric Shewhart chart proposed by Boone and
Chakraborti (2012) is based on the componentwise Wilcoxon signed-rank statistics.
For the l-th component, with l=1,2,..., p, let
ψnl=m
∑
j=1sign/parenleftbig
Xn jl−/tildewideµ0l/parenrightbig
R+
n jl, (9.5)368 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
where R+
n jlis the rank of |Xn jl−/tildewideµ0l|among{|Xn jl−/tildewideµ0l|,j=1,2,..., m}. Then,
clearly, ψnlis the sum of all Wilcoxon signed-ranks for the l-th component within
then-th batch of observed data (cf., the paragraph containing (8.1) in Subsection
8.2.1 for a related discussion). Let ψn= (ψn1,ψn2,..., ψnp)′. Then, when the IC
process distribution is diagonally symmetric in the sense that the distributions of
X−/tildewideµ0and/tildewideµ0−Xare the same when the process is IC, the marginal distributions of
Xn jl, for given nandjand for l=1,2,..., p, are all symmetric about their medians
/tildewideµ0l. In such cases, ψnwould be centered at 0, and the covariance matrix of ψncan
be estimated by /hatwiderW=(/hatwidewl1l2), where l1,l2=1,2,..., p,
/hatwidewl1l2=/braceleftigg
m(m+1)(2m+1)
6, when l1=l2
∑m
j=1sign/parenleftbig
Xn jl1−/tildewideµ0l1/parenrightbig
R+
n jl1sign/parenleftbig
Xn jl2−/tildewideµ0l2/parenrightbig
R+
n jl2,when l1/ne}ationslash=l2.
When one or more components of Xhave location shifts at n, the corresponding
components of ψnwould move away from 0. Therefore, ψncan be used for detecting
process location shifts. The Shewhart charting statistic is then deﬁned by
T2
SR=ψ′
n/hatwiderW−1ψn. (9.6)
The chart gives a signal of process location shift when
T2
SR>hSR, (9.7)
where hSR>0 is a control limit chosen to achieve a given ARL 0value. The chart
(9.6)–(9.7) will be called the multivariate nonparametric signed-rank (MNSR) chart
hereafter.
By Hettmansperger (2006), when mincreases, T2
SRconverges in distribution to
χ2
p. Therefore, when mis large enough, the control limit hSRcan be chosen to be
hSR=χ2
1−α,p, (9.8)
where αis a given false alarm rate. Similar to hSin (9.4), Boone and Chakraborti
(2012) have shown that formula (9.8) provides a reliable control limit only in cases
when mis reasonably large (e.g., m≥50). In cases when mis small, the formula
often provides a conservative control limit. In such cases, a more reliable control
limit can be computed by a bootstrap algorithm from a reasonably large IC dataset.
Between the MNS chart (9.2)–(9.3) and the MNSR chart (9.6)–(9.7), the former
is more general in the sense that it does not require the IC process distribution to
be diagonally symmetric while the latter does. However, in cases when the diagonal
symmetry assumption is valid, Boone and Chakraborti (2012) have shown that the
MNSR chart would generally be more efﬁcient.
Example 9.1 Assume that there are p =2quality characteristic variables involved
in a production process. For phase II process mean monitoring, a sample of size m =
50is obtained at each time point. The two components of the observed 2-dimensional
data obtained at the ﬁrst 20 time points are shown in Figure 9.3(a)–(b). From theRANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 369
plots, it seems that the ﬁrst quality characteristic variable has a mean shift starting
from the 11th time point, and the second variable does not have any mean shift. We
then apply the MNS chart (9.2)–(9.3) and the MNSR chart (9.6)–(9.7) to this dataset.
In both charts, αis chosen to be 0.005 (i.e., ARL 0=200), and their control limits are
chosen by (9.4) and (9.8) to both be χ2
0.995,2=10.597. The two charts are shown in
Figure 9.3(c)–(d). From the plots, both charts give their ﬁrst signals at the 11th time
point. The signal by the MNSR chart seems more convincing because its charting
statistic takes larger values when n ≥11.
0 5 10 15 20−5 0 5
nXnj1
(a)0 5 10 15 20−5 0 5
nXnj2
(b)
0 5 10 15 200 5 10 15 20 25 30 35
nTS2
(c)0 5 10 15 200 5 10 15 20 25 30 35
nTSR2
(d)
Figure 9.3 (a) First component of the observed 2-dimensional batch data with batch size m =
50obtained at the ﬁrst 20 time points. (b) Second component of the observed data. (c) MNS
chart (9.2)–(9.3) when it is applied to the observed data. (d) MNSR chart (9.6)–(9.7) when it
is applied to the observed data. In both charts, αis chosen to be 0.005, and the control limit
is chosen to be χ2
0.995,2=10.597(dashed horizontal lines in plots (c) and (d)).370 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
Both the MNS chart (9.2)–(9.3) and the MNSR chart (9.6)–(9.7) are Shewhart
charts. They are good at detecting large and isolated shifts, but ineffective in detecting
small and persistent shifts, based on the discussion in previous chapters. It is possible
to modify them properly to become multivariate nonparametric CUSUM, EWMA, or
CPD charts, as discussed in univariate cases in Section 8.2. For instance, to modify
the MNS chart (9.2)–(9.3) to become a multivariate nonparametric EWMA chart, we
can deﬁne
En=λξn+(1−λ)En−1, forn≥1,
where E0=0, and λ∈(0,1]is a weighting parameter. Then, the multivariate non-
parametric EWMA chart gives a signal of process mean shift if
E′
nΣ−1
EnEn>h, (9.9)
where h>0 in (9.9) is a control limit chosen to achieve a given ARL 0value.
In the MNS chart (9.2)–(9.3) and the MNSR chart (9.6)–(9.7), the component-
wise sign statistics ξnldeﬁned in (9.1) and the componentwise signed-rank statistics
ψnldeﬁned in (9.5) are used. Zou and Tsung (2011) proposed a multivariate EWMA
chart based on the so-called spatial sign function deﬁned as
U(X)=/braceleftigg
X−µ0
/bardblX−µ0/bardbl,when X/ne}ationslash=µ0
0, when X=µ0,(9.10)
where µ0is the IC mean of X, and/bardbl·/bardblis the Euclidean length. Obviously, the spatial
sign of Xis just the direction of Xfrom its center µ0with unit Euclidean length. Zou
et al. (2012) proposed another multivariate EWMA chart based on the so-called spa-
tial ranks. For a sample of p-dimensional observations (X1,X2,..., Xn), the spatial
rank of Xi, for i=1,2,..., n, is deﬁned as
ri=1
nn
∑
j=1U(Xi−Xj). (9.11)
In cases when p=1,ri= [2R i−(n+1)]/n, where Riis the conventional rank of
Xiin the sample. Because µRi= (n+1)/2,[2R i−(n+1)]/n=2
n[Ri−(n+1)/2]
can be regarded as 2/n times the centered rank of Xi. The spatial rank of Xiis a
generalization of the centered rank in p-dimensional cases. For related discussions
on spatial signs, spatial ranks, and their statistical properties, see Oja (2010), Oja
and Randles (2004), and the references cited therein. Because the two multivariate
EWMA charts based on spatial signs and spatial ranks mentioned above are quite
complicated to present, they are not described in detail here.
Liu (1995) proposed several multivariate control charts based on the concept of
data depth. Let Y1,Y2,..., YMbeMobservations generated from a p-dimensional
distribution F0. The concept of data depth tries to order the observations from the
most central point to the most outlying point with respect to the distribution F0, us-
ing a speciﬁc deﬁnition of data depth. In the literature, there are several different
deﬁnitions of data depth, including the Mahalanobis depth, the half-space depth, theRANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 371
conv ex hull peeling depth, the Oja depth, the simplicial depth, the majority depth, the
likelihood depth, and so forth. Next, we describe two of them. For a quite complete
description of all these deﬁnitions, see Liu et al. (1999) and Liu and Singh (1993).
The Mahalanobis depth of a p-dimensional point ywith respect to the distribution
F0is deﬁned as
DM(y;F0)=1
1+(y−µ0)′Σ−1
0(y−µ0), (9.12)
where µ0andΣ0are the mean vector and covariance matrix of F0. Clearly, the term
(y−µ0)′Σ−1
0(y−µ0)on the right-hand side of (9.12) is the squared statistical dis-
tance (or, the squared Mahalanobis distance) from yto the center µ0ofF0. The
Mahalanobis depth DM(y;F0)is deﬁned as a decreasing function of this squared sta-
tistical distance in (9.12). So, the Mahalanobis depth of ywith respect to F0would be
larger if yis closer to the center of F0in terms of the Mahalanobis distance, and vice
versa. In cases when F0is unknown, but we have a sample (Y1,Y2,..., YM)from F0,
we can deﬁne the empirical Mahalanobis depth of yas
DM(y;F0M)=1
1+(y−Y)′/parenleftbig
S2
Y/parenrightbig−1(y−Y), (9.13)
where YandS2
Yare the sample mean vector and the sample covariance matrix of the
sample(Y1,Y2,..., YM), and F0Mis the empirical estimator of F0.
The simplicial depth of ywith respect to F0(cf., Liu, 1990) is deﬁned as
DS(y;F0)=P(y∈S(Y1,Y2,..., Yp+1)), (9.14)
where the probability P(·) is under F0,(Y1,Y2,..., Yp+1)is a simple random sam-
ple of size p+1 from F0, andS(Y1,Y2,..., Yp+1)is an open simplex with vertices
atY1,Y2,..., Yp+1. Intuitively, in cases when yis closer to the center of the distri-
bution F0,DS(y;F0)in (9.14) would be larger because the random simplex would
have a larger chance to contain y. So, DS(y;F0)measures how central (or, deep) the
point yis with respect to F0. In cases when F0is unknown but there is a sample
(Y1,Y2,..., YM)from F0, the sample simplicial depth of yis deﬁned as
DS(y;F0M)=1/parenleftbigg
M
p+1/parenrightbigg∑I/parenleftig
y∈S(Yi1,Yi2,...,Yip+1)/parenrightig
, (9.15)
where(Yi1,Yi2,..., Yip+1)is a subset of (Y1,Y2,..., YM), and the summation on the
right-hand side of (9.15) is over all possible subsets.
From the above description, it seems that the Mahalanobis depth is easier to com-
pute and perceive. So, we will describe the three control charts by Liu (1995) using
this deﬁnition of data depth, although the charts can be constructed in the same way
using the simplicial depth. Now, for phase II SPC, assume that (Y1,Y2,..., YM)is a
reference sample obtained beforehand from a production process when it is IC, and
F0is the IC process distribution. Let Ybe a p-dimensional random vector with the
distribution F0, and for a given point y∈Rp, deﬁne
r(y;F0)=P(DM(Y;F0)≤DM(y;F0)), (9.16)372 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
where the probability P(·) is under F0. Then, r(y;F0)in (9.16) can be regarded as
the cdf of DM(Y;F0)in terms of DM(y;F0). In cases when F0is unknown but the
reference sample is available, the empirical version of r(y;F0)is deﬁned as
r(y;F0M)=1
MM
∑
i=1I(DM(Yi;F0M)≤DM(y;F0M)). (9.17)
LetXnbe a phase II observation obtained at the n-th time point. Then, if Xnis IC
(i.e., Xn∼F0), Liu and Singh (1993) showed that (i) r(Xn;F0)∼Uni f orm(0, 1)(cf.,
Exercise 2.1 for a description), and (ii) the distribution of r(Xn;F0M)converged to
Uni f orm(0, 1)when Mincreased. Therefore, to monitor Xn, for n≥1, if the value
ofr(Xn;F0M)is too small (i.e., DM(Xn;F0M)is too small or Xnis too outlying with
respect to the empirical distribution F0M), a signal of distributional shift should be
given. The corresponding Shewhart chart, called the r chart in Liu (1995), then gives
a signal when
r(Xn;F0M)<α, (9.18)
where α∈(0,1)is a given false alarm rate. For the rchart (9.18), it is often helpful to
draw a center line at C=1/2, because the charting statistic r(Xn;F0M)should wave
around this line when the process is IC.
Therchart (9.18) can be modiﬁed as follows to become a CUSUM-type control
chart. Let X1,X2,..., Xnbe the ﬁrst nobservations obtained during phase II SPC.
Then, when F0is known,
Sn(F0)=n
∑
i=1/bracketleftbigg
r(Xi;F0)−1
2/bracketrightbigg
provides a measure of the cumulative difference between r(Xi;F0)and its IC mean
1/2. In cases when F0is unknown, but we have a reference sample (Y1,Y2,..., YM),
the above measure can be estimated by its empirical version
Sn(F0M)=n
∑
i=1/bracketleftbigg
r(Xi;F0M)−1
2/bracketrightbigg
,
where r(Xi;F0M)isthe empirical version of r(Xi;F0), deﬁned in (9.17). Liu (1995)
showed that (i) Sn(F0)converged in distribution to N(0,n/12) when nincreased,
and (ii) Sn(F0M)converged in distribution to N(0,n2[(1/M)+(1/n)]/12) when
min(M,n)increased. Therefore, we can use the charting statistic
S∗
n(F0M)=Sn(F0M)
n/radicalbig
[(1/M)+(1/n)]/12, (9.19)
and the chart gives a signal of process distributional shift if
S∗
n(F0M)<−Z1−α, (9.20)
where Z1−αis the(1−α)-th quantile of the standard normal distribution, and α∈
(0,1)is a given false alarm rate. This chart was called the S chart in Liu (1995).RANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 373
Example 9.2 Assume that there are p =2quality characteristic variables involved
in a production process. For phase II process monitoring, a reference sample of size
M=100is obtained beforehand, and the two components of these observations are
shown in Figure 9.4(a)–(b), respectively, by the dark diamond points before the ver-
tical dotted line at n =0. Then, the ﬁrst 20 phase II observations of the production
process are obtained whose two components are shown in Figure 9.4(a)–(b), respec-
tively, by the dark dot points after the vertical dotted line at n =0. The r chart (9.18)
and the S chart (9.19)–(9.20) are then applied to this data. In both charts, αis cho-
sen to be 0.05, and the empirical Mahalanobis depth deﬁned in (9.13) is used. The
two charts are shown in Figure 9.4(c)–(d), respectively. From the plots, it can be seen
that the r chart gives the ﬁrst signal at n =14, and the S chart gives its ﬁrst signal at
n=18.
Both the rchart (9.18) and the Schart (9.19)–(9.20) are for cases with individual
observation data (i.e., there is only one observation vector at each time point). In
cases when the observed data are batch data, Liu (1995) suggested a so-called Q
chart described below. Let Y∼F0andX∼F1be two p-dimensional random vectors,
where F0andF1are two p-dimensional distributions. Deﬁne
Q(F 0,F1) = P(DM(Y;F0)≤DM(X;F0))
=E[r(X;F0)], (9.21)
where the probability P(·) in the ﬁrst equation is under the joint distribution of
(Y,X), and the expectation E (·)in the second equation is with respect to the dis-
tribution F1ofX. From the second equation of (9.21), it can be seen that Q(F 0,F1)
provides a measure about the difference between F0andF1. If they are the same,
then Q(F 0,F1)=1/2, because r(X;F0)∼Uni f orm(0, 1)in such cases, as mentioned
earlier. If Q(F 0,F1)is too small, then it is an indication that on average Xis far away
from the center of F0. Now, for phase II SPC, assume that (Y1,Y2,..., YM)is a ref-
erence sample obtained from a production process when it is IC, F0is the IC process
distribution, and at the n-th time point during phase II SPC, we have the following
batch data with batch size of m:
Xn1,Xn2,..., Xnm, forn≥1.
Then,
Q(F 0,F1m,n)=1
mm
∑
i=1r(Xni;F0)
measures the difference between F0and the empirical distribution F1m,nof the ob-
served data at the n-th time point. In cases when F0is unknown, Q(F 0,F1m,n)can be
estimated by
Q(F 0M,F1m,n)=1
mm
∑
i=1r(Xni;F0M), (9.22)
where F0Misthe empirical distribution of the reference sample. Liu and Singh (1993)
showed that (i) [Q(F 0,F1m,n)−1/2] converged in distribution to N(0,1/(12m)) asm
increased, and (ii) [Q(F 0M,F1m,n)−1/2] converged in distribution to N(0,(1/M+374 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
−100 −60 −40 −20 0 20−4 −2 0 2 4
nXn1
(a)−100 −60 −40 −20 0 20−4 −2 0 2 4
nXn2
(b)
0 5 10 15 200.0 0.2 0.4 0.6 0.8 1.0
nr□Xn;F0M□
(c)0 5 10 15 20−2 −1 0 1
nSn*□F0M□
(d)
Figure 9.4 (a) First component of a reference sample of size M =100(dark diamond points
before the vertical dotted line) and a phase II dataset (dark dot points after the vertical dotted
line). (b) Second component of the reference sample and the phase II dataset. (c) r chart
(9.18). (d) S chart (9.19)–(9.20). In both charts, αis chosen to be 0.05, and the empirical
Mahalanobis depth deﬁned in (9.13) is used.
1/m)/12) as min(M ,m)increased. Based on these results and the corresponding
results in cases when mis small, the Qchart by Liu (1995) gives a signal of process
distributional shift when
Q(F 0M,F1m,n)</braceleftbigg
0.5−Z1−α/radicalbig
(1/M+1/m)/12, when m≥5
(n!α)1/n/n, when m<5.(9.23)
Example 9.3 Assume that there are p =2quality characteristic variables involved
in a production process. For phase II process monitoring, a reference sample of sizeRANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 375
M=100is obtained beforehand, and the two components of these observations are
shown in Figure 9.5(a)–(b), respectively, by the dark diamond points before the ver-
tical dotted line at n =0. Then, the ﬁrst 20 batches of phase II observations of the
production process with batch size of m =10are obtained whose two components
are shown in Figure 9.5(a)–(b), respectively, by the dark dot points after the vertical
dotted line at n =0. The Q chart (9.23) is then applied to this data, in which αis
chosen to be 0.05, and the empirical Mahalanobis depth deﬁned in (9.13) is used.
The chart is shown in Figure 9.5(c). From the plot, it can be seen that the Q chart
gives its ﬁrst signal at n =11.
−20 −10 0 10 200 5 10
nXn1
(a)−20 −10 0 10 200 5 10
nXn2
(b)
0 5 10 15 200.0 0.2 0.4 0.6 0.8 1.0
nQ□F0M,F1m,n□
(c)
Figure 9.5 (a) First component of a reference sample of size M =100(dark diamond points
before the vertical dotted line) and a phase II dataset (dark dot points after the vertical dotted
line). (b) Second component of the reference sample and the phase II dataset. (c) Q chart
(9.23), in which αis chosen to be 0.05, and the empirical Mahalanobis depth deﬁned in (9.13)
is used.376 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
9.2.2 Contr ol charts based on cross-component ranking
The multivariate nonparametric control charts described in the previous subsection
are all based on the longitudinal ranking or ordering information of observations
at different time points, although the deﬁnitions of longitudinal ranking or ordering
might be different in different control charts. For multivariate SPC, another strategy
is to use the ranking or ordering information across different components of observa-
tions at individual time points, and try to detect any change in such cross-component
ranking patterns. Qiu and Hawkins (2001, 2003) proposed multivariate nonparamet-
ric SPC charts based on this strategy for detecting process mean shifts in phase II
SPC, which are described in this subsection.
Assume that Xn=(X n1,Xn2,..., Xnp)′is an observation of a p-dimensional qual-
ity characteristics vector Xat the n-th time point during phase II SPC. Without loss
of generality, we further assume that the IC mean vector µ0is0. In practice, µ0
needs to be estimated from an IC dataset, and then it should be subtracted from all
phase II observations in order for us to use the control charts described below. Let
µ=(µ1,µ2,..., µp)′be the process mean vector at a given time point. Then, the null
hypothesis involved in the multivariate SPC problem is
H0:µ1=µ2=···=µp=0. (9.24)
Apparently, H0in (9.24) is equivalent to the combination of the following two hy-
potheses:
H(1)
0:µ1=µ2=···=µp (9.25)
and
H(2)
0:p
∑
j=1µj=0. (9.26)
The hypothesis H(1)
0is related to the order of magnitudes of {µj,j=1,2,..., p}.
When H(1)
0is true, H(2)
0is related to the magnitudes of {µj,j=1,2,···,p}. In cases
when µhas a ﬁxed non-zero Euclidean length, violation of H0implies violation of
either H(1)
0orH(2)
0or both. Furthermore, if µdoes not satisfy H0, then the closer
it is to H(1)
0(it is therefore more difﬁcult to detect by a control chart designed for
detecting violation of H(1)
0), the farther it is from H(2)
0and consequently it is easier
to detect by a control chart designed for detecting violation of H(2)
0, and vice versa.
Hence, a combination of two CUSUM procedures designed for detecting violation
ofH(1)
0andH(2)
0, respectively, will be able to detect all kinds of shifts in the mean
vector of the process.
Process mean shifts that violate H(2)
0can be detected by a univariate control chart
based on ∑p
j=1Xn j. Next, we introduce a multivariate CUSUM chart for detecting
process mean shifts that violate H(1)
0. As mentioned above, hypothesis H(1)
0deﬁned
in (9.25) is related to the order of magnitudes of {µj,j=1,2,···,p}. It is therefore
natural to expect that some rank-based procedures can detect mean shifts that violateRANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 377
H(1)
0. Let
An=(An1,An2,..., Anp)′
be the antirank vector of Xn. That is, Anis a permutation of (1,2,..., p)′such that
XnAn1≤XnAn2≤...≤XnAnpare the order statistics of {Xn j,j=1,2,..., p}.
Let us ﬁrst consider An1. For 1≤j≤p, deﬁne
ξn1,j=/braceleftbigg
1, ifAn1=j
0, otherwise,(9.27)
andξn1=(ξn1,1,ξn1,2,..., ξn1,p)′. That is, ξn1,jis deﬁned as an indicator of the event
that the j-th component takes the smallest value among pobservation components
at the time point n. Under H(1)
0, assume that E(ξn1,j) =g1,j, for j=1,2,..., p.
Then, the probability distribution of An1isg1= (g 1,1,g1,2,..., g1,p)′. After a shift
in the process mean vector µ, the corresponding distribution of An1is denoted by
g∗
1= (g∗
1,1,g∗
1,2,..., g∗
1,p)′. Qiu and Hawkins (2001) showed that, under some regu-
larity conditions, a process mean shift that violated H(1)
0would result in a shift in the
distribution of An1(i.e., g1andg∗
1were different). Therefore, testing H(1)
0is equiva-
lent to testing
H(1)∗
0: the distribution of An1is{g1,j,j=1,2,..., p}. (9.28)
The hypothesis testing problem (9.28) is similar to the testing problem dis-
cussed in Subsection 8.3.1 about the distribution of the categorized data (cf., (8.32),
(8.33), and the related discussion). Qiu and Hawkins (2001) proposed a multivariate
CUSUM procedure, similar to (8.34)–(8.35), for detecting shifts that violated H(1)∗
0.
LetUobs
0=Uexp
0=0be two p×1 vectors, and


Uobs
n=0, ifBn≤k1
Uexp
n=0,
Uobs
n=/parenleftbig
Uobs
n−1+ξn1/parenrightbig
(1−k1/Bn),ifBn>k1
Uexp
n=/parenleftbig
Uexp
n−1+g1/parenrightbig
(1−k1/Bn),
where
Bn=/braceleftig/parenleftig
Uobs
n−1−Uexp
n−1/parenrightig
+(ξn1−g1)/bracerightig′/parenleftbig
diag(Uexp
n−1+g1)/parenrightbig−1
/braceleftig/parenleftig
Uobs
n−1−Uexp
n−1/parenrightig
+(ξn1−g1)/bracerightig
,
k1≥0 is the allowance constant, diag(a) denotes a diagonal matrix with its diagonal
elements equal to the corresponding elements of the vector a, and the superscripts
“obs” and “exp” denote observed and expected counts, respectively. Deﬁne
Cn1=/parenleftig
Uobs
n−Uexp
n/parenrightig′
(diag(Uexp
n))−1/parenleftig
Uobs
n−Uexp
n/parenrightig
. (9.29)
Then, a shift violating H(1)∗
0is signaled if
Cn1>h1, (9.30)378 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
where h1>0 isa control limit chosen to achieve a given ARL 0level. Chart (9.29)–
(9.30) is called multivariate antirank CUSUM (MA-CUSUM) chart hereafter. Re-
garding the allowance constant k1, Qiu and Hawkins (2001) showed that it should be
chosen in the interval /bracketleftbigg
0,pmax
ℓ=1∑j/negationslash=ℓg1,j
g1,ℓ/parenrightbigg
.
Ifk1is chosen outside this interval, then the MA-CUSUM chart will be restarted at
each time point and consequently the given ARL 0level can not be achieved.
It is apparent that both the IC and OC properties of the MA-CUSUM chart
(9.29)–(9.30) are determined uniquely by the distribution of An1for ﬁxed k1and
h1. The null distribution g1ofAn1could be determined from an IC data by comput-
ing the relative frequencies of (An1=j), for j=1,2,..., p. If the joint distribution
of the original observation Xis known under H0, then g1could also be computed
algebraically or numerically from this distribution. As long as g1is determined, the
IC property of the chart could be obtained by simulating a series of i.i.d. multinomial
random variables {An1,n≥1}. Therefore, the MA-CUSUM chart (9.29)–(9.30) does
not require a parametric form of the distribution of X, and it is indeed nonparametric.
When all or p−1 components of Xare continuous, the chance of ties among
thepcomponents is negligible for all practical purposes. Therefore An1is well de-
ﬁned. When two or more components are discrete and these discrete components
can take the same values, however, ties among the pcomponents are possible. For
instance, assume that p=3 and an observation takes the value of (−1,−1,0)′at the
time point n. Then Xn1andXn2are tied, and the value of An1is not well deﬁned. To
overcome this difﬁculty, there are several existing proposals in the literature (e.g.,
Gibbons and Chakraborti, 2003). One such proposal is to randomly assign 1 or 2
toAn1with a probability 0.5 for each number. Unfortunately, results from such a
random mechanism are not reproducible. Qiu and Hawkins (2001) suggested modi-
fying the deﬁnition of ξn1,jin (9.27) as follows, to overcome the difﬁculty caused by
ties. Suppose that Xn j1,Xn j2,..., Xn jkform a tie and their values reach the minimum
among all pcomponents at the time point n. Then, we deﬁne
ξn1,j=/braceleftbigg
1/k,ifj∈{j1,j2,..., jk}
0, otherwise.
By using this deﬁnition, no information about the antiranks is lost and the results are
reproducible.
The MA-CUSUM chart (9.29)–(9.30) is based on one component of the anti-
rank vector. It is possible to construct a similar CUSUM chart based on several
components of the antirank vector. Let (An j1,An j2,..., An jq)′be any qcomponents
of the antirank vector with j1<j2<···<jq. Assume that the distribution of
(An j1,An j2,..., An jq)′when H(1)
0is true has been determined in the sample space:
S(j1,j2,..., jq)
={(i1,i2,..., iq):i1,i2,..., iqareqdifferent integers in (1,2,..., p)}.
The sample space S(j1,j2,..., jq)hasPq,p=p(p−1)···(p−q+1)elements. Sim-
ilar to (9.27), we can deﬁne a Pq,p-dimensional random vector ξn j1j2...jqwith its j-thRANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 379
component equal to 1 when (An j1,An j2,..., An jq)′takes the value of the j-th element
inS(j1,j2,..., jq)and 0 otherwise. Then, a multivariate CUSUM chart could be con-
structed similarly to (9.29)–(9.30) with ξn1replaced by ξn j1j2...jqandpbyPq,p.
As mentioned above, the MA-CUSUM chart (9.29)–(9.30) can detect shifts in
all directions except the one in which the components of the mean vector are all the
same but not zero. For many applications, this chart is adequate since this situation
is unlikely. If we do care about this situation, however, it can be detected easily by a
univariate CUSUM based on
SXn=∑p
j=1Xn j
∑p
j1=1∑p
j2=1σj1,j2,
where σj1,j2is the(j1,j2)-th element of ΣX. Deﬁne C+
0=C−
0=0, and
/braceleftbiggC+
n=max(0, C+
n−1+SXn−k2)
C−
n=min(0, C−
n−1+SXn+k2),(9.31)
where k2>0 is an allowance constant. Then, this univariate CUSUM chart signals a
shift when
C+
n>h2 or C−
n<−h2, (9.32)
where h2>0 is a control limit. Obviously, this CUSUM chart is the two-sided version
of the conventional CUSUM chart discussed in Subsection 4.2.1 (cf., (4.7)–(4.10)).
Then, a joint CUSUM scheme for detecting all kinds of shift in the process mean
vector can be obtained by combining (9.29)–(9.30) and (9.31)–(9.32), which signals
a shift whenever (9.30) or (9.32) holds.
One question that may occur is why we use the antirank rather than the more
familiar rank of each component within an observation vector. If we were interested
in a univariate control chart for a particular component of X, then the rank of that
component within the vector might indeed be a relevant summand. However, this
problem is not common in multivariate SPC. Instead, we are faced with the detection
of shifts in some unknown component (or perhaps components). For this problem,
the ﬁrst antirank is particularly effective in detecting a downward shift in a single
arbitrary and unknown component since this component will start to ﬁgure promi-
nently in the ﬁrst antirank. Similarly, the last antirank is attractive for detecting an
upward shift in the mean of one of the components. If we do not know the direction
of a shift, then the chart based on both the ﬁrst and the last antirank will be effective
(cf., the numerical results in Example 9.5 below). As a comparison, ranks do not
have these properties.
Example 9.4 We illustrate the MA-CUSUM chart with a dataset from an aluminum
smelter. The dataset contains 5 variables: the content of SiO 2,Fe2O3,MgO, CaO,
and Al 2O3(labeled as X 1,X2,X3,X4, and X 5below) in the charge. All these measures
are relevant to the operation of the smelter. Stability of the alumina level and calcium
oxide level is desirable. The silica, ferric oxide, and magnesium oxide levels are
affected by the raw materials and are potential covariates to be taken into account in
a fully-ﬂedged multivariate scheme. The ﬁve variables are substantially correlated –380 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
both cr oss-correlated with each other, and autocorrelated. The dataset contains 189
vectors. We use the ﬁrst half (95 vectors) as an IC dataset to calibrate the related
control charts and the second half to test. A calibration sample of this size is smaller
than one would like to fully determine the IC distribution, but sufﬁces to illustrate the
use of the method in a real-world setting.
Looking ﬁrst at the autocorrelation, we model each variable by the following k-th
order autoregression model using the Rfunctionar.yw(): for j =1,2,3,4,5,
Xj(n)−µj=α1(Xj(n−1)−µj)+···+αk(Xj(n−k)−µj)+εj(n), (9.33)
where X j(n)denotes the j-th variable at the n-th time point, µjis its mean, and
{εj(n), n≥1}is an i.i.d. sequence of random noise with mean zero and variance
σ2
εj. The default Akaike’s Information Criterion (AIC) is used to determine the value
of k. The results are summarized in Table 9.1.
Table 9.1 Results from the autoregression modeling of the ﬁve variables in the aluminum
smelter example.
variable µ kα1,..., αk
X1 0.63 3 0.07,0.12,0.28
X2 24.81 2 0.30,0.24
X3 12.97 1 0.55
X4 4.14 1 0.54
X5 57.86 1 0.32
The results in Table 9.1 are then used to pre-whiten the original data into residual
vectors ( εj(n)in (9.33)) with cross-component correlation, but with their autocorre-
lations removed. The correlation matrix of the ﬁve residual vectors is

1.0000 0.2287 −0.1056 −0.0277 −0.3062
0.2287 1.0000 −0.5702 −0.0632 0.0676
−0.1056 −0.5702 1.0000 −0.3362 0.2205
−0.0277 −0.0632 −0.3362 1.0000 −0.2826
−0.3062 0.0676 0.2205 −0.2826 1.0000
.
Apparently the residuals are substantially cross-correlated (e.g., between the second
and third components). For simplicity of presentation, the ﬁve components of the
residual vectors are still denoted as X 1,X2,X3,X4, and X 5.
Figures 9.6 and 9.7 show the time series plots and density plots of the residu-
als. As Figure 9.7 makes abundantly clear, the individual residual components are
not normally distributed (e.g., the density of X 1has a long right tail), and so the
residual vector cannot be multivariate normal. It is therefore inadvisable to apply
conventional multivariate control charts under the normality assumption, such as
those described in Chapter 7, to these data. We use the IC dataset (i.e., the ﬁrst half
of the residual vectors) to estimate the IC distribution of the antirank vector, and then
apply the MA-CUSUM charts to the test dataset.
Visually, Figure 9.6 does not suggest step changes in the residuals over the course
of the dataset, so it is interesting to see what multivariate methods can indicate. Fig-
ure 9.8(a)–(b) show the MA-CUSUM charts of the ﬁrst antirank, and of the ﬁrst-
and-last combined antiranks of the residual vectors along with their control limits.
In both cases, k 1is ﬁxed at 1 and h 1is computed to be 11.85 and 34.89, respectively,RANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 381
0 50 100 150−3 −2 −1 0 1 2 3
nX1
0 50 100 150−3 −2 −1 0 1 2 3
nX2
0 50 100 150−3 −2 −1 0 1 2 3
nX3
0 50 100 150−3 −2 −1 0 1 2 3
nX4
0 50 100 150−3 −2 −1 0 1 2 3
nX5
Figure 9.6: Aluminum smelter data after autocorrelation in each component is excluded.382 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
−3 −2 −1 0 1 2 30.0 0.4 0.8 1.2
X1density
−3 −2 −1 0 1 2 30.0 0.2 0.4 0.6
X2density
−3 −2 −1 0 1 2 30.0 0.2 0.4 0.6
X3density
−3 −2 −1 0 1 2 30.0 0.2 0.4 0.6 0.8 1.0
X4density
−3 −2 −1 0 1 2 30.0 0.2 0.4 0.6 0.8
X5density
Figure 9.7 Density plots of the ﬁve components of the aluminum smelter data after autocorre-
lation in each component is excluded.RANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 383
such that the ARL 0value is 200. The ﬁrst MA-CUSUM chart gives a signal of pro-
cess distributional shift brieﬂy around the time 153. The second MA-CUSUM chart,
however, gives a signal almost immediately into the test dataset, and the charting
statistic remains well above the control limit for most part of the test dataset. This
result therefore shows a marked change, which seems to have occurred at or near the
midpoint of the data set.
100 120 140 160 1800 5 10 15
nCn1
(a)100 120 140 160 18020 40 60 80 100 120
nCn15
(b)
Figure 9.8 (a) MA-C USUM chart (denoted as C n1) based on the ﬁrst antirank. (b) MA-
CUSUM chart (denoted as C n15) based on both the ﬁrst and the last antiranks. The horizontal
dashed lines in both plots indicate the control limits of the charts such that their ARL 0values
are both 200.
Example 9.5 The MA-CUSUM chart (9.29)–(9.30) is based on the ﬁrst antirank of
the quality characteristic vector X. As mentioned above, the ﬁrst and last antiranks
are more sensitive to process distributional shifts, compared to the remaining an-
tiranks. Consequently, CUSUM charts based on them should be more effective for
detecting the shifts, which is demonstrated in this example. Suppose p =4and the
IC joint distribution of Xis N 4(0,I4×4). In all charts considered in this example,
their ARL 0values are ﬁxed at 200, and their allowance constants k 1are chosen to
be 1. In Table 9.2, AR1 denotes the MA-CUSUM chart based on the ﬁrst antirank,
AR12 denotes the MA-CUSUM chart based on the ﬁrst and second antiranks, and
the other notations initiated with “AR” are similarly deﬁned. The control limit values
are 6.842 and 15.6887 for AR1–AR4 and AR12–AR34, respectively. Because the four
components of Xare “exchangeable” (i.e., their joint distribution remains the same
when their positions are switched) when the process is IC, the IC distributions of A n j,
for j=1,2,3,4, and(An j1,An j2), for j 1,j2=1,2,3,4and j 1/ne}ationslash=j2, are all uniform
(e.g., the IC distributions of A n1is(g1,1=1/4, g1,2=1/4, g1,3=1/4, g1,4=1/4)).
Assume that there is process mean shift at the initial time point and the shifted pro-
cess mean is µ1= (µ11,µ12,µ13,µ14)′. The numbers in Table 9.2 are the OC ARL
values and their standard errors of various control charts for detecting several shifts,
computed based on 10,000 replicated simulations. Without loss of generality, in this
example, all mean components after the shift are assumed to be non-positive and
each mean vector has at least one component equal to 0. (For a general mean vector,384 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
it can be transformed to the mean vector satisfying these conditions by subtracting
its maximum component from each component of the vector and this transformation
will not affect any property of the antirank vector.)
We ﬁrst check the performance of AR1–AR4 which are based on a single antirank
component. The ﬁrst shift considered is µ′
1=(− 4,0,0,0). In this case, there is only
one component with a mean shift, and the probability for this component to reach
the minimum of the four components is large; consequently, AR1 performs the best.
In the second case, shifts occur in two mean components, with one shift larger in
magnitude than the other one; still AR1 performs the best. In the third situation, two
components have the same shifts; both AR1 and AR4 perform slightly better than the
other two. Each of the last four cases has shifts in three mean components. It can
be seen that at least one of AR1 and AR4 is better than the other two procedures.
This example shows that AR1 and AR4 are indeed more sensitive to a shift than AR2
and AR3 in general. But, we still need to choose between AR1 and AR4. This can be
decided by the following rough guideline: use AR1 if the number of components of
µ1with the smallest or close to the smallest magnitudes is expected to be less than
the number of components of µ1with the largest or close to the largest magnitudes,
and vice versa.
Next, we check the performance of AR12, AR13, ..., AR34, all of which are based
on two antirank components. Overall, the OC ARL values of these procedures are
smaller than those of AR1–AR4 because they use more antirank information for shift
detection. In cases when AR1 performs well (e.g., when µ′
1=(− 4,0,0,0)), the charts
with the ﬁrst antirank involved, namely AR12, AR13, and AR14, also perform reason-
ably well. This phenomenon is also true for AR4. Therefore, we can expect that AR14
works reasonably well in all cases, which is conﬁrmed by this example. We can also
expect that MA-CUSUM charts based on more than two antirank components will
be even more sensitive to shifts. But the charts themselves will become more com-
plicated, especially in cases when p is large. Therefore, we recommend using more
antirank components in cases when p is small, and to use fewer antirank components
otherwise. In most cases, the chart based on the ﬁrst and last antirank components
is highly recommended.
Next, we present some numerical results for testing both H(1)
0in (9.25) and H(2)
0in (9.26), by combining the MA-CUSUM chart (9.29)–(9.30) with the univariate
CUSUM chart (9.31)–(9.32). As mentioned before, these two charts are designed
for two different shift detection purposes, and thus they do not need to be used to-
gether in practice. Here, we just want to show that they can support each other in
the sense that when one chart has difﬁculty in detecting a shift, the other one can
detect the same shift well. In Table 9.3, the IC process distribution is still assumed
to be N 4(0,I4). At the initial time point, the process mean vector shifts to µ1, which
takes six possible vectors with unit Euclidean length. The ﬁrst three mean vectors are
ordered by the decreasing Euclidean distance from µ1to(−0.5,−0.5,−0.5,−0.5)
and by the decreasing numbers of 0 components. The last three vectors are similarly
ordered except that the mean components of each vector have the same absolute mag-
nitude of 0.5. In the CUSUM charts, both k 1and k 2are ﬁxed at 1. The control limits
h1and h 2are searched with a step of 0.0001 such that the ARL 0value is 200, and the
OC ARL values reach the minimum (denoted as h 1,minand h 2,min, respectively, in the
table). The minimum OC ARL values and the standard errors of the joint monitoring
scheme, computed based on 10,000 replications, are listed in the column labeled by
CUSUM 12. The corresponding OC ARL values and their standard errors of the two
individual procedures with (k1=1,h1=h1,min)and(k2=1,h2=h2,min)are pre-RANK-BASED MULTIV ARIATE NONPARAMETRIC CONTROL CHARTS 385
Table 9.2 Comparison of the MA-CUSUM charts based on different antiranks of the p com-
ponents of X, where p =4andXhas the IC joint distribution N 4(0,I4). The ARL 0value of
each chart is ﬁxed at 200 and k 1=1. “AR1” denotes the MA-CUSUM chart based on the ﬁrst
antirank, “AR12” denotes the MA-CUSUM chart based on the ﬁrst and the second antiranks,
and the other notations initiated with “AR” are similarly deﬁned. The numbers in this table
are the OC ARL values and their standard errors (in parentheses) based on 10,000 replicated
simulations.
(µ11,µ12,µ13,µ14)′
(−4,0,0,0) (−4,− 2,0,0) (−4,−4,0,0) (−4,−4,− 2,0)
AR1 4.06 (0.00) 4.97 (0.02) 17.48 (0.11) 20.13 (0.15)
AR2 79.40 (0.77) 7.54 (0.04) 18.44 (0.13) 32.52 (0.30)
AR3 76.73 (0.75) 32.92 (0.30) 18.59 (0.13) 7.55 (0.05)
AR4 78.01 (0.76) 20.52 (0.16) 17.72 (0.12) 4.98 (0.02)
AR12 4.09 (0.02) 2.92 (0.01) 3.03 (0.01) 3.87 (0.02)
AR13 4.12 (0.02) 4.29 (0.02) 5.58 (0.03) 4.70 (0.03)
AR14 4.11 (0.02) 3.67 (0.02) 5.45 (0.03) 3.65 (0.02)
AR23 11.51 (0.09) 4.71 (0.03) 5.58 (0.03) 4.70 (0.03)
AR24 11.49 (0.09) 4.70 (0.03) 5.57 (0.03) 4.27 (0.02)
AR34 11.14 (0.09) 3.90 (0.02) 3.04 (0.01) 2.90 (0.01)
(µ11,µ12,µ13,µ14)′
(−4,−2,−2,0) (−4,− 3,−1,0) (−4,− 4,−4,0)
AR1 5.82 (0.03) 8.54 (0.05) 79.60 (0.79)
AR2 35.17 (0.33) 12.14 (0.09) 78.71 (0.77)
AR3 35.38 (0.33) 12.19 (0.09) 79.34 (0.78)
AR4 5.86 (0.03) 8.65 (0.05) 4.06 (0.00)
AR12 4.12 (0.02) 3.26 (0.02) 11.06 (0.08)
AR13 4.85 (0.03) 4.83 (0.03) 11.41 (0.09)
AR14 3.22 (0.02) 4.01 (0.02) 4.07 (0.02)
AR23 5.36 (0.03) 4.95 (0.03) 11.43 (0.09)
AR24 4.85 (0.03) 4.83 (0.03) 4.11 (0.02)
AR34 4.10 (0.02) 3.28 (0.02) 4.07 (0.02)
sented in the columns labeled by CUSUM 1and C USUM 2, respectively. The values
of(g∗
1,1,g∗
1,2,g∗
1,3,g∗
1,4), Q=∑p
j=1(g∗
1,j−g1,j)2/g1,j, and ∑4
j=1µ1jare given in Table
9.4 for reference. It can be seen from the tables that (i) at least one of the two charts
performs reasonably well for a shift with a ﬁxed Euclidean length, and (ii) the joint
monitoring scheme signals each shift reasonably fast.
From the above description, the MA-CUSUM chart (9.29)–(9.30) can de-
tect all process mean shifts except the ones with equal components (i.e., µ1=
(µ11,µ12,..., µ1p)′with µ11=µ12=···=µ1p). Such shifts are called equal-
component shifts hereafter. Qiu and Hawkins (2003) proposed a simple but effective
modiﬁcation to overcome this limitation, described below.
The main reason the MA-CUSUM chart (9.29)–(9.30) cannot detect equal-
component shifts is that such shifts would not change the distribution of the anti-
ranks because they would not change the order of the components of X. In order to
detect all possible shifts by a control chart based on the antirank vector alone, the386 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
Table 9.3 Thenumbers in the column labeled by CUSUM 12denote the minimum OC ARL
values and their standard errors (in parentheses) of the joint monitoring scheme (9.29)–(9.30)
and (9.31)–(9.32), computed based on 10,000 replicated simulations. h 1,minand h 2,minare the
corresponding control limits in the case when k 1and k 2are ﬁxed at 1, and the ARL 0values
are ﬁxed at 200. The corresponding OC ARL values and their standard errors (in parentheses)
of the two individual charts with (k1=1,h1=h1,min)and(k2=1,h2=h2,min)are presented
in the columns labeled by CUSUM 1and CUSUM 2, respectively.
(µ11,µ12,µ13,µ14) h1,min h2,min CUSUM 1 CUSUM 2CUSUM 12
(−1,0,0,0) 6.99 3.70 25.00 (0.23) 254.65 (2.46) 23.78 (0.21)
(−1√
2,−1√
2,0,0) 10.13 2.21 399.39 (3.94) 25.94 (0.23) 24.51 (0.22)
(−1√
3,−1√
3,−1√
3,0) 12.55 2.19 3297.65 (27.10) 16.28 (0.14) 16.18 (0.13)
(−0. 5,−0.5,0.5,0.5) 6.85 4.77 46.72 (0.46) 4742.12 (56.72) 46.72 (0.46)
(−0. 5,−0.5,−0. 5,0.5) 11.25 2.20 1262.59 (12.73) 49.45 (0.46) 48.00 (0.44)
(−0. 5,−0.5,−0. 5,−0. 5)12.70 2.19 4314.73 (37.31) 11.49 (0.09) 11.49 (0.09)
Table 9.4 The OC distribution of A 1(i), Q=∑4
j=1(g∗
1,j−g1,j)2/g1,j, and ∑4
j=1µ1jfor several
shifts considered in Table 9.3.
(µ11,µ12,µ13,µ14)(g∗
1,1,g∗
1,2,g∗
1,3,g∗
1,4) Q ∑4
j=1µ1j
(−1,0,0,0) (0.55,0.15,0.15,0.15) 0.48 −1
(−1√
2,−1√
2,0,0) (0.37,0.36,0.14,0.13) 0.22 −√
2
(−1√
3,−1√
3,−1√
3,0) (0.29,0.29,0.29,0.13) 0.08 −√
3
(−0.5,− 0.5,0.5,0.5) (0.41,0.40,0.09,0.10) 0.38 0
(−0.5,− 0.5,−0.5,0.5) (0.31,0.31,0.31,0.07) 0.18 −1
(−0.5,− 0.5,−0.5,−0.5) (0.25,0.25,0.25,0.25) 0 −2
deﬁnition of the antirank vector needs to be modiﬁed. The modiﬁed antirank vec-
tor should be sensitive to shifts that violate either H(1)
0orH(2)
0or both. Based on
this observation, we deﬁne /tildewideAn=(/tildewideAn,1,/tildewideAn,2,...,/tildewideAn,p,/tildewideAn,p+1)′as the antirank vector
ofYn= (X n1,Xn2,..., Xnp,0)′, a combination of the observation vector Xnand the
common IC mean of 0. Therefore, /tildewideAnis a permutation of (1,2,···,p,p+1)′such
thatYn,/tildewideAn,1≤Yn,/tildewideAn,2≤···≤ Yn,/tildewideAn,p+1are the order statistics of the components of Yn.
Clearly, the antirank vector /tildewideAncontains the order information of {µ1,µ2,..., µp,0}.
It is sensitive to the ordering of {µj,j=1,2,···,p}and to the ordering between
{µj,j=1,2,···,p}and 0 as well. Therefore, a CUSUM chart based on this anti-
rank vector has the potential to detect all possible shifts. The modiﬁed MA-CUSUM
(MMA-CUSUM) chart can then be constructed in exactly the same way as the chart
(9.29)–(9.30), except that all quantities related to the antirank vector Anshould be
replaced by the corresponding quantities of the modiﬁed antirank vector /tildewideAn.
Example 9.6 Assume that p =4and the IC joint distribution of Xis N(0,I4). In such
a case, the IC distribution of /tildewideAn,1is Multinomial (1,0.2344, 0.2344, 0.2344, 0.2344,
0.0624) (cf., Subsection 2.4.2 for its deﬁnition). We compare the MMA-CUSUM
chart based on /tildewideAn,1with the MA-CUSUM chart based on A n1in this example.MULTIV ARIATE NONPARAMETRIC SPC BY LOG-LINEAR MODELING 387
The ARL 0values of both charts are ﬁxed at 200. The allowance constant k 1in
both charts is chosen to be 0.5. In such cases, the control limits are computed to
be 12.488 and 8.029 for the MMA-CUSUM and MA-CUSUM charts, respectively.
Remember that the MMA-CUSUM chart depends only on the distribution of the
ﬁrst modiﬁed antirank /tildewideAn,1. So, its control limit can be searched by a simulation
in which the CUSUM is constructed from a series of i.i.d. random vectors with
the Multinomial (1,0.2344, 0.2344, 0.2344, 0.2344, 0.0624) distribution. It should be
much faster to search the control limit value in this way, compared to the way to
search its value based on the CUSUM constructed from the original observations.
We ﬁrst study the scenario with equal-component shifts, assuming that the mean
vector has shifted to (a,a,a,a)′, with a taking the values of 0, 0.2, 0.4, 0.6, 0.8, and 1.
Figure 9.9(a) shows the ARL’s given by 10,000 simulations. The MA-CUSUM chart,
as expected, has no ability whatsoever to detect such shifts. The MMA-CUSUM chart,
however, is quite effective in cases when a is above 0.4. This is because the mean shift
substantially increases the probability that the four components of the data are all
positive in such cases. Next, we consider an intermediate scenario where the mean
vector shifts to (a,1,1,1)′(the case when a =1reduces to the equal-component shift
scenario). The corresponding results in this scenario are shown in Figure 9.9(b). The
MA-CUSUM chart is ineffective when a is close to 1, as expected, but it performs
quite well when a is near zero. This is because the situation when a =0is essentially
the same, with respect to the MA-CUSUM chart, as a downward shift in µ1and all
other mean components remaining unchanged. The MMA-CUSUM chart, however,
has a fairly consistent and much better performance for all a values. Figure 9.9(c)
shows a situation in which the ﬁrst component of the mean vector shifts, but in an
upward direction, while Figure 9.9(d) shows the situation for which the MA-CUSUM
chart is designed, a downward shift in just the ﬁrst component of the mean vector.
In the ﬁrst case, the MMA-CUSUM chart retains a small superiority. In the second
case, it is inferior to the MA-CUSUM chart, though the difference is substantial only
when the shift size is relatively small.
From the above example, we can have the following conclusions:
(a)The MMA-CUSUM chart can detect equal-component shifts,
(b)When the shifts are off but close to the equal-component direction, the MMA-
CUSUM chart often outperforms the MA-CUSUM chart, especially in cases when
the shifts are far away from the origin, and
(c)In cases when only a small number of mean components have shifts, the bene-
ﬁt to use the MMA-CUSUM chart is small. Only in special circumstances does
the MMA-CUSUM chart give substantially worse performance than the MA-
CUSUM chart.
9.3 Multivariate Nonparametric SPC by Log-Linear Modeling
As mentioned in Section 9.1, in cases when a p-dimensional random vector Xdoes
not follow a multivariate normal distribution, existing statistical tools for describing
its distribution are limited. A major difﬁculty in this task is in describing the possible
association among the components of X. In cases when all the components of Xare
categorical, in the statistical literature there are some well-developed methods for
describing the association among the components of X(cf., Agresti, 2002). A major388 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
aOut−of−control ARL
0 0.2 0.4 0.6 0.8 1.00 50 100 150 200
(a)aOut−of−control ARL
0 0.2 0.4 0.6 0.8 1.00 50 100 150 200
(b)
aOut−of−control ARL
0 0.5 1.0 1.5 2.0 2.5 3.00 50 100 150 200
(c)aOut−of−control ARL
−3.0 −2.5 −2.0 −1.5 −1.0 −0.5 00 50 100 150 200
(d)
Figure 9.9 The OC ARL values of the MMA-CUSUM (solid lines) and MA-CUSUM charts
(dashed lines). The ARL 0values of the two charts are ﬁxed at 200. The allowance constant k 1
and the control limit h 1are 0.5 and 12.488 in the MMA-CUSUM chart, and 0.5 and 8.029 in
the MA-CUSUM chart. (a) µ1= (a, a,a,a)′and a varies among 0, 0.2, 0.4, 0.6, 0.8, and 1;
(b)µ1=(a, 1,1,1)′and a varies among 0, 0.2, 0.4, 0.6, 0.8, and 1; (c) µ1=(a, 0,0,0)′and a
varies among 0, 0.5, 1.0, 1.5, 2.0, 2.5, and 3; (d) µ1=(a, 0,0,0)′and a varies among −3.0,
−2.5,−2.0,−1.5,−1.0,−0.5, and 0.
tool is the so-called log-linear modeling. This fact opens a door for solving the mul-
tivariate nonparametric SPC problem. Qiu (2008) developed a general framework
for constructing multivariate nonparametric SPC charts, by ﬁrst categorizing the ob-
served multivariate data and then applying the log-linear modeling approach to the
categorized data. This method is described in this section in two parts. In SubsectionMULTIV ARIATE NONPARAMETRIC SPC BY LOG-LINEAR MODELING 389
9.3.1, the log-linear modeling approach is described in detail. Then, in Subsection
9.3.2, the multivariate nonparametric SPC chart by Qiu (2008) is discussed.
9.3.1 Analyzing categorical data by log-linear modeling
Assume that Y1andY2are two categorical variables, Y1hasslevels (or categories),
denoted as c1,c2,..., cs, and Y2hastlevels, denoted as d1,d2,..., dt. Then, obser-
vations of the 2-dimensional vector (Y1,Y2)could look like (c2,d1),(c1,d3), and so
forth. Assume that a dataset of (Y1,Y2)contains nobservations. Then, this dataset
can be summarized by Table 9.5 below.
Table 9.5: An s×t 2-way contingency table.
d1 d2··· dt
c1n11 n12··· n1tn1+
c2n21 n22··· n2tn2+
..................
csns1 ns2··· nstns+
n+1n+2··· n+tn++
In Table 9.5, the column on the left lists all the levels of Y1, the row on the top
lists all the levels of Y2, the(j1,j2)-th entry nj1j2denotes the count of observations
taking the value (Y1=cj1,Y2=dj2), the j1-th element of the column on the right,
nj1+=∑t
j2=1nj1j2, is the j1-th row total, the j2-th element of the row at the bottom,
n+j2=∑s
j1=1nj1j2, is the j2-th column total, and n++at the lower-right corner is
the grand total (i.e., n++=∑s
j1=1nj1+=∑t
j2=1n+j2=n), where j1=1,2,..., sand
j2=1,2,..., t. In this table, the two categorical variables Y1andY2classify all obser-
vations into s×tentries. So, they are also called classiﬁers. Since this table has two
classiﬁers involved, it is called a s×t 2-way contingency table. A general p-way con-
tingency table, with p>2, can be deﬁned in a similar way. Because a contingency
table provides a neat summary of the original data, it is easy to make, and it contains
all useful information in the original categorical data, it is a popular descriptive tool
in categorical data analysis.
Forj1=1,2,..., sandj2=1,2,..., t, let
πj1j2=P/parenleftbig
Y1=cj1,Y2=dj2/parenrightbig
,
πj1+=P/parenleftbig
Y1=cj1/parenrightbig
,
π+j2=P/parenleftbig
Y2=dj2/parenrightbig
.
Then,{πj1j2,j1=1,2,..., s,j2=1,2,..., t}deﬁnes the joint distribution of (Y1,Y2),
{πj1+,j1=1,2,..., s}is the marginal distribution of Y1, and{π+j2,j2=1,2,..., t}
is the marginal distribution of Y2. Deﬁne µj1j2=E(n j1j2)=nπj1j2to be the expected
count of the (j1,j2)-th entry, for j1=1,2,..., sand j2=1,2,..., t. Then, in cases
when Y1andY2are independent, we have πj1j2=πj1+π+j2, for all j1and j2, and
consequently,
µj1j2=nπj1+π+j2.390 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
After taking log-transformation on both sides of the above expression, and denoting
log(n), log( πj1+)and log( π+j2)byµ,λY1
j1andλY2
j2, respectively, we have
log(µj1j2)=µ+λY1
j1+λY2
j2, forj1=1,2,..., s,j2=1,2,..., t, (9.34)
where µis a constant term, {λY1
j1}and{λY2
j2}are parameters satisfying the conditions
that
s
∑
j1=1λY1
j1=0,t
∑
j2=1λY2
j2=0.
In model (9.34), the term λY1
j1reﬂects the impact of Y1onµj1j2, and the term λY2
j1reﬂects the impact of Y2onµj1j2. They are often called the main effect terms of Y1
andY2, respectively (cf., Weisberg, 2005, Section 6.3). In this model, the two main
effect terms are assumed additive, reﬂecting the model assumption that Y1andY2are
independent. This model is thus called the log-linear model of independence.
In cases when Y1andY2are associated, we can consider the following saturated
log-linear model: for j1=1,2,..., sandj2=1,2,..., t,
log(µj1j2)=µ+λY1
j1+λY2
j2+λY1Y2
j1j2, (9.35)
where{λY1Y2
j1j2}are parameters accounting for the interactive effect of Y1andY2on
µj1j2. Therefore, the term λY1Y2
j1j2is called the 2-way interaction term. Because the
main effect term λY1
j1hass−1 non-redundant parameters, and the other main effect
term λY2
j2hast−1 non-redundant parameters, by the analysis of variance or the linear
regression theory (cf., Agresti, 2002; Weisberg, 2005), the interaction term allows a
maximum of (s−1)(t−1)parameters. To this end, besides the constraints on the
two main effect terms described above, we often put the following constraint on the
interaction term:
s
∑
j1=1λY1Y2
j1j2=0, for each j2,
t
∑
j2=1λY1Y2
j1j2=0, for each j1.
Under all these constraints, the model (9.35) has
1+(s−1)+( t−1)+(s−1)(t−1)= st
non-redundant parameters, which is the same as the number of observed counts
(or, the number of cells) in the contingency table. That is the reason this model is
called the saturated model because it already contains the maximal number of non-
redundant parameters.
The log-linear models described above can be generalized to cases with p>2 cat-
egorical variables. For instance, when p=3 and the three categorical variables Y1,Y2,MULTIV ARIATE NONPARAMETRIC SPC BY LOG-LINEAR MODELING 391
andY3haves1,s2,ands3categories, respectively, the saturated log-linear model can
be deﬁned as follows. For j1=1,2,..., s1,j2=1,2,..., s2, and j3=1,2,..., s3,
log(µj1j2j3)=µ+λY1
j1+λY2
j2+λY3
j3+λY1Y2
j1j2+λY1Y3
j1j3+λY2Y3
j2j3+λY1Y2Y3
j1j2j3, (9.36)
where µis a constant term, λY1
j1,λY2
j2, and λY3
j3are the main effects of Y1,Y2, and Y3,
respectively, λY1Y2
j1j2,λY1Y3
j1j3, and λY2Y3
j2j3are the 2-way interaction terms, and λY1Y2Y3
j1j2j3is
the 3-way interaction term. To make all parameters estimable, they should be subject
to certain constraints. One set of such constraints is as follows:
∑j1λY1
j1=∑j2λY2
j2=∑j3λY3
j3=0;
∑j1λY1Y2
j1j2=∑j2λY1Y2
j1j2=0;∑j1λY1Y3
j1j3=∑j3λY1Y3
j1j3=0;∑j2λY2Y3
j2j3=∑j3λY2Y3
j2j3=0;
∑j1λY1Y2Y3
j1j2j3=∑j2λY1Y2Y3
j1j2j3=∑j3λY1Y2Y3
j1j2j3=0,
where ∑j1λY1Y2
j1j2=0 means ∑s1
j1=1λY1Y2
j1j2=0, for all j2, and the other summations are
deﬁned similarly.
Model (9.36) can be denoted by (Y1Y2Y3), which lists the highest-order term in the
model for each variable. If the 3-way interaction term λY1Y2Y3
j1j2j3is not in the model, then
it can be checked that the conditional association between any two variables of Y1,Y2,
andY3is the same at all levels of the remaining variable (cf. Agresti, 2002, Chapter
8). In other words, the association between any two variables is homogeneous across
the different levels of the third variable. This model is called the homogeneous asso-
ciation model, and is denoted by (Y1Y2,Y1Y3,Y2Y3). Similarly, we use (Y1Y2,Y1Y3)to
denote the model with the two 2-way interaction terms λY1Y2
j1j2andλY1Y3
j1j3included, and
with the other 2-way interaction term λY2Y3
j2j3and the 3-way interaction term λY1Y2Y3
j1j2j3excluded. That model implies that Y2andY3are independent conditional on Y1, the
association between Y1andY2is homogeneous across the different levels of Y3, and
the association between Y1andY3is also homogeneous across the different levels of
Y2. So, model (9.36) and its variants can describe all kinds of possible associations
among Y1,Y2, and Y3, by including appropriate 2-way and 3-way interaction terms.
To estimate a log-linear model, we usually need to specify a probability model for
the related contingency table (e.g., the observed count of the (j1,j2,j3)-th entry of a
3-way table has the Poisson( µj1j2j3)distribution). Then, the model can be estimated
by the maximum likelihood estimation method (cf., Subsection 2.7.2). However, the
likelihood function of the table is often quite complicated, and a numerical algorithm,
such as the Newton-Raphson algorithm, is needed. In the software package R, a log-
linear model can be estimated easily using the function glm().
There are some standard procedures for model selection and model goodness-
of-ﬁt testing. For instance, if M1denotes the saturated model (Y1Y2Y3),M0denotes
the homogeneous association model (Y1Y2,Y1Y3,Y2Y3), and we want to know whether
M0is more appropriate to use (or, equivalently, whether the 3-way interaction term
inM1can be removed from the model). For this purpose, we can use the following
likelihood ratio test statistic:
G2(M0|M1)=−2log/parenleftbiggℓM0
ℓM1/parenrightbigg
,392 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
whereℓM0andℓM1denote the likelihood functions of M0andM1, respectively. The-
ory on categorical data analysis shows that G2(M0|M1)has the asymptotic distribu-
tion of χ2
(s1−1)(s2−1)(s3−1)(cf. Agresti, 2002, Chapter 8). So, its observed value can be
compared to the (1−α)-th quantile of the χ2
(s1−1)(s2−1)(s3−1)distribution for making
decisions, where αis a given signiﬁcance level. Note that this test is based on the
asymptotic distribution of G2(M0|M1). So, we should use it with caution when the
sample size is small, although it has been shown in the literature that it is still quite
reliable with fairly sparse tables (cf., Haberman, 1977). There are several different
ways to do model selection using the above model comparison approach, including
the backward, forward, and stepwise procedures. By the backward model selection,
in the above example with p=3, we ﬁrst consider removing the 3-way interaction
term from the saturated model, as described above. If the likelihood ratio test us-
ingG2(M0|M1)suggests that the 3-way interaction term cannot be removed, then
stop. Otherwise, consider removing a 2-way interaction term. This process contin-
ues until no terms can be removed. In each step of the backward model selection,
only one term is considered to be removed and we always consider removing the
highest-order term in the current model. If there are several highest-order terms in
the current model, then the one with the least signiﬁcant (or the smallest) G2(M0|M1)
value is considered to be removed. After a ﬁnal model is determined, its goodness-
of-ﬁt can be tested using the Pearson’s chi-square test or the likelihood ratio G2test,
as discussed in Subsection 2.8.2.
9.3.2 Nonparametric SPC by log-linear modeling
In this subsection, we introduce the general framework for constructing multivariate
nonparametric control charts using the log-linear modeling approach that was ﬁrst
proposed by Qiu (2008). At the end of phase I analysis of a production process,
assume that all bugs are ﬁxed and we are left with an IC dataset
{Xi=(X i1,Xi2,..., Xip)′,i=1,2,..., M},
where Mis a ﬁxed sample size. This sequence of observations is assumed to be
i.i.d. with a common cdf F0(x), which is also the IC process distribution. Let the IC
median of Xi jbe/tildewideµj, for j=1,2,..., p, which can be estimated from the IC data. We
then deﬁne
Yi j=I(Xi j>/tildewideµj), forj=1,2,..., p, (9.37)
andYi= (Yi1,Yi2,..., Yip)′, where I(a)is an indicator function that equals 1 if ais
“true” and 0 otherwise. So equation (9.37) transforms the poriginal quality charac-
teristic variables to pbinary variables. Note that, in equation (9.37), the IC median
/tildewideµjcan be replaced by the more general r-th quantile of the IC distribution of Xi j,
with rbeing any real number in (0,1). We consider using the median, which is the
0.5th quantile, because the resulting joint distribution of Yicould be more efﬁciently
estimated by the log-linear modeling approach discussed in the previous subsection,
due to the fact that relatively fewer cell counts of the contingency table formed by
the components of Yiwould be small in such a case and consequently the model
selection and the model goodness-of-ﬁt test would be more reliable.MULTIV ARIATE NONPARAMETRIC SPC BY LOG-LINEAR MODELING 393
Of course, we lose information by transforming XitoYi. But it is not difﬁcult to
check that the distribution of Yiwould be changed by any shift in the median vector
/tildewideµ=(/tildewideµ1,/tildewideµ2,...,/tildewideµp)′of the process, as long as the IC process distribution F0(x)has
a positive probability to take values in any neighborhood of its IC median vector.
Therefore, if we are interested in detecting shifts in a location parameter vector (e.g.,
the median vector /tildewideµ), then Yiis appropriate to use. If we are also interested in de-
tecting other changes from F0(x)(e.g., changes in the covariance matrix of F0(x)),
then Yineeds to be modiﬁed. In the latter case, one possible approach is to transform
each component of Xito a categorical variable with more than two categories, as was
done in univariate cases discussed in Section 8.3.
For the categorized data Yi, for i=1,2,..., M, we can choose a log-linear model
using a model selection procedure described in the previous subsection for analyzing
the related 2 ×2×···× 2p-way contingency table. After the ﬁnal model is deter-
mined, the expected cell count µj1j2···jpof the(j1,j2,..., jp)-th entry can be com-
puted from the estimated log-linear model, for j1,j2,..., jp=1,2, and the IC joint
distribution of Y1,Y2,..., Ypcan be estimated by
/braceleftig
f(0)
j1j2···jp=µj1j2···jp/n, j1,j2,..., jp=1,2/bracerightig
.
It should be noticed that if the ﬁnal model is the saturated model (e.g. (9.36)),
then µj1j2···jp=Oj1j2···jp, for all j1,j2···jp, where Oj1j2···jpdenotes the observed
count of the (j1,j2,..., jp)-th entry. In such a case, µj1j2···jp/nis just the ordinary
relative frequency of the (j1,j2,..., jp)-th entry. When the components of Yhave
some association structure, the selected log-linear model (e.g., the homogeneous as-
sociation model) would be simpler than the saturated model to reﬂect this structure.
In such cases, the variability of µj1j2···jp/ncomputed from the selected log-linear
model would be smaller than the variability of the corresponding relative frequency
Oj1j2···jp/n, because the selected log-linear model has fewer parameters than the
saturated model. In other words, µj1j2···jp/nis “smoother” than Oj1j2···jp/n. In that
sense, the log-linear modeling is a smoothing process, and the degree of smooth-
ing depends on the association structure of the components of Y. Since both the
log-linear estimator µj1j2···jp/nand the relative frequency estimator Oj1j2···jp/nare
unbiased in cases when the selected model holds, the log-linear estimator
/braceleftig
f(0)
j1j2···jp=µj1j2···jp/n, j1,j2,..., jp=1,2/bracerightig
would provide a better estimator for the joint distribution of Yin such cases.
Now, let us discuss phase II SPC and assume that we are interested in monitoring
the process median vector /tildewideµ. Let Xnbe the original phase II observation vector of the
process at the n-th time point, and Yn=(Yn1,Yn2,..., Ynp)′be its categorized version
deﬁned by (9.37). For j1,j2,..., jp=1,2, deﬁne
gn j1j2···jp=I(Yn1=j1−1,Yn2=j2−1,..., Ynp(i)= jp−1),
andgnis a vector of all gn j1j2···jpvalues. Then, gnis a vector of observed counts
at time point n, and{f(0)
j1j2···jp,j1,j2,..., jp=1,2}are the expected counts. Let f(0)394 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
be the vector of all f(0)
j1j2···jp. Then, a CUSUM chart can be constructed similarly to
the chart (8.34)–(8.35) in univariate cases, as follows. Let Uobs
0=Uexp
0=0be two
2p-dimensional vectors, and


Uobs
n=0, ifBn≤k
Uexp
n=0,
Uobs
n=/parenleftbig
Uobs
n−1+gn/parenrightbig
(1−k/Bn), ifBn>k
Uexp
n=/parenleftig
Uexp
n−1+f(0)/parenrightig
(1−k/Bn),
where
Bn=/braceleftig/parenleftig
Uobs
n−1−Uexp
n−1/parenrightig
+/parenleftig
gn−f(0)/parenrightig/bracerightig′/parenleftig
diag(Uexp
n−1+f(0))/parenrightig−1
/braceleftig/parenleftig
Uobs
n−1−Uexp
n−1/parenrightig
+/parenleftig
gn−f(0)/parenrightig/bracerightig
,
k≥0 is the allowance constant, diag(a) denotes a diagonal matrix with its diagonal
elements equal to the corresponding elements of the vector a, and the superscripts
“obs” and “exp” denote observed and expected counts, respectively. Deﬁne
Cn=/parenleftig
Uobs
n−Uexp
n/parenrightig′
(diag(Uexp
n))−1/parenleftig
Uobs
n−Uexp
n/parenrightig
. (9.38)
Then, a median shift in Xnis signaled if
Cn>h, (9.39)
where h>0 is a control limit chosen to achieve a given IC ARL level. Chart (9.38)–
(9.39) is called the multivariate log-linear CUSUM (MLL-CUSUM) chart hereafter,
to reﬂect the fact that it is based on the log-linear model.
For a given value of ARL 0and a given k, the value of hof the MLL-CUSUM
chart can be searched in a range [0,Uh]by the algorithm described in the box below,
where Uhis an upper bound satisfying the condition that the actual ARL 0value of the
chart is larger than the given ARL 0value when h=Uh.MULTIV ARIATE NONPARAMETRIC SPC BY LOG-LINEAR MODELING 395
Iterative Algorithm for Selecting h
Step 1 Inthei-th iteration, his searched in the range [L(i)
h,U(i)
h]. When i=1,
L(1)
h=0 and U(1)
h=Uh.
Step 2 A series of random vectors from the multinomial distribution with proba-
bility parameters {f(0)
j1,j2,...,jp,j1,j2,..., jp=1,2}are generated by a random num-
ber generator.
Step 3 This series of random vectors are used in place of g(n) in (9.38) and
the run length distribution is obtained by running the chart (9.38)–(9.39) with
h=h(i):= (L(i)
h+U(i)
h)/2 a number of times (e.g., 10,000 times). The IC ARL
value ARL(i)
0is then computed by averaging all the run lengths obtained.
Step 4 If|ARL(i)
0−ARL 0|<ε1, where ε1>0 is a pre-speciﬁed threshold value
andARL 0is a given ARL 0value, then the algorithm stops, and the searched value
ofhish(i). Otherwise, deﬁne
L(i+1)
h=h(i)andU(i+1)
h=U(i)
h,ifARL(i)
0<ARL 0;
L(i+1)
h=L(i)
handU(i+1)
h=h(i),ifARL(i)
0>ARL 0;
andh(i+1)=(L(i+1)
h+U(i+1)
h)/2.
Step 5 If|h(i+1)−h(i)|<ε2, where ε2>0 is another pre-speciﬁed threshold value,
then the algorithm stops, and the searched value of hish(i). In such a case, a
message should be printed, to remind the user of the actual IC ARL value. If
|h(i+1)−h(i)|≥ε2, then the algorithm executes the next iteration.
Based on our experience, the above algorithm usually stops at Step 4. But, occa-
sionally it can happen that it stops at Step 5, especially when ε1is chosen relatively
small and ε2is chosen relatively large. In such cases, users are reminded by the al-
gorithm that the assumed IC ARL value is not reached within the speciﬁed range
by the chart (9.38)–(9.39) using the searched value of h; its actual IC ARL value is
also printed. We have several options if this situation happens. The ﬁrst option is to
decrease the value of ε2and run the iterative algorithm again. But, it can happen that
the given ARL 0value cannot be reached in any accuracy, no matter how small ε2is,
because of the discreteness of the charting statistic, as discussed in Chapter 8 (cf.,
Tables 8.1 and 8.5). Then, the second option is to use the actual ARL 0value of the
chart as a new given ARL 0value. If the new given ARL 0value is difﬁcult to inter-
pret and the original given ARL 0value is preferred, then the third option is to adopt
the modiﬁcation procedure discussed in Subsection 8.3.1 about the P-CUSUM chart
(8.34)–(8.35) (cf., the third paragraph below expression (8.35)).396 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
The allo wance constant kshould be chosen in the interval

0, max
j1,j2,...,jp=1,21−f(0)
j1,j2,...,jp
f(0)
j1,j2,...,jp
.
Otherwise, the MLL-CUSUM chart (9.38)–(9.39) will restart at each time point
when the process is IC. Consequently, the speciﬁed IC ARL property can never be
achieved. If we have a target shift in the mean or median vector of the process dis-
tribution, then for a given ARL 0value, the optimal value of kcan be searched for in
a range[0,Uk]by an iterative algorithm described in the box below, where Ukis an
upper bound.
Iterative Algorithm for Selecting k
Step 1 Inthei-th iteration, kis searched for in the range [L(i)
k,U(i)
k]. When i=1,
L(1)
k=0 and U(1)
k=Uk. Divide[L(i)
k,U(i)
k]into mequally spaced subintervals,
where mis pre-speciﬁed (e.g., m=10). Then kis searched for among all the end
points{k(i)
j=L(i)
k+(U(i)
k−L(i)
k)∗j/m, j=0,1,..., m}of these subintervals.
Step 2 When k=k(i)
j, for any j=0,1,..., m, search for the corresponding h
value by the previous iterative algorithm, such that the actual ARL 0value equals
the given ARL 0value.
Step 3 For the target shift, compute the OC distribution of Yn, denoted by
{f(1)
j1,j2,...,jp,j1,j2,..., jp=1,2}, by the log-linear modeling procedure discussed
in Subsection 9.3.1 and by using the IC data after adjusting for the location shift.
Step 4 Generate a series of random vectors from the multinomial distribution with
probability parameters {f(1)
j1,j2,...,jp,j1,j2,..., jp=1,2}, and use this series of ran-
dom vectors in place of g(n) when computing Cnin (9.38).
Step 5 For each j, compute the OC ARL value, denoted as ARL(i)
1,j, by run-
ning the chart (9.38)–(9.39) with k=k(i)
ja number of times. The minimizer of
{ARL(i)
1,j,j=0,1,..., m}is denoted as J(i).
Step 6 If(U(i)
k−L(i)
k)/m<ε3, where ε3>0 is a pre-speciﬁed threshold value,
then the algorithm stops, and the searched value of kisk(i)
J(i). Otherwise, let
L(i+1)
k=max(0, k(i)
J(i)−1)andU(i+1)
k=min(k(i)
J(i)+1,Uk), and the algorithm executes
the next iteration.
In the above two algorithms, the upper bound Ukcan be simply chosen as
max j1,j2,...,jp=1,2(1−f(0)
j1,j2,...,jp)/f(0)
j1,j2,...,jpif that number is well deﬁned and not too
big. Selection of the upper bound Uhshould not be difﬁcult. For a given ARL 0value
and a given k, we could try a large number (e.g., 50 or 100) for Uh, and then run
the chart (9.38)–(9.39) to make sure that its actual ARL 0value when h=Uhis larger
than the given ARL 0value. Since both algorithms converge reasonably fast, accurateMULTIV ARIATE NONPARAMETRIC SPC BY LOG-LINEAR MODELING 397
selection of UkandUhisnot essential to their convergence speed, which makes the
selection of UkandUhmuch easier. That is, the two upper bounds can be chosen
relatively large, without sacriﬁcing much convergence speed of the two algorithms.
The values of ε1,ε2, and ε3are related to the accuracy requirements for the solutions.
For example, if we require that the actual ARL 0value equals the given ARL 0value
up to the third digit after the decimal point, then we can choose ε1=0.5×10−3.
Example 9.7 In the aluminum smelter example discussed in Example 9.4, let us con-
sider the three quality characteristic variables SiO 2,MgO, and Al 2O3for multivari-
ate SPC. Again, the autocorrelation within each variable is excluded beforehand,
using the autoregression model (9.33), and the resulting residuals are shown in the
three plots in the ﬁrst column of Figure 9.6. For simplicity of presentation, the residu-
als of the three variables are denoted as ε1,ε2,andε3. Both the Pearson’s chi-square
test and the Kolmogorov-Smirnov test (cf., Subsection 2.8.2) conclude that ε1and
ε3in this dataset are not normally distributed (Pearson’s chi-square test: p-value
equals 0 for both ε1andε3. Kolmogorov-Smirnov test: p-value equals 0 for ε1, and
it equals 0.022 for ε3). So the joint distribution of X= (ε1,ε2,ε3)′can not be nor-
mal because a joint normal distribution implies that all marginal distributions are
normal.
We then use the ﬁrst 95 residual vectors as an IC dataset and the remaining for
testing. From the IC dataset, the selected log-linear model is (Y1,Y2Y3), the estimated
IC distribution {f(0)
j1,j2,j3,j1,j2,j3=1,2}ofYby this selected model is calculated
to be (0.1053,0.1474,0.1158,0.1368,0.1895, 0.0632,0.0947,0.1474), where Yis the
categorized version of X. By the ﬁrst iterative algorithm described above, the control
limit value h is searched and found to be 10.793, for k =0.1and ARL 0=200. Then,
the MLL-CUSUM chart (9.38)–(9.39) is used for detecting shifts in the test data, and
the chart is shown in Figure 9.10. It can be seen that there is convincing evidence for
a shift occurring right at the beginning of the test data, which is consistent with the
results shown in Figure 9.8(b).
Example 9.8 In this example, we compare the numerical performance of the MLL-
CUSUM chart (9.38)–(9.39) with certain competing control charts in cases when
p=3and the IC distribution of X= (X 1,X2,X3)′is the normalized version with
mean 0and covariance matrix I 3×3of the distribution speciﬁed below
X1,X2,X3are i.i.d. with the common distribution χ2
1.
When using the chart (9.38)–(9.39), the IC distribution of Yis not assumed known.
Instead, it is estimated from an IC dataset. To this end, we randomly generate 100
such IC datasets, each of which has sample size of 100. Then, from each IC dataset,
the estimated IC distribution of Yis computed, using the log-linear modeling ap-
proach, and the control limit value h is searched for by the iterative algorithm dis-
cussed above, when k and ARL 0are ﬁxed at 1.0 and 200, respectively. In the search-
ing algorithm, we choose U h=30,ε1=.01, and ε2=10−5, and the search is based
on 10,000 replications. Then, the IC dataset and the corresponding control limit
value giving the median actual IC ARL value is used in all cases considered in this
example. Suppose that there is a shift of size (a,0,0)in the median vector of the
process distribution, the shift starts at the 100th phase II observation time, and a
changes its value between 0 and 0.4 with a step of 0.04. The speciﬁc starting time398 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
100 120 140 160 18010 20 30 40 50 60 70
nCn
Figure 9.10 MLL-CUSUM c hart (9.38)–(9.39) with k =0.1and ARL 0=200when it is applied
to the residuals of the quality characteristic variables SiO 2,MgO, and Al 2O3in the aluminum
smelter example. The horizontal dashed line denotes the control limit.
of the shift (i.e., the 100th time point) is used as an approximation to the “steady-
state” start, after which the distribution of the charting statistic C napproaches a
“steady-state distribution” that does not depend on n (cf., Subsection 4.2.2 for a re-
lated discussion). Then, the OC ARL values of the MLL-CUSUM chart are shown in
Figure 9.11(a) by the solid line.
As pointed out in Section 9.1, the conventional multivariate control charts based
on the normality assumption would be inappropriate to use in cases when the normal-
ity assumption is violated. To further demonstrate this, the MCUSUM chart (7.28)–
(7.29) is used here in two different ways. First, the chart is used in the conventional
way that the IC process distribution is assumed to be known N (0,I3×3). Second, the
chart is used under the assumption that the IC process distribution is N (µ,I3×3), but
µshould be estimated from an IC dataset of size 100. The two different versions of
the MCUSUM chart are denoted as MCUSUM1 and MCUSUM2, respectively. Their
computed OC ARL values are shown in Figure 9.11(a) by the dashed and dotted
lines. From Figure 9.11(a), it can be seen that among the three charts MLL-CUSUM,
MCUSUM1, and MCUSUM2, only the MLL-CUSUM chart has its actual ARL 0value
equal to the assumed ARL 0value of 200. The actual IC ARL values of the other two
charts are far from the assumed ARL 0value, which is consistent with the results
shown in Figures 9.1 and 9.2. Figure 9.11(a) also shows that the OC ARL values
of MLL-CUSUM are small, compared to charts MCUSUM1 and MCUSUM2, when
the shift is reasonably large. Considering the fact that the IC ARL of MLL-CUSUM
is much larger than the IC ARL values of MCUSUM1 and MCUSUM2, this is anMULTIV ARIATE NONPARAMETRIC SPC BY LOG-LINEAR MODELING 399
endorsement of the former chart. To further investigate this issue, let us consider the
larger shift (a,0.4,0.4), where a changes its value between 0 and 0.4 with a step
of 0.04. The corresponding OC ARL values of the three charts are shown in Figure
9.11(b). It can be seen that MLL-CUSUM is consistently better than MCUSUM1 and
MCUSUM2 in such cases.
The corresponding results of the MEWMA chart (7.39)–(7.40) in cases when a
single weighting parameter λis used are shown in Figure 9.11(c)–(d) by the dashed
and dotted curves when λ=0.05 andλ=0.2, respectively. In the plots, the two
different versions of the MEWMA chart are denoted as MEWMA1 and MEWMA2,
respectively. For convenience of comparison, the OC ARL values of MLL-CUSUM
are shown in these plots again by the solid curves. From the plots, it can be seen
that: (i) when λis smaller (i.e., λ=0.05), the MEWMA chart is more robust to
the normality assumption, as observed in Figure 9.2, because its actual ARL 0value
is closer to the assumed value 200, (ii) in such cases, its ability to detect possible
shifts is also weaker, compared to the MEWMA chart when λis larger, and (iii)
MLL-CUSUM performs better when the process is IC and when the process becomes
OC with a quite large shift (e.g., shifts (a,0,0)when a>0.34 in plot (c) and shifts
(a,0.4,0.4) for all a values in plot (d)).
Next, we compare MLL-CUSUM with the MA-CUSUM chart (9.29)–(9.30),
which does not require the normality assumption. We still consider the shift (a,0,0),
with a changing its value between 0 and 0.4 with a step of 0.04. Since this shift is
upward, the MA-CUSUM chart based on the third antirank is preferred here, among
all MA-CUSUM charts based on a single antirank. To use this chart, the IC distribu-
tion of the third antirank should be speciﬁed. To this end, there are two possibilities.
One is that the IC process distribution is assumed known, and the IC distribution
of the third antirank can be determined accordingly. In practice, the IC process dis-
tribution is often unknown. In such cases, the IC distribution of the third antirank
needs to be estimated from an IC dataset. In the ﬁrst scenario, the control limit value
h1of the chart is searched and found to be 4.300 such that its ARL 0value equals
200 when k =1. Results under this condition are labeled by MA-CUSUM1. If the
IC distribution is estimated from the same IC dataset used above in estimating the
IC distribution of Y, then the control limit value h 1is searched and found to be
4.430, to reach the ARL 0value 200 when k =1. Results in this case are labeled
by MA-CUSUM2. In these two cases, the OC ARL values of the MA-CUSUM chart
are shown in Figure 9.11(e) by the dashed and dotted curves, respectively. For con-
venience in comparison, the OC ARL values of MLL-CUSUM are also presented
in this plot by the solid curve. It can be seen that the actual ARL 0value of MA-
CUSUM2 is also quite different from the assumed ARL 0value. But the difference
is not so large, compared to charts MCUSUM1, MCUSUM2, and MEWMA2. The
chart MA-CUSUM1 is indeed appropriate to use here, since its actual ARL 0value
is about the same as the assumed ARL 0value. But, in most cases, the MLL-CUSUM
chart outperforms the MA-CUSUM1 chart, and the difference is quite large when the
shift gets large. The corresponding results when the shift is (a,0.4,0.4) are shown in
Figure 9.11(f), where a changes its value between 0 and 0.4 with a step of 0.04, as
before. This shift is closer to the “equal-component” direction discussed in Subsec-
tion 9.2.2, in which all components of the shift are the same, when a is closer to 0.4.
It is expected that performance of the MA-CUSUM chart would get worse when a is
closer to 0.4, because the OC distribution of the third antirank is closer to its IC dis-
tribution in such cases, which is demonstrated in Figure 9.11(f). From the plot, it can400 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
0.0 0.1 0.2 0.3 0.40 50 100 150 200
aOC ARLMLL−CUSUM
MCUSUM1
MCUSUM2
(a)0.0 0.1 0.2 0.3 0.40 50 100 150 200
aOC ARLMLL−CUSUM
MCUSUM1
MCUSUM2
(b)
0.0 0.1 0.2 0.3 0.40 50 100 150 200
aOC ARLMLL−CUSUM
MEWMA1
MEWMA2
(c)0.0 0.1 0.2 0.3 0.40 50 100 150 200
aOC ARLMLL−CUSUM
MEWMA1
MEWMA2
(d)
0.0 0.1 0.2 0.3 0.40 50 100 150 200
aOC ARLMLL−CUSUM
MA−CUSUM1
MA−CUSUM2
(e)0.0 0.1 0.2 0.3 0.40 50 100 150 200
aOC ARLMLL−CUSUM
MA−CUSUM1
MA−CUSUM2
(f)
Figure 9.11 (a) OC ARL values of charts MLL-CUSUM (solid curve), MCUSUM1 (dashed
curve), and MCUSUM2 (dotted curve). The shift is assumed to be (a,0,0)in the median vector
of the process distribution starting at the 100th time point. (b) Corresponding results of plot
(a) when the shift is (a,0.4,0.4). (c) OC ARL values of charts MLL-CUSUM (solid curve),
MEWMA1 (dashed curve), and MEWMA2 (dotted curve), when there is a shift (a,0,0)in the
median vector starting at the 100th time point. (d) Corresponding results of plot (c) when the
shift is(a,0.4,0.4). (e) OC ARL values of charts MLL-CUSUM (solid curve), MA-CUSUM1
(dashed curve), and MA-CUSUM2 (dotted curve), when there is a shift (a,0,0)in the median
vector starting at the 100th time point. (f) Corresponding results of plot (e) when the shift is
(a,0.4,0.4).SOME DISCUSSIONS 401
be seen that the MLL-CUSUM chart performs much better than both MA-CUSUM1
and MA-CUSUM2 in this case.
From Example 9.8, it can be seen that the MLL-CUSUM chart is competitive,
compared to its peers. However, it still has much room for improvement. For instance,
in (9.37), each component of the original observation vector Xis categorized into
two categories. We believe that it would be more effective in detecting shifts in the
process distribution, if each component is categorized into more than two categories,
although the log-linear modeling would become more complex in that case. Also,
the MLL-CUSUM chart can handle cases when all components of Xare categorical
or cases when some components of Xare categorical. In such cases, we only need to
categorize the numerical components before using the control chart.
9.4 Some Discussions
The multivariate nonparametric SPC problem is important because most SPC appli-
cations are multivariate, the multivariate process distributions are often non-normal,
and we do not know much about proper ways to describe the distribution of a multi-
variate non-normal dataset. In this chapter, some existing multivariate nonparametric
SPC charts have been described. They either use the ordering or ranking information
in the observed data, or categorize the observed data ﬁrst and then use the meth-
ods of categorical data analysis for process monitoring. The rank-based methods can
only handle numerical data. The methods based on categorization can handle both
numerical and categorical data.
The existing rank-based methods use either the longitudinal ranking information
among the observed data at consecutive observation times or the cross-component
ranking information among the different components of observation vectors. At least
three types of longitudinal ranking have been discussed in the literature: component-
wise longitudinal ranking, spatial longitudinal ranking, and longitudinal ranking by
data depth. The componentwise longitudinal ranking treats individual components
of the observation vectors separately when computing the longitudinal ranks, while
the spatial longitudinal ranking and the longitudinal ranking by data depth consider
all components jointly when computing the longitudinal ranks. So, the ﬁrst type of
longitudinal ranking depends only on the marginal distributions of individual compo-
nents of the quality characteristic vector Xwhile the second and third types depend
on the joint distribution of X.
The MNS chart (9.2)–(9.3) and the MNSR chart (9.6)–(9.7) are both based on
componentwise longitudinal ranking. Boone and Chakraborti (2012) have shown that
the formulas (9.4) and (9.8) that are based on asymptotic distributions usually pro-
vide conservative control limits for them. It requires much future research to provide
more appropriate control limits based on the ﬁnite-sample distributions of the related
charting statistics or based on an IC dataset. Furthermore, these two charts are She-
whart charts. They are good at detecting large shifts, and may not be effective in
detecting small and persistent shifts. As discussed in the paragraph containing (9.9),
it is not difﬁcult to modify these two charts to become multivariate nonparametric
CUSUM, EWMA, or CPD charts. But, the design of these more effective charts for402 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
detecting small and persistent shifts still requires much research effort. It seems that
spatial ranks deﬁned in (9.11) are more sensitive to potential process distributional
shifts, compared to the longitudinal ranking by data depth, because the former car-
ries information about both the magnitude and the direction of a potential shift while
the latter has information mainly about the magnitude. Theoretical and numerical
comparison of these two types of longitudinal ranking and their applications in the
multivariate nonparametric SPC problem, which is lacking in the current SPC litera-
ture, should be useful. Stoumbos and Jones (2000) studied the design and properties
of a control chart based on data depth, and found that the chart was reliable and
effective only in cases when a large reference sample was available.
The MA-CUSUM chart (9.29)–(9.30) is constructed based on the cross-
component ranking of individual observation vectors. One major beneﬁt of this type
of control chart is that it is relatively simple to compute the cross-component ranks,
compared to the computation of the longitudinal ranks, because the number of com-
ponents pis usually a ﬁxed small integer number (e.g., 5, or 15), but the number of
observation times could be very large. In (9.29)–(9.30), antiranks instead of regular
ranks are used because antiranks have the following “dimension reduction” property.
If we know that a potential location shift can only occur in a single but unknown
component of Xand the shift is downward, then it sufﬁces to use the ﬁrst antirank
for process monitoring. If such a shift is upward, then the last antirank is sufﬁcient
to use. As a comparison, all regular ranks should be used in such cases because we
do not know which components in Xhave shifts. With the MA-CUSUM chart, there
are still many questions to answer. For instance, in which cases should we use the
ﬁrst or last antirank? In which other cases should we use both the ﬁrst and the last
antiranks? Will the chart be more efﬁcient in certain cases if more than two antiranks
are used? Much future research is needed to provide practical guidelines that address
such questions.
The multivariate nonparametric SPC charts based on log-linear modeling are
promising because the log-linear modeling approach can describe the possible asso-
ciation among different components of the categorized data properly. In my opinion,
the essential difﬁculty with the multivariate nonparametric SPC problem is that we
do not know how to describe and estimate the possible association among different
components of the original observed data when they do not follow a normal distri-
bution. Although data categorization would result in information loss, the amount
of lost information can be reduced if more categories are used in data categoriza-
tion. With more categories, the related contingency table of the categorized observed
data would be large and the model selection and model estimation in the log-linear
modeling would become more complex. To handle this issue, the LASSO-based SPC
method described in Subsection 7.6.2 should be helpful.
9.5 Exercises
9.1 Figure 9.2 shows that the actual IC ARL values of the multivariate CUSUM
chart (7.28)–(7.29) and the multivariate EWMA chart (7.39)–(7.40) could be
substantially different from the assumed IC ARL value of 200 in cases whenEXERCISES 403
there are three quality characteristic variables involved in an SPC application,
the variables are independent of each other, and each has the standardized ver-
sion with mean 0 and variance 1 of the χ2
rdistribution where r=1,5,10,20, and
50. Make a similar plot in the same setup, except that each of the three quality
characteristic variables has the standardized version with mean 0 and variance 1
of the trdistribution where r=3,5,10,20, and 50.
9.2 Reproduce the results in Example 9.1.
9.3 Assume that the 20 observation vectors presented in Table 9.6 are obtained from
a 2-dimensional production process with the IC distribution N2(µ0,Σ), where
µ0=(0.5, 0.8)′and
Σ=/parenleftbigg
1.0 0.5
0.5 1.0/parenrightbigg
.
The ﬁrst 10 observation vectors are IC and the remaining 10 observation vectors
have a mean shift from µ0toµ1=(1.0, 1.0)′.
Table 9.6 This table presents the ﬁrst 20 observation vectors obtained from a 2-dimensional
production process.
i Xi1 Xi2 i Xi1 Xi2
1 0.110 0.320 11 0.575 0.666
2 0.662 0.866 12 2.540 0.783
3 0.331 0.832 13 1.158 1.296
4 1.638 1.198 14 1.614 1.725
5 0.663 0.840 15−0.050 0.640
6 0.761 1.091 16 0.509 0.731
7−0.198 0.491 17 0.468 0.285
8 1.374 1.163 18 1.409 0.991
9−0.672 0.542 19 0.530−0.535
10 1.343−0.667 20 1.699 0.729
(i) Compute the spatial signs (cf., (9.10)) of all 20 observation v ectors, and
present them in a plot.
(ii) Compute the spatial ranks (cf., (9.11)) of all 20 observation vectors, and
present them in a plot.
(iii) Based on the two plots made in parts (i) and (ii), do you think spatial signs
and spatial ranks can be used for detecting process mean shifts? Why?
9.4 For the ﬁrst 10 observation vectors in Table 9.6, compute their values of the
Mahalanobis depth and the empirical Mahalanobis depth. When computing the
empirical Mahalanobis depth, treat the ﬁrst 10 observation vectors in Table 9.6
as a sample of size M=10 from the IC process distribution N2(µ0,Σ).
9.5 For the data presented in Table 9.6, construct the rchart (9.18) and the S chart
(9.19)–(9.20), using α=0.01 and the ﬁrst 10 observation vectors in Table 9.6
as a sample of size M=10 from the IC process distribution N2(µ0,Σ). Compare
the performance of the two charts.404 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
9.6 Reproduce the results in Example 9.3.
9.7 The following 10 vectors are observations from a 5-dimensional production pro-
cess:
(−0.502,−0.582,−0.202,−0.914,−0.814),
(0.132, 0.715, 0.740, 2.310, −0.438),
(−0.079,−0.825, 0.123, −0.438,−0.720),
(0.887,−0.360,−0.029, 0.764, 0.231),
(0.117, 0.090, −0.389, 0.262, −1.158),
(0.319, 0.096, 0.511, 0.773, 0.247),
(−2.091,−0.690, 1.065, −1.777, 0.637),
(−0.243,−0.222, 0.970, 0.623, 2.319),
(−2.138, 0.183, −0.102,−0.522, 1.044),
(−2.111, 0.417, 1.403, 1.322, −0.879).
The ﬁrst six vectors are actually generated from a distribution with mean 0and
covariance matrix I5×5, and the remaining four vectors are generated from the
same distribution but with a different mean of (−2,0,0,0,1)′. Therefore, there
is a mean shift from µ0=0toµ1=(− 2,0,0,0,1)′at the 7th time point.
(i) Compute the ﬁve cross-component ranks for each observation vector.
(ii) Compute the ﬁve cross-component antiranks for each observation vector.
(iii) Comment on the useful information in the ﬁve ranks and the ﬁve antiranks
about the mean shift.
9.8 Apply the two MA-CUSUM charts based on the ﬁrst antirank and on the ﬁrst-
and-last antiranks to the data considered in the previous exercise for detecting
process mean shifts. In both charts, choose k1=1 and ARL 0=200. By Exam-
ple 9.4, the control limits of the two charts are 11.85 and 34.89, respectively.
Also, in this exercise, it is assumed that the ﬁve quality characteristic variables
are exchangeable when the process is IC in the sense that the IC process distri-
bution would not be changed if the positions of the ﬁve variables are switched.
Summarize your results.
9.9 The following 10 vectors are observations from a 5-dimensional production pro-
cess:
(0.020,−1.316,−0.259, 1.008, −1.378),
(−0.172,−0.340, 0.922, 0.451, −0.349),
(−1.510,−1.791, 0.816, −0.657,−0.757),
(−0.498,−0.213, 0.074, −1.818,−0.725),
(0.318, 1.189, −1.031,−0.728,−0.110),
(0.341, 0.661, −0.171,−1.852,−0.222),
(3.430,−0.603,−1.199, 2.895, 2.000),
(3.171, 1.541, 0.537, 2.235, −0.266),
(1.387, 0.506, 0.365, 1.563, 1.291),
(2.258, 1.466, 1.544, 0.230, −1.289).
The ﬁrst six vectors are actually generated from a distribution with mean 0and
covariance matrix I5×5, and the remaining four vectors are generated from theEXERCISES 405
same distrib ution but with a different mean of (1,1,1,1,1)′. Therefore, there is
an equal-component mean shift from µ0=0toµ1= (1, 1,1,1,1)′at the 7th
time point.
(i) Compute the ﬁrst antirank value An1for each observation vector.
(ii) Compute the modiﬁed ﬁrst antirank value /tildewideAn,1(cf., its deﬁnition in the para-
graph immediately before Example 9.6) for each observation vector.
(iii) Comment on the useful information in An1and/tildewideAn,1about the mean shift.
9.10 Assume that Y1,Y2, and Y3are the three categorical variables involved in a re-
search problem. They have s1,s2, and s3categories, respectively. Write out the
log-linear models with the following notations:
(Y1Y2,Y1Y3),(Y1Y2,Y3),(Y1,Y2,Y3).
Describe the association among the three variables in each model.
9.11 In the SPC problem considered in Exercise 9.9, assume that the IC process me-
dian vector is/tildewideµ=(0, 0,0,0,0)′. For the 10 observation vectors presented in that
exercise, compute their categorized observation vectors using (9.37).
9.12 Reproduce the results in Example 9.7.
9.13 Table 9.7 presents the ﬁrst 40 observation vectors obtained from a 2-dimensional
production process. Assume that the ﬁrst 30 observation vectors are IC, and the
IC process median vector is known to be /tildewideµ=(0, 0)′. Categorize these 30 obser-
vation vectors using (9.37), and estimate the IC distribution of the categorized
data using the log-linear modeling discussed in Subsection 9.3.1.
Table 9.7 This table presents the ﬁrst 40 observation vectors obtained from a 2-dimensional
production process.
i Xi1 Xi2 i Xi1 Xi2
1−0.502−0.091 21−0.438−0.447
2 0.132 1.757 22 0.764−1.739
3−0.079−0.138 23 0.262 0.179
4 0.887−0.111 24 0.773 1.897
5 0.117−0.690 25−0.814−2.272
6 0.319−0.222 26−0.438 0.980
7−0.582 0.183 27−0.720−1.399
8 0.715 0.417 28 0.231 1.825
9−0.825 1.065 29−1.158 1.381
10−0.360 0.970 30 0.247−0.839
11 0.090−0.102 31 0.738 1.449
12 0.096 1.403 32 0.931−0.064
13−0.202−1.777 33 0.621−0.162
14 0.740 0.623 34 3.582 2.649
15 0.123−0.522 35 1.130−1.062
16−0.029 1.322 36 0.287 1.013
17−0.389−0.363 37 1.638−0.088
18 0.511 1.319 38 1.202 1.271
19−0.914 0.044 39 0.930 2.008
20 2.310−1.879 40 0.908−1.074406 MULTIV ARIATE NONPARAMETRIC PROCESS CONTROL
9.14 F or the data presented in Table 9.7, design the MLL-CUSUM chart (9.38)–
(9.39), using k=1,ARL 0=200, and the estimated IC distribution of the cat-
egorized data obtained in the previous exercise. Apply the resulting chart to the
last 10 observation vectors in the table for detecting possible process mean shifts.
Summarize your results.Chapter 10
Proﬁle Monitoring
10.1 Introduction
In the SPC problems discussed in the previous chapters, the quality of a product is
characterized by one or more variables. Each sampled product has a single obser-
vation of the quality characteristic variable, and we monitor the related production
process using all available observations of the products sampled over time. In some
applications, however, the quality of a product is characterized by the functional rela-
tionship between a response variable and one or more explanatory variables. In these
applications, for each sampled product, one observes a set of data points of these
variables that can be represented by a curve/surface (or a proﬁle), and the major pur-
pose of SPC is to check the stability of this relationship over time based on observed
proﬁle data. This SPC problem is called proﬁle monitoring in the literature, which is
the main topic of this chapter.
The proﬁle monitoring problem has broad applications. For instance, Kang and
Albin (2000) discussed two examples of proﬁle monitoring. The ﬁrst example was
about an artiﬁcial sweetener, called aspartame. In this example, they were concerned
about the amount of aspartame that could be dissolved per liter of water at different
temperatures. In order to evaluate the quality of manufactured aspartame, for each
sampled product, we needed to collect observations of the amount of aspartame dis-
solved per liter of water at a given set of temperatures, which formed a proﬁle. The
second example was about the relationship between the measured pressure and the
level of gas ﬂow controlled by a mass ﬂow controller that was used for etching away
photoresist on chips manufactured by a semiconductor production process. Many
other interesting applications of proﬁle monitoring were discussed by papers includ-
ing Jin and Shi (1999), Qiu et al. (2010), Walker and Wright (2002), and Zhou and
Jin (2005).
Due to its broad applications, the proﬁle monitoring problem has received much
attention from statisticians recently. Early research on this topic assumes that the
mean proﬁle is linear when the process is IC, and various proﬁle monitoring charts
have been proposed for detecting possible shifts in certain parameters of the linear
IC proﬁle. See, for instance, Jensen et al. (2008), Kang and Albin (2000), Kim et al.
(2003), Mahmoud et al. (2007), Mahmoud and Woodall (2004), Stover and Brill
(1998), Wang and Tsung (2005), and Zou et al. (2006). Linear proﬁle monitoring
techniques have been generalized to various cases with parametric nonlinear proﬁles
by some authors, including Ding et al. (2006), Jensen and Birch (2009), Williams
407408 PROFILE MONITORING
et al. (2007a,b), and Zou et al. (2007a). In certain applications, it is difﬁcult to jus-
tify the legitimacy of a speciﬁc parametric model for describing the IC proﬁle data.
Therefore, some nonparametric proﬁle monitoring techniques have been proposed
in the literature (cf., Qiu and Zou, 2010; Qiu et al., 2010; Wei et al., 2012; Zou
et al., 2009b, 2008). In this chapter, we will describe some representative parametric
and nonparametric proﬁle monitoring techniques. For some related discussions, see
Noorossana et al. (2011), Woodall (2007), Woodall et al. (2004), and the references
cited therein.
10.2 Parametric Proﬁle Monitoring
In some applications, a parametric model is available to describe IC proﬁle data,
based on some scientiﬁc knowledge or our past experience about the related produc-
tion process. In such cases, parametric proﬁle monitoring techniques can be consid-
ered. In this section, we describe some parametric proﬁle monitoring charts in two
parts. Those based on linear regression modeling are described in Subsection 10.2.1,
and those based on nonlinear regression modeling are described in Subsection 10.2.2.
10.2.1 Linear proﬁle monitoring
In a proﬁle monitoring problem, assume that we are concerned about the relationship
between a response variable yand a predictor x. To monitor such a relationship, some
products need to be randomly selected over time from the manufactured products.
For the j-th selected product with j=1,2,..., it is assumed that nobservations of
the pair(x,y), denoted as {(xi,yi j),i=1,2,..., n}, are obtained and they follow the
linear regression model
yi j=aj+bjxi+εi j, fori=1,2,..., n,j=1,2,..., (10.1)
where ajandbjare the intercept and slope of the true regression line y=aj+
bjx, and{εi j,i=1,2,..., n}are i.i.d. random errors with the common distribution
N(0,σ2
j). When the j-th product is IC, it is further assumed that aj=a0,bj=b0,
andσ2
j=σ2
0, where a0,b0, and σ2
0are the IC values of the intercept, slope, and
error variance of the regression model (10.1). The resulting model is called the IC
linear regression model in this chapter. In (10.1), it has been assumed that (i) the
design points {xi,i=1,2,..., n}are deterministic and unchanged from one proﬁle
to another, and (ii) the sample size nis the same for all proﬁles. Furthermore, it
is conventionally assumed that between-proﬁle observations are independent of each
other (i.e., observations of different proﬁles are independent). Then, the linear proﬁle
monitoring (LPM) problem is mainly for monitoring the related production process
to make sure that proﬁles of its products follow the IC linear regression model.
Let us ﬁrst discuss phase II LPM, in which the IC parameters a0,b0, and σ2
0
are assumed to be known (as a matter of fact, they need to be estimated from an IC
dataset, as discussed in Subsection 4.5.1). In such cases, to monitor the j-th sampled
product, it is natural to ﬁrst estimate the model (10.1) based on the observations in
thej-th observed proﬁle, and then compare the estimated model with the IC linearPARAMETRIC PROFILE MONITORING 409
regression model. This is also the basic idea of an approach proposed by Kang and
Albin (2000). By the discussion in Subsection 2.7.2, the least squares (LS) estimators
ofbjandajare
/hatwidebj=∑n
i=1(xi−x)/parenleftbig
yi j−yj/parenrightbig
∑n
i=1(xi−x)2
/hatwideaj=yj−/hatwidebjx, (10.2)
where xandyjare the sample means of {xi,i=1,2,..., n}and{yi j,i=1,2,..., n},
respectively. The commonly used estimator of σ2
jis
/hatwideσ2
j=1
n−2n
∑
i=1/bracketleftig
yi j−/parenleftig
/hatwideaj+/hatwidebjxi/parenrightig/bracketrightig2
. (10.3)
When the j-thproduct is IC and the four conventional model assumptions used in lin-
ear regression analysis (cf., the related discussion in the paragraph containing (2.22)
in Subsection 2.7.2) are valid, these estimators have the properties that
/parenleftbigg/hatwideaj
/hatwidebj/parenrightbigg
∼N/parenleftigg/parenleftbigg
a0
b0/parenrightbigg
,σ2
0/parenleftigg
1
n+x2
sxx,−x
sxx
−x
sxx,1
sxx/parenrightigg/parenrightigg
, (10.4)
and
(n−2)/hatwideσ2
j
σ2
0∼χ2
n−2, (10.5)
where sxx=∑n
i=1(xi−x)2. Therefore, to monitor the j-th product, we can use the
Shewhart charting statistic
T2
j=(/hatwidedj−d0)′Σ−1
/hatwidedj(/hatwidedj−d0), (10.6)
where
/hatwidedj=/parenleftbigg/hatwideaj
/hatwidebj/parenrightbigg
, d0=/parenleftbigg
a0
b0/parenrightbigg
, Σ/hatwidedj=σ2
0/parenleftigg
1
n+x2
sxx,−x
sxx
−x
sxx,1
sxx/parenrightigg
.
By (10.4), the IC distribution of T2
jisχ2
2. So, a reasonable decision rule of the chart
is that it gives a signal when
T2
j>χ2
1−α,2, (10.7)
where α∈(0,1)is a given signiﬁcance level, and χ2
1−α,2is the(1−α)-th quantile
of the χ2
2distribution. Obviously, the IC ARL of the Shewhart chart (10.6)–(10.7) is
ARL 0=1/α(cf., (3.8) in Subsection 3.2.1).
Example 10.1 For a production process, assume that its proﬁles are known to be
linear and the IC linear regression model is
yi j=2+xi+εi j, for i=1,2,..., n,j=1,2,...,410 PROFILE MONITORING
where{xi,i=1,2,..., n}are design points in the design interval [0,1], and
{εi j,i=1,2,..., n,j=1,2,...} are i.i.d. random errors with the common distribution
N(0,0.52). The ﬁrst 20 observed proﬁles of the process obtained during phase II SPC
are presented in Table 10.1, where the design points are chosen to be 0.2, 0.4, 0.6,
0.8, and 1.0. For each observed proﬁle, the model (10.1) is ﬁtted, and the estimates
/hatwideaj,/hatwidebj, and/hatwideσ2
jare shown in Figure 10.1(a)–(c). From the plots, it seems that both the
intercept and slope shift at the 11th time point, and the error variance seems quite
stable. Then, we apply the Shewhart chart (10.6)–(10.7) to the 20 observed proﬁles,
in which αis chosen to be 0.005. The chart is shown in Figure 10.1(d). From the
chart, it can be seen that the ﬁrst signal is given at the 11th time point. Therefore, the
production process should be stopped at that time point to investigate the possible
root causes of the detected proﬁle shift.
Table 10.1 The ﬁrst 20 observed proﬁles of a production process obtained during phase II
SPC. The design points of all proﬁles are 0.2, 0.4, 0.6, 0.8, and 1.0.
j y1j y2j y3j y4j y5j
1 2.209 2.308 1.914 2.500 3.147
2 2.395 1.796 2.418 1.987 2.872
3 2.751 2.778 2.481 3.294 3.371
4 2.245 1.923 2.502 3.263 3.241
5 1.902 1.307 2.263 1.740 2.367
6 2.013 2.056 2.164 2.749 2.873
7 1.273 2.361 3.084 2.892 2.310
8 1.482 2.581 1.720 2.638 2.674
9 2.743 2.019 2.186 3.217 2.516
10 2.186 2.516 2.449 2.461 3.328
11 2.900 3.033 3.984 4.469 3.753
12 3.493 2.749 3.566 3.077 3.645
13 2.481 2.972 2.885 3.570 4.033
14 3.708 3.568 3.059 3.681 2.877
15 3.290 2.485 2.776 3.291 2.755
16 3.686 2.460 3.085 2.874 4.261
17 3.396 3.089 3.656 3.758 3.720
18 3.179 3.530 4.410 2.808 3.463
19 2.892 3.104 3.335 3.978 3.797
20 2.390 2.397 3.746 3.474 4.114
Besides the Shewhart chart (10.6)–(10.7), Kang and Albin (2000) also proposed
anRchart (cf., (3.7)) for detecting shift in error variance. As discussed in previous
chapters, we know that Shewhart charts are effective in detecting large and isolated
shifts, but ineffective in detecting small and persistent shifts. To overcome this lim-
itation of the Shewhart charts, Kim et al. (2003) proposed three univariate EWMA
charts for detecting shifts in the intercept, slope, and error variance, respectively,
which are described below. First, let us rewrite model (10.1) as
yi j=a∗
j+bj(xi−x)+εi j, fori=1,2,..., n,j=1,2,..., (10.8)
where a∗
j=aj+bjx. Obviously, the new intercept a∗
jis just the mean value of thePARAMETRIC PROFILE MONITORING 411
ja^j
0 5 10 15 200 1 2 3 4
(a)jb^
j
0 5 10 15 20−1 0 1 2
(b)
jσ^
j2
0 5 10 15 200 0.25 0.5 0.75 1
(c)nTj2
0 5 10 15 200 5 10 15 20
(d)
Figure 10.1 (a) Estimated intercepts {/hatwideaj,j=1,2,..., 20}. (b) Estimated slopes {/hatwidebj,j=
1,2,..., 20}. (c) Estimated error variances {/hatwideσ2
j,j=1,2,..., 20}. (d) Shewhart chart (10.6)–
(10.7) with α=0.005. The dashed horizontal line in (d) denotes the control limit χ2
1−α,2.
response yi jof the j-th proﬁle when xi=x. In the literature, model (10.8) is often
called the centered linear regression model because the new design points {x∗
i=
xi−x,i=1,2,..., n}arecentered at 0. For model (10.8), it is easy to check that the
LS estimator of a∗
jis/hatwidea∗
j=yj, where yjis the sample mean of {yij,i=1,2,..., n}. In
such cases, we can also check that the estimators /hatwidea∗
j,/hatwidebj, and/hatwideσ2
jare independent of
each other. Therefore, to monitor the whole proﬁle without losing any information,
we can simply monitor these three quantities separately.412 PROFILE MONITORING
When the process is IC, it is easy to check that, for each j≥1,
/hatwidea∗
j∼N(a0+b0x,σ2
0/n).
To monitor the sequence {/hatwidea∗
j,j=1,2,...}, Kim et al. (2003) proposed using the
following EWMA charting statistic:
Ej,I=λI/hatwidea∗
j+(1−λI)Ej−1,I, (10.9)
where E0,I=a0+b0x, and λI∈(0,1]is a weighting parameter. The upper control
limit U, the center line C, and the lower control limit Lof the corresponding EWMA
chart are
U=a0+b0x+ρIσ0/radicaligg
λI
(2−λI)n
C=a0+b0x (10.10)
L=a0+b0x−ρIσ0/radicaligg
λI
(2−λI)n,
where ρI>0 is a parameter chosen to reach a given ARL 0value.
For the estimator /hatwidebj, its IC distribution can be derived from (10.4) to be
/hatwidebj∼N(b0,σ2
0/sxx).
To monitor the sequence {/hatwidebj,j=1,2,...}, we can use the following EWMA charting
statistic
Ej,S=λS/hatwidebj+(1−λS)Ej−1,S, (10.11)
where E0,S=b0, and λS∈(0,1]is a weighting parameter. The control limits and the
center line of the corresponding EWMA chart are
U=b0+ρSσ0/radicaligg
λS
(2−λS)sxx
C=b0 (10.12)
L=b0−ρSσ0/radicaligg
λS
(2−λS)sxx,
where ρS>0 is a parameter chosen to reach a given ARL 0value.
The IC distribution of /hatwideσ2
jis given in (10.5), which is a chi-square distribution
that is skewed to the right. To detect an upward shift in the error variance, we can use
the upward EWMA chart originally proposed by Crowder and Hamilton (1992) with
the charting statistic
E+
j,V=max(0, λVlog(/hatwideσ2
j/σ2
0)+(1−λV)Ej−1,V), forj≥1, (10.13)
where E+
0,V=0 and λV∈(0,1]is a weighting parameter. The main purpose to use thePARAMETRIC PROFILE MONITORING 413
log transformation in (10.13) is to make the distribution of /hatwideσ2
j/σ2
0more symmetric.
See a related discussion at the end of Subsection 5.3.1. The chart gives a signal when
E+
j,V>U=ρVσ∗
W/radicaligg
λV
2−λV, (10.14)
where ρV>0 is a parameter chosen to reach a given ARL 0value, and
σ∗
W=/radicaligg
2
n−2+2
(n−2)2+4
3(n−2)3−16
15(n−2)5.
An EWMA chart for detecting downward variance shift can be constructed in a sim-
ilar way, although we are mainly concerned about upward variance shifts in most
applications, as discussed in Subsection 4.3.1.
Example 10.1 (continued) For the phase II LPM problem discussed in Example
10.1, let us consider using the three EWMA charts discussed above for monitoring
the intercept, slope, and error variance. In the three charts, λI,λS, and λVare all
chosen to be 0.2. From Kim et al. (2003), if we choose ρI=3.0156, ρS=3.0109,
andρV=1.3723 in the three charts, then their ARL 0values are all around 584.5,
and the joint monitoring scheme would have an ARL 0value of about 200. The three
charts are shown in Figure 10.2, from which it can be seen that the ﬁrst signal of the
joint monitoring scheme is given at the 13th time point, and it seems that the shift is
in the intercept of the regression line. Compared to the Shewhart chart (10.6)–(10.7)
shown in Figure 10.1(d), it can be seen that the joint monitoring scheme presented in
Figure 10.2 has two beneﬁts. (i) After giving a signal, it can tell us which parameters
among the intercept, slope, and error variance of the IC linear regression model
have shifted. (ii) The signals in Figure 10.2(a) seem more convincing, compared to
the signals in Figure 10.1(d).
Next, we discuss the phase I LPM problem, in which the IC parameters a0,b0,
andσ2
0are all unknown and they need to be estimated from an observed dataset. As-
sume that we have mobserved proﬁles with the observations {yi j,i=1,2,..., n,j=
1,2,..., m}. For the j-th proﬁle with j=1,2,..., m, its observations are assumed
to follow the model (10.1). When the j-th proﬁle is IC, it is further assumed that
aj=a0,bj=b0, and σ2
j=σ2
0. For phase I LPM, Kang and Albin (2000) proposed
the following estimators of a0,b0, and σ2
0:
/hatwidea0=1
mm
∑
j=1/hatwideaj,/hatwideb0=1
mm
∑
j=1/hatwidebj,/hatwideσ2
0=1
mm
∑
j=1/hatwideσ2
j, (10.15)
where/hatwideaj,/hatwidebj, and/hatwideσ2
jare deﬁned in (10.2) and (10.3). Instead of using the model
(10.1), Mahmoud and Woodall (2004) suggested using the centered model (10.8),
due to the property discussed above that the estimators /hatwidea∗
j,/hatwidebj, and/hatwideσ2
jare independent414 PROFILE MONITORING
jEj□□I
0 5 10 15 202 2.5 3 3.5 4
(a)jEj□□S
0 5 10 15 200 0.5 1 1.5 2
(b)
jEj□□V+
0 5 10 15 200 0.1 0.2 0.3 0.4 0.5
(c)
Figure 10.2 (a) EWMA chart (10.9)–(10.10) for monitoring the estimated intercepts {/hatwideaj,j=
1,2,..., 20} shown in Figure 10.1(a). (b) EWMA chart (10.11)–(10.12) for monitoring the
estimated slopes {/hatwidebj,j=1,2,..., 20} shown in Figure 10.1(b). (c) EWMA chart (10.13)–
(10.14) for monitoring the estimated error variances {/hatwideσ2
j,j=1,2,..., 20}shown in Figure
10.1(c). In these charts, λI,λS, and λVare all chosen to be 0.2, ρI,ρS, and ρVare chosen to
be 3.0156, 3.0109, and 1.3723, respectively, so that the ARL 0values of the three charts are all
around 584.5 and the joint monitoring scheme has the ARL 0value of about 200. The dashed
horizontal lines in the three plots denote the upper or lower control limits.
of each other, for each j. In such cases, the IC intercept a∗
0=a0+b0xof the centered
model can be estimated by
/hatwidea∗
0=/hatwidea0+/hatwideb0x=1
mm
∑
j=1yj. (10.16)PARAMETRIC PROFILE MONITORING 415
Because of the independency among /hatwidea∗
j,/hatwidebj, and/hatwideσ2
j, we can monitor the three se-
quences{/hatwidea∗
j,j=1,2,..., m},{/hatwidebj,j=1,2,..., m}, and{/hatwideσ2
j,j=1,2,..., m}sepa-
rately.
To monitor the estimated intercepts {/hatwidea∗
j,j=1,2,..., m}, it is easy to check that
when the process is IC, we have
/hatwidea∗
j−/hatwidea∗
0/radicalig
m−1
mn/hatwideσ2
0∼t(n−2)m.
Therefore, for a given false alarm rate α∈(0,1), it is natural to deﬁne the control
limits of the Shewhart chart for monitoring {/hatwidea∗
j,j=1,2,..., m}to be
U=/hatwidea∗
0+t1−α/2,(n−2)m/hatwideσ0/radicalbigg
m−1
mn
C=/hatwidea∗
0 (10.17)
L=/hatwidea∗
0−t1−α/2,(n−2)m/hatwideσ0/radicalbigg
m−1
mn
where t1−α/2,(n−2)mis the(1−α/2)-th quantile of the t(n−2)mdistribution. A She-
whart chart for monitoring the estimated slopes {/hatwidebj,j=1,2,..., m}can be con-
structed in a similar way, with the control limits
U=/hatwideb0+t1−α/2,(n−2)m/hatwideσ0/radicaligg/parenleftbiggm−1
m/parenrightbigg/slashbigg
sxx
C=/hatwideb0 (10.18)
L=/hatwideb0−t1−α/2,(n−2)m/hatwideσ0/radicaligg/parenleftbiggm−1
m/parenrightbigg/slashbigg
sxx.
To monitor the estimated error variances {/hatwideσ2
j,j=1,2,..., m}, Mahmoud and
Woodall (2004) suggested using the charting statistic
Fj=/hatwideσ2
j
1
m−1∑m
l=1,l/negationslash=j/hatwideσ2
l, (10.19)
which has the IC distribution of F(n−2),(m−1)(n−2). The corresponding Shewhart chart
has the control limits
U=F(1−α/2),(n−2),(m−1)(n−2)
C=1 (10.20)
L=Fα/2,(n−2),(m−1)(n−2),
where F(1−α/2),(n−2),(m−1)(n−2)andFα/2,(n−2),(m−1)(n−2)are the(1−α/2)-th and
α/2-th quantiles of the F(n−2),(m−1)(n−2)distribution.416 PROFILE MONITORING
Example 10.2 In this example, we consider the calibration problem that was origi-
nally discussed by Mestek et al. (1994) and was subsequently analyzed by Mahmoud
and Woodall (2004). In this application, we are mainly concerned about the stability
of the calibration curve in the photometric determination of Fe3+with sulfosalicylic
acid (denoted as x). In each proﬁle, 5 volumes of 0, 1, 2, 3, and 4 mL of 50 µg/mL
Fe3+solution are diluted with water to 25 mL, denoted by 5 levels of x: 0, 1, 2, 3,
and 4. Then, for each volume, 2.5 mL of a 20% solution of sulfosalicylic acid and
1.5 mL of a concentrated solution of ammonia are added to the diluted solution, and
the absorbance of the solution (denoted as y) at 420 nm is measured on a Spekol
11 using 1-cm cells. Each volume is repeated twice, resulting in 10 observations in
each proﬁle. Table 10.2 presents 22 observed proﬁles. We then apply the Shewhart
charts (10.17), (10.18), and (10.19)–(10.20) to this dataset to monitor the estimated
intercepts {/hatwidea∗
j,j=1,2,..., m}, the estimated slopes {/hatwidebj,j=1,2,..., m}, and the
estimated error variances {/hatwideσ2
j,j=1,2,..., m}. In all three charts, αis chosen to
be 0.005, making the ARL 0value of each individual chart 200. The three charts are
shown in Figure 10.3(a),(b),(d), and the estimated error variances are shown in Fig-
ure 10.3(c). From the plots, it can be seen that the estimated slopes and the estimated
error variances are quite stable, but the estimated intercepts seem very unstable.
Table 10.2 This table presents 22 observed proﬁles in the calibration problem discussed by
Mestek et al. (1994) and Mahmoud and Woodall (2004). In each proﬁle, ﬁve levels of x are
considered, and two replicated observations of y are collected at each level of x.
j y1j,y2jy3j,y4j y5j,y6j y7j,y8j y9j,y10j
1 1, 3 104, 104 206, 206 307, 308 409, 412
2 4, 2 104, 103 206, 204 308, 307 412, 413
3 3, 2 105, 104 207, 207 311, 309 414, 411
4 4, 2 104, 104 206, 207 308, 312 411, 413
5 9, 8 92, 95 195, 197 296, 299 397, 400
6 3, 3 107, 105 209, 207 311, 308 412, 410
7 3, 2 104, 105 207, 208 311, 308 414, 410
8 2, 2 105, 104 208, 208 310, 309 412, 412
9 6, 7 95, 94 196, 197 297, 300 401, 401
10 2, 4 104, 105 206, 207 311, 310 413, 412
11 1, 2 103, 104 205, 206 309, 307 412, 411
12 7, 7 94, 96 198, 199 298, 301 404, 402
13 5, 7 105, 107 210, 208 313, 315 415, 415
14 3, 2 106, 104 208, 207 311, 308 411, 414
15 8, 6 94, 95 196, 199 299, 302 400, 404
16 4, 6 104, 106 207, 210 311, 310 415, 413
17 2, 4 105, 106 206, 208 308, 310 410, 413
18 2, 0 104, 103 206, 206 309, 308 414, 409
19 0, 1 101, 102 203, 206 305, 307 409, 411
20 1, 4 104, 106 206, 208 311, 309 410, 414
21 9, 10 92, 92 194, 194 298, 297 400, 398
22 8, 8 95, 95 195, 199 298, 301 401, 403
In the above discussion, within-proﬁle observations are assumed to be indepen-
dent. In practice, they can be correlated due to serial and/or spatial correlation. JensenPARAMETRIC PROFILE MONITORING 417
ja^j*
0 5 10 15 20190 200 210
(a)jb^
j
0 5 10 15 20101.5 102 102.5 103
(b)
jσ^j2
0 5 10 15 200 1 2 3
(c)jFj
0 5 10 15 200 1 2 3
(d)
Figure 10.3 (a) She whart chart (10.17) for monitoring the estimated intercepts {/hatwidea∗
j,j=
1,2,..., m}in the calibration problem discussed in Example 10.2. (b) Shewhart chart (10.18)
for monitoring the estimated slopes {/hatwidebj,j=1,2,..., m}. (c) Estimated error variances
{/hatwideσ2
j,j=1,2,..., m}. (d) Shewhart chart (10.19)–(10.20) for monitoring the estimated error
variances {/hatwideσ2
j,j=1,2,..., 20}. The dashed horizontal lines in plots (a), (b), and (d) denote
the upper and lower control limits.
et al. (2008) discussed the LPM problem in cases when the within-proﬁle observa-
tions were correlated. Mahmoud et al. (2007) and Zou et al. (2006) discussed the
LPM problem under the framework of change-point detection. Zou et al. (2007a)
generalized the LPM problem from cases with a single predictor to cases with mul-
tiple predictors, and proposed an MEWMA chart for handling the generalized LPM418 PROFILE MONITORING
problem. A self-starting control chart was proposed by Zou et al. (2007b) for phase
II LPM in cases when the IC parameters are unknown.
10.2.2 Nonlinear proﬁle monitoring
In the previous subsection, it is assumed that the IC proﬁle is linear (cf., model
(10.1)). In some applications, however, the linearity assumption may not be valid.
For instance, the proﬁle describing the relationship between the total stamping force
(y) and the crank angle (x ) in a manufacturing process of sheet-metal stamping is
often nonlinear (cf. Ding et al., 2006; Jin and Shi, 1999). In dose-response studies,
people often use the nonlinear regression model
y=a+d−a
1+(x/c)b+ε (10.21)
to describe the relationship between the dose level (x ) of a medicine and the cor-
responding response (y) of a patient, where a,b,c,anddare four parameters, and
εis the random error. Model (10.21) describes a speciﬁc nonlinear proﬁle. More
generally, a nonlinear proﬁle can be described by the model
yi=f(xi,θ)+εi, fori=1,2,..., n, (10.22)
where{(xi,yi),i=1,2,..., n}arenobservations of (x,y),fis aknown nonlinear
function, θis aq-dimensional parameter vector, and {εi,i=1,2,..., n}are i.i.d. ran-
dom errors with the common distribution N(0,σ2). The nonlinear proﬁle monitoring
(NLPM) problem is for handling cases when the IC proﬁle of a production process
can be described by the nonlinear regression model (10.22).
Let us ﬁrst discuss the phase II NLPM problem, in which the IC value of θis
assumed known to be θ0. Assume that {(xi,yi j),i=1,2,..., n}is the j-th observed
proﬁle, for j=1,2,..., and that it follows the model (10.22). Namely, we have
yi j=f(xi,θ)+εi j, fori=1,2,..., n,j=1,2,..., (10.23)
where{εi j,i=1,2,..., n,j=1,2,...} are i.i.d. random errors with the common
distribution N(0,σ2). For the j-th proﬁle, the value of θcan be estimated from
the observations {(xi,yi j),i=1,2,..., n}using the nonlinear least squares esti-
mation described as follows. Let θ(0)be an initial estimator of θ, and G(0)=
(∂f(xi,θ)/∂θl|θ=θ(0),i=1,2,..., n,l=1,2,..., q)be an n×qmatrix, where θ=
(θ1,θ2,..., θq)′. Then, for each xin the design space, by the Taylor’s expansion, we
have
f(x,θ)≈f(x,θ(0))+/parenleftbigg∂f(x,θ)
∂θ/vextendsingle/vextendsingle/vextendsingle/vextendsingle
θ=θ(0)/parenrightbigg′/parenleftig
θ−θ(0)/parenrightig
.
So, the objective function of the least squares estimation is
n
∑
i=1(yi j−f(xi,θ))2
≈n
∑
i=1/bracketleftigg
(yi j−f(xi,θ(0)))−/parenleftbigg∂f(xi,θ)
∂θ/vextendsingle/vextendsingle/vextendsingle/vextendsingle
θ=θ(0)/parenrightbigg′/parenleftig
θ−θ(0)/parenrightig/bracketrightigg2
.PARAMETRIC PROFILE MONITORING 419
Then, from the least squares estimation (i.e., min θ∑n
i=1(yi j−f(xi,θ))2), the updated
estimator of θis
θ(1)=θ(0)+/parenleftig
G(0)′G(0)/parenrightig−1
G(0)′y(0)
j,
where y(0)
j= (y 1j,y2j,..., yn j)′−(f(x1,θ(0)),f(x2,θ(0)),..., f(xn,θ(0)))′. The
above algorithm can be made iterative, and at the s-th iteration the updated estimator
ofθis
θ(s)=θ(s−1)+/parenleftig
G(s−1)′G(s−1)/parenrightig−1
G(s−1)′y(s−1)
j, fors≥1, (10.24)
where G(s−1)=(∂f(xi,θ)/∂θl|θ=θ(s−1),i=1,2,..., n,l=1,2,..., q)is an×qma-
trix, and y(s−1)
j=(y 1j,y2j,..., yn j)′−(f(x1,θ(s−1)),f(x2,θ(s−1)),..., f(xn,θ(s−1)))′.
Under some regularity conditions, the iterative algorithm (10.24) will converge when
the number of iterations sincreases. The limit is the ﬁnal estimator of θ, denoted as
/hatwideθj. When the sample size nis large, it has been shown (cf., Seber and Wild, 2003)
that the distribution of this estimator is close to the normal distribution
Nq/parenleftig
θj,σ2/parenleftbig
G′
jGj/parenrightbig−1/parenrightig
, (10.25)
where θjis the true parameter vector of the j-th proﬁle, and
Gj=/parenleftbigg∂f(x1,θ)
∂θ,∂f(x2,θ)
∂θ,···,∂f(xn,θ)
∂θ/parenrightbigg′/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
θ=θj
is an n×qmatrix. The algorithm (10.24) is the well-known Gauss-Newton algorithm.
It has several variants. See Bates and Watts (2007) for a systematic discussion on
nonlinear least squares estimation. As a side note, the estimator /hatwideθjcan be computed
by theR-function nls().
Based on the result (10.25), it is natural to consider the Shewhart chart with the
decision rule that gives a signal at time jwhen
T2
j=1
σ2/parenleftig
/hatwideθj−θ0/parenrightig′/parenleftbig
G′
jGj/parenrightbig/parenleftig
/hatwideθj−θ0/parenrightig
>χ2
1−α,q, (10.26)
where α∈(0,1)is a given signiﬁcance level, and χ2
1−α,qis the(1−α)-th quantile
of the χ2
qdistribution. It is also possible to construct CUSUM, EWMA, and CPD
charts. For instance, we can consider the EWMA charting statistic
Ej=λ/parenleftig
/hatwideθj−θ0/parenrightig
+(1−λ)Ej−1, forj≥1, (10.27)
where E0=0, and λ∈(0,1]is a weighting parameter. Then, the chart gives a signal
at time jif
W2
j=E′
jΣ−1
EjEj>ρ, (10.28)420 PROFILE MONITORING
where ρ>0 is a control limit chosen to achieve a given ARL 0value, and ΣEjis the
covariance matrix of Ejwhich can be computed recursively by the formula
ΣEj=λ2Σ/hatwideθj+(1−λ)2ΣEj−1
≈λ2σ2/parenleftbig
G′
jGj/parenrightbig−1+(1−λ)2ΣEj−1,forj≥1, (10.29)
in which ΣE0=0. The computation involved in computing ΣEjcan be greatly reduced
by using (10.29).
Example 10.3 In a dose-response application, assume that the relationship between
the response y and the dose level x follows the following 2-parameter nonlinear re-
gression model:
y=d
1+xb+ε, for x∈[0,1], (10.30)
where b and d are two parameters, and εis the random error with the distribution
N(0,0.252). It is further assumed that the IC values of b and d are 1 and 2, respec-
tively. Table 10.3 presents the ﬁrst 20 observed proﬁles obtained during phase II SPC,
in each of which the design points are ﬁxed at 0.1, 0.25, 0.4, 0.55, 0.7, 0.85, and 1.0.
In this example, it is assumed that the within-proﬁle and between-proﬁle observations
are independent of each other. We then use the Rfunctionnls() to compute the values
of{(/hatwidebj,/hatwidedj),j=1,2,..., 20}. The computed values are shown in Figure 10.4(a)–(b).
From the plots, it seems that both b and d shift around j =11, with b shifted upward
and d shifted downward. Next, we use the Shewhart chart (10.26) and the EWMA
chart (10.27)–(10.28) to monitor the estimated values {(/hatwidebj,/hatwidedj),j=1,2,..., 20}. In
both charts, we use χ2
0.995,2=10.597 as the control limits. The charts are shown in
Figure 10.4(c)–(d). It can be seen that the Shewhart chart gives its ﬁrst signal at the
11th time point, and the EWMA chart gives its ﬁrst signal at the 15th time point.
Next, we discuss the phase I NLPM problem, in which the IC value of the pa-
rameter vector θis unknown. Assume that there are mobserved proﬁles {(xi,yi j),i=
1,2,..., n,j=1,2,..., m}, and each observed proﬁle follows the model (10.23).
Then, by the nonlinear least squares estimation discussed above (cf., (10.24)), we can
compute the estimators of θ, denoted as {/hatwideθj,j=1,2,..., m}, from the mobserved
proﬁles. One natural idea to monitor these estimators of θis to use the Shewhart
charting statistic
/tildewideT2
j=/parenleftig
/hatwideθj−/hatwideθ/parenrightig′
S−1
/hatwideθ/parenleftig
/hatwideθj−/hatwideθ/parenrightig
, (10.31)
where/hatwideθandS/hatwideθare the sample mean and sample covariance matrix of {/hatwideθj,j=
1,2,..., m}. As discussed in Subsection 7.2.2, the IC distribution ofm
(m−1)2/tildewideT2
jis
Beta(q/2,(m−q−1)/2). So, the chart gives a signal at time jif
/tildewideT2
j>(m−1)2
mBeta1−α(q/2,(m−q−1)/2), (10.32)
where α∈(0,1)is a given signiﬁcance level, and Beta 1−α(q/2,(m−q−1)/2) is
the(1−α)-th quantile of the Beta(q/2, (m−q−1)/2) distribution.PARAMETRIC PROFILE MONITORING 421
Table 10.3 Theﬁrst 20 observed proﬁles of a production process obtained during phase II
SPC. The design points of all proﬁles are the same, with values 0.1, 0.25, 0.4, 0.55, 0.7, 0.85,
and 1.0.
j y1j y2j y3j y4j y5j y6j y7j
1 1.768 1.613 1.421 1.379 1.188 1.113 0.942
2 1.890 1.517 1.393 1.299 1.186 1.061 1.074
3 1.831 1.597 1.390 1.341 1.085 1.312 0.956
4 1.895 1.626 1.506 1.209 1.133 1.009 1.023
5 1.702 1.625 1.419 1.466 1.163 1.070 0.931
6 1.796 1.618 1.470 1.397 1.273 1.071 1.140
7 1.641 1.662 1.376 1.423 1.140 1.213 1.004
8 1.630 1.555 1.255 1.308 1.366 0.854 1.098
9 1.678 1.782 1.567 1.206 1.150 1.074 0.962
10 2.076 1.613 1.357 1.354 1.197 1.074 0.991
11 1.035 0.835 0.746 0.933 0.465 0.582 0.391
12 1.017 1.042 0.655 0.857 0.666 0.446 0.307
13 1.061 0.925 0.884 0.849 0.844 0.570 0.444
14 1.133 0.852 0.746 0.715 0.916 0.497 0.541
15 0.872 0.824 0.829 0.904 0.624 0.665 0.354
16 0.950 0.864 0.825 0.892 0.660 0.598 0.525
17 0.929 0.798 0.829 0.781 0.773 0.555 0.470
18 1.152 0.864 0.904 0.709 0.713 0.426 0.448
19 0.962 1.042 0.815 0.798 0.629 0.496 0.569
20 0.944 1.076 0.906 0.753 0.717 0.577 0.546
Williams et al. (2007b) discussed two alternative Shewhart charts for solving the
phase I NLPM problem. The ﬁrst one uses the charting statistic
/tildewideT2
j,D=/parenleftig
/hatwideθj−/hatwideθ/parenrightig′
S−1
D/parenleftig
/hatwideθj−/hatwideθ/parenrightig
,
where
SD=1
2(m−1)m−1
∑
j=1/parenleftig
/hatwideθj+1−/hatwideθj/parenrightig/parenleftig
/hatwideθj+1−/hatwideθj/parenrightig′
.
The matrix SDprovides a point estimator of the covariance matrix of /hatwideθ. It was ﬁrst
discussed by Hawkins and Merriam (1974). Several papers, including Holmes and
Mergen (1993), Sullivan and Woodall (1996), and Vargas (2003), studied the prop-
erties of the charting statistic /tildewideT2
j,D. They found that /tildewideT2
j,Dwas effective in detecting
both step and ramp shifts, and it was invariant to the full-rank linear transformations
on the original observations. Williams et al. (2006) provided a formula for determin-
ing the control limit of the Shewhart chart using /tildewideT2
j,D. Because this formula is quite
complicated, it is omitted here. The second alternative Shewhart chart discussed by
Williams et al. (2007b) uses the so-called minimum volume ellipsoid (MVE) estima-
tor of the covariance matrix of /hatwideθ. That chart was found ineffective in detecting step
shifts in θ, but effective in detecting outliers.422 PROFILE MONITORING
jb^
j
0 5 10 15 200 1 2 3 4 5
(a)jd^
j
0 5 10 15 200 1 2 3
(b)
jTj2
0 5 10 15 200 25 50 75 100
(c)jWj2
0 5 10 15 200 5 10 15 20 25
(d)
Figure 10.4 (a){/hatwidebj,j=1,2,..., 20}. (b){/hatwidedj,j=1,2,..., 20}. (c) Shewhart chart (10.26)
with control limit χ2
0.995,2=10.597. (d) EWMA chart (10.27)–(10.28) with control limit
χ2
0.995,2=10.597. In plots (c) and (d), the dashed horizontal lines denote the control limits.
Example 10.3 (continued) For the 20 observed proﬁles presented in Table 10.3,
let us now assume that they are collected during phase I NLPM, and each proﬁle
still follows the model (10.30) with the IC values of the parameters b and d un-
known. For each proﬁle, the estimates of b and d are obtained by the nonlinear least
squares estimation, as was done in Example 10.3, and their values are shown in
Figure 10.4(a)–(b). Then, the Shewhart chart (10.31)–(10.32) is applied to these es-
timated values. In the chart, αis chosen to be 0.005, and the corresponding control
limit is192
20Beta0.995(1,8.5) = 8.372. The Shewhart chart is shown in Figure 10.5.
From the plot, it can be seen that no signal is given by this chart.NONPARAMETRIC PROFILE MONITORING 423
jT~
j2
0 5 10 15 200 2 4 6 8 10
Figure 10.5 Shewhart chart (10.31)–(10.32) with α=0.005when it is applied to the data
presented in Table 10.3. The horizontal dashed line denotes the control limit.
In the literature, there are some other proposed methods for handling the NLPM
problem. For instance, Chicken et al. (1998) proposed describing a nonlinear pro-
ﬁle by a linear combination of a ﬁnite number of wavelet basis functions, and then
proﬁle monitoring could be accomplished by monitoring the estimated wavelet co-
efﬁcients. Fan et al. (2012) proposed a similar idea by describing a nonlinear proﬁle
by a linear combination of some sine functions. Jensen and Birch (2009) proposed
using a nonlinear mixed-effects model for describing nonlinear proﬁles, which can
accommodate possible correlation among within-proﬁle observations.
10.3 Nonparametric Proﬁle Monitoring
The LPM and NLPM problems discussed in the previous section are under the as-
sumption that observed proﬁles can be described by a linear regression model or a
parametric nonlinear regression model. In a speciﬁc application, if this assumption is
invalid and an LPM or NLPM control chart is still used, then the results could be un-
reliable or even misleading because the deviation of the true proﬁle model from the
assumed proﬁle model is also a shift and its impact on the performance of the con-
trol chart is difﬁcult to eliminate. To overcome this limitation of the LPM and NLPM
control charts, some nonparametric proﬁle monitoring (NPPM) charts have been pro-
posed in the literature. For instance, Qiu and Zou (2010), and Zou et al. (2008, 2009b)
proposed several NPPM charts under various assumptions on IC parameters, design
points, and the correlation structure among within-proﬁle observations. Wei et al.424 PROFILE MONITORING
(2012) proposed an NPPM Shewhart chart using quantile regression (cf., Koenker,
2005). In this section, we describe the NPPM chart proposed by Qiu et al. (2010),
which does not require restrictive model assumptions. Our description is divided into
two parts. Estimation of the IC proﬁle model based on mixed effects modeling is dis-
cussed in Subsection 10.3.1. A phase II EWMA chart using the estimated IC proﬁle
model is discussed in Subsection 10.3.2.
10.3.1 Nonparametric mixed-effects modeling
The phase II NPPM chart described in the next subsection does not require IC pa-
rameters to be known. Instead, we estimate the related IC parameters from an IC
dataset, using the nonparametric mixed-effects (NME) modeling. In the literature,
the mixed-effects modeling is often used in longitudinal data analysis (e.g., Laird
and Ware, 1982; Diggle et al., 1994). It has become a major tool for accommodating
possible correlation among observed data. NME modeling for analyzing longitudi-
nal data has been discussed by several authors, including Shi et al. (1996) and Rice
and Wu (2001). We follow this framework for modeling possible correlation among
within-proﬁle observations of an IC dataset. It should be noted that, in the litera-
ture on mixed-effects modeling, proﬁles are also called “clusters” or “subjects.” To
simplify the presentation, we choose to discuss cases with a single predictor here;
this discussion can be generalized easily to cases with multiple predictors. In the IC
dataset, assume that there are mproﬁles and the j-th proﬁle has njobservations, for
j=1,2,..., m. Then, the NME model can be written as
yi j=g(xi j)+fj(xi j)+εi j, fori=1,2,..., nj,j=1,2,..., m, (10.33)
where gis the population proﬁle function (i.e., the ﬁxed-effects term), fjis the
random-effects term describing the deviation of the j-th individual proﬁle from g,
{(xi j,yi j),i=1,2,..., nj}is the sample collected for the j-th proﬁle, and {εi j,i=
1,2,..., nj}are i.i.d. random errors with mean 0 and variance σ2. In model (10.33),
it is routinely assumed that the random-effects term fjand the random errors εi jare
independent of each other, and fjis a realization of a mean 0 process with a common
covariance function
γ(x1,x2)=E[fj(x1)fj(x2)].
Without loss of generality, we further assume that xi j∈[0,1], for all iandj.
Model (10.33) is fairly ﬂexible. It includes many common correlation struc-
tures as special cases. For instance, if fj(xi j)=ξjandξjis a mean 0 random vari-
able, then within-proﬁle correlation would have the compound symmetry structure.
If Cor(fj(x1),fj(x2)) = ρ(|x1−x2|;ν), for some correlation function ρand a co-
efﬁcient ν, then the correlation structure includes the nonhomogeneous Ornstein-
Uhlenbeck process and the Gaussian correlation model (cf., Zhang et al., 1998) as
special cases. When the design points are equally spaced and unchanged among dif-
ferent proﬁles, this model can also be used for describing the autoregressive corre-
lation structure. Because of its ﬂexibility, model (10.33) requires a relatively large
set of IC proﬁles for model estimation and calibration, compared to its parametricNONPARAMETRIC PROFILE MONITORING 425
counterparts. Thanks to fast progress in sensor and information technology, auto-
matic data acquisition is becoming increasingly common in industry. Consequently,
a large amount of IC data is often available, and model (10.33) allows us to make use
of such data without imposing a parametric form on the proﬁle model.
Next, we discuss estimation of g,γ, and σ2in model (10.33) when the related
production process is IC. In the literature, there are some existing discussions about
statistical analysis of correlated data under various settings and assumptions, includ-
ing those in Altman (1990), Fan and Zhang (2000), Hart (1991), Hoover et al. (1998),
Lin and Carroll (2000), Wang (1998), Zhang et al. (1998), and many others. Wu and
Zhang (2002) proposed a method for estimating model (10.33) by combining linear
mixed-effects (LME) modeling and local linear kernel smoothing (cf., Subsection
2.8.5). They demonstrated that their estimator of g, which was referred to as local
LME (LLME) estimator, was often more efﬁcient than some alternative estimators
in terms of the mean squared error (cf., Subsection 2.7.1). Furthermore, by their ap-
proach, it is fairly easy to obtain consistent estimators of γandσ2, which is important
for constructing a phase II control chart in the current NPPM problem. For these rea-
sons, Qiu et al. (2010) adopted Wu and Zhang’s method, which is brieﬂy described
below.
For a given point s∈[0,1], LLME estimators of g(s) and fj(s)are obtained
by minimizing the following penalized, negative-log, local linear kernel likelihood
function:
m
∑
j=1/braceleftigg
1
σ2nj
∑
i=1/bracketleftbig
yi j−z′
i j(a+bj)/bracketrightbig2Kh(xi j−s)+b′
jD−1bj+log|D|+njlog/parenleftbig
σ2/parenrightbig/bracerightigg
,
(10.34)
where Kh(x)=K(x/h)/h, Kis a symmetric density kernel function, his a bandwidth,
z′
i j=(1, xi j−s),ais a deterministic two-dimensional coefﬁcient vector, and bjis a
two-dimensional vector of the random effects with mean 0and covariance matrix D.
Minimization of (10.34) with respect to aandbjcan be accomplished by the 4-step
iterative procedure below.
Step 1 Set the initial values for Dandσ2, denoted as D(0)andσ2
(0).
Step 2 At the l-th iteration, for l≥0, compute estimators of aandbjby solving
the so-called mixed-model equation (cf., Davidian and Giltinan, 1995; Wu and
Zhang, 2002), and the resulting estimators are
/hatwidea(l)=/parenleftigg
m
∑
j=1Z′
jΣjZj/parenrightigg−1m
∑
j=1Z′
jΣjyj (10.35)
/hatwideb(l)
j=/parenleftig
Z′
jKjZj+σ2
(l)D−1
(l)/parenrightig−1
Z′
jKj/parenleftig
yj−Zj/hatwidea(l)/parenrightig
, (10.36)
where Zj= (z 1j,z2j,..., znjj)′,yj= (y 1j,y2j,..., ynjj)′,Σj= (Z jD(l)Z′
j+
σ2
(l)K−1
j)−1, and Kj=diag{Kh(x1j−s),Kh(x2j−s),..., Kh(xnjj−s)}.426 PROFILE MONITORING
Step 3 Based on/hatwidea(l)and/hatwideb(l)
j, update the estimators of Dandσ2by
D(l+1)=1
mm
∑
j=1/hatwideb(l)
j/parenleftig
/hatwideb(l)
j/parenrightig′
(10.37)
σ2
(l+1)=1
mm
∑
j=11
nj/bracketleftig
yj−Zj/parenleftig
/hatwidea(l)+/hatwideb(l)
j/parenrightig/bracketrightig′/bracketleftig
yj−Zj/parenleftig
/hatwidea(l)+/hatwideb(l)
j/parenrightig/bracketrightig
.(10.38)
Step 4 Repeat Steps 2–3 until the following condition is satisﬁed:
/bardblD(l)−D(l−1))/bardbl1/slashbig
/bardblD(l−1)/bardbl1≤τ,
where τis a pre-speciﬁed small positive number (e.g., τ=10−4), and/bardblA/bardbl 1de-
notes the sum of absolute values of all elements of a matrix A. Then, the algorithm
stops at the l-th iteration.
Note that, in Step 4, we use the relative difference of the successive estimators
ofDin the convergence criterion. In fact, other estimators can also be used for this
purpose. We use Dhere because our simulation shows that it gives good results in
various cases. As a side note, nonconvergence of the above iterative procedure can
occasionally happen, although we ﬁnd that the frequency of nonconvergence is neg-
ligible in all our simulation studies, except certain extreme cases such as the ones
when mornj’s are too small. To reduce the frequency of nonconvergence, it is sug-
gested in the literature to use good initial values for Dandσ2. A simple but effective
method is to set D(0)to be the identity matrix and
σ2
(0)=1
mm
∑
j=1/braceleftigg
1
njnj
∑
i=1/bracketleftig
yi j−/hatwideg(P)(xij)/bracketrightig2/bracerightigg
,
where/hatwideg(P)(xi j)is the standard local linear kernel estimator constructed from the
pooled data (cf., Hoover et al., 1998).
After obtaining solutions to aandbj, denoted as/hatwidea(s) and/hatwidebj(s), of the minimiza-
tion problem using the above 4-step algorithm, we can deﬁne
/hatwideg(s)= e′
1/hatwidea(s),/hatwidefj(s)= e′
1/hatwidebj(s),/hatwideγ(s1,s2)=1
mm
∑
j=1/hatwidefj(s1)/hatwidefj(s2), (10.39)
where s,s1,s2∈[0,1], and e1= (1, 0)′. Note that the variance estimator from the
above iterative procedure depends on s. Since σ2is a population parameter that does
not depend on s, we suggest estimating it by
/hatwideσ2=1
mm
∑
j=1/braceleftigg
1
njnj
∑
i=1/bracketleftig
yi j−/hatwideg(xi j)−/hatwidefj(xi j)/bracketrightig2/bracerightigg
. (10.40)
Example 10.4 Qiu et al. (2010) considered a dataset obtained from a manufactur-
ing process of aluminium electrolytic capacitors (AECs). This process transformsNONPARAMETRIC PROFILE MONITORING 427
raw materials, such as anode aluminum foil, cathode aluminum foil, guiding pin,
electrolyte sheet, plastic cover, aluminum shell, and plastic tube, into AECs that are
appropriate for use in low leakage circuits and are well adapted to a wide range
of environmental temperatures. The whole manufacturing process consists of a se-
quence of operations, including clenching, rolling, soaking, assembly, cleaning, ag-
ing, and classifying. Before packing, a careful quality monitoring step is required by
sampling from a batch of products. Regarding the quality of AECs, the most impor-
tant characteristic is the dissipation factor (DF), which can be automatically mea-
sured by an electronic device. However, it is known that DF measurements would
change signiﬁcantly with environmental temperature, and there is a speciﬁc require-
ment about the adaptability of AECs to the temperature. To monitor the adaptability,
engineers put a sampled AEC in a container. Then, the container’s temperature is
controlled, and the temperature is supposed to stably increase from −26oF to 78oF.
In this process, measurements of DF and the actual temperature inside the container
are taken at 53 equally spaced time points. The actual temperature inside the con-
tainer is reported by a temperature sensor. So, for each sampled AEC, a set of 53
observations of the pair (temperature, DF), which corresponds to (x,y)in model
(10.33), are obtained for monitoring the adaptability of the AEC to the temperature.
Figure 10.6 shows three AEC proﬁles along with an NME estimator of the IC proﬁle
function (see related discussion below). It should be noted that the actual tempera-
ture inside a container would ﬂuctuate around its nominal level at each observation
time. Therefore, the actual temperature readings of different containers at a given
observation time are all different, although the differences are usually small.
−20 0 20 40 60 800.0 0.1 0.2 0.3 0.4
TemperatureDissipation Factor
Figure 10.6 Three AEC proﬁles (lines connecting points with three different symbols) and the
NME estimator (solid curve) of the IC proﬁle function.
The entire AEC dataset contains 144 proﬁles, and each proﬁle has n =53obser-
vations. We use the ﬁrst 96 proﬁles as the IC data to estimate the IC proﬁle function
and the remaining ones as phase II observed proﬁles. We ﬁrst estimate model (10.33)
from the IC data by the iterative procedure (10.35)–(10.38), using the suggested ini-428 PROFILE MONITORING
tial values of D and σ2given above, the Epanechnikov kernel function, and the CV
bandwidth selection procedure suggested by Wu and Zhang (2002) (cf., Subsections
2.8.4 and 2.8.5 for related descriptions). The resulting IC proﬁle estimator /hatwideg is the
one displayed in Figure 10.6 by the solid curve. From (10.39) and (10.40), we can
also compute the estimated correlation of two within-proﬁle observations of the re-
sponse variable y at any two points s 1and s 2in the design interval
/hatwideρ(s1,s2)=/hatwideγ(s1,s2)/slashbig
[/hatwideν(s1)/hatwideν(s2)],
where/hatwideγ(s1,s2)is deﬁned in (10.39), /hatwideν2(s) =/hatwideγ(s,s)+/hatwideσ2is the estimated variance
of y at s, and /hatwideσ2is deﬁned in (10.40). Let x∗
i=2(i−1)−26, for i=1,2,..., 53,
be 53 equally spaced points in the design interval [−26,78], which denote the nom-
inal temperature levels used when taking DF measurements of the sampled AECs.
The estimated correlations /hatwideρ(x∗
i,x∗
i+1),/hatwideρ(x∗
i,x∗
i+3),/hatwideρ(x∗
1,x∗
i), and/hatwideρ(x∗
i,x∗
53), for
i=1,2,..., 53, are shown in Figure 10.7(a). From the plot, we can see that correla-
tion within AEC proﬁles is substantial; thus, it should not be ignored. Figure 10.7(b)
shows the estimated standard deviation /hatwideν(x∗
i)of the response variable y at x∗
i, for
i=1,2,..., 53, from which heteroscedasticity of the response variable y at different
positions of x is clearly seen. In addition, we can obtain an estimate of the error
standard deviation σto equal 0.016, by formula (10.40), which is much smaller than
/hatwideν(x∗
i), especially when i ∈[12,45]. This result implies that the random-effects term
in model (10.33) describes a substantial amount of random variation in the data.
0 10 20 30 40 500.0 0.2 0.4 0.6 0.8 1.0
i
(a)0 10 20 30 40 500.00 0.05 0.10 0.15
i
(b)
Figure 10.7 (a) Solid, dashed, dotted, and dash-dotted curves represent estimated within-
proﬁle correlations /hatwideρ(x∗
i,x∗
i+1),/hatwideρ(x∗
i,x∗
i+3),/hatwideρ(x∗
1,x∗
i), and/hatwideρ(x∗
i,x∗
53), for i=1,2,..., 53,
where{x∗
i,i=1,2,..., 53} are 53 equally spaced points in the design interval [−26, 78].
(b) Estimated standard deviation /hatwideν(x∗
i)of the response variable y at x∗
i, for i=1,2,..., 53.
10.3.2 Phase II nonparametric proﬁle monitoring
In this part, we describe the phase II NPPM chart proposed by Qiu et al. (2010)
in general cases when within-proﬁle data might be correlated and the design pointsNONPARAMETRIC PROFILE MONITORING 429
within and between proﬁles are arbitrary. Proﬁle monitoring in such cases is chal-
lenging mainly due to the following two reasons. First, because the within-proﬁle
data might be correlated, estimation of the proﬁle function ginvolves a considerable
amount of computation if the NME modeling approach described in the previous sub-
section is also used in phase II NPPM. However, a good on-line control chart should
maintain a reasonable efﬁciency while being effective in detecting proﬁle shifts. Sec-
ond, in cases when the design points xj=(x i j,x2j,..., xnjj)′are unchanged from one
proﬁle to another, one natural proﬁle monitoring method is to ﬁrst average observed
responses yi j’s across different proﬁles and then detect potential proﬁle shifts using
a generalized likelihood ratio test statistic (cf., Fan et al., 2001). This idea cannot be
applied to the current problem directly because the response is observed at different
design points in different proﬁles. One immediate alternative is to estimate gfrom
individual proﬁle data at a given set of points in [0,1]. But the resulting estimators
would be inefﬁcient since they are constructed from individual proﬁle data instead of
from all observed data.
To overcome the above difﬁculties, at a given point s∈[0,1], let us consider the
following local weighted negative-log likelihood:
WL(a,b;s,λ,t)=t
∑
j=1nj
∑
i=1[yi j−a−b(xi j−s)]2Kh(xi j−s)(1−λ)t−j/ν2(xi j),
where tdenotes the current time point during phase II proﬁle monitoring, λ∈(0,1]
is a weighting parameter, and ν2(x) =γ(x,x)+σ2is the variance function of the
response. Note that WL(a,b;s,λ,t)combines the exponential weighting scheme used
in EWMA at different time points through the term (1−λ)t−jand the local linear
kernel smoothing procedure (cf., Subsection 2.8.5). At the same time, it takes into
account the heteroscedasticity of observations by using ν2(xi j). Then, the local linear
kernel estimator of g(s), deﬁned as the solution to aof the minimization problem
min a,bWL(a,b;s,λ,t), has the expression
/hatwidegt,h,λ(s)=t
∑
j=1nj
∑
i=1U(t,h,λ)
i j(s)y i j/slashigg
t
∑
j=1nj
∑
i=1U(t,h,λ)
i j(s), (10.41)
where
U(t,h,λ)
i j(s) =(1−λ)t−jKh(xi j−s)
ν2(xi j)/bracketleftig
m(t,h,λ)
2(s)−(xi j−s)m(t,h,λ)
1(s)/bracketrightig
,
m(t,h,λ)
l(s) =t
∑
j=1(1−λ)t−jnj
∑
i=1(xi j−s)lKh(xi j−s)/ν2(xi j), (10.42)
forl=0,1,2. Note that m(t,h,λ)
0(s)is not used in (10.42), but it will be used later.
From (10.41) and (10.42), we can see that /hatwidegt,h,λ(s)makes use of all the avail-
able observations up to the current time point t, and different proﬁles are weighted
as in a conventional EWMA chart (i.e., more recent proﬁles get more weights and
the weights change exponentially over time). When λ=0 (i.e., all proﬁles receive430 PROFILE MONITORING
equal weight), the resulting estimator is similar to the local linear generalized esti-
mating equations (GEE) estimator considered in Lin and Carroll (2000). The GEE
estimator can accommodate within-proﬁle correlation without specifying the corre-
lation structure (it uses the so-called independent working correlation matrix). Under
certain mild conditions, Lin and Carroll showed that it was asymptotically the best
estimator. Although Wu and Zhang (2002) demonstrated that their LLME estima-
tor performed better in certain cases, especially when within-proﬁle correlation was
strong, this latter estimator involves a considerable amount of computation, and may
not be feasible for phase II proﬁle monitoring, which is an on-line sequential proce-
dure. As a comparison, the estimator (10.41) has an explicit formula, and the related
computation is relatively fast.
Following the convention of phase II SPC, we assume that the IC proﬁle function,
denoted as g0, and the variance function ν2(·)are both known. In practice, they need
to be estimated from an IC dataset, as described in Subsection 10.3.1. Let ξi j=
yi j−g0(xi j), for all iandj, and/hatwideξt,h,λ(s)be the estimator deﬁned in (10.41) after yi j
are replaced by ξi j. Then, the IC distribution of/hatwideξt,h,λ(s)does not depend on g0, and
the original testing problem with H0:g=g0versus H1:g/ne}ationslash=g0, which is associated
with the proﬁle monitoring problem, is changed to the one with H0:g=0 versus
H1:g/ne}ationslash=0. Consequently, the IC distribution of the proposed control chart deﬁned
below and all quantities related to this distribution (e.g., the control limit ρ) do not
depend on g0either, which should simplify the design and implementation of our
proposed control chart.
When the process is IC, |/hatwideξt,h,λ(s)|should be small. So, a natural statistic that can
be used for SPC is
Tt,h,λ=c0,t,λ/integraldisplay[/hatwideξt,h,λ(s)]2
ν2(s)Γ1(s)ds,
where
ct0,t1,λ=a2
t0,t1,λ/bt0,t1,λ,
at0,t1,λ=t1
∑
j=t0+1(1−λ)t1−jnj,
bt0,t1,λ=t1
∑
j=t0+1(1−λ)2(t1−j)nj,
andΓ1is some pre-speciﬁed density function. In the expression of Tt,h,λ, quantities
c0,t,λandν(·)are used for unifying its asymptotic variance. In practice, we suggest
using the following discrete version:
Tt,h,λ≈c0,t,λ
n0n0
∑
k=1/bracketleftig/hatwideξt,h,λ(sk)/bracketrightig2
ν2(sk), (10.43)
where{sk,k=1,..., n0}are some i.i.d. random numbers generated from Γ1. Then,NONPARAMETRIC PROFILE MONITORING 431
the chart gives a signal if
Tt,h,λ>ρ,
where ρ>0 is a control limit chosen to achieve a given ARL 0level. Hereafter, this
chart is referred to as the nonparametric mixed-effects proﬁle monitoring (NMEPM)
chart.
In phase II SPC, it is a convention that the IC distribution of the process observa-
tions is assumed known. Then, the control limit ρcan be searched for by simulation
based on this distribution. In practice, the IC distribution is often unknown. Instead,
we usually have a quite large IC dataset. In such cases, ρcan be searched for by a
resampling algorithm, brieﬂy described below. In each simulation run, we resample
the IC dataset by randomly choosing a sequence of proﬁles with replacement. The
sequence of proﬁles is sequentially chosen until a signal of shift is triggered by the
chart NMEPM. Then, an estimated ARL 0value is computed based on Bsimulation
runs, and ρis searched for by matching the estimated ARL 0value to the nominal
value. In all our numerical examples presented below, we choose B=10,000.
For on-line process monitoring, which generally handles a large number of pro-
ﬁles, fast implementation is important and some computational issues deserve our
careful examination. For the chart NMEPM, computing the test statistic Tt,h,λby for-
mulas (10.41)–(10.43) requires a considerable amount of computing time and a sub-
stantial amount of storage space as well to save all past proﬁle observations. Next,
we provide updating formulas for computing Tt,h,λ, which can greatly simplify the
computation and reduce the storage requirement. Let
/tildewidem(t,h)
l(s) =nt
∑
i=1(xit−s)lKh(xit−s)/ν2(xit),forl=0,1,2,
/tildewideq(t,h)
l(s) =nt
∑
i=1(xit−s)lKh(xit−s)yit/ν2(xit),forl=0,1.
Then, m(t,h,λ)
l(s)in (10.42) can be recursively updated by
m(t,h,λ)
l(s)=(1−λ)m(t−1,h,λ)
l(s)+/tildewidem(t,h)
l(s), forl=0,1,2,
where m(0,h,λ)
l(s)= 0. Let q(t,h,λ)
l(s), for l=0,1, be two working functions deﬁned
by the recursive formula
q(t,h,λ)
l(s)=(1−λ)q(t−1,h,λ)
l(s)+/tildewideq(t,h)
l(s),
where q(0,h,λ)
l(s)= 0. Then, we have
/hatwidegt,h,λ(s) =/bracketleftig
(1−λ)2M(t−1,h,λ)/hatwidegt−1,h,λ+/parenleftig
/tildewideq(t,h)
0m(t,h,λ)
2−/tildewideq(t,h)
1m(t,h,λ)
1/parenrightig
+(1−λ)/parenleftig
q(t−1,h,λ)
0/tildewidem(t,h)
2−q(t−1,h,λ)
1/tildewidem(t,h)
1/parenrightig/bracketrightig/slashig
M(t,h,λ),(10.44)
where M(t,h,λ)(s) = m(t,h,λ)
2(s)m(t,h,λ)
0(s)−[m(t,h,λ)
0(s)]2. On the right-hand side of432 PROFILE MONITORING
the above equation, dependence on sin each function is not made explicit in notation
for simplicity, which should not cause any confusion.
By using the above updating formulas, implementation of the NMEPM chart
can be brieﬂy summarized as follows. At time point t, we ﬁrst compute quantities
/tildewidem(t,h)
l(s), for l=0,1,2, and/tildewideq(t,h)
l(s), for l=0,1, at n0pre-determined slocations
{sk,k=1,..., n0}(cf., (10.43)). Then, m(t,h,λ)
l(sk), for l=0,1,2, and q(t,h,λ)
l(sk),
forl=0,1, are updated by the above formulas. Finally, /hatwidegt,h,λ(s)is computed from
(10.44), and the test statistic Tt,h,λis computed from /hatwidegt,h,λ(s), after yi jis replaced by
ξi j.
Qiu et al. (2010) provided some practical guidelines for choosing some param-
eters involved in the chart NMEPM, which are summarized below. (i) To attain de-
sirable IC distributional properties, the IC data should be large enough that nj≥20,
for each j, and m≥500. (ii) In estimating the NME model (10.33) by the iterative
procedure described in Subsection 10.3.1, we can use a data-driven bandwidth se-
lection technique, such as the CV procedure by Wu and Zhang (2002). In phase II
proﬁle monitoring, we suggest using the following empirical formula to choose the
bandwidth:
hE=/braceleftigg
c1n−1/5/parenleftbig
∑n
i=1(xi−x)2/n/parenrightbig1/2for balanced design cases
c2[˜n(2−λ)/λ]−1/5/radicalbig
Var(x)for random design cases,(10.45)
where x=1
n∑n
i=1xiis the mean of the ndesign points in the balanced design cases
(i.e., in cases when all proﬁles have the same design points), ˜ nand Var(x )are the
average number of design points and the variance of design points within a proﬁle,
respectively, in the random design cases, which can be estimated from the IC data,
andc1andc2are two constants. Empirically, c1andc2can be chosen as any values
in the interval [1.0,2.0]. (iii) We suggest choosing λ∈[0.02, 0.1]ifhEin (10.45) is
used in phase II SPC. (iv) Based on our numerical experience, selection of {sk,k=
1,2,..., n0}does not much affect the performance of the NMEPM chart, as long
asn0is not too small and sk’s cover all the key parts of g0(e.g., peaks/valleys or
oscillating regions) well. Our numerical examples show that results would hardly
change when n0≥40.
Example 10.4 (continued) For the AEC data discussed in Example 10.4 of the
previous subsection, we construct the NMEPM chart here for phase II monitoring
of the last 48 proﬁles in the data, using the estimated IC parameters discussed in
Example 10.4. In designing the NMEPM chart, the IC ARL is ﬁxed at 200, and
λis chosen to be 0.1. The bandwidth h used in (10.41) and (10.42) is chosen to
be h=1.5[n(2−λ)/λ]−1/5/radicalbig
Var(x). For simplicity, we choose n 0=n=53and
{sk,k=1,2,..., n0}to be equally spaced in the design interval [−26,78]of the pre-
dictor “temperature”. The control limit ρis computed to be 18.24 by simulation.
Values of the charting statistic T t,h,λ, for t=97,98,..., 144, are shown in Figure
10.8 along with the control limit by the solid curve and solid horizontal line, re-
spectively. As a comparison, we also compute the nonparametric ﬁxed-effects proﬁle
monitoring (NFEPM) chart, which is the same as the NMEPM chart except that the
random-effects term f j(xi j)is removed from the model (10.33). Note that the NFEPMSOME DISCUSSIONS 433
chart can be regarded as a generalization of the NPPM chart by Zou et al. (2008);
the latter assumes that design points in different proﬁles are deterministic and un-
changed from one proﬁle to another while the former can handle arbitrary designs.
The NFEPM chart, using the same λand h as those in the NMEPM chart, is also
presented in Figure 10.8 along with its control limit 34.52, by the dashed curve and
the dashed horizontal line. From the plot, it can be seen that the NMEPM chart gives
a signal of proﬁle shift around the 112th time point, and remains above the control
limit for several proﬁles until the 120th proﬁle. This result conﬁrms a marked step-
change that seems to have occurred around the 108th proﬁle. The process seems
to have been adjusted around the 119th proﬁle; thus, the NMEPM charting statistic
goes back below its control limit afterward. As a comparison, the NFEPM chart does
not give a signal until the 118th proﬁle.
100 110 120 130 1400 10 20 30 40
Profile IndexCharting StatisticsNMEPM
NFEPM
Figure 10.8 NMEPM and NFEPM control charts for monitoring the AEC process. The solid
and dashed horizontal lines indicate their control limits, respectively.
10.4 Some Discussions
Proﬁle monitoring is a relatively new research topic. But, it is in rapid development
because of its broad applications. In this chapter, we brieﬂy describe some existing
parametric and nonparametric proﬁle monitoring methods. Regarding the two types
of methods, parametric methods would be more efﬁcient than nonparametric meth-
ods if the related parametric model assumptions are valid. But proper justiﬁcation
of such parametric model assumptions is currently lacking in the proﬁle monitor-
ing literature. In cases when parametric models are inappropriate or unavailable for
describing the observed proﬁle data, nonparametric methods should be used.
Our description about proﬁle monitoring in this chapter is far from complete.
There are new proﬁle monitoring methods appearing in academic journals on a daily
basis. For instance, Yeh et al. (2009) discussed the proﬁle monitoring problem with434 PROFILE MONITORING
a binary response. Yu et al. (2012) recently proposed a nonparametric proﬁle moni-
toring method based on outlier detection in analyzing functional data. Paynabar et al.
(2013) proposed a nonlinear proﬁle monitoring method for monitoring a sequence of
multichannel proﬁles (i.e., the response variable yis multivariate). In several recent
years, statistical monitoring of spatial proﬁle data has attracted much attention from
statisticians. One important application of this research topic concerns the monitor-
ing of image data. See, for instance, Megahed et al. (2011b, 2012). Another impor-
tant application concerns the monitoring of environmental data (cf., Anderson and
Thompson, 2004; Morrison, 2008). Qiu and Xiang (2014, 2013) recently proposed
univariate and multivariate dynamic screening systems (DySS) for identifying irreg-
ular longitudinal patterns. The so-called dynamic screening (DS) problem handled
by these DySS methods is related to the proﬁle monitoring problem discussed in this
chapter.
There are many open research problems in the area of proﬁle monitoring. For
instance, in most existing proﬁle monitoring charts, observations of different pro-
ﬁles are routinely assumed to be independent. In practice, they can be autocorrelated
over time or spatially correlated, as in the conventional SPC problem. In previous
chapters, we have demonstrated several times that results from control charts that are
based on the assumption of independent observations would be unreliable or even
misleading in cases when the observations are actually correlated (cf., e.g., Example
4.5 in Subsection 4.2.2, and Example 5.3 in Subsection 5.2.2). It therefore requires
much future research to handle the proﬁle monitoring problem in cases when both
between-proﬁle observations and within-proﬁle observations are correlated. Further-
more, almost all practical issues related to the conventional control charts are shared
by proﬁle monitoring charts, including proper estimation of the IC values of certain
process parameters used in phase II process monitoring (e.g., g0andσ2used in the
chart (10.43)) and determination of some procedure parameters (e.g., λused in the
chart (10.43)) when designing a phase II control chart. Therefore, self-starting and
adaptive control charts are also relevant in proﬁle monitoring, which have not been
discussed sufﬁciently yet in the literature. When control charts are used for monitor-
ing spatial data (e.g., images), the spatial data structures (e.g., step and roof/valley
edges in images) should be well accommodated in process monitoring. For instance,
when monitoring a sequence of images, it is critical to align them properly before-
hand, which is related to the research area of image registration (cf., Qiu and Xing,
2013a,b; Xing and Qiu, 2011). Otherwise, some statistics summarizing the differ-
ence between an observed image and an IC image may not be meaningful. It there-
fore requires much future research to properly accommodate spatial data structures
in the related control charts. For basic image processing methods, read Gonzalez and
Woods (2007), Pratt (2007), Qiu (2005), and the references cited therein.
10.5 Exercises
10.1 For the charting statistic T2
jdeﬁned in (10.6), verify that its IC distribution is
χ2
2.
10.2 For the data presented in Table 10.1, assume that the IC error variance is knownEXERCISES 435
to be 0.52. Construct a phase II Shewhart chart to monitor the estimated error
variances {/hatwideσ2
j,j=1,2,...}, and apply this chart to the data in Table 10.1.
10.3 For the centered linear regression model (10.8), verify that
(i)a∗
j=aj+bjx, for each j, where ajandbjareregression coefﬁcients in
model (10.1),
(ii) under some regularity conditions, the IC distribution of /hatwidea∗
jisN(a0+
b0x,σ2
0/n), where/hatwidea∗
jis the LS estimator of a∗
j,a0,b0, and σ2
0are IC val-
ues of aj,bj, and σ2,
(iii) under some regularity conditions, /hatwidea∗
jand/hatwidebjare independent of each other.
10.4 Reproduce the results in Figure 10.2.
10.5 Verify that (10.16) is valid for deﬁning the LS estimator of the IC intercept a∗
0
discussed immediately below (10.15).
10.6 For constructing the phase I Shewhart chart (10.17), verify that the IC distri-
bution of the statistic (/hatwidea∗
j−/hatwidea∗
0)//radicalig
m−1
mn/hatwideσ2
0ist(n−2)m. Also, verify that the IC
distribution of Fjdeﬁned in (10.19) is F(n−2),(m−1)(n−2).
10.7 Redo Example 10.2 using the ﬁrst 20 observed proﬁles presented in Table 10.2.
10.8 The data presented in Table 10.4 are the ﬁrst 20 observed proﬁles of a produc-
tion process obtained during a phase II process monitoring. The design points
of all proﬁles are the same, with values 0.1, 0.25, 0.4, 0.55, 0.7, 0.85, and 1.0.
As in Example 10.3, the 2-parameter nonlinear regression model (10.30) is be-
lieved to be appropriate to describe these proﬁles. Use the phase II Shewhart
chart (10.26) and the phase II EWMA chart (10.27)–(10.28) to monitor the es-
timated values {(/hatwidebj,/hatwidedj),j=1,2,..., 20}. In both charts, use χ2
0.995,2=10.597
as the control limits.
10.9 For the calibration data presented in Table 10.2, assume that the following para-
metric model is appropriate to describe the j-th observed proﬁle:
yi j=aj+bjxcj
i+εi j, i=1,2,..., n,j=1,2,..., m,
where aj,bj, and cjare parameters. Apply the Shewhart chart (10.31)–(10.32)
with α=0.005 to this dataset for phase I proﬁle monitoring.
10.10 In model (10.33), for each jandi1,i2=1,2,..., nj, verify that
Cov(yi1j,yi2j)=/braceleftbigg
γ(xi1j,xi1j)+σ2,when i1=i2
γ(xi1j,xi2j), when i1/ne}ationslash=i2.436 PROFILE MONITORING
Table 10.4 The ﬁrst 20 observed proﬁles of a production process obtained during phase II
SPC. The design points of all proﬁles are the same, with values 0.1, 0.25, 0.4, 0.55, 0.7, 0.85,
and 1.0.
j y1j y2j y3j y4j y5j y6j y7j
1 1.768 1.613 1.421 1.379 1.188 1.113 0.942
2 1.890 1.517 1.393 1.299 1.186 1.061 1.074
3 1.831 1.597 1.390 1.341 1.085 1.312 0.956
4 1.895 1.626 1.506 1.209 1.133 1.009 1.023
5 1.702 1.625 1.419 1.466 1.163 1.070 0.931
6 1.796 1.618 1.470 1.397 1.273 1.071 1.140
7 1.641 1.662 1.376 1.423 1.140 1.213 1.004
8 1.630 1.555 1.255 1.308 1.366 0.854 1.098
9 1.678 1.782 1.567 1.206 1.150 1.074 0.962
10 2.076 1.613 1.357 1.354 1.197 1.074 0.991
11 1.530 1.305 1.177 1.316 0.801 0.872 0.641
12 1.512 1.513 1.086 1.241 1.002 0.736 0.557
13 1.556 1.396 1.315 1.233 1.179 0.860 0.694
14 1.628 1.322 1.177 1.099 1.251 0.788 0.791
15 1.367 1.294 1.260 1.288 0.960 0.955 0.604
16 1.445 1.334 1.256 1.276 0.996 0.888 0.775
17 1.424 1.269 1.260 1.164 1.109 0.845 0.720
18 1.647 1.334 1.336 1.093 1.048 0.716 0.698
19 1.457 1.513 1.246 1.181 0.965 0.786 0.819
20 1.439 1.547 1.337 1.137 1.052 0.867 0.796
10.11 Derive formulas (10.41) and (10.42) from the minimization problem
min a,bWL(a,b;s,λ,t), where WL(a,b;s,λ,t)is deﬁned in the second para-
graph of Subsection 10.3.2.Appendix A
RFunctions for SPC
Ris a freely available language and environment for statistical computing and graph-
ics. It can be downloaded from the Comprehensive R Archive Network (CRAN)
web page of the address http://cran.r-project.org/. During the past 15 years, Rhas
become a standard and popular statistical software package that is widely used in
academia and industries. Most ﬁgures in this book are generated in R. Computation
involved in many examples and tables in the book is also accomplished by using
computer codes in R. In this appendix, we make a brief introduction of some basic
functions in Rand some Rpackages that are developed speciﬁcally for SPC analysis.
We also make a list of all Rsource codes that are written by the author and used in
the book. These codes are posted on the author’s home page for free download.
A.1 Basic RFunctions
To enter the Rsoftware, double click the Ricon if you are using a computer running a
windows system, or type the following UNIX/LINUX command after the command
prompt “%”:
% R
Note that you need to hit the Return orEnter key to execute each UNIX/LINUX
orRcommand after typing the command. After the above command is executed,
you will enter the Rsoftware and get some description about it, followed by the R
command prompt
>
You can type any legitimate Rcommands after the prompt “> ”. Here are some
examples of some basic algebraic manipulations.
> 1+2
[1] 3
> 4*2/2
[1] 4
> 4**2
[1] 16
> 4^2 # 4^2 is the same as 4**2
[1] 16
Note that “#” is a sign for comments. Rwill ignore all material written after this sign.
Here are several examples about how to enter data from a keyboard.
437438 RFUNCTIONS FOR SPC
> tmp <- c(1,1,2,2,3,3) # create a numerical vector (1,1,2,2,
> # 3,3) and assign it to the variable
> # named "tmp."
> tmp = c(1,1,2,2,3,3) # same as the previous command.
> c(1,1,2,2,3,3) # show the vector on screen.
[1] 1 1 2 2 3 3
> tmp <- c(T,F,F,F) # create a logical vector (T,F,F,F),
> # where T denotes "true" and F
> # denotes "false."
> tmp <- c(‘‘HOT’’,’’HOT’’,’’COLD’’) # create a character
> # variable.
> length(tmp) # check the length of the vector
[1] 3 # "tmp."
> mode(tmp) # check the mode of the vector "tmp."
[1] ‘‘character’’
> rep(5,3) # create a 3-dimensional vector by
[1] 5 5 5 # repeating 5 three times.
> rep(c(1,2,3),2) # repeat the vector (1,2,3) 2 times.
[1] 1 2 3 1 2 3
> rep(c(1,2),c(3,4)) # create a vector by repeating 1
[1] 1 1 1 2 2 2 2 # three times and then 2 four times.
> 1:10 # create a vector consisting of
[1] 1 2 3 4 5 6 7 8 9 10 # integers from 1 to 10.
> seq(2,4,0.5) # create a vector consisting of
[1] 2 2.5 3 3.5 4 # numbers from 2 to 4 with step 0.5.
> tmp _ scan() # Entering data in the subsequent
1: 2 2 3 # lines from keyboard.
4: 4 9 6
7:
> tmp
[1] 2 2 3 4 9 6
> help(seq) # get some online help about the
> # command "seq."
> q() # exit RBASICRFUNCTIONS 439
Sometimes, we need to enter data into Rfrom an external ﬁle, or write some
results to an external ﬁle. The following Rcommands are for this purpose.
> x <- scan("filename") # Read numerical data from the file
> # "filename" into a vector and assign
> # the vector to the variable x.
> x <- read.table("filename") # Read data in table format
> # from the external file "filename."
> write(x,"filename") # Write the data assigned to x to
> # the external file "filename."
> write.table(x,"filename") # Write the data in table format
> # to the external file "filename."
Here are some Rcommands about the binomial distribution. The use of Rcom-
mands for other parametric distributions is similar.
> dbinom(3,10,0.3) # compute P(X=3) when X has binomial
[1] .2668279 # distribution with n=10 and pi=0.3.
> pbinom(3,10,0.3) # compute P(X<=3) when X has binomial
[1] .6496107 # distribution with n=10 and pi=0.3.
> qbinom(0.4,10,0.3) # Find the smallest x so that P(X<=x)
[1] .6496107 # >= 0.4 (x is the 0.4 quantile).
> rbinom(3,10,0.3) # Generate 3 random numbers from the
[1] 6 3 2 # binomial(10,0.3) distribution.
> x <- seq(0,10) # These commands compute the mean
> dist <- dbinom(x,10,0.3) # of the binomial(10,0.3) distri-
> sum(x*dist) # bution. The command "sum"
[1] 3 # computes the summation of all
# elements of a vector.
> sum(x**2*dist)-3^2 # Computes the variance of the
# binomial(10,0.3) distribution.
Here is an example to make a plot including lines of l(x)=(1−x)10andl(x)=
210x6(1−x)4on the computer screen.
> X11() # Open a window on computer screen.
> x <- seq(0,100)/100 # Create a sequence for x.
> y1 <- (1-x)^10 # Compute function values for line 1.
> y2 <- 210*x^6*(1-x)^4 # Compute function values for line 2.
> plot(x,y1,type=’’l’’,lty=1,xlab=’’pi’’,ylab=’’Likelihood’’)
> lines(x,y2,lty=2)
> dev.off() # Close the plot window.
If you want to put the plot in a postscript ﬁle, instead of showing it in a window, then
you can replace the ﬁrst and last commands above by the following two commands,
respectively.
> postscript(file=’’likelihood.ps’’,width=4in,height=4in,
horizontal=F)
> graphics.off()440 RFUNCTIONS FOR SPC
Again, you can use the command “help(postscript)” to read more about the Rfunc-
tionpostscript() .
A.2RPackages for SPC
There are several Rpackages written speciﬁcally for SPC. In Chapters 4 and 5, we
have used one of them (i.e., the package spc). This package along with several others
are brieﬂy described below.
cpm (Ross, 2012) The package cpm can be used for phase II SPC of univariate
processes under the change point detection (CPD) framework (cf., Chapter 6).
It contains Rfunctions for parametric monitoring of processes with normal and
Bernoulli distributions. It also provides Rfunctions for executing certain nonpara-
metric CPD charts.
mnspc (Bezener and Qiu, 2011) The package mnspc accomplishes the MLL-
CUSUM chart (9.38)–(9.39) discussed in Subsection 9.3.2. A function is provided
to categorize components of multivariate response vectors. Tools for setting up a
CUSUM chart for the transformed data are included. The CUSUM chart can also
be applied to cases when some (or all) of the multivariate response components
are binary-categorical.
msqc (Santos-Fernandez, 2012) The package msqc provides Rfunctions for ex-
ecuting certain conventional multivariate control charts, such as the multivari-
ate Shewhart charts based on Hotelling’s T2statistic, MCUSUM, and MEWMA
charts. It also includes some tools for assessing multivariate normality.
qcc(Scrucca, 2010) The package qcccontains functions for making various She-
whart charts, and the conventional CUSUM and EWMA charts.
spc(Knoth, 2011) The package spccan be used to compute the zero-state and
steady-state IC and OC ARL values of the one- and two-sided EWMA, CUSUM,
and Shiryaev-Roberts charts for monitoring the mean or variance of a normally
distributed univariate production process. This package can also be used for deter-
mining the control limits of the above-mentioned control charts when their ARL 0
values and other parameters are given, and the optimal allowance constant kof a
CUSUM chart or the optimal weighting parameter λof an EWMA chart when
theARL 0value and a target are given.
A.3 List of RFunctions Used in the Book
This part gives a list of all Rfunctions written by the author for this book. The R
functions are organized by chapters. A brief description about the main purpose of
each function is also given.
Chapter 2
ﬁg21.rR-code for making Figure 2.1.
ﬁg22.rR-code for making Figure 2.2.LIST OF RFUNCTIONS USED IN THE BOOK 441
ﬁg23.rR-code for making Figure 2.3.
ﬁg24.rR-code for making Figure 2.4.
ﬁg26.rR-code for making Figure 2.6.
ﬁg27.rR-code for making Figure 2.7.
ﬁg28.rR-code for making Figure 2.8.
ﬁg29.rR-code for making Figure 2.9.
ﬁg210.rR-code for making Figure 2.10.
ﬁg211.rR-code for making Figure 2.11.
ﬁg212.rR-code for making Figure 2.12.
Chapter 3
ﬁg31.rR-code for making Figure 3.1. It reads data from the ﬁle “exam-
ple31.summary.”
ﬁg32.rR-code for making Figure 3.2.
ﬁg33.rR-code for making Figure 3.3.
ﬁg34.rR-code for making Figure 3.4.
ﬁg35.rR-code for making Figure 3.5. It reads data from the ﬁle “exam-
ple31.summary.”
ﬁg36.rR-code for making Figure 3.6. It reads data from the ﬁle “example33.dat.”
ﬁg37.rR-code for making Figure 3.7.
ﬁg38.rR-code for making Figure 3.8.
ﬁg39.rR-code for making Figure 3.9.
ﬁg310.rR-code for making Figure 3.10. It reads data from “example37.dat.”
ﬁg311.rR-code for making Figure 3.11.
table33.r R-code for making Table 3.3
Chapter 4
ex415.rR-code for generating the data ﬁle “ex415.dat” used in Exercise 4.15.
example45ARL0.r R-code for computing the ARL 0values of the upward CUSUM
chart when the data are auto-correlated and follow the AR(1) model. It is used in
Example 4.5 and Table 4.3.
example45ARL1.r R-code for computing the ARL 1values of the upward CUSUM
chart when the data are auto-correlated and follow the AR(1) model. It is used in
Example 4.5 and Table 4.3.
example46.r R-code for computing the residuals of the soil data used in Example
4.6.
example412.r R-code for making Figure 4.12. It also generates the data ﬁle “exam-
ple412.dat” used in Example 4.12.442 RFUNCTIONS FOR SPC
ﬁg41.rR-code for making Figure 4.1. It reads data from “example41.dat.”
ﬁg42.rR-code for making Figure 4.2. It reads data from “example41.dat.”
ﬁg43.rR-code for making Figure 4.3. It reads data from “example41.dat.”
ﬁg44.rR-code for making Figure 4.4. It reads data from “example41.dat.”
ﬁg45.rR-code for making Figure 4.5.
ﬁg46.rR-code for making Figure 4.6.
ﬁg47.rR-code for making Figure 4.7. It reads data from “soil.dat”
ﬁg48.rR-code for making Figure 4.8. It also generates the data ﬁle “example48.dat”
used in Example 4.8.
ﬁg49.rR-code for making Figure 4.9. It reads data from “example48.dat.”
ﬁg410.rR-code for making Figure 4.10. It also generates the data ﬁle “exam-
ple49.dat” used in Example 4.9.
ﬁg411.rR-code for making Figure 4.11.
table44.r R-code for computing the ARL 0values of the upward CUSUM chart
when the data are auto-correlated and follow the AR(1) model and when they
are grouped into batches with batch size m. It is used in Table 4.4.
Chapter 5
example53ARL0.r R-code for computing the ARL 0values of the EWMA chart
when the data are auto-correlated. It is used in Example 5.3 and Table 5.2.
example53ARL1.r R-code for computing the ARL 1values of the EWMA chart
when the data are auto-correlated. It is used in Example 5.3 and Table 5.2.
example57RhoU.r R-code for searching ρUvalue used in Example 5.7.
example59.r R-code for generating data ﬁle “example59.dat” and making Figure
5.13 in Example 5.9.
ﬁg51.rR-code for making Figure 5.1.
ﬁg52.rR-code for making Figure 5.2. It reads data from “example51.dat.”
ﬁg53.rR-code for making Figure 5.3.
ﬁg54.rR-code for making Figure 5.4.
ﬁg55.rR-code for making Figure 5.5.
ﬁg55ARL0chisq.r R-code for computing the actual ARL 0values of the EWMA
chart when the actual process distribution is chi-square. It is used for making
Figure 5.5.
ﬁg55ARL0normal.r R-code for computing the actual ARL 0values of the EWMA
chart when the actual process distribution is normal. It is used for making Figure
5.5.
ﬁg55ARL0t.r R-code for computing the actual ARL 0values of the EWMA chart
when the actual process distribution is t. It is used for making Figure 5.5.LIST OF RFUNCTIONS USED IN THE BOOK 443
ﬁg56.rR-code for making Figure 5.6. It also generates the data ﬁle “example54.dat”
used in Example 5.4.
ﬁg57.rR-code for making Figure 5.7.
ﬁg58.rR-code for making Figure 5.8. It also generates the data ﬁle “example55.dat”
used in Example 5.5.
ﬁg59.rR-code for making Figure 5.9. It reads data from “example55.dat.”
ﬁg510.rR-code for making Figure 5.10. It also generates the data ﬁle “exam-
ple56.dat” used in Example 5.6.
ﬁg511TwoSideRho.r R-code for computing the actual ARL 0value of a 2-sided
EWMA chart for detecting process variance shifts. It is used in Example 5.6 and
Figure 5.11.
ﬁg511.rR-code for making Figure 5.11. It also generates the data ﬁle “exam-
ple56.dat” used in Example 5.6.
ﬁg512.rR-code for making Figure 5.12. It also generates the data ﬁle “exam-
ple57.dat” used in Example 5.7.
ﬁg514.rR-code for making Figure 5.14.
ﬁg515.rR-code for making Figure 5.15. It also generates the data ﬁle “exam-
ple510.dat” used in Example 5.10.
table53.r R-code for computing numbers in Table 5.3. It needs to use the R-package
spcwhich should be installed beforehand.
table54RhoU.r R-code for computing ρUvalues in Table 5.4.
table54RhoL.r R-code for computing ρLvalues in Table 5.4.
table55ARL0TwoSided.r R-code for computing ARL 0values of the two-sided
EWMA chart considered in Table 5.5.
table55ARL0Upward.r R-code for computing ARL 0values of the upward EWMA
chart considered in Table 5.5.
table55ARL1TwoSided.r R-code for computing ARL 1values of the two-sided
EWMA chart considered in Table 5.5.
table55ARL1Upward.r R-code for computing ARL 1values of the upward EWMA
chart considered in Table 5.5.
Chapter 6
example61.r R-code for Example 6.1. It writes the related data to the ﬁle “exam-
ple61.dat.”
example62.r R-code for Example 6.2. It writes the related data to the ﬁle “exam-
ple62.dat.” It also creates “ﬁg61.ps.”
example64.r R-code for Example 6.4. It writes the related data to the ﬁle “exam-
ple64.dat.” It also creates “ﬁg63.ps.”
example65.r R-code for Example 6.5. It writes the related data to the ﬁle “exam-
ple65.dat.” It also creates “ﬁg65.ps.”444 RFUNCTIONS FOR SPC
ﬁg62.rR-code for making Figure 6.2.
ﬁg66.rR-code for making Figure 6.6.
Chapter 7
ex722.rR-code for generating data used in Exercise 7.22.
example71.r R-code for Example 7.1. It writes the related data to the ﬁle “exam-
ple71.dat.” It also makes “ﬁg73.ps.”
example71a.r R-code for Example 7.1(continued). It also makes “ﬁg74.ps.”
example72.r R-code for Example 7.2. It writes the related data to the ﬁle “exam-
ple72.dat.” It also makes “ﬁg75.ps.”
example73.r R-code for Example 7.3. It writes the related data to the ﬁle “exam-
ple73.dat.” It also makes “ﬁg76.ps.”
example73Searchh1.r R-code for searching for the control limit hof the chart
(7.25).
example73Searchh2.r R-code for searching for the control limit hof the chart
(7.26)–(7.27).
example74.r R-code for Example 7.4. It writes the related data to the ﬁle “exam-
ple74a.dat,” “example74b.dat,” and “example74c.dat.” It also makes “ﬁg77.ps.”
example74Searchh1.r R-code for searching for the control limit hof the chart
(7.32)–(7.33).
example74Searchh2.r R-code for searching for the control limit hof the chart
(7.30)–(7.31).
example75.r R-code for Example 7.5. It writes the related data to the ﬁle “exam-
ple75.dat.” It also makes “ﬁg78.ps.”
example76.r R-code for Example 7.6. It writes the related data to the ﬁle “exam-
ple76.dat.” It also makes “ﬁg79.ps.”
example76Searchh.r R-code for searching for the control limit hof the chart
(7.45)–(7.46).
example77.r R-code for Example 7.7. It writes the related data to the ﬁle “exam-
ple77.dat.” It also makes “ﬁg710.ps.”
example78.r R-code for Example 7.8. It writes the related data to the ﬁle “exam-
ple78.dat.” It also makes “ﬁg711.ps.”
ﬁg71.rR-code for making Figure 7.1.
ﬁg72.rR-code for making Figure 7.2.
Chapter 8
ex85.rR-code for generating data used in Exercise 8.5.
ex86.rR-code for generating data used in Exercise 8.6.
ex810.rR-code for generating data used in Exercise 8.10.LIST OF RFUNCTIONS USED IN THE BOOK 445
ex815.rR-code for generating data used in Exercise 8.15.
ex816.rR-code for generating data used in Exercise 8.16.
example81.r R-code for Example 8.1. It writes the related data to the ﬁle “exam-
ple81.dat.” It also makes “ﬁg82.ps.”
example82.r R-code for Example 8.2. It writes the related data to the ﬁle “exam-
ple82.dat.” It also makes “ﬁg83.ps.”
example83.r R-code for Example 8.3. It writes the related data to the ﬁle “exam-
ple83.dat.” It also makes “ﬁg84.ps.”
example84.r R-code for Example 8.4. It writes the related data to the ﬁle “exam-
ple84.dat.” It also makes “ﬁg85.ps.”
example85.r R-code for Example 8.5. It writes the related data to the ﬁle “exam-
ple85.dat.” It also makes “ﬁg86.ps.”
example86.r R-code for Example 8.6. It writes the related data to the ﬁle “exam-
ple86.dat.” It also makes “ﬁg88.ps.”
example87.r R-code for Example 8.7. It writes the related data to the ﬁle “exam-
ple87.dat.” It also makes “ﬁg89.ps.”
example88.r R-code for Example 8.8. It writes the related data to the ﬁle “exam-
ple88.dat.” It also makes “ﬁg810.ps.”
ﬁg87.rR-code for making Figure 8.7.
Chapter 9
ex93.rR-code for generating data used in Exercise 9.3.
ex97.rR-code for generating data used in Exercise 9.7.
ex99.rR-code for generating data used in Exercise 9.9.
ex913.rR-code for generating data used in Exercise 9.13.
example91.r R-code for Example 9.1. It writes the related data to the ﬁle “exam-
ple91.dat.” It also makes “ﬁg93.ps.”
example92.r R-code for Example 9.2. It writes the related data to the ﬁle “exam-
ple92.dat.” It also makes “ﬁg94.ps.”
example93.r R-code for Example 9.3. It writes the related data to the ﬁle “exam-
ple93.dat.” It also makes “ﬁg95.ps.”
ﬁg91.rR-code for making Figure 9.1.
ﬁg92.rR-code for making Figure 9.2.
ﬁg96.rR-code for making Figure 9.6. It reads data from “soilResidual.dat.”
ﬁg97.rR-code for making Figure 9.7. It reads data from “soil.dat.”
ﬁg98.rR-code for making Figure 9.8. It reads data from ﬁles “ﬁg98crit1.dat” and
“ﬁg98crit2.dat.”
ﬁg99.rR-code for making Figure 9.9.446 RFUNCTIONS FOR SPC
Chapter 10
ex107.rR-code for generating data used in Exercise 10.7.
example101.r R-code for Example 10.1. It writes the related data to the ﬁle “exam-
ple101.dat.” It also makes “ﬁg101.ps.”
example101a.r R-code for Example 10.1 (continued). It also makes “ﬁg102.ps.”
example102.r R-code for Example 10.2. It writes the related data to the ﬁle “exam-
ple102.dat.” It also makes “ﬁg103.ps.”
example103.r R-code for Example 10.3. It writes the related data to the ﬁle “exam-
ple103.dat.” It also makes “ﬁg104.ps.”
example103a.r R-code for Example 10.3 (continued). It also makes “ﬁg105.ps.”Appendix B
Datasets Used in the Book
This appendix gives a list of all datasets used in the book, along with some brief
descriptions. They are posted on the author’s home page for free download.
ex35.dat Data used in Exercise 3.5.
ex39.dat Data used in Exercise 3.9.
ex318.dat Data used in Exercise 3.18.
ex415.dat Data used in Exercise 4.15.
ex421.dat Data used in Exercise 4.21.
ex722.dat Data used in Exercise 7.22.
ex85.dat Data used in Exercise 8.5.
ex86.dat Data used in Exercise 8.6.
ex810.dat Data used in Exercise 8.10.
ex815.dat Data used in Exercise 8.15.
ex816.dat Data used in Exercise 8.16.
ex93.dat Data used in Exercise 9.3.
ex97.dat Data used in Exercise 9.7.
ex99.dat Data used in Exercise 9.9.
ex913.dat Data used in Exercise 9.13.
ex107.dat Data used in Exercise 10.7.
example31.dat Original data used in Example 3.1. Note that we only use the ﬁrst
120 data points of this ﬁle in the example.
example31.summary Summary statistics included in Table 3.2. Note that we only
use the ﬁrst 24 lines of this ﬁle in Table 3.2.
example33.dat Original data used in Example 3.3.
example37.dat Original data used in Example 3.7.
example41.dat Original data used in Example 4.1.
example48.dat Original data used in Example 4.8.
example49.dat Original data used in Example 4.9.
example412.dat Original data used in Example 4.12.
447448 DATASETS USED IN THE BOOK
example51.dat Original data used in Example 5.1.
example54.dat Original data used in Example 5.4.
example55.dat Original data used in Example 5.5.
example56.dat Original data used in Example 5.6.
example57.dat Data used in Example 5.7. The ﬁrst four columns are the sample
means in four different cases, and the remaining four columns are the sample
standard deviations.
example59.dat The columns in this dataset are n,Xn,Xn,sn,Zn,En, and En,SSused
inExample 5.9.
example510.dat Original data used in Example 5.10.
example61.dat The three columns in the data are Xi,/tildewideS2
i, and/hatwide/tildewideS2
ipresented in Table
6.1 of Example 6.1.
example62.dat The three columns in the data are i,Xi,X2(2,h)+ Q(h, 30), and
X2(1,h)+ Q(h, 20)shown in Figure 6.1 of Example 6.2.
example64.dat The ﬁve columns in the data are Xn,Wn,S2
n,Tmax,n, and hnpresented
in Table 6.3 of Example 6.4.
example65.dat The ﬁve columns in the data denote Xn,Wn,S2
n,Bmax,n, and hnpre-
sented in Table 6.6 of Example 6.5.
example71.dat The ﬁve columns in the data are X1,X2,X3presented in Table 7.1,
andXandT2
1,iused in Example 7.1.
example72.dat The ﬁrst three columns in the data are X1,X2,X3presented in Figure
7.5(a)(c)(e), and the last column is T2
0,nused in Example 7.2.
example73.dat The ﬁrst three columns in the data are X1,X2,X3presented in Figure
7.6(a)(b)(c), the fourth column is Cndeﬁned in (7.25), and the ﬁfth column is /tildewideCn
deﬁned in (7.26). This data is used in Example 7.3.
example74a.dat Data in case (i) considered in Example 7.4. The ﬁrst three columns
contain observations of X1,X2,X3, the remaining three columns contain values of
T2
n,Cndeﬁned in (7.32), and /tildewideCndeﬁned in (7.31).
example74b.dat Data in case (ii) considered in Example 7.4. The ﬁrst three columns
contain observations of X1,X2,X3, the remaining three columns contain values of
T2
n,Cndeﬁned in (7.32), and /tildewideCndeﬁned in (7.31).
example74c.dat Data in case (iii) considered in Example 7.4. The ﬁrst three
columns contain observations of X1,X2,X3, the remaining three columns contain
values of T2
n,Cndeﬁned in (7.32), and /tildewideCndeﬁned in (7.31).
example75.dat The ﬁrst three columns in the data are X1,X2,X3, the fourth–sixth
columns are Endeﬁned in (7.39), and the last column is V2
ndeﬁned in (7.40). This
data is used in Example 7.5.
example76.dat The ﬁrst three columns in the data are X1,X2,X3, the fourth–sixth
columns are undeﬁned in (7.44), the seventh–ninth columns are En,SSdeﬁned inDATASETS USED IN THE BOOK 449
(7.45), and the last column is V2
n,SSdeﬁned in (7.46). This data is used in Example
7.6.
example77.dat The ﬁrst three columns in the data are X1,X2,X3, the fourth–sixth
columns are Yndeﬁned in (7.50), and the last column is Cndeﬁned in (7.52). This
data is used in Example 7.7.
example78.dat The ﬁrst three columns in the data are X1,X2,X3, the fourth–sixth
columns are X0,r, and the last two columns are T2
max,nandhndeﬁned in (7.54) and
(7.56). This data is used in Example 7.8.
example81.dat The ﬁrst ten columns are the batch data with batch size m=10, and
the last column is Ψideﬁned in (8.1). This data is used in Example 8.1.
example82.dat The ﬁrst ﬁve columns are the batch data with batch size m=5, and
the last column is the median Xi(3)shown in Figure 8.3(b). This data is used in
Example 8.2.
example83.dat The ﬁrst six columns are the batch data with batch size m=6, and
the last two columns are ΨnandC+
ndeﬁned in (8.7) and (8.8). This data is used
in Example 8.3.
example84.dat The ﬁrst ﬁve columns are the batch data with batch size m=5, the
sixth column is Wn, and the last two columns are C+
nandC−
ndeﬁned in (8.10) and
(8.12). This data is used in Example 8.4.
example85.dat The ﬁrst ten columns are the batch data with batch size m=10, the
eleventh column is Ψn, and the last column is Endeﬁned in (8.17). This data is
used in Example 8.5.
example86.dat The ﬁrst column is the reference sample, the second column con-
tains the phase II data, the third column is Fn,λ(Xn), the fourth column is /hatwideF0(Xn),
the ﬁfth column is /tildewideGn, and the last column is En,SS. This data is used in Example
8.6.
example87.dat The ﬁrst and the second columns are XnandTmax,ndeﬁned in (8.28).
This data is used in Example 8.7.
example88.dat The ﬁrst column is the data Xn, and the last two columns are Bnand
Cn,Pdeﬁned in (8.34). This data is used in Example 8.8.
example91.dat Original data used in Example 9.1.
example92.dat The ﬁrst two columns are the original data, and the last three
columns are r(Xn;F0M),Sn(F0M)andS∗
n(F0M)deﬁned in (9.19). This data is used
in Example 9.2.
example93.dat The ﬁrst two columns are the original data, and the last column is
r(Xni;F0M)used in (9.22). This data is used in Example 9.3.
example101.dat The proﬁle data presented in Table 10.1 of Example 10.1.
example102.dat The proﬁle data presented in Table 10.2 of Example 10.2.
example103.dat The proﬁle data presented in Table 10.3 of Example 10.3.450 DATASETS USED IN THE BOOK
ﬁg87.dat The ﬁrst ﬁve columns are the batch data with batch size m=5, the sixth
column is Wn, and the last column is Endeﬁned in (8.20). This data is used in
Figure 8.7.
ﬁg98crit1.dat The ﬁrst column is the case id, and the second column is Cn1used in
Figure 9.8(a).
ﬁg98crit2.dat The ﬁrst column is the case id, and the second column is Cn15used in
Figure 9.8(b).
ﬁg910.dat The ﬁrst column is the case id, and the second column is Cnused in
Figure 9.10.
soil.dat This is the aluminum smelter dataset. It is used in Example 2.5, Figure 2.12,
Example 4.6, Figure 4.7, Figure 9.7.
soilResidual.dat This dataset contains the residuals of the soil.dat after auto-
correlation is removed by a time series model. It is used in Figure 9.7.Bibliography
B.M. Adams and I.T. Tseng. Robustness of forecast-based monitoring schemes.
Journal of Quality Technology, 30:328–339, 1998.
A. Agresti. Categorical data analysis. John Wiley & Sons, New York, NY , USA,
2nd edition, 2002.
A. Agresti and B.A. Coull. Approximate is better than ’exact’ for interval estimation
of binomial proportions. The American Statistician, 52:119–126, 1998.
W. Albers. Control charts for health care monitoring under overdispersion. Metrika,
74:67–83, 2011.
W. Albers and W.C.M. Kallenberg. Empirical nonparametric control charts: estima-
tion effects and corrections. Journal of Applied Statistics, 31:345–360, 2004.
W. Albers and W.C.M. Kallenberg. CUMIN charts. Metrika, 70:111–130, 2009.
W. Albers, W.C.M. Kallenberg, and S. Nurdiati. Data driven choice of control
charts. Journal of Statistical Planning and Inference, 136:909–941, 2006.
D. Allen. The relationship between variable selection and data augmentation and a
method for prediction. Technometrics, 16:125–127, 1974.
J.A. Alloway, Jr. and M. Raghavachari. Control chart based on the Hodges-
Lehmann estimator. Journal of Quality Technology, 23:336–347, 1991.
F.B. Alt. Multivariate quality control. The Encyclopedia of Statistical Sciences (S.
Kotz, N.L. Johnson, and C.R. Read, eds.), pages 110–122, 1985.
N.S. Altman. Kernel smoothing of data with correlated errors. Journal of the
American Statistical Association, 85:749–759, 1990.
L.C. Alwan. Effects of autocorrelation on control chart performance. Communica-
tions in Statistics - Theory and Methods, 21:1025–1049, 1992.
L.C. Alwan and H.V . Roberts. Time-series modeling for statistical process control.
Journal of Business and Economic Statistics, 6:87–95, 1988.
R. Amin and A.J. Searcy. A nonparametric exponentially weighted moving average
control scheme. Communications in Statistics - Simulation and Computation,
20:1049–1072, 1991.
R. Amin and O. Widmaier. Sign control charts with variable sampling intervals.
Communications in Statistics - Theory and Methods, 28:1961–1985, 1999.
R. Amin, M.R. Reynolds, Jr., and S.T. Bakir. Nonparametric quality control charts
based on the sign statistic. Communications in Statistics - Theory and Methods,
24:1597–1623, 1995.
451452 BIBLIOGRAPHY
M.J. Anderson and A.A. Thompson. Multivariate control charts for ecological and
environmental monitoring. Ecological Applications, 14:1921–1935, 2004.
T.W. Anderson. An Introduction to Multivariate Statistical Analysis. John Wiley &
Sons, New York, NY , USA, 3rd edition, 2003.
F. Aparisi, J. Jabaloyes, and A. Carrion. Statistical properties of the |S|multivariate
control chart. Communications in Statistics - Theory and Methods, 28:2671–
2686, 1999.
F. Aparisi, J. Jabaloyes, and A. Carrion. Generalized variance chart design with
adaptive sample sizes. Communications in Statistics - Simulation and Compu-
tation, 30:931–948, 2001.
D.W. Apley and H.C. Lee. Design of exponentially weighted moving average con-
trol charts for autocorrelated processes with model uncertainty. Technometrics,
45:187–198, 2003.
D.W. Apley and J. Shi. The GLRT for statistical process control of autocorrelated
processes. IIE Transactions, 31:1123–1134, 1999.
R.B. Ash. Real Analysis and Probability. Academic Press, San Diego, CA, USA,
1972.
S.T. Bakir. A distribution-free Shewhart quality control chart based on signed-ranks.
Quality Engineering, 16:613–623, 2004.
S.T. Bakir. Distribution-free quality control charts based on signed-rank-like statis-
tics. Communications in Statistics - Theory and Methods, 35:743–757, 2006.
S.T. Bakir and M.R. Reynolds, Jr. A nonparametric procedure for process control
based on within group ranking. Technometrics, 21:175–183, 1979.
M.S. Bartlett. Property of sufﬁciency and statistical tests. Proceedings of the Royal
Society of London (Series A), 160:268–282, 1937.
M.S. Bartlett. Approximate conﬁdence intervals: III. a bias correction. Biometrika,
42:201–204, 1955.
M.S. Bartlett and D.G. Kendall. The statistical analysis of variance-heterogeneity
and the logarithmic transformation. Supplement to the Journal of the Royal
Society of London, 8:128–138, 1946.
D.M. Bates and D.G. Watts. Nonlinear Regression Analysis and Its Applications.
John Wiley & Sons, New York, NY , USA, 2007.
R.E. Bellman and S.E. Dreyfus. Applied Dynamic Programming. Princeton Uni-
versity Press, Princeton, NJ, USA, 1962.
S. Bersimis, S. Psarakis, and J. Panaretos. Multivariate statistical process control
charts: an overview. Quality and Reliability Engineering International, 23:
517–543, 2007.
M. Bezener and P. Qiu. mnspc: multivariate nonparametric statisti-
cal process control. Rpackage version 1.01, pages http://CRAN.r–
project.org/package=mnspc, 2011.
P.K. Bhattacharya. Some aspects of change-point analysis. In Change-Point Prob-BIBLIOGRAPHY 453
lems (E. Carlstein, H.G. M ¨uller, and D. Siegmund, eds.), pages 28–56, Hay-
ward, CA, USA, 1994. IMS Monograph.
P.J. Bickel and B. Li. Regularization in statistics. Test, 15:271–344, 2006.
A.F. Bissell. CUSUM techniques for quality control (with discussions). Applied
Statistics, 18:1–30, 1969.
A.F. Bissell. The performance of control charts and Cusums under linear trend.
Applied Statistics, 33:145–151, 1984a.
A.F. Bissell. Estimation of linear trend from a CUSUM chart or tabulation. Applied
Statistics, 33:152–157, 1984b.
G. Black, J. Smith, and S. Wells. The impact of Weibull data and autocorrelation on
the performance of the Shewhart and exponentially weighted moving average
control charts. International Journal of Industrial Engineering Computations,
2:575–582, 2011.
J.M. Boone and S. Chakraborti. Two simple Shewhart-type multivariate nonpara-
metric control charts. Applied Stochastic Models in Business and Industry, 28:
130–140, 2012.
C.M. Borror, C.W. Champ, and S.E. Ridgon. Poisson EWMA control charts. Jour-
nal of Quality Technology, 30:352–361, 1998.
C.M. Borror, D.C. Montgomery, and G.C. Runger. Robustness of the EWMA con-
trol chart to non-normality. Journal of Quality Technology, 31:309–316, 1999.
P.D. Bourke. The geometric CUSUM chart with sampling inspection for monitoring
fraction defective. Journal of Applied Statistics, 28:951–972, 2001.
G.E.P. Box and G.C. Tiao. A change in level of non-stationary time series.
Biometrika, 52:181–192, 1965.
G.E.P. Box, G.M. Jenkins, and G.C. Reinsel. Time Series Analysis: Forecasting and
Control. Springer, New York, NY , USA, 4th edition, 2008.
L. Breiman. Heuristics of instability and stabilization in model selection. The
Annals of Statistics, 24:2350–2383, 1996.
L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classiﬁcation and Re-
gression Trees. Wadsworth, Belmont, CA, USA, 1984.
P.J. Brockwell and R.A. Davis. Time Series: Theory and Methods. Springer, New
York, NY , USA, 2nd edition, 2009.
B.E. Brodsky and B.S. Darkhovsky. Nonparametric Methods in Change-Point
Problems. Kluwer Academic Publishers, AA Dordrecht, The Netherlands,
1993.
D. Brook and D.A. Evans. An approach to the probability distribution of CUSUM
run length. Biometrika, 59:539–549, 1972.
L.D. Brown, T.T. Cai, and A. DasGupta. Interval estimation for a binomial propor-
tion. Statistical Science, 16:101–133, 2001.
G. Capizzi and G. Masarotto. An adaptive exponentially weighted moving average454 BIBLIOGRAPHY
control chart. Technometrics, 45:199–207, 2003.
G. Capizzi and G. Masarotto. A least angle regression control chart for multidimen-
sional data. Technometrics, 53:285–296, 2011.
G. Casella and R.L. Berger. Statistical Inference. Duxbury Press, Paciﬁc Grove,
CA, USA, 2nd edition, 2002.
P. Castagliola and P.E. Maravelakis. A CUSUM control chart for monitoring the
variance when parameters are estimated. Journal of Statistical Planning and
Inference, 141:1463–1478, 2011.
S. Chakraborti and S. Eryilmaz. A nonparametric Shewhart-type signed-rank con-
trol chart based on runs. Communications in Statistics - Simulation and Com-
putation, 36:335–356, 2007.
S. Chakraborti and P. van der Laan. Precedence tests and conﬁdence bounds for
complete data: an overview and some results. Journal of the Royal Statistical
Society (Series D) - The Statistician, 45:351–369, 1996.
S. Chakraborti and P. van der Laan. An overview of precedence tests for censored
data. Biometrical Journal, 39:99–116, 1997.
S. Chakraborti and P. van der Laan. Precedence probability and prediction intervals.
Journal of the Royal Statistical Society (Series D) - The Statistician, 49:219–
228, 2000.
S. Chakraborti, P. van der Laan, and S.T. Bakir. Nonparametric control charts: an
overview and some results. Journal of Quality Technology, 33:304–315, 2001.
S. Chakraborti, P. van der Laan, and M.A. van de Wiel. A class of distribution-free
control charts. Journal of the Royal Statistical Society (Series C) - Applied
Statistics, 53:443–462, 2004.
S. Chakraborti, S. Eryilmaz, and S.W. Human. A phase II nonparametric control
chart based on precedence statistics with runs-type signaling rules. Computa-
tional Statistics and Data Analysis, 53:1054–1065, 2009.
I.M. Chakravarti, R.G. Laha, and J. Roy. Handbook of Methods of Applied Statis-
tics. John Wiley & Sons, New York, NY , USA, 1967.
C.W. Champ and W.H. Woodall. Exact results for Shewhart control charts with
supplementary runs rules. Technometrics, 29:393–399, 1987.
S. Chatterjee and P. Qiu. Distribution-free cumulative sum control charts using
bootstrap-based control limits. Annals of Applied Statistics, 3:349–369, 2009.
J. Chen and A.K. Gupta. Testing and locating variance changepoints with appli-
cation to stock prices. Journal of the American Statistical Association, 92:
739–747, 1997.
J. Chen and A.K. Gupta. Parametric Statistical Change Point Analysis. Birkh ¨auser
Boston, Boston, MA, USA, 2000.
S. Chib. Estimation and comparison of multiple change-points models. Journal of
Economics, 86:221–241, 1998.
E. Chicken, J.J. Pignatiello, Jr., and J.R. Simpson. Statistical process monitoring ofBIBLIOGRAPHY 455
nonlinear proﬁles using wavelets. Journal of Quality Technology, 41:198–212,
1998.
H. Choi, H. Ombao, and B. Ray. Sequential change-point detection methods for
nonstationary time series. Technometrics, 50:40–52, 2008.
Y .M. Chou, A.M. Polansky, and R.L. Mason. Transforming non-normal data to
normality in statistical process control. Journal of Quality Technology, 30:
133–141, 1998.
K.L. Chung. A Course In Probability Theory. Academic Press, San Diego, CA,
USA, 3rd edition, 2001.
W.G. Cochran. Sampling Techniques: Probability and Mathematical Statistics.
John Wiley & Sons, New York, NY , USA, 2nd edition, 1977.
A.F.B. Costa. Joint XandRcharts with variable parameters. IIE Transactions, 30:
505–514, 1998.
R.B. Crosier. Multivariate generalizations of cumulative sum quality-control
schemes. Technometrics, 30:291–303, 1988.
S.V . Crowder. Average run lengths of exponentially weighted moving average con-
trol charts. Journal of Quality Technology, 19:161–164, 1987a.
S.V . Crowder. A simple method for studying run length distributions of exponen-
tially weighted moving average control charts. Technometrics, 29:401–407,
1987b.
S.V . Crowder. Design of exponentially weighted moving average schemes. Journal
of Quality Technology, 21:155–162, 1989.
S.V . Crowder and M. Hamilton. Average run lengths of EWMA control charts for
monitoring a process standard deviation. Journal of Quality Technology , 24:
44–50, 1992.
M. Davidian and D.M. Giltinan. Nonlinear Models for Repeated Measurement
Data. Chapman and Hall, London, UK, 1995.
R.B. Davis and W.H. Woodall. Performance of the control chart trend rule under
linear shift. Journal of Quality Technology, 20:260–262, 1988.
C. Derman and S.M. Ross. Statistical Aspects of Quality Control. Academic Press,
San Diego, CA, USA, 1997.
J.L. Devore. Probability and Statistics for Engineering and the Sciences. Duxbury
Press, Paciﬁc Grove, CA, USA, 8th edition, 2011.
P.J. Diggle, K.Y . Liang, and S.L. Zeger. Analysis of Longitudinal Data. Oxford
University Press, New York, USA, 1994.
Y . Ding, L. Zeng, and S. Zhou. Phase I analysis for monitoring nonlinear proﬁles in
manufacturing processes. Journal of Quality Technology, 38:199–216, 2006.
W.J. Dixon and F.J. Massey. Introduction to Statistical Analysis. McGraw-Hill
Book Company, New York, NY , USA, 3rd edition, 1969.
R. Domangue and S.C. Patch. Some omnibus exponentially weighted moving aver-456 BIBLIOGRAPHY
age statistical process monitoring schemes. Technometrics, 33:299–313, 1991.
J.L. Doob. Stochastic Processes. John Wiley & Sons, New York, NY , USA, 1953.
F.D.J. Dunstan, A.B.J. Nix, and J.F. Reynolds. Statistical Tables. R.N.D. Publica-
tions, Cardiff, United Kingdom, 1979.
M.L. Eaton. Multivariate Statistics. John Wiley & Sons, New York, NY , USA,
1983.
M.L. Eaton. Multivariate Statistics: A Vector Space Approach. Lecture Notes–
Monograph Series, V olume 53, Institute of Mathematical Statistics, Beach-
wood, OH, USA, 2007.
B. Efron. Bootstrap methods: another look at the jackknife. The Annals of Statistics,
7:1–26, 1979.
B. Efron. Least angle regression. The Annals of Statistics, 32:407–489, 2004.
B. Efron and R. Tibshirani. An Introduction to the Bootstrap. Chapman &
Hall/CRC, Boca Raton, FL, USA, 1993.
J.R. English, S.C. Lee, T.W. Martin, and C. Tilmon. Detecting changes in autore-
gressive processes with X and EWMA charts. IIE Transactions, 32:1103–1113,
2000.
W.D. Ewan. When and how to use CUSUM charts. Technometrics, 5:1–22, 1963.
J. Fan and R. Li. Variable selection via nonconcave penalized likelihood and its
oracle properties. Journal of the American Statistical Association, 96:1348–
1360, 2001.
J. Fan and J. Zhang. Two-step estimation of functional linear models with applica-
tions to longitudinal data. Journal of the Royal Statistical Society (Series B),
62:303–322, 2000.
J. Fan, C. Zhang, and J. Zhang. Generalized likelihood ratio statistics and Wilks
phenomenon. The Annals of Statistics, 29:153–193, 2001.
S.K.S. Fan, Y .J. Chang, and N. Aidara. Nonlinear proﬁle monitoring of reﬂow
process data based on the sum of sine functions. Quality and Reliability Engi-
neering International, page doi: 10.1002/qre.1425, 2012.
K.T. Fang, S. Kotz, and K.W. Ng. Symmetric Multivariate and Related Distribu-
tions. Chapman and Hall, New York, NY , USA, 1990.
P. Fearnhead. Exact and efﬁcient bayesian inference for multiple changepoint prob-
lems. Statistics and Computing, 16:203–213, 2006.
W.H. Fellner. AS 258: average run length for cumulative sum scheme. Applied
Statistics, 39:402–412, 1990.
T.S. Ferguson. Mathematical Statistics: A Decision Theoretical Approach. Aca-
demic Press, Inc., New York, NY , USA, 1967.
C. Fuchs and R.S. Kenett. Multivariate Quality Control. Marcel Dekker, New York,
NY , USA, 1998.
F.F. Gan. Monitoring Poisson observations using modiﬁed exponentially weightedBIBLIOGRAPHY 457
moving average control charts. Communications in Statistics: Simulation and
Computation, 19:103–124, 1990a.
F.F. Gan. Monitoring observations generated from a binomial distribution using
modiﬁed exponentially weighted moving average control chart. Journal of
Statistical Computation and Simulation, 37:45–60, 1990b.
F.F. Gan. An optimal design of CUSUM quality control charts. Journal of Quality
Technology, 23:279–286, 1991a.
F.F. Gan. EWMA control chart under linear drift. Journal of Statistical Computation
and Simulation, 38:181–200, 1991b.
F.F. Gan. Exact run length distributions for one-sided exponential CUSUM
schemes. Statistica Sinica, 2:197–312, 1992a.
F.F. Gan. CUSUM control charts under linear drift. The Statistician, 41:71–84,
1992b.
F.F. Gan. The run length distribution of a cumulative sum control chart. Journal of
Quality Technology, 25:205–215, 1993a.
F.F. Gan. An optimal design of CUSUM control charts for binomial counts. Journal
of Applied Statistics, 20:445–460, 1993b.
F.F. Gan. Joint monitoring of process mean and variance using exponentially
weighted moving average control charts. Technometrics, 37:446–453, 1995.
D.A. Garvin. Competing in the eight dimensions of quality. Harvard Business
Review, 87:101–109, 1987.
E.I. George and D.P. Foster. The risk inﬂation criterion for multiple regression. The
Annals of Statistics, 22:1947–1975, 1994.
J.D. Gibbons and S. Chakraborti. Nonparametric statistical inference. Marcel
Dekker, Inc., New York, NY , USA, 4th edition, 2003.
I. Gijbels, A. Lambert, and P. Qiu. Jump-preserving regression and smoothing
using local linear ﬁtting: a compromise. Annals of the Institute of Statistical
Mathematics, 59:235–272, 2007.
A.L. Goel and S.M. Wu. Determination of A.R.L. and a contour nomogram for
CUSUM charts to control normal mean. Technometrics, 13:221–230, 1971.
E. Gombay. Sequential change-point detection and estimation. Sequential Analysis,
22:203–222, 2003.
E. Gombay. Change detection in autoregressive time series. Journal of Multivariate
Analysis, 99:451–464, 2008.
R.C. Gonzalez and R.E. Woods. Digital Image Processing . Prentice Hall, Upper
Saddle River, NJ, USA, 3rd edition, 2007.
M.A. Graham, S.W. Human, and S. Chakraborti. A Phase I nonparametric
Shewhart-type control chart based on the median. Journal of Applied Statistics,
37:1795–1813, 2010.
M.A. Graham, S. Chakraborti, and S.W. Human. A nonparametric exponentially458 BIBLIOGRAPHY
weighted mo ving average signed-rank chart for monitoring location. Compu-
tational Statistics and Data Analysis, 55:2490–2503, 2011.
O.A. Grigg, D.J. Spiegelhalter, and H.E. Jones. Local and marginal control charts
applied to methicillin resistant Staphylococcus aureus bacteraemia reports in
UK acute National Health Service trusts. Journal of the Royal Statistical Soci-
ety (Series A), 172:49–66, 2009.
F. Gustafsson. Adaptive Filtering and Change Detection. John Wiley & Sons, New
York, NY , USA, 2000.
S.J. Haberman. Log-linear models and frequency tables with small expected cell
counts. The Annals of Statistics, 5:1148–1169, 1977.
P. Hackl and J. Ledolter. A control chart based on ranks. Journal of Quality Tech-
nology, 23:117–124, 1991.
P. Hackl and J. Ledolter. A new nonparametric quality control technique. Commu-
nications in Statistics-Simulation and Computation, 21:423–443, 1992.
D. Han and F. Tsung. A generalized EWMA control chart and its comparison with
the optimal EWMA, CUSUM and GLR schemes. The Annals of Statistics, 32:
316–339, 2004.
D. Han, F. Tsung, X. Hu, and K. Wang. CUSUM and EWMA multi-charts for
detecting a range of mean shifts. Statistica Sinica, 17:1139–1164, 2007.
Western Electric Handbook. Statistical Quality Control Handbook. Western Elec-
tric Corporation, Indianapolis, IN, USA, 1956.
W. H ¨ardle, P. Hall, and J.S. Marron. Regression smoothing parameters that are not
far from their optimal. Journal of the American Statistical Association, 87:
227–233, 1992.
J.D. Hart. Kernel regression estimation with time series errors. Journal of the Royal
Statistical Society (Series B), 53:173–187, 1991.
J.D. Hart. Nonparametric Smoothing and Lack-of-Fit Tests. Springer-Verlag, New
York, NY , USA, 1997.
D.M. Hawkins. On the distribution and power of a test for a single outlier. South
African Statistical Journal, 3:9–15, 1969.
D.M. Hawkins. Testing a sequence of observations for a shift in location. Journal
of the American Statistical Association, 72:180–186, 1977.
D.M. Hawkins. A CUSUM for a scale parameter. Journal of Quality Technology,
13:228–231, 1981.
D.M. Hawkins. Self-starting cusums for location and scale. The Statistician, 36:
299–315, 1987.
D.M. Hawkins. Multivariate quality control based on regression-adjusted variables.
Technometrics, 33:61–75, 1991.
D.M. Hawkins. Evaluation of the average run length for cumulative sum charts
for an arbitrary data distribution. Communications in Statistics (Series B), 21:
1001–1020, 1992a.BIBLIOGRAPHY 459
D.M. Ha wkins. A fast accurate approximation of average run lengths of cusum
control charts. Journal of Quality Technology, 24:37–42, 1992b.
D.M. Hawkins. Cumulative sum control charting: an underutilized SPC tool. Qual-
ity Engineering, 5:463–477, 1993a.
D.M. Hawkins. Regression adjustment for variables in multivariate quality control.
Journal of Quality Technology, 25:170–182, 1993b.
D.M. Hawkins. Fitting multiple change-point models to data. Computational Statis-
tics & Data Analysis, 37:323–341, 2001.
D.M. Hawkins and Q. Deng. A nonparametric change-point control chart. Journal
of Quality Technology, 42:165–173, 2010.
D.M. Hawkins and E.M. Maboudou-Tchao. Self-starting multivariate exponentially
weighted moving average control charting. Technometrics, 49:199–209, 2007.
D.M. Hawkins and E.M. Maboudou-Tchao. Multivariate exponentially weighted
moving covariance matrix. Technometrics, 50:155–166, 2008.
D.M. Hawkins and D.F. Merriam. Zonation of multivariate sequences of digitized
geologic data. Mathematical Geology, 6:263–269, 1974.
D.M. Hawkins and D.H. Olwell. Cumulative Sum Charts and Charting for Quality
Improvement. Springer-Verlag, New York, NY , USA, 1998.
D.M. Hawkins and K.D. Zamba. A change-point model for a shift in variance.
Journal of Quality Technology, 37:21–31, 2005a.
D.M. Hawkins and K.D. Zamba. Statistical process control for shifts in mean or
variance using a change-point formulation. Technometrics, 47:164–173, 2005b.
D.M. Hawkins, P. Qiu, and C.W. Kang. The changepoint model for statistical pro-
cess control. Journal of Quality Technology, 35:355–366, 2003.
D.M. Hawkins, S. Choi, and S. Lee. A general multivariate exponentially weighted
moving-average control chart. Journal of Quality Technology, 39:118–125,
2007.
J.D. Healy. A note on multivariate CUSUM procedures. Technometrics, 29:409–
412, 1987.
R. Henderson. Change-point problem with correlated observations, with an appli-
cation in material accountancy. Technometrics, 28:381–389, 1986.
T. Herberts and U. Jensen. Optimal detection of a change point in a Poisson process
for different observation schemes. Scandinavian Journal of Statistics, 31:347–
366, 2004.
T.P. Hettmansperger. Multivariate location tests. In Encyclopedia of Statistical
Sciences. John Wiley & Sons, New York, NY , USA, 2006.
D.V . Hinkley. Inference about the change-point in a sequence of random variables.
Biometrika, 57:1–17, 1970.
P.G. Hoel, S.C. Port, and C.J. Stone. Introduction to Stochastic Processes. Wave-
land Press, Inc., Prospect Heights, Illinois, USA, 1972.460 BIBLIOGRAPHY
M. Hollander and D.A. Wolfe. Nonparametric statistical methods. John Wiley &
Sons, New York, NY , USA, 2nd edition, 1999.
D.S. Holmes and A.E. Mergen. Improving the performance of the T2control chart.
Quality Engineering, 5:619–625, 1993.
D.R. Hoover, J.A. Rice, C.O. Wu, and L.P. Yang. Nonparametric smoothing esti-
mates of time-varying coefﬁcient models with longitudinal data. Biometrika,
85:809–822, 1998.
J.L. Horowitz and V .G. Spokoiny. An adaptive, rate-optimal test of a parametric
mean-regression model against a nonparametric alternative. Econometrica, 69:
599–631, 2001.
H. Hotelling. The generalization of student’s ratio. Annals of Mathematical Statis-
tics, 2:360–378, 1931.
H. Hotelling. Multivariate quality control. Techniques of Statistical Analysis (C.
Eisenhart, M. Hastay, and W.A. Wallis, eds.), pages 111–184, 1947.
S.W. Human, P. Kritzinger, and S. Chakraborti. Robustness of the EWMA control
chart for individual observations. Journal of Applied Statistics, pages 2071–
2087, 2011.
L. Huwang, A. Yeh, and C.W. Wu. Monitoring multivariate process variability for
individual observations. Journal of Quality Technology, 39:258–278, 2007.
L. Huwang, Y .T. Wang, A. Yeh, and Z.J. Chen. On the exponentially weighted
moving variance. Naval Research Logistics, 56:659–668, 2009.
L. Huwang, C.J. Huang, and Y .H. Wang. New EWMA control charts for mon-
itoring process dispersion. Computational Statistics and Data Analysis, 54:
2328–2342, 2010.
J.M. Irvine. Changes in regime in regression models. Ph.D. Dissertation, Yale
University, New Haven, Connecticut, 1982.
J.E. Jackson. Quality control methods for several related variables. Technometrics,
1:359–377, 1959.
J.E. Jackson. Principal components and factor analysis: part I – principal compo-
nents. Journal of Quality Technology, 12:201–213, 1980.
J.E. Jackson and G.S. Mudholkar. Control procedures for residuals associated with
principal component analysis. Technometrics, 21:341–349, 1979.
W.A. Jensen and J.B. Birch. Proﬁle monitoring via nonlinear mixed models. Jour-
nal of Quality Technology, 41:18–34, 2009.
W.A. Jensen, L.A. Jones-Farmer, C.W. Champ, and W.H. Woodall. Effects of pa-
rameter estimation on control chart properties: a literature review. Journal of
Quality Technology, 38:349–364, 2006.
W.A. Jensen, J.B. Birch, and W.H. Woodall. Monitoring correlation within lin-
ear proﬁles using mixed models. Journal of Quality Technology, 40:167–183,
2008.
W. Jiang. Multivariate control charts for monitoring autocorrelated processes. Jour-BIBLIOGRAPHY 461
nal of Quality Technology, 36:367–379, 2004.
W. Jiang, K.L. Tsui, and W. Woodall. A new SPC monitoring method: the ARMA
chart. Technometrics, 42:399–410, 2000.
J. Jin and J. Shi. Feature-preserving data compression of stamping tonnage infor-
mation using wavelets. Technometrics, 41:327–339, 1999.
N.L. Johnson and F.C. Leone. Cumulative sum control charts - mathematical prin-
ciples applied to their construction and use (Parts I, II, III). Industrial Quality
Control, 19:15–36, 1962.
N.L. Johnson, A.W. Kemp, and S. Kotz. Univariate Discrete Distributions. John
Wiley & Sons, New York, NY , USA, 2nd edition, 1992.
N.L. Johnson, S. Kotz, and N. Balakrishnan. Continuous Univariate Distributions
(Volume 1). John Wiley & Sons, New York, NY , USA, 2nd edition, 1994.
N.L. Johnson, S. Kotz, and N. Balakrishnan. Continuous Univariate Distributions
(Volume 2). John Wiley & Sons, New York, NY , USA, 2nd edition, 1995.
R.A. Johnson and M. Bagshaw. The effect of serial correlation on the performance
of CUSUM tests. Technometrics, 16:103–112, 1974.
R.A. Johnson and D.W. Wichern. Applied Multivariate Statistical Analysis. Pearson
Education, Inc., Upper Saddle River, NJ, USA, 6th edition, 2007.
L.A. Jones, C.W. Champ, and S.E. Rigdon. The performance of exponentially
weighted moving average charts with estimated parameters. Technometrics,
43:156–167, 2001.
L.A. Jones, C.W. Champ, and S.E. Rigdon. The run length distribution of the
CUSUM with estimated parameters. Industrial Quality Control, 36:95–108,
2004.
M. Jones, S. Marron, and S. Sheather. A brief survey of bandwidth selection for
density estimation. Journal of the American Statistical Association, 91:401–
407, 1996.
L.A. Jones-Farmer, V . Jordan, and C.W. Champ. Distribution-free phase I con-
trol charts for subgroup location. Journal of Quality Technology, 41:304–317,
2009.
J. Joo and P. Qiu. Jump detection in a regression curve and its derivative. Techno-
metrics, 51:289–305, 2009.
L. Kang and S.L. Albin. On-line monitoring when the process yields a linear proﬁle.
Journal of Quality Technology, 32:418–426, 2000.
M.G. Kendall and A. Stuart. The Advanced Theory of Statistics, Volume 2. Hafner
Publishing Company, New York, NY , USA, 1961.
J.F. Kenney and E.S. Keeping. Mathematics of Statistics, Part Two. Van Nostrand
Company Inc., Princeton, NJ, USA, 2nd edition, 1951.
M.B. Khoo and S.H. Quah. Multivariate control chart for process dispersion based
on individual observations. Quality Engineering, 15:639–642, 2003.462 BIBLIOGRAPHY
H.J. Kim. Change-point detection for correlated observations. Statistica Sinica, 6:
275–287, 1996.
K. Kim, M.A. Mahmoud, and W.H. Woodall. On the monitoring of linear proﬁles.
Journal of Quality Technology, 35:317–328, 2003.
S.H. Kim, C. Alexopoulos, K.L. Tsui, and J.R. Wilson. A distribution-free tabular
CUSUM chart for autocorrelated data. IIE Transactions, 39:317–330, 2007.
M. Klein. Two alternatives to the Shewhart Xcontrol chart. Journal of Quality
Technology, 32:427–431, 2000.
S. Knoth. Accurate ARL calculation for EWMA control charts monitoring normal
mean and variance simultaneously. Sequential Analysis, 26:251–263, 2007.
S. Knoth. spc: statistical process control. R package version 0.4.0, pages
http://CRAN.r–project.org/package=spc, 2011.
K. Koehler. Goodness-of-ﬁt tests for loglinear models in sparse contingency tables.
Journal of the American Statistical Association, 81:483–493, 1986.
K. Koehler and K. Larntz. An empirical investigation of goodness-of-ﬁt statistics
for sparse multinomials. Journal of the American Statistical Association, 75:
336–344, 1980.
R. Koenker. Quantile Regression. Cambridge University Press, Cambridge, UK,
2005.
P. Kokoszka and R. Leipus. Change-point in the mean of dependent observations.
Statistics and Probability Letters, 40:385–393, 1998.
A.N. Kolmogorov. Sulla determinazione empirica di una legge di distribuzione.
Giornio Instituto Italia Attuari, 4:83–91, 1933.
S. Kotz and N.L. Johnson. Process capability indices: a review 1992–2000 (with
discussion). Journal of Quality Technology, 34:2–19, 2002.
S. Kotz and C.R. Lovelace. Process Capability Indices in Theory and Practice.
Hodder Arnold Publication, London, UK, 1998.
H. Kramer and W. Schmid. EWMA charts for multivariate time series. Sequential
Analysis, 16:131–154, 1997.
P.H. Kvam and B. Vidakovic. Nonparametric Statistics with Applications to Science
and Engineering. John Wiley & Sons, New York, NY , USA, 2007.
T.L. Lai. Sequential change-point detection in quality control and dynamical sys-
tems (with discussions). Journal of the Royal Statistical Society (Series B), 57:
613–658, 1995.
T.L. Lai. Sequential analysis: some classical problems and new challenges (with
discussions). Statistica Sinica, 11:303–408, 2001.
N.M. Laird and J.H. Ware. Random effects models for longitudinal data. Biomet-
rics, 38:963–974, 1982.
M. Lavielle. Using penalized contrasts for the change-points problems. Signal
Processing, 85:1501–1510, 2005.BIBLIOGRAPHY 463
M. La vielle and C. Ludena. The multiple change-points problem for the spectral
distribution. Bernoulli, 6:845–869, 2000.
M. Lavielle and E. Moulines. Least-squares estimation of an unknown number of
shifts in a time series. Journal of Time Series Analysis, 21:33–59, 2000.
D.N. Lawley. A general method for approximation to the distribution of likelihood
ratio criteria. Biometrika, 43:295–303, 1956.
E. Lebarbier. Detecting multiple change-points in the mean of a Gaussian process
by model selection. Signal Processing, 85:717–736, 2005.
E.L. Lehmann and G. Casella. Theory of Point Estimation. Springer-Verlag, New
York, NY , USA, 2nd edition, 1998.
E.L. Lehmann and J.P. Romano. Testing Statistical Hypotheses. Springer-Verlag,
New York, NY , USA, 3rd edition, 2005.
S.M. Lesch and D.R. Jeske. Some suggestions for teaching about normal approxi-
mation to Poisson and binomial distribution functions. The American Statisti-
cian, 63:274–277, 2009.
W. Levinson, D.S. Holmes, and A.E. Mergen. Variation charts for multivariate
processes. Quality Engineering, 14:539–545, 2002.
W.A. Levinson. Statistical Process Control for Real-World Applications. CRC
Press, Boca Raton, FL, USA, 2010.
B. Li, K. Wang, and A.B. Yeh. Monitoring covariance matrix via penalized likeli-
hood estimation. IIE Transactions, 45:132–146, 2013a.
S.Y . Li, L.C. Tang, and S.H. Ng. Nonparametric CUSUM and EWMA control
charts for detecting mean shifts. Journal of Quality Technology, 42:209–226,
2010.
Z. Li and P. Qiu. Statistical process control using dynamic sampling. Technometrics,
accepted, 2013.
Z. Li, P. Qiu, S. Chatterjee, and Z. Wang. Using p-values to design statistical pro-
cess control charts. Statistical Papers, 54:523–539, 2013b.
X. Lin and R.J. Carroll. Nonparametric function estimation for clustered data when
the predictor is measured without/with error. Journal of the American Statisti-
cal Association, 95:520–534, 2000.
S. Ling. Testing for change points in time series models and limiting theorems for
NED sequences. The Annals of Statistics, 35:1213–1237, 2007.
R.Y . Liu. On a notion of data depth based on random simplices. Annals of Statistics,
18:405–414, 1990.
R.Y . Liu. Control charts for multivariate processes. Journal of the American Statis-
tical Association, 90:1380–1387, 1995.
R.Y . Liu and K. Singh. A quality index based on data depth and multivariate rank
tests. Journal of the American Statistical Association, 88:257–260, 1993.
R.Y . Liu, J.M. Parelius, and K. Singh. Multivariate analysis by data depth: descrip-464 BIBLIOGRAPHY
tive statistics, graphics and inference (with discussions). Annals of Statistics,
27:783–858, 1999.
R.Y . Liu, K. Singh, and J.H. Teng. DDMA-charts: nonparametric multivariate mov-
ing average control charts based on data depth. Allgemeines Statisches Archiv,
88:235–258, 2004.
W. Liu. Some Charting Methodologies in MSPC (Ph.D. Thesis). School of Statis-
tics, University of Minnesota, Minneapolis, MN, USA, 2010.
C.R. Loader. Change point estimation using nonparametric regression. The Annals
of Statistics, 24:1667–1678, 1996.
C.R. Loader. Bandwidth selection: classical or plug-in? The Annals of Statistics,
27:415–438, 1999.
G. Lorden. Procedures for reacting to a change in distribution. Annals of Mathe-
matical Statistics, 42:1897–1908, 1971.
C.A. Lowry and D.C. Montgomery. A review of multivariate control charts. IIE
Transactions, 27:800–810, 1995.
C.A. Lowry, W.H. Woodall, C.W. Champ, and S.E. Rigdon. A multivariate expo-
nentially weighted moving average control chart. Technometrics, 34:46–53,
1992.
C.W. Lu and M.R. Reynolds, Jr. Control chart for monitoring the mean and variance
of autocorrelated processes. Journal of Quality Technology, 31:259–274, 1999.
C.W. Lu and M.R. Reynolds, Jr. Control charts for monitoring an autocorrelated
process. Journal of Quality Technology, 33:316–334, 2001.
J.M. Lucas. A modiﬁed V-mask control scheme. Technometrics, 15:833–847, 1973.
J.M. Lucas. Combined Shewhart-CUSUM quality control schemes. Journal of
Quality Technology, 14:51–59, 1982.
J.M. Lucas and R.B. Crosier. Fast initial response for CUSUM quality control
schemes: give your CUSUM a head start. Technometrics, 24:199–205, 1982a.
J.M. Lucas and R.B. Crosier. Robust CUSUM: a robust study for CUSUM quality
control schemes. Communications in Statistics-Theory and Methods, 11:2669–
2687, 1982b.
J.M. Lucas and M.S. Saccucci. Exponentially weighted moving average control
schemes: properties and enhancements (with discussions). Technometrics, 32:
1–29, 1990.
A. Luce ˜no. A process capability ratio with reliable conﬁdence intervals. Commu-
nications in Statistics - Simulation and Computation , 25:235–246, 1996.
A. Luce ˜no and J. Puig-Pey. Evaluation of the run-length probability distribution
for CUSUM charts: assessing chart performance. Technometrics, 42:411–416,
2000.
Y . Luo, Z. Li, and Z. Wang. Adaptive CUSUM control chart with variable sampling
intervals. Computational Statistics and Data Analysis, 53:2693–2701, 2009.BIBLIOGRAPHY 465
J.F.MacGregor and T.J. Harris. The exponentially weighted moving variance. Jour-
nal of Quality Technology, 25:106–118, 1993.
M.A. Mahmoud and W.H. Woodall. Phase I analysis of linear proﬁles with calibra-
tion applications. Technometrics, 46:380–391, 2004.
M.A. Mahmoud, P.A. Parker, W.H. Woodall, and D.M. Hawkins. A change point
method for linear proﬁle data. Quality and Reliability Engineering Interna-
tional, 23:247–268, 2007.
C.L. Mallows. Some comments on Cp.Technometrics, 15:661–675, 1973.
P.E. Maravelakis and P. Castagliola. An EWMA chart for monitoring the process
standard deviation when parameters are estimated. Computational Statistics
and Data Analysis, 53:2653–2664, 2009.
R.L. Mason and J.C. Young. Multivariate Statistical Process Control with Indus-
trial Applications. ASA/SIAM, Philadelphia, PA, USA, 2002.
R.L. Mason, Y .M. Chou, and J.C. Young. Applying Hotelling’s T2statistic to batch
processes. Journal of Quality Technology, 33:466–479, 2001.
D. McDonald. A CUSUM procedure based on sequential ranks. Naval Research
Logistics, 37:627–646, 1990.
F.M. Megahed, J.L.K. Kensler, K. Bedair, and W.H. Woodall. A note on the ARL
of two-sided Bernoulli-based CUSUM control charts. Journal of Quality Tech-
nology, 43:43–49, 2011a.
F.M. Megahed, W.H. Woodall, and J.A. Camelio. A review and perspective on
control charting with image data. Journal of Quality Technology , 43:83–98,
2011b.
F.M. Megahed, L.J. Wells, J.A. Camelio, and W.H. Woodall. A spatiotemporal
method for the monitoring of image data. Quality and Reliability Engineering
International, 28:967–980, 2012.
Y . Mei. Sequential change-point detection when unknown parameters are present
in the pre-change distribution. Annals of Statistics, 34:92–122, 2006.
O. Mestek, J. Pavlik, and M. Such ´anek. Multivariate control charts: control charts
for calibration curves. Fresenius’ Journal of Analytical Chemistry , 350:344–
351, 1994.
D.C. Montgomery. Introduction to Statistical Quality Control. John Wiley & Sons,
New York, NY , USA, 6th edition, 2009.
D.C. Montgomery and C.M. Mastrangelo. Some statistical process control methods
for autocorrelated data. Journal of Quality Technology, 23:179–204, 1991.
L.W. Morrison. The use of control charts to interpret environmental monitoring
data. Natural Areas Journal, 28:66–73, 2008.
S. Mousavi and M.R. Reynolds, Jr. A CUSUM chart for monitoring a proportion
with autocorrelated binary observations. Journal of Quality Technology , 41:
401–414, 2009.
G.V . Moustakides. Optimal stopping times for detecting changes in distributions.466 BIBLIOGRAPHY
The Annals of Statistics, 14:1379–1387, 1986.
C.H. M ¨uller. Robust estimators for estimating discontinuous functions. Metrika,
55:99–109, 2002.
H.G. M ¨uller. Change-points in nonparametric regression analysis. The Annals of
Statistics, 20:737–761, 1992.
E.A. Nadaraya. On estimating regression. Theory of Probability and Its Applica-
tions, 9:141–142, 1964.
J. Needham. Science and Civilisation in China. Cambridge University Press, New
York, NY , USA, 1986.
L.S. Nelson. Tables for a precedence life test. Technometrics, 5:491–499, 1963.
L.S. Nelson. The Shewhart control chart - tests for special causes. Journal of
Quality Technology, 16:237–239, 1984.
L.S. Nelson. Tests on early failures - the precedence life test. Journal of Quality
Technology, 25:140–149, 1993.
R. Noorossana, A. Saghaei, and A. Amir. Statistical Analysis of Proﬁle Monitoring.
John Wiley & Sons, New York, NY , USA, 2011.
H. Oja. Multivariate Nonparametric Methods with R. Springer-Verlag, New York,
NY , USA, 2010.
H. Oja and R. Randles. Multivariate nonparametric tests. Statistical Science, 19:
598–605, 2004.
D.A. Olteanu. Cumulative Sum Control Charts for Censored Reliability Data, Ph.D.
Thesis. Department of Statistics, Virginia Polytechnic Institute and State Uni-
versity, Blacksburg, Virginia, USA, 2010.
E.S. Page. Continuous inspection scheme. Biometrika, 41:100–115, 1954.
E.S. Page. Cumulative sum control charts. Technometrics, 3:1–9, 1961.
X. Pan and J. Jarrett. Applying state space to SPC: monitoring multivariate time
series. Journal of Applied Statistics, 31:397–418, 2004.
X. Pan and J. Jarrett. Using vector autoregressive residuals to monitor multivari-
ate processes in the presence of serial correlation. International Journal of
Production Economics, 106:204–216, 2007.
E.A. Pappanastos and B.M. Adams. Alternative designs of the Hodges-Lehmann
control chart. Journal of Quality Technology, 28:213–223, 1996.
C. Park and M.R. Reynolds, Jr. Nonparametric procedures for monitoring a location
parameter based on linear placement statistics. Sequential Analysis, 6:303–323,
1987.
E. Parzen. On estimation of a probability density function and mode. Annals of
Mathematical Statistics, 33:1065–1076, 1962.
F. Pascual. EWMA Charts for the Weibull Shape Parameter. Journal of Quality
Technology, 42:400–416, 2010.
K. Paynabar, J. Jin, and M. Pacella. Analysis of multichannel nonlinearBIBLIOGRAPHY 467
proﬁles using uncorrelated multilinear principal component analysis with
applications in fault detection and diagnosis. IIE Transactions, page
DOI:10.1080/0740817X.2013.770187, 2013.
W.L. Pearn, S. Kotz, and N.L. Johnson. Distributional and inferential properties of
process capability indices. Journal of Quality Technology, 24:216–231, 1992.
K. Pearson. On the criterion that a given system of deviations from the probable
in the case of a correlated system of variables is such that it can be reasonably
supposed to have arisen from random sampling. Philosophical Magazine, 50:
157–175, 1900.
R. Peck and J. Devore. Statistics: The Exploration and Analysis of Data. Duxbury-
Thomson Brooks/Cole, Paciﬁc Grove, CA, USA, 7th edition, 2012.
M.B. Perry and J.J. Pignatiello, Jr. Estimation of the change point of the process
fraction nonconforming in SPC applications. International Journal of Relia-
bility, Quality and Safety Engineering, 12:95–110, 2005.
M.B. Perry and J.J. Pignatiello, Jr. A change point model for the location parameter
of exponential family densities. IIE Transactions, 40:947–956, 2008.
M.B. Perry, J.J. Pignatiello, Jr., and J.R. Simpson. A magnitude-robust control
chart for monitoring and estimating step changes in a Poisson rate parameter.
International Journal of Reliability, Quality and Safety Engineering, 14:1–19,
2007.
M.B. Perry, G.R. Mercado, and J.J. Pignatiello, Jr. Phase II monitoring of covari-
ance stationary autocorrelated processes. Quality and Reliability Engineering
International, 27:35–45, 2011.
A.N. Pettitt. A non-parametric approach to the change-point problem. Applied
Statistics, 28:126–135, 1979.
J.J. Pignatiello, Jr. and T.R. Samuel. Estimation of the change point of a normal
process mean in SPC applications. Journal of Quality Technology, 33:82–95,
2001.
W.K. Pratt. Digital Image Processing . John Wiley & Sons, New York, NY , USA,
4th edition, 2007.
P. Qiu. Estimation of the number of jumps of the jump regression functions. Com-
munications in Statistics-Theory and Methods, 23:2141–2155, 1994.
P. Qiu. Discontinuous regression surfaces ﬁtting. The Annals of Statistics, 26:
2218–2245, 1998.
P. Qiu. A jump-preserving curve ﬁtting procedure based on local piecewise-linear
kernel estimation. Journal of Nonparametric Statistics, 15:437–453, 2003.
P. Qiu. The local piecewisely linear kernel smoothing procedure for ﬁtting jump
regression surfaces. Technometrics, 46:87–98, 2004.
P. Qiu. Image Processing and Jump Regression Analysis. John Wiley & Sons, New
York, NY , USA, 2005.
P. Qiu. Distribution-free multivariate process control based on log-linear modeling.468 BIBLIOGRAPHY
IIE T ransactions, 40:664–677, 2008.
P. Qiu and D.M. Hawkins. A rank based multivariate CUSUM procedure. Techno-
metrics, 43:120–132, 2001.
P. Qiu and D.M. Hawkins. A nonparametric multivariate CUSUM procedure for
detecting shifts in all directions. Journal of the Royal Statistical Society (Series
D) - The Statistician, 52:151–164, 2003.
P. Qiu and Z. Li. On nonparametric statistical process control of univariate pro-
cesses. Technometrics, 53:390–405, 2011a.
P. Qiu and Z. Li. Distribution-free monitoring of univariate processes. Statistics
and Probability Letters, 81:1833–1840, 2011b.
P. Qiu and D. Xiang. Multivariate dynamic screening system for identifying irreg-
ular longitudinal patterns. in review, 2013.
P. Qiu and D. Xiang. Univariate dynamic screening system: an approach for iden-
tifying individuals with irregular longitudinal behavior. Technometrics, 56:in
press, 2014.
P. Qiu and C. Xing. On nonparametric image registration. Technometrics, 55:174–
188, 2013a.
P. Qiu and C. Xing. Feature based image registration using non-degenerate pixels.
Signal Processing, 93:706–720, 2013b.
P. Qiu and B. Yandell. A local polynomial jump detection algorithm in nonpara-
metric regression. Technometrics, 40:141–152, 1998.
P. Qiu and C. Zou. Control chart for monitoring nonparametric proﬁles with arbi-
trary design. Statistica Sinica, 20:1655–1682, 2010.
P. Qiu, C. Asano, and X. Li. Estimation of jump regression function. Bulletin of
Informatics and Cybernetics, 24:197–212, 1991.
P. Qiu, C. Zou, and Z. Wang. Nonparametric proﬁle monitoring by mixed effects
modeling (with discussions). Technometrics, 52:265–293, 2010.
C.P. Quesenberry. SPC Methods for Quality Improvement. John Wiley & Sons,
New York, NY , USA, 1997.
M.R. Reynolds, Jr. A sequential signed-rank test for symmetry. Annals of Statistics,
3:382–400, 1975.
M.R. Reynolds, Jr. and J.C. Arnold. EWMA control charts with variable sample
sizes and variable sampling intervals. IIE Transactions, 33:511–530, 2001.
M.R. Reynolds, Jr. and Z.G. Stoumbos. A general approach to modeling CUSUM
charts for a proportion. IIE Transactions, 32:515–535, 2000.
M.R. Reynolds, Jr. and Z.G. Stoumbos. Should exponentially weighted moving av-
erage and cumulative sum charts be used with Shewhart limits. Technometrics,
47:409–424, 2005.
M.R. Reynolds, Jr. and Z.G. Stoumbos. Comparisons of some exponentially
weighted moving average control charts for monitoring the process mean andBIBLIOGRAPHY 469
variance. Technometrics, 48:550–567, 2006.
M.R. Reynolds, Jr. and Z.G. Stoumbos. Comparisons of multivariate Shewhart and
MEWMA control charts for monitoring the mean vector and covariance matrix.
Journal of Quality Technology, 40:381–393, 2008.
M.R. Reynolds, Jr., R.W. Amin, and J.C. Arnold. CUSUM charts with variable
sampling intervals. Technometrics, 32:371–384, 1990.
J.A. Rice and C.O. Wu. Nonparametric mixed effects models for unequally sampled
noisy curves. Biometrics, 57:253–259, 2001.
Y . Ritov. Decision theoretic optimality of the CUSUM procedure. The Annals of
Statistics, 18:1464–1469, 1990.
S.V . Roberts. Control chart tests based on geometric moving averages. Technomet-
rics, 1:239–250, 1959.
D.M. Rocke. Robust control charts. Technometrics, 31:173–184, 1989.
R.N. Rodriguez. Recent developments in process capability analysis. Journal of
Quality Technology, 24:176–187, 1992.
M. Rosenblatt. Remarks on some nonparametric estimates of a density function.
Annals of Mathematical Statistics, 27:832–837, 1956.
G.J. Ross. cpm: sequential parametric and nonparametric change detection. R
package version 1.0, pages http://CRAN.r–project.org/package=cpm, 2012.
G.J. Ross and N.M. Adams. Two nonparametric control charts for detecting arbi-
trary distribution changes. Journal of Quality Technology, 44:102–116, 2012.
G.J. Ross, D.K. Tasoulis, and N.M. Adams. Nonparametric monitoring of data
streams for changes in location and scale. Technometrics, 53:379–389, 2011.
T.D. Ross. Accurate conﬁdence intervals for binomial proportion and Poisson rate
estimation. Computers in Biology and Medicine, 33:509–531, 2003.
G.C. Runger and T.R. Willemain. Model-based and model-free control of autocor-
related processes. Journal of Quality Technology, 27:283–292, 1995.
G.C. Runger and T.R. Willemain. Batch means control charts for autocorrelated
data. IIE Transactions, 28:483–487, 1996.
D. Ruppert, S.J. Sheather, and M.P. Wand. An efﬁcient bandwidth selector for local
least squares regression. Journal of the American Statistical Association, 90:
1257–1270, 1995.
T.P. Ryan. Statistical Methods for Quality Improvement. John Wiley & Sons, New
York, NY , USA, 2nd edition, 2000.
J.H. Ryu, H. Wan, and S. Kim. Optimal design of a CUSUM chart for a mean shift
of unknown size. Journal of Quality Technology, 42:1–16, 1995.
T.R. Samuel and J.J. Pignatiello, Jr. Estimation of the change point of a normal
process mean in SPC applications. Journal of Quality Technology, 33:82–95,
2001.
E. Santos-Fernandez. msqc: multivariate statistical quality control. R package ver-470 BIBLIOGRAPHY
sion 1.0.0 , pages http://CRAN.r–project.org/package=msqc, 2012.
D.W. Scott. Multivariate Density Estimation. John Wiley & Sons, New York, NY ,
USA, 1992.
L. Scrucca. qcc: quality control charts. R package version 2.0.1, pages
http://CRAN.r–project.org/package=qcc, 2010.
G.A.F. Seber and C.J. Wild. Nonlinear Regression. John Wiley & Sons, New York,
NY , USA, 2003.
X. Shao and X. Zhang. Testing for change points in time series. Journal of the
American Statistical Association, 105:1228–1240, 2010.
S.S. Shapiro and M.B. Wilk. An analysis of variance test for normality (complete
samples). Biometrika, 52:591–611, 1965.
W.A. Shewhart. Economic control of quality of manufactured product. D. Van
Nostrand Company, New York, NY , USA, 1931.
M. Shi, Weiss R.E., and J.M.G. Taylor. An analysis of paediatric CD4 counts for
acquired immune deﬁciency syndrome using ﬂexible random curves. Applied
Statistics, 45:151–163, 1996.
L. Shu and W. Jiang. A Markov chain model for the adaptive CUSUM control chart.
Journal of Quality Technology, 38:135–147, 2006.
L. Shu and W. Jiang. A new EWMA chart for monitoring process dispersion. Jour-
nal of Quality Technology, 40:319–331, 2008.
L. Shu, W. Jiang, and K.L. Tsui. A weighted CUSUM chart for detecting patterned
mean shifts. Journal of Quality Technology, 40:194–213, 2008.
D. Siegmund. Sequential Analysis Tests and Conﬁdence Intervals. Springer-Verlag,
New York, USA, 1985.
G. Simons. An improved statement of optimality for sequential probability ratio
tests. The Annals of Statistics, 4:1240–1243, 1976.
N.V . Smirnov. On the estimation of the discrepancy between empirical curves of
distribution for two independent samples. Bulletin Moscow University, 2:3–16,
1939.
A.F.M. Smith. A Bayesian approach to inference about a change-point in a sequence
of random variables. Biometrika, 62:407–416, 1975.
R.S. Sparks. CUSUM charts for signalling varying location shifts. Journal of
Quality Technology, 32:157–171, 2000.
R.S. Sparks, T. Keighley, and D. Muscatello. Optimal exponentially weighted mov-
ing average (EWMA) plans for detecting seasonal epidemics when faced with
non-homogeneous negative binomial counts. Journal of Applied Statistics, 38:
2165–2181, 2011.
F. Spiring, B. Leung, S. Cheng, and A. Yeung. A bibliography of process capability
papers. Quality and Reliability Engineering International, 19:445–460, 2003.
V . Spokoiny. Multiscale local change point detection with applications to value-at-BIBLIOGRAPHY 471
risk. Annals of Statistics, 37:1405–1436, 2009.
S.H. Steiner. Grouped data exponentially weighted moving average control charts.
Applied Statistics, 47:203–216, 1998.
S.H. Steiner and R.J. MacKay. Monitoring processes with highly censored data.
Journal of Quality Technology, 32:199–208, 2000.
S.H. Steiner, P.L. Geyer, and G.O. Wesolowsky. Grouped data-sequential probabil-
ity ratio tests and cumulative sum control charts. Technometrics, 38:230–237,
1996.
Z.G. Stoumbos and L.A. Jones. On the properties and design of individuals control
charts based on simplicial depth. Nonlinear Studies, 7:147–178, 2000.
Z.G. Stoumbos and J.H. Sullivan. Robustness to non-normality of the multivariate
EWMA control chart. Journal of Quality Technology, 34:260–276, 2002.
F.S. Stover and R.V . Brill. Statistical quality control applied to ion chromatography
calibrations. Journal of Chromatography, A804:37–43, 1998.
Y . Su, L. Shu, and K.L. Tsui. Adaptive EWMA procedures for monitoring processes
subject to linear drifts. Computational Statistics and Data Analysis, 55:2819–
2829, 2011.
J.H. Sullivan and L.A. Jones. A self-starting control chart for multivariate individual
observations. Technometrics, 44:24–33, 2002.
J.H. Sullivan and W.H. Woodall. A comparison of multivariate control charts for
individual observations. Journal of Quality Technology, 28:398–408, 1996.
R. Sun and F. Tsung. A kernel-distance-based multivariate control chart using sup-
port vector methods. International Journal of Production Research, 41:2975–
2989, 2003.
P.F. Tang and N.S. Barnett. Dispersion control for multivariate processes. The
Australian Journal of Statistics, 38:235–251, 1996a.
P.F. Tang and N.S. Barnett. Dispersion control for multivariate processes - some
comparisons. The Australian Journal of Statistics, 38:253–273, 1996b.
M.C. Testik, G.C. Runger, and C.M. Borror. Robustness properties of multivariate
EWMA control charts. Quality and Reliability Engineering International, 19:
31–38, 2003.
R.J. Tibshirani. Regression shrinkage and selection via the LASSO. Journal of the
Royal Statistical Society (Series B), 58:267–288, 1996.
D.H. Timmer, J. Pignatiello, and M. Longnecker. The development and evaluation
of CUSUM-based control charts for an AR(1) process. IIE Transactions, 30:
525–534, 1998.
E. Topalidou and S. Psarakis. Review of multinomial and multiattribute quality
control charts. Quality and Reliability Engineering International, 25:773–804,
2009.
N.D. Tracy, J.C. Young, and R.L. Mason. Multivariate control charts for individual
observations. Journal of Quality Technology, 24:88–95, 1992.472 BIBLIOGRAPHY
S.T.Tseng, F. Tsung, and P.Y . Liu. Variable EWMA run-to-run controller for drifted
processes. IIE Transactions, 39:291–301, 2007.
S.T. Tseng, B.Y . Jou, and C.H. Liao. Adaptive variable EWMA controller for drifted
processes. IIE Transactions, 42:247–259, 2010.
C.S. Van Dobben de Bruyn. Cumulative Sum Tests: Theory and Practice. Lubrecht
& Cramer Ltd, London, UK, 1968.
L.N. Vanbrackle and M.R. Reynolds, Jr. EWMA and cusum control charts in the
presence of correlation. Communications in Statistics - Simulation and Com-
putation, 26:979–1008, 1997.
L.C. Vance. Average run lengths of cumulative sum control charts for controlling
normal means. Journal of Quality Technology, 18:189–193, 1986.
J.A. Vargas. Robust estimation in multivariate control charts for individual obser-
vations. Journal of Quality Technology, 35:367–376, 2003.
H.M. Wadsworth, K.S. Stephens, and A.B. Godfrey. Modern Methods for Quality
Control and Improvement. John Wiley & Sons, New York, NY , USA, 2nd
edition, 2002.
A. Wald. Sequential tests of statistical hypotheses. Annals of Mathematical Statis-
tics, 16:117–186, 1945.
A. Wald and J. Wolfowitz. Optimum character of the sequential probability ratio
test. Annals of Mathematical Statistics, 19:326–339, 1948.
K.H. Waldmann. Bounds for the distribution of the run length of one-sided and
two-sided CUSUM quality control schemes. Technometrics, 28:61–67, 1986.
E. Walker and S.P. Wright. Comparing curves using additive models. Journal of
Quality Technology, 34:118–129, 2002.
M.P. Wand and M.C. Jones. Kernel Smoothing. Chapman & Hall/CRC, Boca Raton,
FL, USA, 3rd edition, 1995.
K. Wang and W. Jiang. High-dimensional process monitoring and fault isolation
via variable selection. Journal of Quality Technology, 41:247–258, 2009.
K. Wang and F. Tsung. Using proﬁle monitoring techniques for a data-rich envi-
ronment with hugh sample sizes. Quality and Reliability Engineering Interna-
tional, 21:677–688, 2005.
Y . Wang. Smoothing spline models with correlated random errors. Journal of the
American Statistical Association, 93:341–348, 1998.
D.G. Wardell, H. Moskowitz, and R.D. Plante. Run length distributions of special-
cause control charts for correlated processes. Technometrics, 36:3–17, 1994.
G.S. Watson. Smooth regression analysis. Sankhya (Series A), 26:359–372, 1964.
Y . Wei, Z. Zhao, and D.K.J. Lin. Proﬁle control charts based on nonparametric L1
regression methods. Annals of Applied Statistics, 6:409–427, 2012.
S. Weisberg. Applied Linear Regression. John Wiley & Sons, New York, NY , USA,
3rd edition, 2005.BIBLIOGRAPHY 473
C.H. W eiß. EWMA monitoring of correlated processes of Poisson counts. Quality
Technology & Quantitative Management, 6:137–153, 2009.
F. Wilcoxon, S.K. Katti, and R.A. Wilcox. Critical values and probability levels
for the Wilcoxon rank sum test and the Wilcoxon signed rank test. In Selected
Tables in Mathematical Statistics, volume I, pages 171–259. American Mathe-
matical Society, Providence, RI, USA, 1972.
S.S. Wilks. The large-sample distribution of the likelihood ratio for testing com-
posite hypotheses. The Annals of Mathematical Statistics, 9:60–62, 1938.
T.R. Willemain and G.C. Runger. Designing control charts using an empirical ref-
erence distribution. Journal of Quality Technology, 28:31–38, 1996.
J.D. Williams, W.H. Woodall, J.B. Birch, and J.H. Sullivan. On the distribution of
T2statistics based on successive differences. Journal of Quality Technology,
38:217–229, 2006.
J.D. Williams, J.B. Birch, W.H. Woodall, and N.M. Ferry. Statistical monitor-
ing of heteroscedastic dose-response proﬁles from high-throughput screening.
Journal of Agriculture, Biological, and Environmental Statistics, 12:216–235,
2007a.
J.D. Williams, W.H. Woodall, and J.B. Birch. Statistical monitoring of nonlinear
product and process quality proﬁles. Quality and Reliability Engineering In-
ternational, 23:925–941, 2007b.
W.H. Woodall. The distribution of the run length of one-sided CUSUM procedures
for continuous random variables. Technometrics, 25:295–301, 1983.
W.H. Woodall. Current research on proﬁle monitoring. Produc ´ao, 17:420–425,
2007.
W.H. Woodall and B.M. Adams. The statistical design of CUSUM charts. Quality
Engineering, 5:559–570, 1993.
W.H. Woodall and M.M. Ncube. Multivariate CUSUM quality-control procedures.
Technometrics, 27:285–292, 1985.
W.H. Woodall, D.J. Spitzner, D.C. Montgomery, and S. Gupta. Using control charts
to monitor process and product proﬁles. Journal of Quality Technology, 36:
309–320, 2004.
K.J. Worsley. On the likelihood ratio test for a shift in location of normal popula-
tions. Journal of the American Statistical Association, 74:365–367, 1979.
K.J. Worsley. An improved Bonferroni inequality and applications. Biometrika, 69:
297–302, 1982.
K.J. Worsley. The power of the likelihood ratio and cumulative sum tests for a
change in a binomial probability. Biometrika, 70:455–464, 1983.
K.J. Worsley. Conﬁdence regions and test for a change-point in a sequence of
exponential family random variables. Biometrika, 73:91–104, 1986.
H. Wu and J. Zhang. Local polynomial mixed-effects models for longitudinal data.
Journal of the American Statistical Association, 97:883–897, 2002.474 BIBLIOGRAPHY
J.S. W u and C.K. Chu. Kernel type estimators of jump points and values of a
regression function. The Annals of Statistics, 21:1545–1566, 1993.
W.B. Wu and Z. Zhao. Inference of trends in time series. Journal of the Royal
Statistical Society (Series B), 69:391–410, 2007.
Z. Wu, S. Zhang, and P. Wang. A CUSUM scheme with variable sample sizes and
sampling intervals for monitoring the process mean and variance. Quality and
Reliability Engineering International, 23:157–170, 2007.
Z. Wu, J. Jiao, and Y . Liu. A binomial CUSUM chart for detecting large shifts in
fraction nonconforming. Journal of Applied Statistics, 35:1267–1276, 2008a.
Z. Wu, M. Yang, W. Jiang, and M.B.C. Khoo. Optimization designs of the combined
Shewhart-CUSUM control charts. Computational Statistics and Data Analysis,
53:496–506, 2008b.
M. Xie, T.N. Goh, and X.S. Lu. A comparative study of CCC and CUSUM charts.
Quality and Reliability Engineering International, 14:339–345, 1998.
M. Xie, T.N. Goh, and V . Kuralmani. Statistical Models and Control Chart for High
Quality Processes. Kluwer, Boston, MA, USA, 2002.
C. Xing and P. Qiu. Intensity based image registration by nonparametric local
smoothing. IEEE Transactions on Pattern Analysis and Machine Intelligence,
33:2081–2092, 2011.
Y . Yang. Can the strengths of AIC and BIC be shared?–a conﬂict between model
identiﬁcation and regression estimation. Biometrika, 92:937–950, 2005.
Y .C. Yao. Approximating the distribution of the maximum likelihood estimate of
the change-point in a sequence of independent random variables. The Annals
of Statistics, 15:1321–1328, 1987.
Y .C. Yao and S.T. Au. Least-squares estimation of a step function. Sankhya (Series
A), 51:370–381, 1989.
E. Yashchin. Analysis of CUSUM and other Markov-type control schemes by using
empirical distributions. Technometrics, 34:54–63, 1992.
E. Yashchin. Performance of CUSUM control schemes for serially correlated ob-
servations. Technometrics, 35:37–52, 1993a.
E. Yashchin. Statistical control schemes: methods, applications, and generaliza-
tions. International Statistical Review, 61:41–66, 1993b.
A.B. Yeh and S. Bhattacharya. A robust process capability index. Communications
in Statistics - Simulation and Computation, 27:565–589, 1998.
A.B. Yeh and H. Chen. A non-parametric multivariate process capability index.
International Journal of Modeling and Simulation, 21:218–224, 2001.
A.B. Yeh and D.K.J. Lin. A new variables control chart for simultaneously moni-
toring multivariate process mean and variability. International Journal of Reli-
ability, Quality and Safety Engineering, 9:41–59, 2002.
A.B. Yeh, D.K.J. Lin, H. Zhou, and C. Venkataramani. A multivariate exponen-
tially weighted moving average control chart for monitoring process variability.BIBLIOGRAPHY 475
Journal of Applied Statistics, 30:507–536, 2003.
A.B. Yeh, L. Huwang, and Y .F. Wu. A likelihood ratio based EWMA control chart
for monitoring variability of multivariate normal processes. IIE Transactions,
36:865–879, 2004a.
A.B. Yeh, D.K.J. Lin, and C. Venkataramani. Uniﬁed CUSUM charts for monitor-
ing process mean and variability. Quality Technology and Quantitative Man-
agement, 1:65–86, 2004b.
A.B. Yeh, L. Huwang, and Y .F. Wu. A multivariate EWMA control chart for mon-
itoring process variability with individual observations. IIE Transactions, 37:
1023–1035, 2005.
A.B. Yeh, D.K.J. Lin, and R.N. McGrath. Multivariate control charts for monitor-
ing covariance matrix: a review. Quality Technology and Quantitative Man-
agement, 3:415–436, 2006.
A.B. Yeh, L. Huwang, and Y .M. Lee. Proﬁle monitoring for binary response. IIE
Transactions, 41:931–941, 2009.
A.B. Yeh, L. Huwang, R.N. McGrath, and Z. Zhang. On monitoring process vari-
ance with individual observations. Quality and Reliability Engineering Inter-
national, 26:631–641, 2010.
S.A. Yourstone and W.J. Zimmer. Non-normality and the design of control charts
for averages. Decision Sciences, 23:1099–1113, 1992.
G. Yu, C. Zou, and Z. Wang. Outlier detection in functional observations with
applications to proﬁle monitoring. Technometrics, 54:308–318, 2012.
B.J. Yum and K.W. Kim. A bibliography of the literature on process capability
indices: 2000–2009. Quality and Reliability Engineering International, 27:
251–268, 2011.
K.D. Zamba and D.M. Hawkins. A multivariate change-point model for statistical
process control. Technometrics, 48:539–549, 2006.
K.D. Zamba and D.M. Hawkins. A multivariate change-point model for change in
mean vector and/or covariance structure. Journal of Quality Technology , 41:
285–303, 2009.
D. Zhang, X. Lin, J. Raz, and M. Sowers. Semiparametric stochastic mixed models
for longitudinal data. Journal of the American Statistical Association, 93:710–
719, 1998.
J. Zhang. Powerful goodness-of-ﬁt tests based on likelihood ratio. Journal of the
Royal Statistical Society (Series B), 64:281–294, 2002.
L. Zhang and G. Chen. EWMA charts for monitoring the mean of censored Weibull
lifetimes. Journal of Quality Technology, 36:321–328, 2004.
N.F. Zhang. Detection capability of residual chart for autocorrelated data. Journal
of Applied Statistics, 24:475–492, 1997.
N.F. Zhang. A statistical control chart for stationary process data. Technometrics,
40:24–38, 1998.N.F. Zhang, G.A. Stenback, and D.M. Wardrop. Interval estimation of process
capability index Cpk.Communications in Statistics - Theory and Methods, 19:
4455–4470, 1990.
P. Zhao and B. Yu. On model selection consistency of lasso. Journal of Machine
Learning Research, 7:2541–2563, 2006.
Y . Zhao, F. Tsung, and Z. Wang. Dual CUSUM control schemes for detecting a
range of mean shifts. IIE Transactions, 37:1047–1057, 2005.
C. Zhou, C. Zou, Y . Zhang, and Z. Wang. Nonparametric control chart based on
change-point model. Statistical Papers, 50:13–28, 2009.
S. Zhou and J. Jin. Automatic feature selection for unsupervised clustering of cycle-
based signals in manufacturing processes. IIE Transactions, 37:569–584, 2005.
C. Zou and P. Qiu. Multivariate statistical process control using LASSO. Journal
of the American Statistical Association, 104:1586–1596, 2009.
C. Zou and F. Tsung. Likelihood ratio-based distribution-free EWMA control
charts. Journal of Quality Technology, 42:1–23, 2010.
C. Zou and F. Tsung. A multivariate sign EWMA control chart. Technometrics, 53:
84–97, 2011.
C. Zou, Y . Zhang, and Z. Wang. Control chart based on change-point model for
monitoring linear proﬁles. IIE Transactions, 38:1093–1103, 2006.
C. Zou, F. Tsung, and Z. Wang. Monitoring general linear proﬁles using multi-
variate exponentially weighted moving average schemes. Technometrics, 49:
395–408, 2007a.
C. Zou, C. Zhou, Z. Wang, and F. Tsung. A self-starting control chart for linear
proﬁles. Journal of Quality Technology, 39:364–375, 2007b.
C. Zou, F. Tsung, and Z. Wang. Monitoring proﬁles based on nonparametric regres-
sion methods. Technometrics, 50:512–526, 2008.
C. Zou, Y . Liu, and Z. Wang. Comparisons of control schemes for monitoring the
mean of processes subject to drifts. Metrika, 70:141–163, 2009a.
C. Zou, P. Qiu, and D.M. Hawkins. Nonparametric control chart for monitoring
proﬁles using change point formulation and adaptive smoothing. Statistica
Sinica, 19:1337–1357, 2009b.
C. Zou, W. Jiang, and F. Tsung. A LASSO-based SPC diagnostic framework for
multivariate statistical process control. Technometrics, 53:297–309, 2011.
C. Zou, Z. Wang, and F. Tsung. A spatial rank-based multivariate EWMA control
chart. Naval Research Logistics, 59:91–110, 2012.
H. Zou. The adaptive lasso and its oracle properties. Journal of the American
Statistical Association, 101:1418–1429, 2006.
H. Zou and R. Li. One-step sparse estimates in nonconcave penalized likelihood
models (with discussions). The Annals of Statistics, 36:1509–1533, 2008.
H. Zou, T. Hastie, and R. Tibshirani. On the ’Degrees of Freedom’ of Lasso. The
Annals of Statistics, 35:2173–2192, 2007c.K12137A major tool for quality control and management, statistical process 
control (SPC) monitors sequential processes, such as production lines and 
Internet traffic, to ensure that they work stably and satisfactorily. Along 
with covering traditional methods, Introduction to Statistical Process 
Control  describes many recent SPC methods that improve upon the more 
established techniques. The author—a leading researcher on SPC—shows 
how these methods can handle new applications.
After exploring the role of SPC and other statistical methods in quality 
control and management, the book covers basic statistical concepts and 
methods useful in SPC. It then systematically describes traditional SPC 
charts, including the Shewhart, CUSUM, and EWMA charts, as well as 
recent control charts based on change-point detection and fundamental 
multivariate SPC charts under the normality assumption. The text also 
introduces novel univariate and multivariate control charts for cases when 
the normality assumption is invalid and discusses control charts for profile 
monitoring. All computations in the examples are solved using R, with R 
functions and datasets available for download on the author’s website. 
Features
• Explores the major advantages and limitations of both traditional and 
state-of-the-art SPC methods
• Offers practical guidelines on implementing the techniques
• Examines the most recent research results in various areas, including 
univariate and multivariate nonparametric SPC, SPC based on 
change-point detection, and profile monitoring
• Keeps the mathematical and statistical prerequisites to a minimum, 
only requiring basic linear algebra, some calculus, and introductory 
statistics
• Provides more advanced or technical material in discussions at the 
end of each chapter, along with exercises that encourage hands-on 
practice with the methods
• Presents pseudo codes for important methodsPeihua Qiu
QiuIntroduction to
Statistical 
Process Control
Introduction to  
Statistical Process ControlStatisticsTexts in Statistical Science
K12137_Cover.indd   1 9/9/13   10:26 AM